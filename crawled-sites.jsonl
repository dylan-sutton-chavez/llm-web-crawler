{"reference": "https://www.geeksforgeeks.org/machine-learning/what-is-perceptron-the-simplest-artificial-neural-network/", "content": "# What is Perceptron | The Simplest Artificial Neural Network\n\nThe **Perceptron** is one of the simplest **artificial neural network** architectures, introduced by Frank Rosenblatt in 1957. It is primarily used for **binary classification**.\n\nAt that time, traditional methods like Statistical Machine Learning and Conventional Programming were commonly used for predictions. Despite being one of the simplest forms of artificial neural networks, the Perceptron model proved to be highly effective in solving specific classification problems, laying the groundwork for advancements in AI and machine learning.\n\n**The article aims to provide fundamentals of the perceptron model, its architecture, working principles, and application, covering both theory and practical implementation using PyTorch.**\n\n## Table of Contents\n\n- [What is Perceptron?](#what-is-perceptron)\n- [Components of Perceptron](#basic-components-of-perceptron)\n- [How does Perceptron work?](#how-does-perceptron-work)\n- [Building and Training Single Layer Perceptron Model](#building-and-training-single-layer-perceptron-model)\n- [Binary Classification using Perceptron with PyTorch](#binary-classification-using-perceptron-with-pytorch)\n- [Limitations of Perceptron](#limitations-of-perceptron)\n\n## What is Perceptron?\n\n**Perceptron** is a type of [neural network](https://www.geeksforgeeks.org/machine-learning/neural-networks-a-beginners-guide/) that performs binary classification that maps input features to an output decision, usually classifying data into one of two categories, such as 0 or 1.\n\nPerceptron consists of a single layer of input nodes that are fully connected to a layer of output nodes. It is particularly good at learning **linearly separable patterns**. It utilizes a variation of artificial neurons called **Threshold Logic Units (TLU)**, which were first introduced by McCulloch and Walter Pitts in the 1940s. This foundational model has played a crucial role in the development of more advanced neural networks and machine learning algorithms.\n\n### Types of Perceptron\n\n1. **Single-Layer Perceptron** is a type of perceptron is limited to learning linearly separable patterns. It is effective for tasks where the data can be divided into distinct categories through a straight line. While powerful in its simplicity, it struggles with more complex problems where the relationship between inputs and outputs is non-linear.\n2. **Multi-Layer Perceptron** possess enhanced processing capabilities as they consist of two or more layers, adept at handling more complex patterns and relationships within the data.\n\n## Basic Components of Perceptron\n\nA Perceptron is composed of key components that work together to process information and make predictions.\n\n- **Input Features:** The perceptron takes multiple input features, each representing a characteristic of the input data.\n- **Weights:** Each input feature is assigned a weight that determines its influence on the output. These weights are adjusted during training to find the optimal values.\n- **Summation Function:** The perceptron calculates the weighted sum of its inputs, combining them with their respective weights.\n- **Activation Function:** The weighted sum is passed through the **Heaviside step function**, comparing it to a threshold to produce a binary output (0 or 1).\n- **Output:** The final output is determined by the activation function, often used for **binary classification** tasks.\n- **Bias:** The bias term helps the perceptron make adjustments independent of the input, improving its flexibility in learning.\n- **Learning Algorithm:** The perceptron adjusts its weights and bias using a learning algorithm, such as the Perceptron Learning Rule, to minimize prediction errors.\n\nThese components enable the perceptron to learn from data and make predictions. While a single perceptron can handle simple binary classification, complex tasks require multiple perceptrons organized into layers, forming a neural network.\n\n## How does Perceptron work?\n\nA weight is assigned to each input node of a perceptron, indicating the importance of that input in determining the output. The Perceptron's output is calculated as a weighted sum of the inputs, which is then passed through an activation function to decide whether the Perceptron will fire.\n\nThe weighted sum is computed as:\n\n$$ z = w_1x_1 + w_2x_2 + \\ldots + w_nx_n = X^TW $$\n\nThe step function compares this weighted sum to a threshold. If the input is larger than the threshold value, the output is 1; otherwise, it's 0. This is the most common activation function used in Perceptrons are represented by the Heaviside step function:\n\n$$ h(z) = \\begin{cases} 0 & \\text{if } z < \\text{Threshold} \\\\ 1 & \\text{if } z \\geq \\text{Threshold} \\end{cases} $$\n\nA perceptron consists of a single layer of Threshold Logic Units (TLU), with each TLU fully connected to all input nodes.\n\n![Threshold Logic units](https://media.geeksforgeeks.org/wp-content/uploads/20230426162726/Perceptron-1.webp)\n\n*Threshold Logic units*\n\nIn a fully connected layer, also known as a dense layer, all neurons in one layer are connected to every neuron in the previous layer.\n\nThe output of the fully connected layer is computed as:\n\n$$ f_{W,b}(X)=h(XW+b) $$\n\nwhere X is the input W is the weight for each inputs neurons and b is the bias and h is the step function.\n\nDuring training, the Perceptron's weights are adjusted to minimize the difference between the predicted output and the actual output. This is achieved using supervised learning algorithms like the delta rule or the Perceptron learning rule.\n\nThe weight update formula is:\n\n$$ w_{i,j} = w_{i,j} +\\eta (y_j -\\hat y_j)x_i $$\n\nWhere:\n\n- $w_{i,j}$ is the weight between the i^{th} input and j^{th} output neuron,\n- $x_i$ is the i^{th} input value,\n- $y_j$ is the actual value, and $\\hat{y}_j$ is the predicted value,\n- $\\eta$ is the **learning rate**, controlling how much the weights are adjusted.\n\nThis process enables the perceptron to learn from data and improve its prediction accuracy over time.\n\n### Example: Perceptron in Action\n\nLet's take a simple example of classifying whether a given fruit is an apple or not based on two inputs: its weight (in grams) and its color (on a scale of 0 to 1, where 1 means red). The perceptron receives these inputs, multiplies them by their weights, adds a bias, and applies the activation function to decide whether the fruit is an apple or not.\n\n- Input 1 (Weight): 150 grams\n- Input 2 (Color): 0.9 (since the fruit is mostly red)\n- Weights: [0.5, 1.0]\n- Bias: 1.5\n\nThe perceptron's weighted sum would be:\n\n(150 * 0.5) + (0.9 * 1.0) + 1.5 = 76.4\n\n**Let's assume the activation function uses a threshold of 75. Since 76.4 > 75, the perceptron classifies the fruit as an apple (output = 1).**\n\n## Building and Training Single Layer Perceptron Model\n\nFor building the perceptron model we are going to implement following steps\n\n**Step 1: Initialize the weight and learning rate**\n\nWe consider the weight values for the number of inputs + 1 (with the additional +1 accounting for the bias term). This ensures that both the inputs and bias are included during training.\n\n```python\nclass Perceptron:  \n    def __init__(self, num_inputs, learning_rate=0.01):  \n        # Initialize the weights (num_inputs + 1 for bias)  \n        self.weights = np.random.rand(num_inputs + 1)  # Random initialization  \n        self.learning_rate = learning_rate  # Learning rate\n```\n\n**Step 2: Define the Linear Layer**\n\nThe first step is to calculate the **weighted sum** of the inputs. This is done using the formula: `Z = XW + b`, where `X` represents the inputs, `W` the weights, and `b` the bias.\n\n```python\ndef linear(self, inputs):  \n    Z = inputs @ self.weights[1:].T + self.weights[0]  # Weighted sum: XW + b  \n    return Z\n```\n\n**Step 3: Define the Activation Function**\n\nThe **Heaviside Step function** is used as the activation function, which compares the weighted sum to a threshold. If the sum is greater than or equal to 0, it outputs 1; otherwise, it outputs 0.\n\n```python\ndef Heaviside_step_fn(self, z):  \n    if z >= 0:  \n        return 1  # Output 1 if the input is >= 0  \n    else:  \n        return 0  # Output 0 otherwise\n```\n\n**Step 4: Define the Prediction**\n\nUse the linear function followed by the activation function to generate predictions based on the input features.\n\n```python\ndef predict(self, inputs):  \n    Z = self.linear(inputs)  # Pass inputs through the linear layer  \n    try:  \n        pred = []  \n        for z in Z:  # For batch inputs  \n            pred.append(self.Heaviside_step_fn(z))  \n    except:  \n        return self.Heaviside_step_fn(Z)  # For single input  \n    return pred  # Return prediction\n```\n\n**Step 5: Define the Loss Function**\n\nThe **loss function** calculates the error between the predicted output and the actual output. In the Perceptron, the loss is the difference between the target value and the predicted value.\n\n```python\ndef loss(self, prediction, target):  \n    loss = (prediction - target)  # Error or loss calculation  \n    return loss\n```\n\n**Step 6: Define Training**\n\nIn this step, weights and bias are **updated** according to the error calculated from the loss function. The **Perceptron learning rule** is applied to adjust the weights to minimize the error.\n\n```python\ndef train(self, inputs, target):  \n    prediction = self.predict(inputs)  # Get prediction  \n    error = self.loss(prediction, target)  # Calculate error (loss)  \n    self.weights[1:] += self.learning_rate * error * inputs  # Update weights  \n    self.weights[0] += self.learning_rate * error  # Update bias\n```\n\n**Step 7: Fit the Model**\n\nThe fitting process involves training the model over multiple iterations (epochs) to adjust the weights and bias. This allows the Perceptron to learn from the data and improve its prediction accuracy over time.\n\n```python\ndef fit(self, X, y, num_epochs):  \n    for epoch in range(num_epochs):  \n        for inputs, target in zip(X, y):  # Loop through dataset  \n            self.train(inputs, target)  # Train on each input-target pair\n```\n\n**Complete Code:**\n\n```python\n# Import the necessary library\nimport numpy as np\n\n# Build the Perceptron Model\nclass Perceptron:\n\n    def __init__(self, num_inputs, learning_rate=0.01):\n        # Initialize the weight and learning rate\n        self.weights = np.random.rand(num_inputs + 1)\n        self.learning_rate = learning_rate\n\n    # Define the first linear layer \n    def linear(self, inputs):\n        Z = inputs @ self.weights[1:].T + self.weights[0]\n        return Z\n\n    # Define the Heaviside Step function.\n    def Heaviside_step_fn(self, z):\n        if z>=0:\n            return 1\n        else:\n            return 0\n\n    # Define the Prediction\n    def predict(self, inputs):\n        Z = self.linear(inputs)\n        try:\n            pred = []\n            for z in Z:\n                pred.append(self.Heaviside_step_fn(z))\n        except:\n            return self.Heaviside_step_fn(Z)\n        return pred\n\n    # Define the Loss function\n    def loss(self, prediction, target):\n        loss = (prediction-target)\n        return loss\n\n    #Define training\n    def train(self, inputs, target):\n        prediction = self.predict(inputs)\n        error = self.loss(prediction, target)\n        self.weights[1:] += self.learning_rate * error * inputs\n        self.weights[0]  += self.learning_rate * error\n\n    # Fit the model\n    def fit(self, X, y, num_epochs):\n        for epoch in range(num_epochs):\n            for inputs, target in zip(X, y):\n                self.train(inputs, target)\n```\n\n### Binary Classification on a Linearly Separable Dataset\n\nHere, we are going to process of building, training, and evaluating a **Perceptron model** for binary classification using a synthetic, linearly separable dataset. It covers data preprocessing, model training, and performance evaluation. We will follow these steps:\n\n1. Import Libraries\n2. Generate Dataset using **make_blobs()**\n3. Train-Test Split with **train_test_split()**\n4. Scale Features using **StandardScaler()**\n5. Initialize Perceptron with appropriate input size\n6. Train the Model with **fit()** over 100 epochs\n7. Predict on test data and evaluate accuracy by comparing predictions with actual labels\n8. Visualize Results using a scatter plot\n\n```python\n# Import the necessary library\nimport numpy as np\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate a linearly separable dataset with two classes\nX, y = make_blobs(n_samples=1000,\n                  n_features=2, \n                  centers=2, \n                  cluster_std=3,\n                  random_state=23)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.2,\n                                                    random_state=23,\n                                                    shuffle=True\n                                                   )\n\n# Scale the input features to have zero mean and unit variance\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Set the random seed legacy\nnp.random.seed(23)\n\n# Initialize the Perceptron with the appropriate number of inputs\nperceptron = Perceptron(num_inputs=X_train.shape[1])\n\n# Train the Perceptron on the training data\nperceptron.fit(X_train, y_train, num_epochs=100)\n\n# Prediction\npred = perceptron.predict(X_test)\n\n# Test the accuracy of the trained Perceptron on the testing data\naccuracy = np.mean(pred != y_test)\nprint(\"Accuracy:\", accuracy)\n\n# Plot the dataset\nplt.scatter(X_test[:, 0], X_test[:, 1], c=pred)\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.show()\n```\n\n**Output**:\n\n```\nAccuracy: 0.975\n```\n\n![Scatter Plot of the Classified Data Points](https://media.geeksforgeeks.org/wp-content/uploads/20230426175004/download-(8).png)\n\n*Scatter Plot of the Classified Data Points*\n\n## Binary Classification using Perceptron with PyTorch\n\nIn this section, we are going to implement perceptron model using PyTorch to perform binary classification on linearly separable data that is generated using make_blobs().\n\nThe steps include:\n\n1. **Data Preparation:** A synthetic dataset with two features is created, scaled, and split into training and test sets.\n2. **Perceptron Model:** A single-layer perceptron is implemented using PyTorch's nn.Module.\n3. **Training:** The Perceptron is trained using a simple learning rate and weight update rule for 10 epochs.\n4. **Evaluation:** The model's performance is evaluated by calculating the accuracy on the test set.\n5. **Visualization:** The test dataset is visualized, with the predictions color-coded for easy interpretation.\n\n```python\n# Import the necessary libraries\nimport torch\nimport torch.nn as nn\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate a linearly separable dataset with two classes\nX, y = make_blobs(n_samples=1000,\n                  n_features=2, \n                  centers=2, \n                  cluster_std=3,\n                  random_state=23)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.2,\n                                                    random_state=23,\n                                                    shuffle=True\n                                                   )\n\n# Scale the input features to have zero mean and unit variance\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Convert the data to PyTorch tensors\nX_train = torch.tensor(X_train, dtype=torch.float32, requires_grad=False)\nX_test = torch.tensor(X_test, dtype=torch.float32, requires_grad=False)\ny_train = torch.tensor(y_train, dtype=torch.float32, requires_grad=False)\ny_test = torch.tensor(y_test, dtype=torch.float32, requires_grad=False)\n\n# reshape the target tensor to match the predicted output tensor\ny_train = y_train.reshape(-1, 1)\ny_test = y_test.reshape(-1, 1)\n\ntorch.random.seed()\n\n# Define the Perceptron model\nclass Perceptron(nn.Module):\n    def __init__(self, num_inputs):\n        super(Perceptron, self).__init__()\n        self.linear = nn.Linear(num_inputs, 1)\n\n    # Heaviside Step function\n    def heaviside_step_fn(self,Z):\n        Class = []\n        for z in Z:\n            if z >=0:\n                Class.append(1)\n            else:\n                Class.append(0)\n        return torch.tensor(Class)\n\n    def forward(self, x):\n        Z = self.linear(x)\n        return self.heaviside_step_fn(Z)\n\n# Initialize the Perceptron with the appropriate number of inputs\nperceptron = Perceptron(num_inputs=X_train.shape[1])\n\n# loss function\ndef loss(y_pred,Y):\n    cost = y_pred-Y\n    return cost\n\n# Learning Rate\nlearning_rate = 0.001\n\n# Train the Perceptron on the training data\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    Losses = 0\n    for Input, Class in zip(X_train, y_train):\n        # Forward pass\n        predicted_class = perceptron(Input)\n        error = loss(predicted_class, Class)\n        Losses += error\n        # Perceptron Learning Rule\n\n    # Model Parameter\n        w = perceptron.linear.weight\n        b = perceptron.linear.bias\n\n    # Matually Update the model parameter\n        w = w - learning_rate * error * Input\n        b = b - learning_rate * error\n\n    # assign the weight & bias parameter to the linear layer\n        perceptron.linear.weight = nn.Parameter(w)\n        perceptron.linear.bias   = nn.Parameter(b)\n    print('Epoch [{}/{}], weight:{}, bias:{} Loss: {:.4f}'.format(\n        epoch+1,num_epochs,\n        w.detach().numpy(),\n        b.detach().numpy(),\n        Losses.item()))\n\n# Test the accuracy of the trained Perceptron on the testing data\npred = perceptron(X_test)\n\naccuracy = (pred==y_test[:,0]).float().mean()\nprint(\"Accuracy on Test Dataset:\", accuracy.item())\n\n# Plot the dataset\nplt.scatter(X_test[:, 0], X_test[:, 1], c=pred)\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.show()\n```\n\n**Output**:\n\n```\nEpoch [1/10], weight:[[ 0.01072957 -0.7055903 ]], bias:[0.07482227] Loss: 4.0000  \nEpoch [2/10], weight:[[ 0.0140219  -0.70487624]], bias:[0.07082226] Loss: 4.0000  \nEpoch [3/10], weight:[[ 0.0175706  -0.70405596]], bias:[0.06782226] Loss: 3.0000  \n. . .  \nEpoch [9/10], weight:[[ 0.03782528 -0.69902927]], bias:[0.05182226] Loss: 2.0000  \nEpoch [10/10], weight:[[ 0.04085522 -0.6981565 ]], bias:[0.04982227] Loss: 2.0000  \nAccuracy on Test Dataset: 0.9750000238418579\n```\n\n![Scatter Plot of the Classified Data Points](https://media.geeksforgeeks.org/wp-content/uploads/20230426175111/download-(9).png)\n\n*Scatter Plot of the Classified Data Points*\n\n## Limitations of Perceptron\n\nThe Perceptron was a significant breakthrough in the development of neural networks, proving that simple networks could learn to classify patterns. However, the Perceptron model has certain limitations that can make it unsuitable for some tasks:\n\n- **Limited to linearly separable problems**\n- **Struggles with convergence when handling non-separable data**\n- **Requires labeled data for training**\n- **Sensitive to input scaling**\n- **Lacks hidden layers for complex decision-making**\n\nTo overcome these limitations, more advanced neural network architectures, such as Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs), have been developed. These models can learn more complex patterns and are widely used in modern machine learning and deep learning applications."}
{"reference": "https://www.geeksforgeeks.org/aptitude/aptitude-questions-and-answers/", "content": "# Aptitude Questions and Answers\n\nAptitude questions can be challenging, but with the right preparation and practice, you can tackle them with ease. Our comprehensive guide to aptitude questions and answers covers all the essential topics of Aptitude, including **Quantitative Aptitude**, **Logical Reasoning**, and **Verbal Ability**. Whether you're a student preparing for an examination or looking for a job to improve your problem-solving skills, with our step-by-step guide and sample questions, you will easily gain the confidence to tackle aptitude questions in interviews and competitive exams.\n\n> Try our free course [Aptitude & Reasoning SKILLUP](https://www.geeksforgeeks.org/courses/aptitude-and-reasoning-skill-up) with day-wise concept explanations, solved questions, a quiz at the end of each day and a weekly contest.\n\n## Quantitative Aptitude Topics\n\nQuantitative aptitude covers a wide range of topics and questions, including:\n\n- **[Numbers](https://www.geeksforgeeks.org/aptitude/numbers-aptitude-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/numbers-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/numbers-gq/)\n- **[Work and Wages](https://www.geeksforgeeks.org/aptitude/time-work-and-wages/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/work-and-wages-aptitude-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/work-and-wages-gq/)\n- **[Pipes and Cistern](https://www.geeksforgeeks.org/maths/pipes-and-cistern/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/pipes-and-cisterns-aptitude-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/pipes-and-cisterns-gq/)\n- **[Time, Speed, and Distance](https://www.geeksforgeeks.org/aptitude/speed-time-distance/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/speed-time-distance-aptitude-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/time-speed-distance-gq/)\n- **[Trains, Boats, and Streams](https://www.geeksforgeeks.org/aptitude/boats-and-streams/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/boats-and-streams-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/trains-boats-and-streams-2-gq/)\n- **[LCM and HCF](https://www.geeksforgeeks.org/maths/hcf-and-lcm/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/hcf-and-lcm-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/lcm-and-hcf/)\n- **[Percentages](https://www.geeksforgeeks.org/maths/percentage/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/percentage-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/percentages-gq/)\n- **[Ratio, Proportion, and Partnership](https://www.geeksforgeeks.org/maths/ratio-and-proportion/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/ratio-and-proportion-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/ratio-and-proportion-gq/)\n- **[Mixture and Alligations](https://www.geeksforgeeks.org/aptitude/mixtures-and-alligation/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/alligation-or-mixture-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/mixtures-and-alligation-gq/)\n- **[Algebra](https://www.geeksforgeeks.org/maths/basics-of-algebra/)** | [Solved Questions](https://www.geeksforgeeks.org/maths/algebra-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/algebra-gq/)\n- **[Average](https://www.geeksforgeeks.org/aptitude/average/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/average-aptitude-questions-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/aptitude-average/)\n- **[Problem on Age](https://www.geeksforgeeks.org/aptitude/ages/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/problems-on-ages-aptitude/) | [Quiz](https://www.geeksforgeeks.org/quizzes/age-gq/)\n- **[Profit and Loss](https://www.geeksforgeeks.org/aptitude/profit-loss/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/profit-and-loss-questions-aptitude/) | [Quiz](https://www.geeksforgeeks.org/quizzes/profit-and-loss-gq/)\n- **[Simple Interest](https://www.geeksforgeeks.org/maths/simple-interest/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/simple-interest-questions-aptitude/) | [Quiz](https://www.geeksforgeeks.org/quizzes/simple-interest-gq/)\n- **[Compound Interest](https://www.geeksforgeeks.org/maths/compound-interest-formula/)** | [Solved Questions](https://www.geeksforgeeks.org/dsa/compound-interest-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/compound-interest-gq/)\n- **[Mensuration 2D](https://www.geeksforgeeks.org/aptitude/2d-mensturation/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/mensuration-2d/) | [Quiz](https://www.geeksforgeeks.org/quizzes/mensuration-2d-gq/)\n- **[Mensuration 3D](https://www.geeksforgeeks.org/aptitude/3d-mensturation/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/mensuration-3d/) | [Quiz](https://www.geeksforgeeks.org/quizzes/mensuration-3d-gq/)\n- **[Trigonometry & Height and Distances](https://www.geeksforgeeks.org/maths/height-and-distance/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/height-and-distance-questions-aptitude/) | [Quiz](https://www.geeksforgeeks.org/quizzes/trigonometry-height-and-distances-gq/)\n- **[Progressions](https://www.geeksforgeeks.org/maths/progressions-for-aptitude/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/progression-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/progressions-gq/)\n- **[Logarithms](https://www.geeksforgeeks.org/maths/introduction-to-logarithm/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/logarithm-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/logarithms/)\n- **[Permutation and Combination](https://www.geeksforgeeks.org/maths/permutations-and-combinations/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/permutation-and-combination-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/permutation-and-combination-gq/)\n- **[Probability](https://www.geeksforgeeks.org/maths/basic-concepts-of-probability/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/probability-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/probability-gq/)\n- **[Geometry](https://www.geeksforgeeks.org/maths/basic-geometry-formulas/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/geometry-aptitude-questions-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/geometry-quiz/)\n- **[Clocks](https://www.geeksforgeeks.org/aptitude/clocks-aptitude/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/clock-questions-aptitude/) | [Quiz](https://www.geeksforgeeks.org/quizzes/calendars-gq/)\n- **[Calendars](https://www.geeksforgeeks.org/aptitude/calendars/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/calendar-questions-aptitude-and-reasoning/) | [Quiz](https://www.geeksforgeeks.org/quizzes/calendars-gq/)\n- **[Coding-Decoding](https://www.geeksforgeeks.org/aptitude/reasoning-tricks-to-solve-coding-decoding/)** | [Solved Questions](https://www.geeksforgeeks.org/python/coding-decoding/) | [Quiz](https://www.geeksforgeeks.org/quizzes/coding-decoding/)\n- **[Race](https://www.geeksforgeeks.org/aptitude/race-and-games/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/races-and-games-aptitude-questions/) | [Quiz](https://www.geeksforgeeks.org/quizzes/race-gq/)\n- **[Simplification and Approximation](https://www.geeksforgeeks.org/aptitude/simplification-and-approximation/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/simplification-and-approximation-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/simplification-and-approximation-gq/)\n- **[Data Interpretation](https://www.geeksforgeeks.org/aptitude/data-interpretation-1/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/data-interpretation-questions-aptitude/) | [Quiz](https://www.geeksforgeeks.org/quizzes/data-interpretation-gq/)\n\n## Logical Reasoning Topics\n\nLogical Reasoning covers a wide range of topics and questions, including:\n\n- **[Number Series](https://www.geeksforgeeks.org/aptitude/number-series-in-quantitative-aptitude/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/number-series-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/series-gq/)\n- **[Letter and Symbol Series](https://www.geeksforgeeks.org/aptitude/alphanumeric-series/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/alphanumeric-series-logical-reasoning-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/alphanumeric-series/)\n- **[Verbal Classification](https://www.geeksforgeeks.org/aptitude/classification-logical-reasoning-question-and-answer/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/classification-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/verbal-classification/)\n- **[Analogies](https://www.geeksforgeeks.org/ssc-banking/word-analogy-for-ssc-cgl-exams/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/analogy-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/analogies/)\n- **[Logical Problems](https://www.geeksforgeeks.org/aptitude/logical-problems-logical-reasoning-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/logical-problems-solved-question-and-answer/) | [Quiz](https://www.geeksforgeeks.org/quizzes/logical-problems/)\n- **[Course of Action](https://www.geeksforgeeks.org/aptitude/assumptions-and-conclusions-courses-of-action/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/course-of-action-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/course-of-action/)\n- **[Statement and Conclusion](https://www.geeksforgeeks.org/aptitude/statement-and-conclusion-analytical-and-logical-reasoning/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/statement-and-conclusion-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/syllogism-gq/)\n- **[Theme Detection](https://www.geeksforgeeks.org/aptitude/theme-detection/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/theme-detection-logical-reasoning/) | [Quiz](https://www.geeksforgeeks.org/quizzes/theme-detection/)\n- **[Blood Relations](https://www.geeksforgeeks.org/aptitude/blood-relation-reasoning/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/blood-relation-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/blood-relation/)\n- **[Directions](https://www.geeksforgeeks.org/aptitude/puzzles-direction/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/direction-sense-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/directions/)\n- **[Statement and Argument](https://www.geeksforgeeks.org/aptitude/statement-and-argument-analytical-reasoning/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/statement-and-argument-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/statement-and-argument/)\n- **[Logical Deduction](https://www.geeksforgeeks.org/aptitude/logical-deduction-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/logical-deduction-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/logical-deduction/)\n- **[Letter Series](https://www.geeksforgeeks.org/aptitude/letter-series-reasoning-questions/)** | [Solved Questions](https://www.geeksforgeeks.org/ssc-banking/letter-series-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/letter-series/)\n- **[Coding Decoding](https://www.geeksforgeeks.org/aptitude/reasoning-tricks-to-solve-coding-decoding/)** | [Solved Questions](https://www.geeksforgeeks.org/python/coding-decoding/) | [Quiz](https://www.geeksforgeeks.org/quizzes/coding-decoding/)\n- **[Statement and Assumptions](https://www.geeksforgeeks.org/aptitude/statement-and-assumption/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/statement-and-argument-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/statement-and-argument/)\n- **[Logical Venn Diagram](https://www.geeksforgeeks.org/aptitude/venn-diagrams-verbal-reasoning-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/venn-diagrams-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/logical-venn-diagrams/)\n\n## Verbal Ability Topics\n\nVerbal Ability covers a wide range of topics and questions, including:\n\n- **[Spotting Errors](https://www.geeksforgeeks.org/english/tricks-to-solve-spotting-errors/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/spotting-errors-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/spotting-errors/)\n- **[Synonyms](https://www.geeksforgeeks.org/aptitude/synonyms/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/synonyms-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/synonyms/)\n- **[Antonyms](https://www.geeksforgeeks.org/aptitude/antonyms/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/antonyms-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/antonyms/)\n- **[Selecting Words](https://www.geeksforgeeks.org/aptitude/selecting-words/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/selecting-words-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/selecting-words/)\n- **[Spellings](https://www.geeksforgeeks.org/aptitude/spellings/)** | [Solved Questions](https://www.geeksforgeeks.org/ssc-banking/practice-set-on-spelling-test/) | [Quiz](https://www.geeksforgeeks.org/quizzes/spellings/)\n- **[Sentence Formation](https://www.geeksforgeeks.org/english/verbal-ability-sentence-formation/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/sentence-formation-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/sentence-formation/)\n- **[Ordering of Words](https://www.geeksforgeeks.org/aptitude/ordering-of-words/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/ordering-of-words-solved-question-and-answer/) | [Quiz](https://www.geeksforgeeks.org/quizzes/ordering-of-words/)\n- **[Sentence Correction](https://www.geeksforgeeks.org/aptitude/sentence-correction-verbal-ability/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/sentence-correction-solved-question-and-answer/) | [Quiz](https://www.geeksforgeeks.org/quizzes/sentence-correction/)\n- **[Sentence Improvement](https://www.geeksforgeeks.org/aptitude/sentence-improvement/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/sentence-improvement-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/sentence-improvement/)\n- **[Completing Statements](https://www.geeksforgeeks.org/english/sentence-completion-with-examples/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/sentence-completion-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/completing-statement/)\n- **[Para Jumbles](https://www.geeksforgeeks.org/aptitude/para-jumbles-verbal-ability-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/para-jumbles-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/para-jumbles-1/)\n- **[Paragraph Formation](https://www.geeksforgeeks.org/aptitude/paragraphs-formation/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/paragraph-formation-with-examples/) | [Quiz](https://www.geeksforgeeks.org/quizzes/paragraph-formation/)\n- **[Cloze Test](https://www.geeksforgeeks.org/aptitude/cloze-test-verbal-ability-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/cloze-test-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/cloze-test/)\n- **[Comprehension](https://www.geeksforgeeks.org/english/reading-comprehension-questions/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/reading-comprehension-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/comprehension/)\n- **[One Word Substitutes](https://www.geeksforgeeks.org/aptitude/one-word-substitutes-verbal-ability-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/one-word-substitutes-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/one-word-substitution-1/)\n- **[Idioms and Phrases](https://www.geeksforgeeks.org/english/30-most-common-idioms-and-phrases/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/idioms-and-phrases-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/idioms-and-phrases/)\n- **[Change of Voice](https://www.geeksforgeeks.org/english/change-of-voice-verbal-ability-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/change-of-voice-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/change-of-voice/)\n- **[Change of Speech](https://www.geeksforgeeks.org/aptitude/change-of-speech-verbal-ability-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/change-of-speech-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/change-of-speech/)\n- **[Verbal Analogies](https://www.geeksforgeeks.org/aptitude/verbal-analogies-types-with-examples/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/verbal-analogies-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/verbal-analogy/)\n- **[Articles](https://www.geeksforgeeks.org/ssc-banking/definite-and-indefinite-articles/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/article-solved-questions-and-answer/) | [Quiz](https://www.geeksforgeeks.org/quizzes/articles/)\n- **[Preposition](https://www.geeksforgeeks.org/aptitude/preposition-verbal-ability-questions-and-answers/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/preposition-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/preposition/)\n- **[Adjectives](https://www.geeksforgeeks.org/aptitude/adjective/)** | [Solved Questions](https://www.geeksforgeeks.org/aptitude/adjective-solved-questions-and-answers/) | [Quiz](https://www.geeksforgeeks.org/quizzes/adjective-quiz-test-your-knowledge/)\n\n### Rarely Asked Topics in Aptitude Exams\n\n- [Artificial Language](https://www.geeksforgeeks.org/aptitude/artificial-language-logical-reasoning/)\n- [Matching Definitions](https://www.geeksforgeeks.org/aptitude/matching-definitions-logical-reasoning/)\n- [Making Judgments](https://www.geeksforgeeks.org/aptitude/making-judgement-analytical-reasoning/)\n- [Logical Games](https://www.geeksforgeeks.org/aptitude/logical-games-logical-reasoning-questions-and-answers/)\n- [Verification of the Truth of the Statement](https://www.geeksforgeeks.org/aptitude/verification-of-the-truth-verbal-reasoning/)\n- [Assertion and Reason](https://www.geeksforgeeks.org/aptitude/assertion-and-reason-questions-logical-reasoning/)"}
{"reference": "https://www.geeksforgeeks.org/videos/category/python/", "content": "# Python Videos\n\n## Enumerate() in Python\n- **Duration**: 05:52  \n- **Views**: 3.2K  \n- **Date**: 12/09/2025  \n- **Tags**: Python  \n- [Watch Video](/videos/enumerate-in-python-1/)\n\n## Automated Trading using Python\n- **Duration**: 12:01  \n- **Views**: 48.9K  \n- **Date**: 15/02/2025  \n- **Tags**: Python  \n- [Watch Video](/videos/automated-trading-using-python/)\n\n## Support Vector Regression Intuition\n- **Duration**: 10:50  \n- **Views**: 179.5K  \n- **Date**: 21/01/2025  \n- **Tags**: Python, Data Science, linear-regression  \n- [Watch Video](/videos/support-vector-regression-intuition/)\n\n## Generators in Python\n- **Duration**: 08:08  \n- **Views**: 48.8K  \n- **Date**: 07/01/2025  \n- **Tags**: Python  \n- [Watch Video](/videos/generators-in-python/)\n\n## Tkinter Application to Switch Between Different Page Frames\n- **Duration**: 08:58  \n- **Views**: 12.5K  \n- **Date**: 31/12/2024  \n- **Tags**: Python, Python-projects  \n- [Watch Video](/videos/tkinter-application-to-switch-between-different-page-frames/)\n\n## Abstract Classes in Python\n- **Duration**: 15:01  \n- **Views**: 2.4K  \n- **Date**: 31/12/2024  \n- **Tags**: Python  \n- [Watch Video](/videos/abstract-classes-in-python/)\n\n## Python | Implementation of Movie Recommender System\n- **Duration**: 11:06  \n- **Views**: 36.8K  \n- **Date**: 27/12/2024  \n- **Tags**: Machine Learning, Python, machine-learning, machine-learning-project, Python-projects  \n- [Watch Video](/videos/python-implementation-of-movie-recommender-system/)\n\n## Fine-tuning BERT model for Sentiment Analysis\n- **Duration**: 24:32  \n- **Views**: 9.3K  \n- **Date**: 27/12/2024  \n- **Tags**: Python, Machine Learning, machine-learning, machine-learning-project  \n- [Watch Video](/videos/fine-tuning-bert-model-for-sentiment-analysis/)\n\n## Find and Union Operation on Disjoint Sets\n- **Duration**: 07:18  \n- **Views**: 19.4K  \n- **Date**: 13/12/2024  \n- **Tags**: Python, DSA, Data Structures, Data Structure and Algorithm  \n- [Watch Video](/videos/find-and-union-operation-on-disjoint-sets/)\n\n## Convert a list of characters into a string in Python\n- **Duration**: 02:48  \n- **Views**: 19.6K  \n- **Date**: 12/12/2024  \n- **Tags**: Python, Python-list, python-string  \n- [Watch Video](/videos/convert-a-list-of-characters-into-a-string-in-python/)\n\n## Get current timestamp using Python\n- **Duration**: 09:40  \n- **Views**: 1.4K  \n- **Date**: 09/12/2024  \n- **Tags**: Python  \n- [Watch Video](/videos/get-current-timestamp-using-python/)\n\n## Python end parameter in print()\n- **Duration**: 06:06  \n- **Views**: 1.5K  \n- **Date**: 05/12/2024  \n- **Tags**: Python  \n- [Watch Video](/videos/python-end-parameter-in-print/)\n\n*Showing 1-12 of 58 videos*"}
{"reference": "https://www.geeksforgeeks.org/courses/sql-skill-up", "content": "# SQL - Skill Up\n\n**Self-Paced Course**\n\n![course-thumbnail](/_next/image?url=https%3A%2F%2Fmedia.geeksforgeeks.org%2Fwp-content%2Fuploads%2F20250825040433640543%2FLearn-SQL--Beginner-t.png&w=3840&q=75)\n\n9k+ interested Geeks\n\n**The Advanced SQL Program** is a practical, hands-on course designed to help learners master database design, querying, and management. Covering everything from SQL fundamentals and data types to joins, subqueries, indexing, stored procedures, and transactions, this 4-week program offers a complete journey into SQL.\n\n**Duration:** 4 Weeks\n\n## Course Overview\n\n**The Advanced SQL Program** is a hands-on course designed to build strong skills in database management and querying. Covering everything from **SQL and Database Fundamentals** to **Mastering SQL Queries**, **Database Design Basics**, **Advanced Querying and Performance**, **SQL for Testing**, and **SQL Security & Administration**, this 6-week program offers a complete learning path for SQL.\n\nLearners will gain practical experience in writing efficient queries, designing reliable databases, ensuring security, and managing database systems—preparing them to work confidently with SQL in real-world projects.\n\n## Course Content\n\n### Week 1: SQL and Database Fundamentals\n\n- Introduction to Databases\n- Setting Up SQL Environment\n- Basic SQL Commands: DDL & DML\n- Querying with SELECT\n- SQL Operators\n\n### Week 2: Mastering SQL Queries\n\n- Aggregate Functions\n- Filtering Aggregated Data\n- Joins\n- Subqueries\n- SQL Functions\n\n### Week 3: Database Design Basics\n\n- Database Design & ER Modeling\n- Normalization & Data Integrity\n- Keys & Constraints\n- Indexes & Query Optimization\n- Views in SQL\n- Stored Procedures & Parameters\n- Transactions & Error Handling\n\n### Week 4: Advanced Querying and Performance\n\n- Window Functions\n- Common Table Expressions (CTEs)\n- Query Performance Basics\n- Optimizing Joins & Subqueries\n- Indexing for Performance\n- Triggers & Database Events\n- Database Security & Backups"}
{"reference": "https://www.geeksforgeeks.org/", "content": "# GeeksforGeeks | Your All-in-One Learning Portal\n\n## Explore\n\n- [Data Structure and Algorithms](https://www.geeksforgeeks.org/learn-data-structures-and-algorithms-dsa-tutorial/)\n- [Web Development](https://www.geeksforgeeks.org/web-development/)\n- [AI ML & Data Science](https://www.geeksforgeeks.org/ai-ml-ds/)\n- [Machine Learning](https://www.geeksforgeeks.org/machine-learning/)\n- [Python](https://www.geeksforgeeks.org/python-programming-language/)\n- [Java](https://www.geeksforgeeks.org/java/java/)\n- [System Design](https://www.geeksforgeeks.org/system-design-tutorial/)\n- [DevOps](https://www.geeksforgeeks.org/devops-tutorial/)\n- [Programming Languages](https://www.geeksforgeeks.org/computer-science-fundamentals/programming-language-tutorials/)\n- [CS Subjects](https://www.geeksforgeeks.org/software-engineering/articles-on-computer-science-subjects-gq/)\n- [Practice DSA](https://www.geeksforgeeks.org/blogs/geeksforgeeks-practice-best-online-coding-platform/)\n- [Interview Preparation](https://www.geeksforgeeks.org/interview-prep/interview-corner/)\n- [Databases](https://www.geeksforgeeks.org/sql/guide-to-databases/)\n- [Software & Tools](https://www.geeksforgeeks.org/websites-apps/software-and-tools-a-to-z-list/)\n\n## Courses\n\n- **Generative AI Training Program - Live**  \n  Beginner to Advance  \n  13k+ interested Geeks  \n  [Explore now](https://www.geeksforgeeks.org/courses/generative-ai-training-program/)\n\n- **Tech Interview 101: DSA to System Design for Working Professionals - Live**  \n  Beginner to Advance  \n  367k+ interested Geeks  \n  [Explore now](https://www.geeksforgeeks.org/courses/interviewe-101-data-structures-algorithm-system-design/)\n\n- **MERN Full Stack Development - Live**  \n  Beginner to Advance  \n  394k+ interested Geeks  \n  [Explore now](https://www.geeksforgeeks.org/courses/full-stack-node/)\n\n- **DevOps Engineering: Planning to Production - Live**  \n  Beginner to Advance  \n  131k+ interested Geeks  \n  [Explore now](https://www.geeksforgeeks.org/courses/devops-live/)\n\n- **C++ Programming - Self Paced**  \n  Beginner to Advance  \n  297k+ interested Geeks  \n  [Explore now](https://www.geeksforgeeks.org/courses/cpp-programming-basic-to-advanced/)\n\n- **Java Programming - Self Paced**  \n  Beginner to Advance  \n  398k+ interested Geeks  \n  [Explore now](https://www.geeksforgeeks.org/courses/java-online-course-complete-beginner-to-advanced/)\n\n## Must Explore\n\n- [Trending Now](https://www.geeksforgeeks.org/trending/)\n- [Watch Videos](https://www.geeksforgeeks.org/videos/)\n- [GfG Coding Contest](https://www.geeksforgeeks.org/events)"}
{"reference": "https://www.geeksforgeeks.org/courses/c-skill-up", "content": "# C Skill Up\n\nSelf-Paced Course\n\n**10k+ interested Geeks**\n\nThe Nation SkillUp C Course is structured in order to build strong foundations in C language. This course covers core concepts such as data types, pointers, and memory management, then applies them to build command-line tools, simple operating-system components, and performance-critical modules.\n\nEnroll now to build solid C foundations, master low-level memory management and build something for a change.\n\n**5 Weeks**\n\n## Course Overview\n\nThe Nation Skill Up C Program is tailored to help you master one of the most powerful and foundational programming languages C. Known for its speed, efficiency, and control over system-level operations, C is the backbone of modern software, operating systems, embedded systems, and more.\n\nThis program starts from the ground up covering variables, data types, operators, loops, and conditional statements and progresses into functions, arrays, pointers, memory management, structures, and file handling. Each module is carefully structured to strengthen your understanding of how C interacts closely with hardware and memory.\n\n**Nation SkillUp C Course - Highlights**\n\n* Close-to-hardware control via pointers and manual memory management.\n* Foundation for operating systems, embedded firmware, and compilers.\n* Exceptional performance with minimal runtime overhead.\n* High portability across platforms, from microcontrollers to supercomputers.\n* Virtually every language can call C libraries.\n* Essential for maintaining and modernizing legacy codebases.\n* Enables creation of custom memory allocators and toolchains.\n\n## Course Content\n\n### Week 0: C Language Overview\n\nWhat is C and its Overview\n\n### Week 1: Fundamentals of C\n\n* Introduction to C (history, setup, First Program) and warmup print exercises\n* Data types, variables, keywords, constants/macros, and basic swap/size problems\n* Basic input/output, format specifiers, escape sequences, and precision challenges\n* Operators (arithmetic, logical, bitwise), precedence rules, and formula evaluation\n* Decision making and a simple calculator implementation\n* Loop constructs and pattern problems\n* Weekly Project\n\n### Week 2: Functions, Recursion & Arrays\n\n* Defining and using functions (prototypes, scope, parameters, return values)\n* Recursive patterns, call stack insights, and recursion vs. iteration exercises\n* Array fundamentals (1D/2D arrays), traversal, sizing, and element search problems\n* C style strings and string library functions with substring.\n* Pointer basics (addressing, arithmetic, array pointer relationship)\n* Advanced pointers (void/function pointers, callbacks).\n* Weekly Project\n\n### Week 3: Dynamic Memory & User-Defined Types\n\n* Memory layout of C programs; dynamic allocation and leak avoidance\n* User defined types: struct, union, enum, bit fields, and struct padding considerations\n* pointers to pointers, void pointers, function pointers, and callbacks\n* formatted vs. unformatted I/O, scansets, and custom formatting\n* Reading/Writing files and structs, file positioning with fseek/ftell\n* Weekly Project"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/", "content": "# Logistic Regression in Machine Learning\n\nLogistic Regression is a supervised machine learning algorithm used for classification problems. Unlike linear regression which predicts continuous values it predicts the probability that an input belongs to a specific class. It is used for binary classification where the output can be one of two possible categories such as Yes/No, True/False or 0/1. It uses sigmoid function to convert inputs into a probability value between 0 and 1. In this article, we will see the basics of logistic regression and its core concepts.\n\n## Types of Logistic Regression\n\nLogistic regression can be classified into three main types based on the nature of the dependent variable:\n\n1. **Binomial Logistic Regression**: This type is used when the dependent variable has only two possible categories. Examples include Yes/No, Pass/Fail or 0/1. It is the most common form of logistic regression and is used for binary classification problems.\n\n2. **Multinomial Logistic Regression**: This is used when the dependent variable has three or more possible categories that are not ordered. For example, classifying animals into categories like \"cat,\" \"dog\" or \"sheep.\" It extends the binary logistic regression to handle multiple classes.\n\n3. **Ordinal Logistic Regression**: This type applies when the dependent variable has three or more categories with a natural order or ranking. Examples include ratings like \"low,\" \"medium\" and \"high.\" It takes the order of the categories into account when modeling.\n\n## Assumptions of Logistic Regression\n\nUnderstanding the assumptions behind logistic regression is important to ensure the model is applied correctly, main assumptions are:\n\n1. **Independent observations**: Each data point is assumed to be independent of the others means there should be no correlation or dependence between the input samples.\n\n2. **Binary dependent variables**: It takes the assumption that the dependent variable must be binary, means it can take only two values. For more than two categories [SoftMax](https://www.geeksforgeeks.org/deep-learning/what-is-softmax-classifier/) functions are used.\n\n3. **Linearity relationship between independent variables and log odds**: The model assumes a linear relationship between the independent variables and the log odds of the dependent variable which means the predictors affect the log odds in a linear way.\n\n4. **No outliers**: The dataset should not contain extreme outliers as they can distort the estimation of the logistic regression coefficients.\n\n5. **Large sample size**: It requires a sufficiently large sample size to produce reliable and stable results.\n\n## Understanding Sigmoid Function\n\n1. The sigmoid function is a important part of logistic regression which is used to convert the raw output of the model into a probability value between 0 and 1.\n\n2. This function takes any real number and maps it into the range 0 to 1 forming an \"S\" shaped curve called the sigmoid curve or logistic curve. Because probabilities must lie between 0 and 1, the sigmoid function is perfect for this purpose.\n\n3. In logistic regression, we use a threshold value usually 0.5 to decide the class label.\n\n   - If the sigmoid output is same or above the threshold, the input is classified as Class 1.\n   - If it is below the threshold, the input is classified as Class 0.\n\nThis approach helps to transform continuous input values into meaningful class predictions.\n\n## How does Logistic Regression work?\n\nLogistic regression model transforms the [linear regression](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/) function continuous value output into categorical value output using a sigmoid function which maps any real-valued set of independent variables input into a value between 0 and 1. This function is known as the logistic function.\n\nSuppose we have input features represented as a matrix:\n\n$$\nX = \\begin{bmatrix} \nx_{11} & \\dots & x_{1m} \\\\ \nx_{21} & \\dots & x_{2m} \\\\ \n\\vdots & \\ddots & \\vdots \\\\ \nx_{n1} & \\dots & x_{nm} \n\\end{bmatrix}\n$$\n\nand the dependent variable is Y having only binary value i.e 0 or 1.\n\n$$\nY = \\begin{cases} \n0 & \\text{ if } Class\\;1 \\\\ \n1 & \\text{ if } Class\\;2 \n\\end{cases}\n$$\n\nthen, apply the multi-linear function to the input variables X.\n\n$$\nz = \\left(\\sum_{i=1}^{n} w_{i}x_{i}\\right) + b\n$$\n\nHere $x_i$ is the ith observation of X, $w_i = [w_1, w_2, w_3, \\cdots,w_m]$ is the weights or Coefficient and b is the bias term also known as intercept. Simply this can be represented as the dot product of weight and bias.\n\n$$\nz = w\\cdot X +b\n$$\n\nAt this stage, z is a continuous value from the linear regression. Logistic regression then applies the sigmoid function to z to convert it into a probability between 0 and 1 which can be used to predict the class.\n\nNow we use the [sigmoid function](https://www.geeksforgeeks.org/machine-learning/derivative-of-the-sigmoid-function/) where the input will be z and we find the probability between 0 and 1. i.e. predicted y.\n\n$$\n\\sigma(z) = \\frac{1}{1+e^{-z}}\n$$\n\n![Sigmoid function](https://media.geeksforgeeks.org/wp-content/uploads/20190522162153/sigmoid-function-300x138.png)\n\n*Sigmoid function*\n\nAs shown above the sigmoid function converts the continuous variable data into the probability i.e between 0 and 1.\n\n- $\\sigma(z)$ tends towards 1 as $z\\rightarrow\\infty$\n- $\\sigma(z)$ tends towards 0 as $z\\rightarrow-\\infty$\n- $\\sigma(z)$ is always bounded between 0 and 1\n\nwhere the probability of being a class can be measured as:\n\n$$\nP(y=1) = \\sigma(z) \\\\ \nP(y=0) = 1-\\sigma(z)\n$$\n\n### Logistic Regression Equation and Odds:\n\nIt models the odds of the dependent event occurring which is the ratio of the probability of the event to the probability of it not occurring:\n\n$$\n\\frac{p(x)}{1-p(x)} = e^z\n$$\n\nTaking the natural logarithm of the odds gives the log-odds or logit:\n\n$$\n\\begin{aligned}\n\\log \\left[\\frac{p(x)}{1-p(x)} \\right] &= z \\\\ \n\\log \\left[\\frac{p(x)}{1-p(x)} \\right] &= w\\cdot X +b\\\\ \n\\frac{p(x)}{1-p(x)}&= e^{w\\cdot X +b} \\quad \\cdots\\text{Exponentiate both sides}\\\\ \np(x) &=e^{w\\cdot X +b}\\cdot (1-p(x))\\\\ \np(x) &=e^{w\\cdot X +b}-e^{w\\cdot X +b}\\cdot p(x))\\\\ \np(x)+e^{w\\cdot X +b}\\cdot p(x))&=e^{w\\cdot X +b}\\\\ \np(x)(1+e^{w\\cdot X +b}) &=e^{w\\cdot X +b}\\\\ \np(x)&= \\frac{e^{w\\cdot X +b}}{1+e^{w\\cdot X +b}}\n\\end{aligned}\n$$\n\nthen the final logistic regression equation will be:\n\n$$\np(X;b,w) = \\frac{e^{w\\cdot X +b}}{1+e^{w\\cdot X +b}} = \\frac{1}{1+e^{-w\\cdot X +b}}\n$$\n\nThis formula represents the probability of the input belonging to Class 1.\n\n### Likelihood Function for Logistic Regression\n\nThe goal is to find weights w and bias b that maximize the likelihood of observing the data.\n\nFor each data point i\n\n- for y=1, predicted probabilities will be: p(X;b,w) = p(x)\n- for y=0 The predicted probabilities will be: 1-p(X;b,w) = 1-p(x)\n\n$$\nL(b,w) = \\prod_{i=1}^{n}p(x_i)^{y_i}(1-p(x_i))^{1-y_i}\n$$\n\nTaking natural logs on both sides:\n\n$$\n\\begin{aligned}\n\\log(L(b,w)) &= \\sum_{i=1}^{n} y_i\\log p(x_i)\\;+\\; (1-y_i)\\log(1-p(x_i)) \\\\ \n&= \\sum_{i=1}^{n} y_i\\log p(x_i)+\\log(1-p(x_i))-y_i\\log(1-p(x_i)) \\\\ \n&= \\sum_{i=1}^{n} \\log(1-p(x_i)) + \\sum_{i=1}^{n}y_i\\log \\frac{p(x_i)}{1-p(x_i} \\\\ \n&= \\sum_{i=1}^{n} -\\log1-e^{-(w\\cdot x_i+b)} + \\sum_{i=1}^{n}y_i (w\\cdot x_i +b) \\\\ \n&= \\sum_{i=1}^{n} -\\log1+e^{w\\cdot x_i+b} + \\sum_{i=1}^{n}y_i (w\\cdot x_i +b) \n\\end{aligned}\n$$\n\nThis is known as the log-likelihood function.\n\n### Gradient of the log-likelihood function\n\nTo find the best w and b we use gradient ascent on the log-likelihood function. The gradient with respect to each weight $w_j$ is:\n\n$$\n\\begin{aligned} \n\\frac{\\partial J(l(b,w)}{\\partial w_j}&= -\\sum_{i=n}^{n}\\frac{1}{1+e^{w\\cdot x_i+b}}e^{w\\cdot x_i+b} x_{ij} + \\sum_{i=1}^{n}y_{i}x_{ij} \\\\ \n&= -\\sum_{i=n}^{n}p(x_i;b,w)x_{ij}+ \\sum_{i=1}^{n}y_{i}x_{ij} \\\\ \n&= \\sum_{i=n}^{n}(y_i -p(x_i;b,w))x_{ij} \n\\end{aligned}\n$$\n\n## Terminologies involved in Logistic Regression\n\nHere are some common terms involved in logistic regression:\n\n1. **Independent Variables:** These are the input features or predictor variables used to make predictions about the dependent variable.\n\n2. **Dependent Variable**: This is the target variable that we aim to predict. In logistic regression, the dependent variable is categorical.\n\n3. **Logistic Function**: This function transforms the independent variables into a probability between 0 and 1 which represents the likelihood that the dependent variable is either 0 or 1.\n\n4. **Odds**: This is the ratio of the probability of an event happening to the probability of it not happening. It differs from probability because probability is the ratio of occurrences to total possibilities.\n\n5. **Log-Odds (Logit)**: The natural logarithm of the odds. In logistic regression, the log-odds are modeled as a linear combination of the independent variables and the intercept.\n\n6. **Coefficient**: These are the parameters estimated by the logistic regression model which shows how strongly the independent variables affect the dependent variable.\n\n7. **Intercept**: The constant term in the logistic regression model which represents the log-odds when all independent variables are equal to zero.\n\n8. **Maximum Likelihood Estimation (MLE)**: This method is used to estimate the coefficients of the logistic regression model by maximizing the likelihood of observing the given data.\n\n## Implementation for Logistic Regression\n\nNow, let's see the implementation of logistic regression in Python. Here we will be implementing two main types of Logistic Regression:\n\n### 1. Binomial Logistic regression:\n\nIn binomial logistic regression, the target variable can only have two possible values such as \"0\" or \"1\", \"pass\" or \"fail\". The sigmoid function is used for prediction.\n\nWe will be using [sckit-learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/) library for this and shows how to use the breast cancer dataset to implement a Logistic Regression model for classification.\n\n```python\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX, y = load_breast_cancer(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=23)\n\nclf = LogisticRegression(max_iter=10000, random_state=0)\nclf.fit(X_train, y_train)\n\nacc = accuracy_score(y_test, clf.predict(X_test)) * 100\nprint(f\"Logistic Regression model accuracy: {acc:.2f}%\")\n```\n\n**Output**:\n\n> Logistic Regression model accuracy (in %): 96.49%\n\nThis code uses logistic regression to classify whether a sample from the breast cancer dataset is malignant or benign.\n\n### 2. Multinomial Logistic Regression:\n\nTarget variable can have 3 or more possible types which are not ordered i.e types have no quantitative significance like “disease A” vs “disease B” vs “disease C”.\n\nIn this case, the softmax function is used in place of the sigmoid function. [Softmax function](https://www.geeksforgeeks.org/python/understanding-activation-functions-in-depth/) for K classes will be:\n\n$$\n\\text{softmax}(z_i) =\\frac{ e^{z_i}}{\\sum_{j=1}^{K}e^{z_{j}}}\n$$\n\nHere K represents the number of elements in the vector z and i, j iterates over all the elements in the vector.\n\nThen the probability for class c will be:\n\n$$\nP(Y=c \\mid \\overrightarrow{X}=x) = \\frac{e^{w_c \\cdot x + b_c}}{\\sum_{k=1}^{K}e^{w_k \\cdot x + b_k}}\n$$\n\nBelow is an example of implementing multinomial logistic regression using the Digits dataset from scikit-learn:\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets, linear_model, metrics\n\ndigits = datasets.load_digits()\n\nX = digits.data\ny = digits.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n\nreg = linear_model.LogisticRegression(max_iter=10000, random_state=0)\nreg.fit(X_train, y_train)\n\ny_pred = reg.predict(X_test)\n\nprint(f\"Logistic Regression model accuracy: {metrics.accuracy_score(y_test, y_pred) * 100:.2f}%\")\n```\n\n**Output:**\n\n> Logistic Regression model accuracy: 96.66%\n\nThis model is used to predict one of 10 digits (0-9) based on the image features.\n\n## How to Evaluate Logistic Regression Model?\n\nEvaluating the logistic regression model helps assess its performance and ensure it generalizes well to new, unseen data. The following metrics are commonly used:\n\n**1. Accuracy:** [Accuracy](https://www.geeksforgeeks.org/data-analysis/techniques-to-evaluate-accuracy-of-classifier-in-data-mining/) provides the proportion of correctly classified instances.\n\n> Accuracy = $\\frac{True \\, Positives + True \\, Negatives}{Total}$\n\n**2. Precision:**[Precision](https://www.geeksforgeeks.org/r-language/precision-recall-and-f1-score-using-r/) focuses on the accuracy of positive predictions.\n\n> Precision = $\\frac{True \\, Positives }{True\\, Positives + False \\, Positives}$\n\n**3. Recall (Sensitivity or True Positive Rate):**[Recall](https://www.geeksforgeeks.org/machine-learning/precision-and-recall-in-machine-learning/) measures the proportion of correctly predicted positive instances among all actual positive instances.\n\n> Recall = $\\frac{ True \\, Positives}{True\\, Positives + False \\, Negatives}$\n\n**4. F1 Score:** [F1 score](https://www.geeksforgeeks.org/machine-learning/f1-score-in-machine-learning/) is the harmonic mean of precision and recall.\n\n> F1 \\, Score = 2 * $\\frac{Precision * Recall}{Precision + Recall}$\n\n**5. Area Under the Receiver Operating Characteristic Curve (AUC-ROC):** The ROC curve plots the true positive rate against the false positive rate at various thresholds. [AUC-ROC](https://www.geeksforgeeks.org/machine-learning/auc-roc-curve/) measures the area under this curve which provides an aggregate measure of a model's performance across different classification thresholds.\n\n**6. Area Under the Precision-Recall Curve (AUC-PR):** Similar to AUC-ROC, [AUC-PR](https://www.geeksforgeeks.org/machine-learning/precision-recall-curve-ml/) measures the area under the precision-recall curve helps in providing a summary of a model's performance across different precision-recall trade-offs.\n\n## Differences Between Linear and Logistic Regression\n\nLogistic regression and linear regression differ in their application and output. Here's a comparison:\n\n| Linear Regression | Logistic Regression |\n| --- | --- |\n| Linear regression is used to predict the continuous dependent variable using a given set of independent variables. | Logistic regression is used to predict the categorical dependent variable using a given set of independent variables. |\n| It is used for solving regression problem. | It is used for solving classification problems. |\n| In this we predict the value of continuous variables | In this we predict values of categorical variables |\n| In this we find best fit line. | In this we find S-Curve. |\n| Least square estimation method is used for estimation of accuracy. | Maximum likelihood estimation method is used for Estimation of accuracy. |\n| The output must be continuous value, such as price, age etc. | Output must be categorical value such as 0 or 1, Yes or no etc. |\n| It required linear relationship between dependent and independent variables. | It not required linear relationship. |\n| There may be collinearity between the independent variables. | There should be little to no collinearity between independent variables. |"}
{"reference": "https://www.geeksforgeeks.org/courses/category/trending-technologies/", "content": "### We couldn't find what you're looking for"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/a-comprehensive-guide-to-ensemble-learning/", "content": "# Ensemble Learning\n\nEnsemble learning is a method where we use many small models instead of just one. Each of these models may not be very strong on its own, but when we put their results together, we get a better and more accurate answer. It's like asking a group of people for advice instead of just one person—each one might be a little wrong, but together, they usually give a better answer.\n\n## Types of Ensemble Learning in Machine Learning\n\nThere are three main types of ensemble methods:\n\n1. **Bagging (Bootstrap Aggregating):** Models are trained independently on different random subsets of the training data. Their results are then combined—usually by averaging (for regression) or voting (for classification). This helps reduce variance and prevents overfitting.\n\n2. **Boosting:** Models are trained one after another. Each new model focuses on fixing the errors made by the previous ones. The final prediction is a weighted combination of all models, which helps reduce bias and improve accuracy.\n\n3. **Stacking (Stacked Generalization):** Multiple different models (often of different types) are trained and their predictions are used as inputs to a final model, called a meta-model. The meta-model learns how to best combine the predictions of the base models, aiming for better performance than any individual model.\n\nWhile stacking is also a method but bagging and boosting method is widely used and lets see more about them.\n\n### 1. Bagging Algorithm\n\n[Bagging classifier](https://www.geeksforgeeks.org/machine-learning/What-is-Bagging-classifier/) can be used for both regression and classification tasks. Here is an overview of Bagging classifier algorithm:\n\n- **Bootstrap Sampling:** Divides the original training data into ‘N’ subsets and randomly selects a subset with replacement in some rows from other subsets. This step ensures that the base models are trained on diverse subsets of the data and there is no class imbalance.\n\n- **Base Model Training:** For each bootstrapped sample we train a base model independently on that subset of data. These weak models are trained in parallel to increase computational efficiency and reduce time consumption. We can use different base learners i.e. different ML models as base learners to bring variety and robustness.\n\n- **Prediction Aggregation:** To make a prediction on testing data combine the predictions of all base models. For classification tasks it can include majority voting or weighted majority while for regression it involves averaging the predictions.\n\n- **Out-of-Bag (OOB) Evaluation**: Some samples are excluded from the training subset of particular base models during the bootstrapping method. These “out-of-bag” samples can be used to estimate the model’s performance without the need for cross-validation.\n\n- **Final Prediction:** After aggregating the predictions from all the base models, Bagging produces a final prediction for each instance.\n\n#### Python pseudo code for Bagging Estimator implementing libraries:\n\n##### 1. Importing Libraries and Loading Data\n\nWe will import [scikit learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/) for:\n\n- **BaggingClassifier:** for creating an ensemble of classifiers trained on different subsets of data.\n\n- **DecisionTreeClassifier:** the base classifier used in the bagging ensemble.\n\n- **load_iris:** to load the Iris dataset for classification.\n\n- **train_test_split:** to split the dataset into training and testing subsets.\n\n- **accuracy_score**: to evaluate the model’s prediction accuracy.\n\n```python\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n```\n\n##### 2. Loading and Splitting the Iris Dataset\n\n- **data = load_iris():** loads the Iris dataset, which includes features and target labels.\n\n- **X = data.data:** extracts the feature matrix (input variables).\n\n- **y = data.target:** extracts the target vector (class labels).\n\n- **train_test_split(...):** splits the data into training (80%) and testing (20%) sets, with random_state=42 to ensure reproducibility.\n\n```python\ndata = load_iris()\nX = data.data\ny = data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n\n##### 3. Creating a Base Classifier\n\nDecision tree is chosen as the base model. They are prone to overfitting when trained on small datasets making them good candidates for bagging.\n\n- **base_classifier = DecisionTreeClassifier()**: initializes a Decision Tree classifier, which will serve as the base estimator in the Bagging ensemble.\n\n```python\nbase_classifier = DecisionTreeClassifier()\n```\n\n##### 4. Creating and Training the Bagging Classifier\n\n- A **BaggingClassifier** is created using the decision tree as the base classifier.\n\n- **n_estimators = 10** specifies that 10 decision trees will be trained on different bootstrapped subsets of the training data.\n\n```python\nbagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\nbagging_classifier.fit(X_train, y_train)\n```\n\n##### 5. Making Predictions and Evaluating Accuracy\n\n- The trained bagging model predicts labels for test data.\n\n- The accuracy of the predictions is calculated by comparing the predicted labels (**y_pred**) to the actual labels (**y_test**).\n\n```python\ny_pred = bagging_classifier.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n```\n\n**Output:**\n\n> Accuracy: 1.0\n\n### 2. Boosting Algorithm\n\n[Boosting](https://www.geeksforgeeks.org/machine-learning/boosting-in-machine-learning-boosting-and-adaboost/) is an ensemble technique that combines multiple weak learners to create a strong learner. Weak models are trained in series such that each next model tries to correct errors of the previous model until the entire training dataset is predicted correctly. One of the most well-known boosting algorithms is [AdaBoost (Adaptive Boosting).](https://www.geeksforgeeks.org/machine-learning/implementing-the-adaboost-algorithm-from-scratch/) Here is an overview of Boosting algorithm:\n\n- **Initialize Model Weights**: Begin with a single weak learner and assign equal weights to all training examples.\n\n- **Train Weak Learner**: Train weak learners on these dataset.\n\n- **Sequential Learning**: Boosting works by training models sequentially where each model focuses on correcting the errors of its predecessor. Boosting typically uses a single type of weak learner like decision trees.\n\n- **Weight Adjustment**: Boosting assigns weights to training datapoints. Misclassified examples receive higher weights in the next iteration so that next models pay more attention to them.\n\n#### Python pseudo code for boosting Estimator implementing libraries:\n\n##### 1. Importing Libraries and Modules\n\n- **AdaBoostClassifier from sklearn.ensemble:** for building the AdaBoost ensemble model.\n\n- **DecisionTreeClassifier from sklearn.tree:** as the base weak learner for AdaBoost.\n\n- **load_iris from sklearn.datasets:** to load the Iris dataset.\n\n- **train_test_split from sklearn.model_selection:** to split the dataset into training and testing sets.\n\n- **accuracy_score from sklearn.metrics:** to evaluate the model’s accuracy.\n\n```python\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n```\n\n##### 2. Loading and Splitting the Dataset\n\n- **data = load_iris(): loads the Iris dataset, which includes features and target labels.**\n\n- **X = data.data: extracts the feature matrix (input variables).**\n\n- **y = data.target: extracts the target vector (class labels).**\n\n- **train_test_split(...): splits the data into training (80%) and testing (20%) sets, with random_state=42 to ensure reproducibility.**\n\n```python\ndata = load_iris()\nX = data.data\ny = data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n\n##### 3. Defining the Weak Learner\n\nWe are creating the base classifier as a decision tree with maximum depth 1 (a decision stump). This simple tree will act as a weak learner for the AdaBoost algorithm, which iteratively improves by combining many such weak learners.\n\n```python\nbase_classifier = DecisionTreeClassifier(max_depth=1)\n```\n\n##### 4. Creating and Training the AdaBoost Classifier\n\n- **base_classifier: The weak learner used in boosting.**\n\n- **n_estimators = 50: Number of weak learners to train sequentially.**\n\n- **learning_rate = 1.0: Controls the contribution of each weak learner to the final model.**\n\n- **random_state = 42: Ensures reproducibility.**\n\n```python\nadaboost_classifier = AdaBoostClassifier(\n    base_classifier, n_estimators=50, learning_rate=1.0, random_state=42\n)\nadaboost_classifier.fit(X_train, y_train)\n```\n\n##### 5. Making Predictions and Calculating Accuracy\n\nWe are calculating the accuracy of the model by comparing the true labels **y_test** with the predicted labels **y_pred**. The accuracy_score function returns the proportion of correctly predicted samples. Then, we print the accuracy value.\n\n```python\ny_pred = adaboost_classifier.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n```\n\n**Output:**\n\n> Accuracy: 1.0\n\n## Benefits of Ensemble Learning in Machine Learning\n\nEnsemble learning is a versatile approach that can be applied to machine learning model for:\n\n- **Reduction in Overfitting**: By aggregating predictions of multiple model's ensembles can reduce overfitting that individual complex models might exhibit.\n\n- **Improved Generalization**: It generalizes better to unseen data by minimizing variance and bias.\n\n- **Increased Accuracy**: Combining multiple models gives higher predictive accuracy.\n\n- **Robustness to Noise**: It mitigates the effect of noisy or incorrect data points by averaging out predictions from diverse models.\n\n- **Flexibility**: It can work with diverse models including decision trees, neural networks and support vector machines making them highly adaptable.\n\n- **Bias-Variance Tradeoff**: Techniques like bagging reduce variance, while boosting reduces bias leading to better overall performance.\n\nThere are various ensemble learning techniques we can use as each one of them has their own pros and cons.\n\n## Ensemble Learning Techniques\n\n| Technique | Category | Description |\n| --- | --- | --- |\n| Random Forest | Bagging | [Random forest](https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/) constructs multiple decision trees on bootstrapped subsets of the data and aggregates their predictions for final output, reducing overfitting and variance. |\n| Random Subspace Method | Bagging | Trains models on random subsets of input features to enhance diversity and improve generalization while reducing overfitting. |\n| Gradient Boosting Machines (GBM) | Boosting | [Gradient Boosting Machines](https://www.geeksforgeeks.org/machine-learning/ml-gradient-boosting/) sequentially builds decision trees, with each tree correcting errors of the previous ones, enhancing predictive accuracy iteratively. |\n| Extreme Gradient Boosting (XGBoost) | Boosting | [XGBoost](https://www.geeksforgeeks.org/machine-learning/xgboost/) do optimizations like tree pruning, regularization and parallel processing for robust and efficient predictive models. |\n| AdaBoost (Adaptive Boosting) | Boosting | [AdaBoost](https://www.geeksforgeeks.org/machine-learning/implementing-the-adaboost-algorithm-from-scratch/) focuses on challenging examples by assigning weights to data points. Combines weak classifiers with weighted voting for final predictions. |\n| CatBoost | Boosting | [CatBoost](https://www.geeksforgeeks.org/machine-learning/catboost-ml/) specialize in handling categorical features natively without extensive preprocessing with high predictive accuracy and automatic overfitting handling. |"}
{"reference": "https://www.geeksforgeeks.org/videos/category/java-w6y5f4/", "content": "# Java W6y5f4 Videos\n\n## Video List\n\n### Introduction to Postman\n- **Duration**: 18:23\n- **Views**: 7.6K\n- **Date**: 27/02/2025\n- **Tags**: Java, software-engineering\n- [Watch Video](/videos/introduction-to-postman/)\n\n### Shadow DOM\n- **Duration**: 17:39\n- **Views**: 2.1K\n- **Date**: 11/02/2025\n- **Tags**: Java\n- [Watch Video](/videos/shadow-dom/)\n\n### Exceptions in WebDriver\n- **Duration**: 36:26\n- **Views**: 110\n- **Date**: 11/02/2025\n- **Tags**: Java\n- [Watch Video](/videos/exceptions-in-webdriver/)\n\n### Best Practices and Tips for API Testing\n- **Duration**: 07:55\n- **Views**: 360\n- **Date**: 11/02/2025\n- **Tags**: Java, software-engineering\n- [Watch Video](/videos/best-practices-and-tips-for-api-testing/)\n\n### Selenium WebDriver Best Practices and Tips\n- **Duration**: 13:12\n- **Views**: 390\n- **Date**: 11/02/2025\n- **Tags**: Java\n- [Watch Video](/videos/selenium-webdriver-best-practices-and-tips/)\n\n### Introduction to REST Assured\n- **Duration**: 22:05\n- **Views**: 13.1K\n- **Date**: 11/02/2025\n- **Tags**: Java, software-engineering\n- [Watch Video](/videos/introduction-to-rest-assured/)\n\n### Taking Screenshots\n- **Duration**: 25:10\n- **Views**: 130\n- **Date**: 11/02/2025\n- **Tags**: Java\n- [Watch Video](/videos/taking-screenshots/)\n\n### WebDriver Architecture\n- **Duration**: 32:17\n- **Views**: 4.1K\n- **Date**: 11/02/2025\n- **Tags**: Java\n- [Watch Video](/videos/webdriver-architecture/)\n\n### Cross-Browser Testing\n- **Duration**: 27:27\n- **Views**: 50\n- **Date**: 11/02/2025\n- **Tags**: Java\n- [Watch Video](/videos/cross-browser-testing/)\n\n### API Testing with Postman\n- **Duration**: 40:22\n- **Views**: 4.5K\n- **Date**: 11/02/2025\n- **Tags**: Java, software-engineering\n- [Watch Video](/videos/api-testing-with-postman/)\n\n### Introduction to API Testing\n- **Duration**: 44:05\n- **Views**: 19.3K\n- **Date**: 11/02/2025\n- **Tags**: Java, software-engineering\n- [Watch Video](/videos/introduction-to-api-testing/)\n\n### Advanced REST Assured Concepts\n- **Duration**: 37:33\n- **Views**: 100\n- **Date**: 11/02/2025\n- **Tags**: Java, software-engineering\n- [Watch Video](/videos/advanced-rest-assured-concepts/)\n\n*Showing 1 of 21 videos*"}
{"reference": "https://www.instagram.com/geeks_for_geeks/", "content": "# GeeksforGeeks | Learn to Code\n\n**Instagram Profile**  \n469K Followers, 4 Following, 3,040 Posts  \n@geeks_for_geeks  \n\n1 DSA problem a day, keeps joblessness away! 💻💼  \nExplore Offline Programs near you: @gfg_classroom_program 🗺️"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/", "content": "# Cross Validation in Machine Learning\n\nCross-validation is a technique used to check how well a machine learning model performs on unseen data while preventing overfitting. It works by:\n\n- Splitting the dataset into several parts.\n- Training the model on some parts and testing it on the remaining part.\n- Repeating this resampling process multiple times by choosing different parts of the dataset.\n- Averaging the results from each validation step to get the final performance.\n\n## Types of Cross-Validation\n\nThere are several types of cross-validation techniques which are as follows:\n\n### 1. Holdout Validation\n\nIn [Holdout Validation](https://www.geeksforgeeks.org/software-engineering/introduction-of-holdout-method/) method typically 50% data is used for training and 50% for testing. Making it simple and quick to apply. The major drawback of this method is that only 50% data is used for training, the model may miss important patterns in the other half which leads to high bias.\n\n### 2. LOOCV (Leave One Out Cross Validation)\n\nIn this method the model is trained on the entire dataset except for one data point which is used for testing. This process is repeated for each data point in the dataset.\n\n- All data points are used for training, resulting in low bias.\n- Testing on a single data point can cause high variance, especially if the point is an outlier.\n- It can be very time-consuming for large datasets as it requires one iteration per data point.\n\n### 3. Stratified Cross-Validation\n\nIt is a technique that ensures each fold of the cross-validation process has the same class distribution as the full dataset. This is useful for imbalanced datasets where some classes are underrepresented.\n\n- The dataset is divided into k folds, keeping class proportions consistent in each fold.\n- In each iteration, one fold is used for testing and the remaining folds for training.\n- This process is repeated k times so that each fold is used once as the test set.\n- It helps classification models generalize better by maintaining balanced class representation.\n\n### 4. K-Fold Cross Validation\n\n[K-Fold Cross Validation](https://www.geeksforgeeks.org/r-language/k-fold-cross-validation-in-r-programming/) splits the dataset into **k** equal-sized folds. The model is trained on **k-1** folds and tested on the remaining fold. This process is repeated **k** times each time using a different fold for testing.\n\n> **Note:** It is always suggested that the value of k should be 10 as the lower value of k takes towards validation and higher value of k leads to LOOCV method.\n\n## Example of K Fold Cross Validation\n\nThe diagram below shows an example of the training subsets and evaluation subsets generated in k-fold cross-validation. Here we have total 25 instances.\n\n*K Fold Cross Validation*\n\n![K Fold Cross Validation](https://media.geeksforgeeks.org/wp-content/uploads/20250927122541290704/222.webp)\n\n- Here we will take k as 5.\n- **1st iteration:** The first 20% of data [1–5] is used for testing and the remaining 80% [6–25] is used for training.\n- **2nd iteration:** The second 20% [6–10] is used for testing and the remaining data [1–5] and [11–25] is used for training.\n- This process continues until each fold has been used once as the test set.\n\n| Iteration | Training Set Observations | Testing Set Observations |\n| --- | --- | --- |\n| 1 | [5-24] | [0-4] |\n| 2 | [0-4, 10-24] | [5-9] |\n| 3 | [0-9, 15-24] | [10-14] |\n| 4 | [0-14, 20-24] | [15-19] |\n| 5 | [0-19] | [20-24] |\n\nEach iteration uses different subsets for testing and training, ensuring that all data points are used for both training and testing.\n\n## Comparison between K-Fold Cross-Validation and Hold Out Method\n\nK-Fold Cross-Validation and Hold Out Method are widely used technique and sometimes they are confusing so here is the quick comparison between them:\n\n| Feature | K-Fold Cross-Validation | Holdout Method |\n| --- | --- | --- |\n| **Data Split** | Dataset is divided into k folds and each fold is used once as test set | Dataset is split once, typically into training and testing sets |\n| **Training & Testing** | Model is trained and tested k times, each fold serving as test set once | Model is trained once on training set and tested once on test set |\n| **Bias & Variance** | Lower bias, more reliable performance estimate and variance depends on k | Higher bias if the split is not representative and results can vary significantly |\n| **Execution Time** | Slower, especially for large datasets because model is trained k times | Faster, only one training and testing cycle |\n| **Best Use Case** | Small to medium datasets where accuracy estimation is important | Very large datasets or when quick evaluation is needed |\n\n## Python implementation for k fold cross-validation\n\n### Step 1: Importing necessary libraries\n\nWe will import [scikit learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/).\n\n```python\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\n```\n\n### Step 2: Loading the dataset\n\nlet's use the iris dataset which is a multi-class classification in-built dataset.\n\n```python\niris = load_iris()\nX, y = iris.data, iris.target\n```\n\n### Step 3: Creating SVM classifier\n\n`SVC` is a [Support Vector Classification](https://www.geeksforgeeks.org/machine-learning/kernel-trick-in-support-vector-classification/) model from scikit-learn.\n\n```python\nsvm_classifier = SVC(kernel='linear')\n```\n\n### Step 4: Defining the number of folds for cross-validation\n\nHere we will be using 5 folds.\n\n```python\nnum_folds = 5\nkf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n```\n\n### Step 5: Performing k-fold cross-validation\n\n```python\ncross_val_results = cross_val_score(svm_classifier, X, y, cv=kf)\n```\n\n### Step 6: Evaluation metrics\n\n```python\nprint(\"Cross-Validation Results (Accuracy):\")\nfor i, result in enumerate(cross_val_results, 1):\n    print(f\"  Fold {i}: {result * 100:.2f}%\")\n\nprint(f'Mean Accuracy: {cross_val_results.mean()* 100:.2f}%')\n```\n\n**Output:**\n\n![Cross validation accuracy](https://media.geeksforgeeks.org/wp-content/uploads/20250508172030797636/Cross-validation-accuracy.png)\n\nThe output shows the accuracy scores from each of the 5 folds in the K-fold cross-validation process. The mean accuracy is the average of these individual scores which is approximately 97.33% indicating the model's overall performance across all the folds.\n\n## Advantages\n\n1. **Better performance estimate:** Provides a more reliable evaluation than a single train-test split.\n2. **Reduces overfitting:** Helps ensure the model generalizes well to unseen data.\n3. **Efficient use of data:** All data points are used for both training and testing at different iterations.\n4. **Flexible:** Works with different types of datasets and models.\n\n## Disadvantages\n\n1. **Computationally Expensive:** It can be computationally expensive especially when the number of folds is large.\n2. **Time-consuming:** Methods like LOOCV can take a long time for datasets with many data instances.\n3. **Bias-Variance Tradeoff:** Few folds may result in high bias while too many folds may result in high variance."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/", "content": "# Linear Regression in Machine Learning\n\nLinear regression is a type of **supervised machine-learning algorithm** that learns from the labelled datasets and maps the data points with most optimized linear functions which can be used for prediction on new datasets. It assumes that there is a linear relationship between the input and output, meaning the output changes at a constant rate as the input changes. This relationship is represented by a straight line.\n\n**For example** we want to predict a student's exam score based on how many hours they studied. We observe that as students study more hours, their scores go up. In the example of predicting exam scores based on hours studied. Here\n\n- **Independent variable (input):** Hours studied because it's the factor we control or observe.\n- **Dependent variable (output):** Exam score because it depends on how many hours were studied.\n\nWe use the independent variable to predict the dependent variable.\n\n## Why Linear Regression is Important?\n\nHere’s why linear regression is important:\n\n- **Simplicity and Interpretability:** It’s easy to understand and interpret, making it a starting point for learning about machine learning.\n- **Predictive Ability**: Helps predict future outcomes based on past data, making it useful in various fields like finance, healthcare and marketing.\n- **Basis for Other Models:** Many advanced algorithms, like logistic regression or neural networks, build on the concepts of linear regression.\n- **Efficiency:** It’s computationally efficient and works well for problems with a linear relationship.\n- **Widely Used:** It’s one of the most widely used techniques in both statistics and machine learning for regression tasks.\n- **Analysis:** It provides insights into relationships between variables (e.g., how much one variable influences another).\n\n## Best Fit Line in Linear Regression\n\nIn linear regression, the best-fit line is the straight line that most accurately represents the relationship between the independent variable (input) and the dependent variable (output). It is the line that minimizes the difference between the actual data points and the predicted values from the model.\n\n### 1. Goal of the Best-Fit Line\n\nThe goal of linear regression is to find a straight line that minimizes the error (the difference) between the observed data points and the predicted values. This line helps us predict the dependent variable for new, unseen data.\n\n![Linear Regression](https://media.geeksforgeeks.org/wp-content/uploads/20231129130431/11111111.png)\n\nHere Y is called a dependent or target variable and X is called an independent variable also known as the predictor of Y. There are many types of functions or modules that can be used for regression. A linear function is the simplest type of function. Here, X may be a single feature or multiple features representing the problem.\n\n### 2. Equation of the Best-Fit Line\n\nFor simple linear regression (with one independent variable), the best-fit line is represented by the equation\n\n> y = mx + b\n\n**Where:**\n\n- **y** is the predicted value (dependent variable)\n- **x** is the input (independent variable)\n- **m** is the slope of the line (how much y changes when x changes)\n- **b** is the intercept (the value of y when x = 0)\n\nThe best-fit line will be the one that optimizes the values of m (slope) and b (intercept) so that the predicted y values are as close as possible to the actual data points.\n\n### 3. Minimizing the Error: The Least Squares Method\n\nTo find the best-fit line, we use a method called **Least Squares**. The idea behind this method is to minimize the sum of squared differences between the actual values (data points) and the predicted values from the line. These differences are called residuals.\n\nThe formula for residuals is:\n\n> Residual = yᵢ - ŷᵢ\n\n**Where:**\n\n- yᵢ is the actual observed value\n- ŷᵢ is the predicted value from the line for that xᵢ\n\nThe least squares method minimizes the sum of the squared residuals:\n\n> Sum of squared errors (SSE) = Σ(yᵢ - ŷᵢ)²\n\nThis method ensures that the line best represents the data where the sum of the squared differences between the predicted values and actual values is as small as possible.\n\n### 4. Interpretation of the Best-Fit Line\n\n- **Slope (m):** The slope of the best-fit line indicates how much the dependent variable (y) changes with each unit change in the independent variable (x). For example if the slope is 5, it means that for every 1-unit increase in x, the value of y increases by 5 units.\n- **Intercept (b):** The intercept represents the predicted value of y when x = 0. It’s the point where the line crosses the y-axis.\n\nIn linear regression some hypothesis are made to ensure reliability of the model's results.\n\n### Limitations\n\n- **Assumes Linearity:** The method assumes the relationship between the variables is linear. If the relationship is non-linear, linear regression might not work well.\n- **Sensitivity to Outliers:** Outliers can significantly affect the slope and intercept, skewing the best-fit line.\n\n## Hypothesis function in Linear Regression\n\nIn linear regression, the hypothesis function is the equation used to make predictions about the dependent variable based on the independent variables. It represents the relationship between the input features and the target output.\n\nFor a simple case with one independent variable, the hypothesis function is:\n\n> h(x) = β₀ + β₁x\n\n**Where:**\n\n- h(x) (or ŷ) is the predicted value of the dependent variable (y).\n- x is the independent variable.\n- β₀ is the intercept, representing the value of y when x is 0.\n- β₁ is the slope, indicating how much y changes for each unit change in x.\n\nFor **multiple linear regression** (with more than one independent variable), the hypothesis function expands to:\n\n> h(x₁, x₂, ..., xₖ) = β₀ + β₁x₁ + β₂x₂ + ... + βₖxₖ\n\n**Where:**\n\n- x₁, x₂, ..., xₖ are the independent variables.\n- β₀ is the intercept.\n- β₁, β₂, ..., βₖ are the coefficients, representing the influence of each respective independent variable on the predicted output.\n\n## Assumptions of the Linear Regression\n\n**1. Linearity**: The relationship between inputs (X) and the output (Y) is a straight line.\n\n![Linearity](https://media.geeksforgeeks.org/wp-content/uploads/20231123113044/python-linear-regression-4.png)\n\n**2. Independence of Errors**: The errors in predictions should not affect each other.\n\n**3. Constant Variance (Homoscedasticity):** The errors should have equal spread across all values of the input. If the spread changes (like fans out or shrinks), it's called heteroscedasticity and it's a problem for the model.\n\n![Homoscedasticity](https://media.geeksforgeeks.org/wp-content/uploads/20231123113103/python-linear-regression-5.png)\n\n**4. Normality of Errors**: The errors should follow a normal (bell-shaped) distribution.\n\n**5. No Multicollinearity** *(for multiple regression)*: Input variables shouldn't be too closely related to each other.\n\n**6. No Autocorrelation**: Errors shouldn't show repeating patterns, especially in time-based data.\n\n**7. Additivity**: The total effect on Y is just the sum of effects from each X, no mixing or interaction between them.\n\nTo understand Multicollinearity in detail refer to article: **Multicollinearity**.\n\n## Types of Linear Regression\n\nWhen there is only one independent feature it is known as Simple Linear Regression or [Univariate Linear Regression](https://www.geeksforgeeks.org/python/univariate-linear-regression-in-python/) and when there are more than one feature it is known as Multiple Linear Regression or [Multivariate Regression](https://www.geeksforgeeks.org/machine-learning/multivariate-regression/).\n\n### 1. Simple Linear Regression\n\n[Simple linear regression](https://www.geeksforgeeks.org/machine-learning/simple-linear-regression-in-python/) is used when we want to predict a target value (dependent variable) using only one input feature (independent variable). It assumes a straight-line relationship between the two.\n\n### Formula:\n\n> \\hat{y} = \\theta_0 + \\theta_1 x\n\n**Where:**\n\n- \\hat{y} is the predicted value\n- x is the input (independent variable)\n- \\theta_0 is the intercept (value of \\hat{y} when x=0)\n- \\theta_1 is the slope or coefficient (how much \\hat{y} changes with one unit of x)\n\n### Example:\n\nPredicting a person's salary (y) based on their years of experience (x).\n\n### 2. Multiple Linear Regression\n\n[Multiple linear regression](https://www.geeksforgeeks.org/machine-learning/ml-multiple-linear-regression-using-python/) involves more than one independent variable and one dependent variable. The equation for multiple linear regression is:\n\n> \\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n\n\n**where:**\n\n- \\hat{y} is the predicted value\n- x_1, x_2, \\dots, x_n are the independent variables\n- \\theta_1, \\theta_2, \\dots, \\theta_n are the coefficients (weights) corresponding to each predictor.\n- \\theta_0 is the intercept.\n\nThe goal of the algorithm is to find the best Fit Line equation that can predict the values based on the independent variables.\n\nIn regression set of records are present with X and Y values and these values are used to learn a function so if you want to predict Y from an unknown X this learned function can be used. In regression we have to find the value of Y, So, a function is required that predicts continuous Y in the case of regression given X as independent features.\n\n### Use Case of Multiple Linear Regression\n\nMultiple linear regression allows us to analyze relationship between multiple independent variables and a single dependent variable. Here are some use cases:\n\n- **Real Estate Pricing:** In real estate MLR is used to predict property prices based on multiple factors such as location, size, number of bedrooms, etc. This helps buyers and sellers understand market trends and set competitive prices.\n- **Financial Forecasting:** Financial analysts use MLR to predict stock prices or economic indicators based on multiple influencing factors such as interest rates, inflation rates and market trends. This enables better investment strategies and risk management.\n- **Agricultural Yield Prediction:** Farmers can use MLR to estimate crop yields based on several variables like rainfall, temperature, soil quality and fertilizer usage. This information helps in planning agricultural practices for optimal productivity\n- **E-commerce Sales Analysis:** An e-commerce company can utilize MLR to assess how various factors such as product price, marketing promotions and seasonal trends impact sales.\n\nNow that we have understood about linear regression, its assumption and its type now we will learn how to make a linear regression model.\n\n## Cost function for Linear Regression\n\nAs we have discussed earlier about best fit line in linear regression, its not easy to get it easily in real life cases so we need to calculate errors that affects it. These errors need to be calculated to mitigate them. The difference between the predicted value\\hat{Y}and the true value Y and it is called [cost function](https://www.geeksforgeeks.org/microeconomics/what-is-cost-function/) or the [loss function](https://www.geeksforgeeks.org/machine-learning/ml-common-loss-functions/).\n\nIn Linear Regression, the Mean Squared Error (MSE) cost function is employed, which calculates the average of the squared errors between the predicted values \\hat{y}_i and the actual values {y}_i. The purpose is to determine the optimal values for the intercept \\theta_1 and the coefficient of the input feature \\theta_2 providing the best-fit line for the given data points. The linear equation expressing this relationship is \\hat{y}_i = \\theta_1 + \\theta_2x_i.\n\nMSE function can be calculated as:\n\n> \\text{Cost function}(J) = \\frac{1}{n}\\sum_{n}^{i}(\\hat{y_i}-y_i)^2\n\nUtilizing the MSE function, the iterative process of gradient descent is applied to update the values of \\theta_1 \\& \\theta_2 . This ensures that the MSE value converges to the global minima, signifying the most accurate fit of the linear regression line to the dataset.\n\nThis process involves continuously adjusting the parameters (\\theta_1) and (\\theta_2) based on the gradients calculated from the MSE. The final result is a linear regression line that minimizes the overall squared differences between the predicted and actual values, providing an optimal representation of the underlying relationship in the data.\n\nNow we have calculated loss function we need to optimize model to mtigate this error and it is done through gradient descent.\n\n## Gradient Descent for Linear Regression\n\nGradient descent is an optimization technique used to train a linear regression model by minimizing the prediction error. It works by starting with random model parameters and repeatedly adjusting them to reduce the difference between predicted and actual values.\n\n![Gradient Descent](https://media.geeksforgeeks.org/wp-content/uploads/20230424151248/Gradient-Descent-for-ML-Linear-Regression-(1).webp)\n\nHow it works:\n\n- Start with random values for slope and intercept.\n- Calculate the error between predicted and actual values.\n- Find how much each parameter contributes to the error (gradient).\n- Update the parameters in the direction that reduces the error.\n- Repeat until the error is as small as possible.\n\nThis helps the model find the best-fit line for the data.\n\nFor more details you can refer to: [Gradient Descent in Linear Regression](https://www.geeksforgeeks.org/machine-learning/gradient-descent-in-linear-regression/)\n\n## Evaluation Metrics for Linear Regression\n\nA variety of [evaluation measures](https://www.geeksforgeeks.org/machine-learning/metrics-for-machine-learning-model/) can be used to determine the strength of any linear regression model. These assessment metrics often give an indication of how well the model is producing the observed outputs.\n\nThe most common measurements are:\n\n### 1. Mean Square Error (MSE)\n\n[Mean Squared Error (MSE)](https://www.geeksforgeeks.org/python/python-mean-squared-error/) is an evaluation metric that calculates the average of the squared differences between the actual and predicted values for all the data points. The difference is squared to ensure that negative and positive differences don't cancel each other out.\n\n> MSE = \\frac{1}{n}\\sum_{i=1}^{n}\\left ( y_i - \\widehat{y_{i}} \\right )^2\n\nHere,\n\n- n is the number of data points.\n- y_i is the actual or observed value for thei^{th} data point.\n- \\widehat{y_{i}} is the predicted value for the i^{th} data point.\n\nMSE is a way to quantify the accuracy of a model's predictions. MSE is sensitive to outliers as large errors contribute significantly to the overall score.\n\n### 2. Mean Absolute Error (MAE)\n\n[Mean Absolute Error](https://www.geeksforgeeks.org/python/how-to-calculate-mean-absolute-error-in-python/) is an evaluation metric used to calculate the accuracy of a regression model. MAE measures the average absolute difference between the predicted values and actual values.\n\nMathematically MAE is expressed as:\n\n> MAE =\\frac{1}{n} \\sum_{i=1}^{n}\\|Y_i - \\widehat{Y_i}\\|\n\nHere,\n\n- n is the number of observations\n- Yi represents the actual values.\n- \\widehat{Y_i} represents the predicted values\n\nLower MAE value indicates better model performance. It is not sensitive to the outliers as we consider absolute differences.\n\n### 3. Root Mean Squared Error (RMSE)\n\nThe square root of the residuals' variance is the [Root Mean Squared Error](https://www.geeksforgeeks.org/r-language/root-mean-square-error-in-r-programming/). It describes how well the observed data points match the expected values or the model's absolute fit to the data. \nIn mathematical notation, it can be expressed as:\n\n> RMSE=\\sqrt{\\frac{RSS}{n}}=\\sqrt\\frac{{{\\sum_{i=2}^{n}(y^{actual}_{i}}- y_{i}^{predicted})^2}}{n}\n\nRather than dividing the entire number of data points in the model by the number of degrees of freedom, one must divide the sum of the squared residuals to obtain an unbiased estimate. Then, this figure is referred to as the Residual Standard Error (RSE).\n\nIn mathematical notation, it can be expressed as:\n\n> RMSE=\\sqrt{\\frac{RSS}{n}}=\\sqrt\\frac{{{\\sum_{i=2}^{n}(y^{actual}_{i}}- y_{i}^{predicted})^2}}{(n-2)}\n\nRSME is not as good of a metric as R-squared. Root Mean Squared Error can fluctuate when the units of the variables vary since its value is dependent on the variables' units (it is not a normalized measure).\n\n### 4. Coefficient of Determination (R-squared)\n\n[R-Squared](https://www.geeksforgeeks.org/maths/r-squared/) is a statistic that indicates how much variation the developed model can explain or capture. It is always in the range of 0 to 1. In general, the better the model matches the data, the greater the R-squared number.  \nIn mathematical notation, it can be expressed as:\n\n> R^{2}=1-\\left(\\frac{RSS}{TSS}\\right)\n\n- **[Residual sum of Squares](https://www.geeksforgeeks.org/maths/residual-sum-of-squares/#:~:text=Residual%20sum%20of%20squares%20is%20used%20to%20calculate%20the%20variance,squares%2C%20the%20better%20the%20model.)(RSS):** The sum of squares of the residual for each data point in the plot or data is known as the residual sum of squares or RSS. It is a measurement of the difference between the output that was observed and what was anticipated.\n\n> RSS=\\sum_{i=1}^{n}(y_{i}-b_{0}-b_{1}x_{i})^{2}\n\n- **Total Sum of Squares (TSS):** The sum of the data points' errors from the answer variable's mean is known as the total sum of squares or TSS.\n\n> TSS=\\sum_{i=1}^{n}(y-\\overline{y_{i}})^2.\n\nR squared metric is a measure of the proportion of variance in the dependent variable that is explained the independent variables in the model.\n\n### 5. Adjusted R-Squared Error\n\nAdjusted R^2 measures the proportion of variance in the dependent variable that is explained by independent variables in a regression model. [Adjusted R-square](https://www.geeksforgeeks.org/machine-learning/ml-adjusted-r-square-in-regression-analysis/) accounts the number of predictors in the model and penalizes the model for including irrelevant predictors that don't contribute significantly to explain the variance in the dependent variables.\n\nMathematically, adjusted R^2 is expressed as:\n\n> Adjusted \\, R^2 = 1 - \\left(\\frac{(1-R^2\\.).(n-1)}{n-k-1}\\right)\n\nHere,\n\n- n is the number of observations\n- k is the number of predictors in the model\n- R2  is coeeficient of determination\n\nAdjusted R-square helps to prevent overfitting. It penalizes the model with additional predictors that do not contribute significantly to explain the variance in the dependent variable.\n\nWhile evaluation metrics help us measure the performance of a model, regularization helps in improving that performance by addressing overfitting and enhancing generalization.\n\n## Regularization Techniques for Linear Models\n\n### 1. Lasso Regression (L1 Regularization)\n\n[Lasso Regression](https://www.geeksforgeeks.org/machine-learning/implementation-of-lasso-regression-from-scratch-using-python/) is a technique used for regularizing a linear regression model, it adds a penalty term to the linear regression objective function to prevent [overfitting](https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/).\n\nThe objective function after applying lasso regression is:\n\n> J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m}(\\widehat{y_i} - y_i) ^2+ \\lambda \\sum_{j=1}^{n}\\|\\theta_j\\|\n\n- the first term is the least squares loss, representing the squared difference between predicted and actual values.\n- the second term is the L1 regularization term, it penalizes the sum of absolute values of the regression coefficient θj.\n\n### 2. Ridge Regression (L2 Regularization)\n\n[Ridge regression](https://www.geeksforgeeks.org/machine-learning/implementation-of-ridge-regression-from-scratch-using-python/) is a linear regression technique that adds a regularization term to the standard linear objective. Again, the goal is to prevent overfitting by penalizing large coefficient in linear regression equation. It useful when the dataset has multicollinearity where predictor variables are highly correlated.\n\nThe objective function after applying ridge regression is:\n\n> J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m}(\\widehat{y_i} - y_i)^2 + \\lambda \\sum_{j=1}^{n}\\theta_{j}^{2}\n\n- the first term is the least squares loss, representing the squared difference between predicted and actual values.\n- the second term is the L1 regularization term, it penalizes the sum of square of values of the regression coefficient θj.\n\n### 3. Elastic Net Regression\n\n[Elastic Net Regression](https://www.geeksforgeeks.org/machine-learning/implementation-of-elastic-net-regression-from-scratch/) is a hybrid regularization technique that combines the power of both L1 and L2 regularization in linear regression objective.\n\n> J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m}(\\widehat{y_i} - y_i)^2 + \\alpha \\lambda \\sum_{j=1}^{n}{\\|\\theta_j\\|} + \\frac{1}{2}(1- \\alpha) \\lambda \\sum_{j=1}{n} \\theta_{j}^{2}\n\n- the first term is least square loss.\n- the second term is L1 regularization and third is ridge regression.\n- \\lambda is the overall regularization strength.\n- \\alpha controls the mix between L1 and L2 regularization.\n\nNow that we have learned how to make a linear regression model, now we will implement it.\n\n## Python Implementation of Linear Regression\n\n### 1. Import the necessary libraries:\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.axes as ax\nfrom matplotlib.animation import FuncAnimation\n```\n\n### 2. Load the dataset and separate input and Target variables\n\nHere is the link for dataset: [Dataset Link](https://media.geeksforgeeks.org/wp-content/uploads/20240320114716/data_for_lr.csv)\n\n```python\nurl = 'https://media.geeksforgeeks.org/wp-content/uploads/20240320114716/data_for_lr.csv'\ndata = pd.read_csv(url)\n\ndata = data.dropna()\n\ntrain_input = np.array(data.x[0:500]).reshape(500, 1)\ntrain_output = np.array(data.y[0:500]).reshape(500, 1)\n\ntest_input = np.array(data.x[500:700]).reshape(199, 1)\ntest_output = np.array(data.y[500:700]).reshape(199, 1)\n```\n\n### 3. Build the Linear Regression Model and Plot the regression line\n\nIn forward propagation Linear regression function Y=mx+c is applied by initially assigning random value of parameter (m and c). The we have written the function to finding the cost function i.e the mean\n\n```python\nclass LinearRegression: \n    def __init__(self): \n        self.parameters = {}\n\ndef forward_propagation(self, train_input): \n    m = self.parameters['m'] \n    c = self.parameters['c'] \n    predictions = np.multiply(m, train_input) + c \n    return predictions\n\ndef cost_function(self, predictions, train_output): \n    cost = np.mean((train_output - predictions) ** 2) \n    return cost\n\ndef backward_propagation(self, train_input, train_output, predictions): \n    derivatives = {} \n    df = (predictions-train_output) \n    dm = 2 * np.mean(np.multiply(train_input, df)) \n    dc = 2 * np.mean(df) \n    derivatives['dm'] = dm \n    derivatives['dc'] = dc \n    return derivatives\n\ndef update_parameters(self, derivatives, learning_rate): \n    self.parameters['m'] = self.parameters['m'] - learning_rate * derivatives['dm'] \n    self.parameters['c'] = self.parameters['c'] - learning_rate * derivatives['dc']\n\ndef train(self, train_input, train_output, learning_rate, iters): \n    self.parameters['m'] = np.random.uniform(0, 1) * -1\n    self.parameters['c'] = np.random.uniform(0, 1) * -1\n\n    self.loss = []\n\n    fig, ax = plt.subplots() \n    x_vals = np.linspace(min(train_input), max(train_input), 100) \n    line, = ax.plot(x_vals, self.parameters['m'] * x_vals + self.parameters['c'], color='red', label='Regression Line') \n    ax.scatter(train_input, train_output, marker='o', color='green', label='Training Data')\n\n    ax.set_ylim(0, max(train_output) + 1)\n\n    def update(frame): \n        predictions = self.forward_propagation(train_input) \n        cost = self.cost_function(predictions, train_output) \n        derivatives = self.backward_propagation(train_input, train_output, predictions) \n        self.update_parameters(derivatives, learning_rate) \n        line.set_ydata(self.parameters['m'] * x_vals + self.parameters['c']) \n        self.loss.append(cost) \n        print(\"Iteration = {}, Loss = {}\".format(frame + 1, cost)) \n        return line,\n\n    ani = FuncAnimation(fig, update, frames=iters, interval=200, blit=True) \n    ani.save('linear_regression_A.gif', writer='ffmpeg')\n\n    plt.xlabel('Input') \n    plt.ylabel('Output') \n    plt.title('Linear Regression') \n    plt.legend() \n    plt.show()\n\n    return self.parameters, self.loss\n```\n\nThe linear regression line provides valuable insights into the relationship between the two variables. It represents the best-fitting line that captures the overall trend of how a dependent variable (Y) changes in response to variations in an independent variable (X).\n\n- **Positive Linear Regression Line**: A positive linear regression line indicates a direct relationship between the independent variable (X) and the dependent variable (Y). This means that as the value of X increases, the value of Y also increases. The slope of a positive linear regression line is positive, meaning that the line slants upward from left to right.\n- **Negative Linear Regression Line**: A negative linear regression line indicates an inverse relationship between the independent variable (X) and the dependent variable (Y ). This means that as the value of X increases, the value of Y decreases. The slope of a negative linear regression line is negative, meaning that the line slants downward from left to right.\n\n### 4. Trained the model and Final Prediction\n\n```python\nlinear_reg = LinearRegression()\nparameters, loss = linear_reg.train(train_input, train_output, 0.0001, 20)\n```\n\n**Output**:\n\n![Model Training](https://media.geeksforgeeks.org/wp-content/uploads/20250514161415540322/model-training.png)\n\n## Applications of Linear Regression\n\nLinear regression is used in many different fields including finance, economics and psychology to understand and predict the behavior of a particular variable.\n\nFor example linear regression is widely used in finance to analyze relationships and make predictions. It can model how a company's earnings per share (EPS) influence its stock price. If the model shows that a $1 increase in EPS results in a $15 rise in stock price, investors gain insights into the company's valuation. Similarly, linear regression can forecast currency values by analyzing historical exchange rates and economic indicators, helping financial professionals make informed decisions and manage risks effectively.\n\nAlso read - [Linear Regression - In Simple Words, with real-life Examples](https://www.geeksforgeeks.org/machine-learning/linear-regression-real-life-examples/)\n\n## Advantages and Disadvantages of Linear Regression\n\n### Advantages of Linear Regression\n\n- Linear regression is a relatively simple algorithm, making it easy to understand and implement. The coefficients of the linear regression model can be interpreted as the change in the dependent variable for a one-unit change in the independent variable, providing insights into the relationships between variables.\n- Linear regression is computationally efficient and can handle large datasets effectively. It can be trained quickly on large datasets, making it suitable for real-time applications.\n- Linear regression is relatively robust to outliers compared to other machine learning algorithms. Outliers may have a smaller impact on the overall model performance.\n- Linear regression often serves as a good baseline model for comparison with more complex machine learning algorithms.\n- Linear regression is a well-established algorithm with a rich history and is widely available in various machine learning libraries and software packages.\n\n### Disadvantages of Linear Regression\n\n- Linear regression assumes a linear relationship between the dependent and independent variables. If the relationship is not linear, the model may not perform well.\n- Linear regression is sensitive to multicollinearity, which occurs when there is a high correlation between independent variables. Multicollinearity can inflate the variance of the coefficients and lead to unstable model predictions.\n- Linear regression assumes that the features are already in a suitable form for the model. Feature engineering may be required to transform features into a format that can be effectively used by the model.\n- Linear regression is susceptible to both overfitting and underfitting. Overfitting occurs when the model learns the training data too well and fails to generalize to unseen data. Underfitting occurs when the model is too simple to capture the underlying relationships in the data.\n- Linear regression provides limited explanatory power for complex relationships between variables. More advanced machine learning techniques may be necessary for deeper insights."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/", "content": "# Feature Selection Techniques in Machine Learning\n\nFeature selection is a core step in preparing data for machine learning where the goal is to identify and keep only the input features that contribute most to accurate predictions. By focusing on the most relevant variables, feature selection helps build models that are simpler, faster, less prone to overfitting and easier to interpret especially when we use datasets containing many features, some of which may be irrelevant or redundant.\n\n## Need of Feature Selection\n\nFeature selection methods are essential in data science and machine learning for several key reasons:\n\n- **Improved Accuracy**: Focusing only on the most relevant features enables models to learn more effectively often resulting in higher predictive accuracy.\n- **Faster Training**: With fewer features to process, models train more quickly and require less computational power hence saving time.\n- **Greater Interpretability**: Reducing the number of features makes it easier to understand, analyze and explain how a model makes its decisions which is helpful for debugging and transparency.\n- **Avoiding the Curse of Dimensionality**: Limiting feature count prevents models from being overwhelmed in high-dimensional spaces which helps in maintain performance and reliable results.\n\n## Types of Feature Selection Methods\n\nThere are various algorithms used for feature selection and are grouped into three main categories and each one has its own strengths and trade-offs depending on the use case.\n\n### 1. Filter Methods\n\nFilter methods evaluate each feature independently with target variable. Feature with high correlation with target variable are selected as it means this feature has some relation and can help us in making predictions. These methods are used in the preprocessing phase to remove irrelevant or redundant features based on statistical tests (correlation) or other criteria.\n\n![Filter Method](https://media.geeksforgeeks.org/wp-content/uploads/20250830103247936857/filter.webp)\n\n#### Advantages\n\n- **Fast and efficient**: Filter methods are computationally inexpensive, making them ideal for large datasets.\n- **Easy to implement**: These methods are often built-in to popular machine learning libraries, requiring minimal coding effort.\n- **Model Independence**: Filter methods can be used with any type of machine learning model, making them versatile tools.\n\n#### Limitations\n\n- **Limited interaction with the model**: Since they operate independently, filter methods might miss data interactions that could be important for prediction.\n- **Choosing the right metric**: Selecting the appropriate metric for our data and task is crucial for optimal performance.\n\nSome techniques used are:\n\n- **Information Gain**: It is defined as the amount of information provided by the feature for identifying the target value and measures reduction in the entropy values. Information gain of each attribute is calculated considering the target values for feature selection. ([Information Gain and Mutual Information for Machine Learning](https://www.geeksforgeeks.org/machine-learning/information-gain-and-mutual-information-for-machine-learning/))\n- **Chi-square test**: It is generally used to test the relationship between categorical variables. It compares the observed values from different attributes of the dataset to its expected value. ([Chi-square Test](https://www.geeksforgeeks.org/maths/chi-square-test/))\n- **Fisher’s Score**: It selects each feature independently according to their scores under Fisher criterion leading to a suboptimal set of features. Larger the Fisher’s score means selected feature is better to choose. ([Fisher's F-Test in R Programming](https://www.geeksforgeeks.org/r-language/fishers-f-test-in-r-programming/))\n- **Pearson’s Correlation Coefficient**: It is a measure of quantifying the association between the two continuous variables and the direction of the relationship with its values ranging from -1 to 1. ([Pearson Correlation Coefficient](https://www.geeksforgeeks.org/maths/pearson-correlation-coefficient/))\n- **Variance Threshold**: It is an approach where all features are removed whose variance doesn’t meet the specific threshold. By default this method removes features having zero variance. The assumption made using this method is higher variance features are likely to contain more information. ([Variance Threshold](https://www.geeksforgeeks.org/machine-learning/variance-threshold/))\n- **Mean Absolute Difference**: It is a method is similar to variance threshold method but the difference is there is no square in this method. This method calculates the mean absolute difference from the mean value. ([Mean Absolute Deviation](https://www.geeksforgeeks.org/maths/mean-absolute-deviation/))\n- **Dispersion ratio**: It is defined as the ratio of the Arithmetic mean (AM) to that of Geometric mean (GM) for a given feature. Its value ranges from +1 to infinity as AM ≥ GM for a given feature. Higher dispersion ratio implies a more relevant feature. ([Measures of Dispersion](https://www.geeksforgeeks.org/maths/measures-of-dispersion/))\n\n### 2. Wrapper methods\n\nWrapper methods are also referred as greedy algorithms that train algorithm. They use different combination of features and compute relation between these subset features and target variable and based on conclusion addition and removal of features are done. Stopping criteria for selecting the best subset are usually pre-defined by the person training the model such as when the performance of the model decreases or a specific number of features are achieved.\n\n![Wrapper Method](https://media.geeksforgeeks.org/wp-content/uploads/20250830104446954251/wrapper.webp)\n\n#### Advantages\n\n- **Model-specific optimization**: Wrapper methods directly consider how features influence the model, potentially leading to better performance compared to filter methods.\n- **Flexible**: These methods can be adapted to various model types and evaluation metrics.\n\n#### Limitations\n\n- **Computationally expensive**: Evaluating different feature combinations can be time-consuming, especially for large datasets.\n- **Risk of overfitting**: Fine-tuning features to a specific model can lead to an overfitted model that performs poorly on unseen data.\n\nSome techniques used are:\n\n- **Forward selection**: This method is an iterative approach where we initially start with an empty set of features and keep adding a feature which best improves our model after each iteration. The stopping criterion is till the addition of a new variable does not improve the performance of the model.\n- **Backward elimination**: This method is also an iterative approach where we initially start with all features and after each iteration, we remove the least significant feature. The stopping criterion is till no improvement in the performance of the model is observed after the feature is removed.\n- **Recursive elimination**: [Recursive Feature Elimination with Cross-Validation in Scikit Learn](https://www.geeksforgeeks.org/machine-learning/recursive-feature-elimination-with-cross-validation-in-scikit-learn/) is a greedy method that selects features by recursively removing the least important ones. It trains a model, ranks features based on importance and eliminates them one by one until the desired number of features is reached.\n\n### 3. Embedded methods\n\nEmbedded methods perform feature selection during the model training process. They combine the benefits of both filter and wrapper methods. Feature selection is integrated into the model training allowing the model to select the most relevant features based on the training process dynamically.\n\n![Embedded Method](https://media.geeksforgeeks.org/wp-content/uploads/20250830104521819821/embedded.webp)\n\n#### Advantages\n\n- **Efficient and effective**: Embedded methods can achieve good results without the computational burden of some wrapper methods.\n- **Model-specific learning**: Similar to wrapper methods these techniques usees the learning process to identify relevant features.\n\n#### Limitations\n\n- **Limited interpretability**: Embedded methods can be more challenging to interpret compared to filter methods making it harder to understand why specific features were chosen.\n- **Not universally applicable**: Not all machine learning algorithms support embedded feature selection techniques.\n\nSome techniques used are:\n\n- **L1 Regularization (Lasso)**: A regression method that applies L1 regularization to encourage sparsity in the model. Features with non-zero coefficients are considered important. ([What is Lasso Regression](https://www.geeksforgeeks.org/machine-learning/what-is-lasso-regression/))\n- **Decision Trees** and **Random Forests**: These algorithms naturally perform feature selection by selecting the most important features for splitting nodes based on criteria like Gini impurity or information gain. ([Decision Tree](https://www.geeksforgeeks.org/machine-learning/decision-tree/), [Random Forest Algorithm in Machine Learning](https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/))\n- **Gradient Boosting**: Like random forests gradient boosting models select important features while building trees by prioritizing features that reduce error the most. ([ML Gradient Boosting](https://www.geeksforgeeks.org/machine-learning/ml-gradient-boosting/))\n\n## Choosing the Right Feature Selection Method\n\nChoice of feature selection method depends on several factors:\n\n- **Dataset size**: Filter methods are generally faster for large datasets while wrapper methods might be suitable for smaller datasets.\n- **Model type**: Some models like tree-based models, have built-in feature selection capabilities.\n- **Interpretability**: If understanding the rationale behind feature selection is crucial, filter methods might be a better choice.\n- **Computational resources**: Wrapper methods can be time-consuming, so consider our available computing power.\n\nWith these feature selection methods we can easily improve performance of our model and reduce its computational cost."}
{"reference": "https://www.geeksforgeeks.org/python/statistics-with-python/", "content": "# Statistics with Python\n\n**Last Updated**: 23 Jul, 2025\n\n****Statistics****, in general, is the method of collection of data, tabulation, and interpretation of numerical data. It is an area of applied mathematics concerned with data collection analysis, interpretation, and presentation. With statistics, we can see how data can be used to solve complex problems.\n\nIn this tutorial, we will learn about solving statistical problems with [Python](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/) and will also learn the concept behind it. Let's start by understanding some concepts that will be useful throughout the article.\n\n****Note:**** We will be covering [descriptive statistics](https://www.geeksforgeeks.org/maths/descriptive-statistics/) with the help of the statistics module provided by Python.\n\n## Understanding the Descriptive Statistics\n\nIn layman's terms, descriptive statistics generally means describing the data with the help of some representative methods like charts, tables, Excel files, etc. The data is described in such a way that it can express some meaningful information that can also be used to find some future trends. Describing and summarizing a single variable is called ****univariate analysis.**** Describing a statistical relationship between two variables is called ****bivariate analysis.**** Describing the statistical relationship between multiple variables is called ****multivariate analysis.****\n\n****There are two types of Descriptive Statistics:****\n\n+ The measure of central tendency\n+ Measure of variability\n\n![Types of Descriptive Statistics](https://media.geeksforgeeks.org/wp-content/uploads/20200310224503/TypesOfStatistic-1.png)\n\n## Measure of Central Tendency\n\nThe measure of central tendency is a single value that attempts to describe the whole set of data. There are three main features of central tendency:\n\n+ Mean\n+ Median\n  - Median Low\n  - Median High\n+ Mode\n\n![The measure of Central Tendency](https://media.geeksforgeeks.org/wp-content/uploads/20200310224543/TypesOFCentralTendency-1.png)\n\n### Mean\n\nIt is the sum of observations divided by the total number of observations. It is also defined as average which is the sum divided by count.\n\nMean (\\(\\overline{x}\\)) = \\(\\frac{\\sum{x}}{n}\\)\n\nThe [****mean()****](https://www.geeksforgeeks.org/python/python-statistics-mean-function/)function returns the mean or average of the data passed in its arguments. If the passed argument is empty, ****StatisticsError**** is raised.\n\n****Example:**** Python code to calculate mean\n\n```python\n# Python code to demonstrate the working of \n# mean()\n\n# importing statistics to handle statistical\n# operations \nimport statistics\n\n# initializing list \nli = [1, 2, 3, 3, 2, 2, 2, 1]\n\n# using mean() to calculate average of list\n# elements \nprint (\"The average of list values is : \",end=\"\") \nprint (statistics.mean(li))\n```\n\n****Output:****\n\n```\nThe average of list values is : 2\n```\n\n### Median\n\nIt is the middle value of the data set. It splits the data into two halves. If the number of elements in the data set is odd then the center element is the median and if it is even then the median would be the average of two central elements. it first sorts the data i=and then performs the median operation\n\n****For Odd Numbers:****\n\n\\(\\frac{n+1}{2}\\)\n\n****For Even Numbers:****\n\n\\(\\frac{\\frac{n}{2} + (\\frac{n}{2}+1)}{2}\\)\n\nThe [****median()****](https://www.geeksforgeeks.org/python/python-statistics-median/) function is used to calculate the median, i.e middle element of data. If the passed argument is empty, ****StatisticsError**** is raised.\n\n****Example:**** Python code to calculate Median\n\n```python\n# Python code to demonstrate the \n# working of median() on various \n# range of data-sets\n\n# importing the statistics module \nfrom statistics import median\n\n# Importing fractions module as fr \nfrom fractions import Fraction as fr\n\n# tuple of positive integer numbers \ndata1 = (2, 3, 4, 5, 7, 9, 11)\n\n# tuple of floating point values \ndata2 = (2.4, 5.1, 6.7, 8.9)\n\n# tuple of fractional numbers \ndata3 = (fr(1, 2), fr(44, 12), \n        fr(10, 3), fr(2, 3))\n\n# tuple of a set of negative integers \ndata4 = (-5, -1, -12, -19, -3)\n\n# tuple of set of positive \n# and negative integers \ndata5 = (-1, -2, -3, -4, 4, 3, 2, 1)\n\n# Printing the median of above datasets \nprint(\"Median of data-set 1 is % s\" % (median(data1))) \nprint(\"Median of data-set 2 is % s\" % (median(data2))) \nprint(\"Median of data-set 3 is % s\" % (median(data3))) \nprint(\"Median of data-set 4 is % s\" % (median(data4))) \nprint(\"Median of data-set 5 is % s\" % (median(data5)))\n```\n\n****Output:****\n\n```\nMedian of data-set 1 is 5  \nMedian of data-set 2 is 5.9  \nMedian of data-set 3 is 2  \nMedian of data-set 4 is -5  \nMedian of data-set 5 is 0.0\n```\n\n### Median Low\n\nThe [****median_low()****](https://www.geeksforgeeks.org/python/median_low-python-statistics/) function returns the median of data in case of odd number of elements, but in case of even number of elements, returns the lower of two middle elements. If the passed argument is empty, ****StatisticsError**** is raised\n\n****Example:**** Python code to calculate Median Low\n\n```python\n# Python code to demonstrate the \n# working of median_low()\n\n# importing the statistics module \nimport statistics\n\n# simple list of a set of integers \nset1 = [1, 3, 3, 4, 5, 7]\n\n# Print median of the data-set\n\n# Median value may or may not \n# lie within the data-set \nprint(\"Median of the set is % s\"\n    % (statistics.median(set1)))\n\n# Print low median of the data-set \nprint(\"Low Median of the set is % s \"\n    % (statistics.median_low(set1)))\n```\n\n****Output:****\n\n```\nMedian of the set is 3.5  \nLow Median of the set is 3 \n```\n\n### Median High\n\nThe [****median_high()****](https://www.geeksforgeeks.org/python/python-statistics-median_high/) function returns the median of data in case of odd number of elements, but in case of even number of elements, returns the higher of two middle elements. If passed argument is empty, ****StatisticsError**** is raised.\n\n****Example:**** Python code to calculate Median High\n\n```python\n# Working of median_high() and median() to \n# demonstrate the difference between them.\n\n# importing the statistics module \nimport statistics\n\n# simple list of a set of integers \nset1 = [1, 3, 3, 4, 5, 7]\n\n# Print median of the data-set\n\n# Median value may or may not \n# lie within the data-set \nprint(\"Median of the set is %s\"\n    % (statistics.median(set1)))\n\n# Print high median of the data-set \nprint(\"High Median of the set is %s \"\n    % (statistics.median_high(set1)))\n```\n\n****Output:****\n\n```\nMedian of the set is 3.5  \nHigh Median of the set is 4 \n```\n\n### Mode\n\nIt is the value that has the highest frequency in the given data set. The data set may have no mode if the frequency of all data points is the same. Also, we can have more than one mode if we encounter two or more data points having the same frequency.\n\nThe [****mode()****](https://www.geeksforgeeks.org/python/python-statistics-mode-function/) function returns the number with the maximum number of occurrences. If the passed argument is empty, ****StatisticsError**** is raised.\n\n****Example:**** Python code to calculate Mode\n\n```python\n# Python code to demonstrate the \n# working of mode() function \n# on a various range of data types\n\n# Importing the statistics module \nfrom statistics import mode\n\n# Importing fractions module as fr \n# Enables to calculate harmonic_mean of a \n# set in Fraction \nfrom fractions import Fraction as fr\n\n# tuple of positive integer numbers \ndata1 = (2, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 7)\n\n# tuple of a set of floating point values \ndata2 = (2.4, 1.3, 1.3, 1.3, 2.4, 4.6)\n\n# tuple of a set of fractional numbers \ndata3 = (fr(1, 2), fr(1, 2), fr(10, 3), fr(2, 3))\n\n# tuple of a set of negative integers \ndata4 = (-1, -2, -2, -2, -7, -7, -9)\n\n# tuple of strings \ndata5 = (\"red\", \"blue\", \"black\", \"blue\", \"black\", \"black\", \"brown\")\n\n# Printing out the mode of the above data-sets \nprint(\"Mode of data set 1 is % s\" % (mode(data1))) \nprint(\"Mode of data set 2 is % s\" % (mode(data2))) \nprint(\"Mode of data set 3 is % s\" % (mode(data3))) \nprint(\"Mode of data set 4 is % s\" % (mode(data4))) \nprint(\"Mode of data set 5 is % s\" % (mode(data5)))\n```\n\n****Output:****\n\n```\nMode of data set 1 is 5  \nMode of data set 2 is 1.3  \nMode of data set 3 is 1/2  \nMode of data set 4 is -2  \nMode of data set 5 is black\n```\n\nRefer to the below article to get detailed information about averages and Measures of central tendency.\n\n+ [Statistical Functions in Python | Set 1 (Averages and Measure of Central Location)](https://www.geeksforgeeks.org/python/statistical-functions-python-set-1averages-measure-central-location/)\n\n## Measure of Variability\n\nTill now, we have studied the measure of central tendency but this alone is not sufficient to describe the data. To overcome this we need the ****measure of variability****. The measure of variability is known as the spread of data or how well our data is distributed. The most common variability measures are:\n\n+ Range\n+ Variance\n+ Standard deviation\n\n![Measure of Variability](https://media.geeksforgeeks.org/wp-content/uploads/20200310232355/TypesOfVariance-final-1.png)\n\n### Range\n\nThe difference between the largest and smallest data point in our data set is known as the range. The range is directly proportional to the spread of data which means the bigger the range, the more the spread of data and vice versa.\n\n> Range = Largest data value – smallest data value\n\nWe can calculate the maximum and minimum values using the [****max()****](https://www.geeksforgeeks.org/python/python-max-function/) and [****min()****](https://www.geeksforgeeks.org/python/python-min-function/) methods respectively.\n\n****Example:**** Python code to calculate Range\n\n```python\n# Sample Data \narr = [1, 2, 3, 4, 5]\n\n#Finding Max \nMaximum = max(arr)\n# Finding Min \nMinimum = min(arr)\n\n# Difference Of Max and Min\nRange = Maximum-Minimum     \nprint(\"Maximum = {}, Minimum = {} and Range = {}\".format(\n    Maximum, Minimum, Range))\n```\n\n****Output:****\n\n```\nMaximum = 5, Minimum = 1 and Range = 4\n```\n\n### Variance\n\nIt is defined as an average squared deviation from the mean. It is calculated by finding the difference between every data point and the average which is also known as the mean, squaring them, adding all of them, and then dividing by the number of data points present in our data set.\n\n\\(\\sigma^2=\\frac{\\sum(x-\\mu^2)}{N}\\)\n\nwhere N = number of terms\n\nu = Mean\n\nThe statistics module provides the [****variance()****](https://www.geeksforgeeks.org/python/python-statistics-variance/) method that does all the maths behind the scene. If the passed argument is empty, ****StatisticsError**** is raised.\n\n****Example:**** Python code to calculate Variance\n\n```python\n# Python code to demonstrate variance()\n# function on varying range of data-types\n\n# importing statistics module\nfrom statistics import variance\n\n# importing fractions as parameter values\nfrom fractions import Fraction as fr\n\n# tuple of a set of positive integers\n# numbers are spread apart but not very much\nsample1 = (1, 2, 5, 4, 8, 9, 12)\n\n# tuple of a set of negative integers\nsample2 = (-2, -4, -3, -1, -5, -6)\n\n# tuple of a set of positive and negative numbers\n# data-points are spread apart considerably\nsample3 = (-9, -1, -0, 2, 1, 3, 4, 19)\n\n# tuple of a set of fractional numbers\nsample4 = (fr(1, 2), fr(2, 3), fr(3, 4),\n           fr(5, 6), fr(7, 8))\n\n# tuple of a set of floating point values\nsample5 = (1.23, 1.45, 2.1, 2.2, 1.9)\n\n# Print the variance of each samples\nprint(\"Variance of Sample1 is % s \" % (variance(sample1)))\nprint(\"Variance of Sample2 is % s \" % (variance(sample2)))\nprint(\"Variance of Sample3 is % s \" % (variance(sample3)))\nprint(\"Variance of Sample4 is % s \" % (variance(sample4)))\nprint(\"Variance of Sample5 is % s \" % (variance(sample5)))\n```\n\n****Output:****\n\n```\nVariance of Sample1 is 15.80952380952381   \nVariance of Sample2 is 3.5   \nVariance of Sample3 is 61.125   \nVariance of Sample4 is 1/45   \nVariance of Sample5 is 0.17613000000000006 \n```\n\n### Standard Deviation\n\nIt is defined as the square root of the variance. It is calculated by finding the Mean, then subtracting each number from the Mean which is also known as the average, and squaring the result. Adding all the values and then dividing by the no of terms followed by the square root.\n\n\\(\\sigma=\\sqrt\\frac{\\sum(x-\\mu)^2}{N}\\)\n\nwhere N = number of terms\n\nu = Mean\n\nThe [****stdev()****](https://www.geeksforgeeks.org/python/python-statistics-stdev/)method of the statistics module returns the standard deviation of the data. If the passed argument is empty, ****StatisticsError**** is raised.\n\n****Example:**** Python code to calculate Standard Deviation\n\n```python\n# Python code to demonstrate stdev()\n# function on various range of datasets\n\n# importing the statistics module\nfrom statistics import stdev\n\n# importing fractions as parameter values\nfrom fractions import Fraction as fr\n\n# creating a varying range of sample sets\n# numbers are spread apart but not very much\nsample1 = (1, 2, 5, 4, 8, 9, 12)\n\n# tuple of a set of negative integers\nsample2 = (-2, -4, -3, -1, -5, -6)\n\n# tuple of a set of positive and negative numbers\n# data-points are spread apart considerably\nsample3 = (-9, -1, -0, 2, 1, 3, 4, 19)\n\n# tuple of a set of floating point values\nsample4 = (1.23, 1.45, 2.1, 2.2, 1.9)\n\n# Print the standard deviation of\n# following sample sets of observations\nprint(\"The Standard Deviation of Sample1 is % s\"\n      % (stdev(sample1)))\n\nprint(\"The Standard Deviation of Sample2 is % s\"\n      % (stdev(sample2)))\n\nprint(\"The Standard Deviation of Sample3 is % s\"\n      % (stdev(sample3)))\n\nprint(\"The Standard Deviation of Sample4 is % s\"\n      % (stdev(sample4)))\n```\n\n****Output:****\n\n```\nThe Standard Deviation of Sample1 is 3.9761191895520196  \nThe Standard Deviation of Sample2 is 1.8708286933869707  \nThe Standard Deviation of Sample3 is 7.8182478855559445  \nThe Standard Deviation of Sample4 is 0.41967844833872525\n```\n\nRefer to the below article to get detailed information about the Measure of variability.[[Statistical Functions in Python | Set 2 ( Measure of Spread)](https://www.geeksforgeeks.org/python/statistical-functions-in-python-set-2-measure-of-spread/)]"}
{"reference": "https://www.geeksforgeeks.org/python/python-programming-language-tutorial/", "content": "# Python Tutorial - Learn Python Programming Language\n\nPython is one of the most popular programming languages. It’s simple to use, packed with features and supported by a wide range of libraries and frameworks. Its clean syntax makes it beginner-friendly.\n\n- A high-level language, used in web development, data science, automation, AI and more.\n- Known for its readability, which means code is easier to write, understand and maintain.\n- Backed by library support, so we don’t have to build everything from scratch, there’s probably a library that already does what we need.\n\n## Why to Learn Python?\n\n- Requires fewer lines of code compared to other programming languages like Java.\n- Provides Libraries / Frameworks like Django, Flask and many more for Web Development, and Pandas, Tensorflow, Scikit-learn and many more for, AI/ML, Data Science and Data Analysis\n- Cross-platform, works on Windows, Mac and Linux without major changes.\n- Used by top tech companies like Google, Netflix and NASA.\n- Many Python coding job opportunities in Software Development, Data Science and AI/ML.\n\n> Try our ongoing free course [Python Skillup](https://www.geeksforgeeks.org/courses/python-skill-up) with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## First Python Program\n\nHere is a simple Python code, printing a string. We recommend you to edit the code and try to print your own name.\n\n```python\nprint(\"Hello World\")\n```\n\n**Output**\n\n```\nHello World\n```\n\n## 1. Python Basics\n\nIn this section, we’ll cover the basics of Python programming, including installing Python, writing first program, understanding comments and working with variables, keywords and operators.\n\n> Before starting to learn python we need to [install python](https://www.geeksforgeeks.org/python/download-and-install-python-3-latest-version/) on our system.\n\n- [Introduction](https://www.geeksforgeeks.org/python/introduction-to-python/)\n- [Applications](https://www.geeksforgeeks.org/python/python-language-advantages-applications/)\n- [Input and Output](https://www.geeksforgeeks.org/python/input-and-output-in-python/)\n- [Variables](https://www.geeksforgeeks.org/python/python-variables/)\n- [Operators](https://www.geeksforgeeks.org/python/python-operators/)\n- **Quiz:** [Basics](https://www.geeksforgeeks.org/quizzes/python-fundamentals/), [I/O](https://www.geeksforgeeks.org/quizzes/python-input-output/)\n- [Keywords](https://www.geeksforgeeks.org/python/python-keywords/)\n- [Data Types](https://www.geeksforgeeks.org/python/python-data-types/)\n- **Quiz:** [Data Types](https://www.geeksforgeeks.org/quizzes/data-type-gq/), [Numbers](https://www.geeksforgeeks.org/quizzes/python-numbers-1/), [Boolean](https://www.geeksforgeeks.org/quizzes/python-boolean-1/)\n- [Conditional Statements](https://www.geeksforgeeks.org/python/conditional-statements-in-python/)\n- [Loops](https://www.geeksforgeeks.org/python/loops-in-python/)\n- **Quiz:** [Control Flow](https://www.geeksforgeeks.org/quizzes/python-control-flow-conditional-logic-quiz/), [Loops](https://www.geeksforgeeks.org/quizzes/python-loops/)\n\n## 2. Python Functions\n\nIn this section of Python 3 tutorial we'll explore Python function syntax, parameter handling, return values and variable scope. Along the way, we'll also introduce versatile functions like range(), map, filter and lambda functions.\n\n- [Functions](https://www.geeksforgeeks.org/python/python-functions/)\n- [Pass Statement in Function](https://www.geeksforgeeks.org/python/python-pass-statement/)\n- [Global and Local Variables](https://www.geeksforgeeks.org/python/global-local-variables-python/)\n- [Recursion](https://www.geeksforgeeks.org/python/recursion-in-python/)\n- [*args and **kwargs in Function](https://www.geeksforgeeks.org/python/args-kwargs-python/)\n- [‘Self’ as Default Argument](https://www.geeksforgeeks.org/python/why-python-uses-self-as-default-argument/)\n- [First Class Function](https://www.geeksforgeeks.org/python/first-class-functions-python/)\n- [Lambda Function](https://www.geeksforgeeks.org/python/python-lambda-anonymous-functions-filter-map-reduce/)\n- [Map](https://www.geeksforgeeks.org/python/python-map-function/), [Reduce](https://www.geeksforgeeks.org/python/reduce-in-python/) and [Filter Function](https://www.geeksforgeeks.org/python/filter-in-python/)\n- [Inner Function](https://www.geeksforgeeks.org/python/python-inner-functions/)\n- [Decorators](https://www.geeksforgeeks.org/python/decorators-in-python/)\n- **Quiz:** [Functions](https://www.geeksforgeeks.org/quizzes/functions-python-gq/)\n\n## 3. Python Data Structures\n\nPython offers versatile collections of data types, including lists, string, tuples, sets, dictionaries and arrays. In this section, we will learn about each data types in detail.\n\n- [Strings](https://www.geeksforgeeks.org/python/python-string/)\n- [List](https://www.geeksforgeeks.org/python/python-lists/)\n- **Quiz:** [List](https://www.geeksforgeeks.org/quizzes/python-list-quiz/), [String](https://www.geeksforgeeks.org/quizzes/python-string-quiz/)\n- [Tuples](https://www.geeksforgeeks.org/python/python-tuples/)\n- [Dictionary](https://www.geeksforgeeks.org/python/python-dictionary/)\n- **Quiz:** [Tuples](https://www.geeksforgeeks.org/quizzes/python-tuples-quiz/), [Dictionary](https://www.geeksforgeeks.org/quizzes/python-dictionary-quiz/)\n- [Sets](https://www.geeksforgeeks.org/python/python-sets/)\n- [Arrays](https://www.geeksforgeeks.org/python/python-arrays/)\n- [List Comprehension](https://www.geeksforgeeks.org/python/python-list-comprehension/)\n- **Quiz:** [Sets](https://www.geeksforgeeks.org/quizzes/python-sets-quiz/), [Arrays](https://www.geeksforgeeks.org/quizzes/python-arrays-1/), [List Comprehension](https://www.geeksforgeeks.org/quizzes/python-list-comprehension-quiz/)\n\nPython's collections module offers essential data structures, including the following:\n\n- [Counters](https://www.geeksforgeeks.org/python/counters-in-python-set-1/)\n- [Heapq](https://www.geeksforgeeks.org/python/heap-queue-or-heapq-in-python/)\n- [Deque](https://www.geeksforgeeks.org/python/deque-in-python/)\n- [OrderedDict](https://www.geeksforgeeks.org/python/ordereddict-in-python/)\n- [Defaultdict](https://www.geeksforgeeks.org/python/defaultdict-in-python/)\n- **Quiz:** [Counters](https://www.geeksforgeeks.org/quizzes/python-collection-counters/), [Heapq](https://www.geeksforgeeks.org/quizzes/python-heapq/), [Deque](https://www.geeksforgeeks.org/quizzes/python-deque/), [OrderedDict](https://www.geeksforgeeks.org/quizzes/python-ordereddict/)\n\n> To learn data structure and algorithm with python in detail, you can refer to our [DSA with Python](https://www.geeksforgeeks.org/dsa/python-data-structures-and-algorithms/) Tutorial.\n\n## 4. Python OOP Concepts\n\nIn this section, we'll explore the core principles of object-oriented programming (OOP) in Python. From encapsulation to inheritance, polymorphism, abstract classes and iterators, we'll cover the essential concepts that helps you to build modular, reusable and scalable code.\n\n- [Python OOP](https://www.geeksforgeeks.org/python/python-oops-concepts/)\n- [Classes and Objects](https://www.geeksforgeeks.org/python/python-classes-and-objects/)\n- [Polymorphism](https://www.geeksforgeeks.org/python/polymorphism-in-python/)\n- [Inheritance](https://www.geeksforgeeks.org/python/inheritance-in-python/)\n- [Abstraction](https://www.geeksforgeeks.org/python/data-abstraction-in-python/)\n- [Encapsulation](https://www.geeksforgeeks.org/python/encapsulation-in-python/)\n- [Iterators](https://www.geeksforgeeks.org/python/iterators-in-python/)\n- **Quiz:** [OOP](https://www.geeksforgeeks.org/quizzes/python-oops-quiz/)\n\n## 5. Python Exception Handling\n\nIn this section, we'll explore Python Exception Handling that how Python deals with unexpected errors, enabling us to write fault-tolerant code. We'll cover file handling, including reading from and writing to files.\n\n- [Exception Handling](https://www.geeksforgeeks.org/python/python-exception-handling/)\n- [Built-in Exception](https://www.geeksforgeeks.org/python/built-exceptions-python/)\n- [User defined Exception](https://www.geeksforgeeks.org/python/user-defined-exceptions-python-examples/)\n- **Quiz:** [Exception Handling](https://www.geeksforgeeks.org/quizzes/python-exception-handling-quiz/)\n\n## 6. File Handling\n\nIn this section, we will cover file handling, including reading from and writing to files.\n\n- [File Handling](https://www.geeksforgeeks.org/python/file-handling-python/)\n- [Read Files](https://www.geeksforgeeks.org/python/how-to-read-from-a-file-in-python/)\n- [Write/Create Files](https://www.geeksforgeeks.org/python/writing-to-file-in-python/)\n- [OS Module](https://www.geeksforgeeks.org/python/os-module-python-examples/)\n- [pathlib Module](https://www.geeksforgeeks.org/python/pathlib-module-in-python/)\n- [Directory Management](https://www.geeksforgeeks.org/python/python-directory-management/)\n- **Quiz:** [File Handling](https://www.geeksforgeeks.org/quizzes/python-file-handling-quiz/)\n\n## 7. Python Database Handling\n\nIn this section we will learn how to access and work with MySQL and MongoDB databases\n\n- [Python MongoDB Tutorial](https://www.geeksforgeeks.org/python/python-mongodb-tutorial/)\n- [Python MySQL Tutorial](https://www.geeksforgeeks.org/python/python-mysql/)\n\n## 8. Python Packages or Libraries\n\nPython is a huge collection of Python Packages standard libraries that make development easier. These libraries help with a wide range of tasks and can save you a lot of time by providing ready-to-use tools.\n\nSome commonly used types of libraries in Python include:\n\n- [Packages](https://www.geeksforgeeks.org/python/python-packages/)\n- [Built-in Modules](https://www.geeksforgeeks.org/python/python-modules/)\n- [DSA Libraries](https://www.geeksforgeeks.org/python/python-dsa-libraries/)\n- [GUI Libraries](https://www.geeksforgeeks.org/python/python3-gui-application-overview/)\n\n## 9. Data Science with Python\n\n**1. Foundational Libraries**: These are the libraries that form the base for all data science work. Start here to build a strong foundation.\n\n- [NumPy](https://www.geeksforgeeks.org/python/numpy-tutorial/)\n- [Pandas](https://www.geeksforgeeks.org/pandas/pandas-tutorial/)\n- [Matplotlib](https://www.geeksforgeeks.org/python/matplotlib-tutorial/)\n\n**2. Advanced Visualization and Statistical Tools:** Once you’re comfortable with basic data handling and visualization, move to creating cleaner visuals and performing statistical analysis.\n\n- [Seaborn](https://www.geeksforgeeks.org/python/introduction-to-seaborn-python/)\n- [Statsmodel](https://www.geeksforgeeks.org/data-science/statsmodel-library-tutorial/)\n\n**3. Machine Learning Libraries:** After data manipulation and visualization, learn machine learning, starting with simpler models and moving to advanced ones.\n\n- [Scikit-learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/)\n- [XGBoost](https://www.geeksforgeeks.org/machine-learning/xgboost/) /[LightGBM](https://www.geeksforgeeks.org/machine-learning/lightgbm-light-gradient-boosting-machine/)\n\n4. **Deep Learning Frameworks:** If you’re interested in AI and deep learning, these libraries will allow you to build and train neural networks.\n\n- [TensorFlow](https://www.geeksforgeeks.org/deep-learning/tensorflow/) and [Keras](https://www.geeksforgeeks.org/deep-learning/what-is-keras/)\n- [PyTorch](https://www.geeksforgeeks.org/deep-learning/pytorch-learn-with-examples/)\n\n> To learn more, you can refer to [Python for Data Science](https://www.geeksforgeeks.org/data-science/data-science-with-python-tutorial/).\n\n## 10. Web Development with Python\n\n**1. Core Web Frameworks (Backend Development with Python):** These are the tools for building Python-based web applications.\n\n- [Flask](https://www.geeksforgeeks.org/python/flask-tutorial/)\n- [Django](https://www.geeksforgeeks.org/python/django-tutorial/)\n\n**2. Database Integration:** Learn how to connect Python web frameworks to databases for storing and retrieving data.\n\n- [SQLite](https://www.geeksforgeeks.org/sqlite/sqlite-tutorial/)\n- [SQLAlchemy](https://www.geeksforgeeks.org/python/sqlalchemy-introduction/)\n- [Django ORM](https://www.geeksforgeeks.org/python/django-orm-inserting-updating-deleting-data/)\n\n**3. Front-End and Backend Integration:** Learn how to connect Python backends with front-end technologies to create dynamic, full-stack web applications.\n\n- [Jinja2 (Flask)](https://www.geeksforgeeks.org/python/templating-with-jinja2-in-flask/)\n- [Django Templates](https://www.geeksforgeeks.org/python/django-templates/)\n\n**4. API Development:** Learn to build APIs (Application Programming Interfaces) for connecting your backend with front-end apps or other services.\n\n- [Flask-RESTful](https://www.geeksforgeeks.org/python/python-build-a-rest-api-using-flask/)\n- [Django REST Framework (DRF)](https://www.geeksforgeeks.org/python/how-to-create-a-basic-api-using-django-rest-framework/)\n\n> To learn more, you can refer to [Python for Web Development.](https://www.geeksforgeeks.org/python/python-web-development/)\n\n## Python Practice\n\nPython quiz page covers topics including variables, data types, input, output, lists, tuples, dictionaries and sets. The Python Coding Practice Problems page offers exercises on loops, functions, lists, strings, dictionaries, sets and advanced structures like heaps and deques.\n\n- [Quizzes](https://www.geeksforgeeks.org/python/python-quizzes/)\n- [Python Coding Problems](https://www.geeksforgeeks.org/python/python-exercises-practice-questions-and-solutions/)\n\n> This Python tutorial is updated based on latest Python 3.13.1 version."}
{"reference": "https://www.geeksforgeeks.org/user/pawankrgunjan/", "content": "# Pawan Kumar Gunjan - Profile\n\n**Institution:** Amritsar College of Engineering and Technology (ACET) Amritsar  \n**Institute Rank:** 15  \n\n**Organization:** GeeksforGeeks  \n**Languages Used:** Python, C++  \n\n**Coding Score:** 821  \n\n- **Problems Solved:** 396  \n- **Contest Rating:** —  \n\n**Current POTD Streak:** 9/1528 days  \n\n**Contributor Points:** 379  \n\n## Problems Solved by Difficulty\n\n### SCHOOL (1)\n- Reverse an Array\n\n### BASIC (100)\n- Reverse a linked list\n- Delete in a Doubly Linked List\n- Inorder Traversal\n- Reverse a Doubly Linked List\n- Bubble Sort\n- Insertion Sort\n- Right View of Binary Tree\n- Mirror Tree\n- Maximum Width of Tree\n- Height of Binary Tree\n- Balanced Tree Check\n- Kth from End of Linked List\n- Check If Circular Linked List\n- Left View of Binary Tree\n- Queue using two Stacks\n- Remove Duplicates from a Sorted Linked List\n- Postorder Traversal\n- DFS of Graph\n- Stack using Linked List\n- Insert a node in a BST\n- BFS of graph\n- Identical Trees\n- Square Root\n- Insertion at doubly linked list\n- Binary Search\n- BST Keys in a Range\n- You and your books\n- Three way partitioning\n- More than n/k Occurrences\n- Counting Sort\n- Queue Reversal\n- Reverse first K of a Queue\n- Delete Mid of a Stack\n- Swap the array elements\n- Get min at pop\n- Deque Implementations\n- Hashing for pair - 1\n- Hashing for pair - 2\n- Implement Stack Using Array\n- First Set Bit\n- Rightmost different bit\n- Check K-th Bit\n- Factorial Of Number\n- Digits In Factorial\n- GP Term\n- Primality Test\n- Longest Consecutive 1's\n- Exactly 3 Divisors\n- Mean And Median of Array\n- Modular Inverse\n- Power of 2\n- Swap odd and even bits\n- Array Leaders\n- Count 1's in binary array\n- Floor in a Sorted Array\n- Minimum Number in a sorted rotated array\n- Roof Top\n- Intersection of two sorted arrays\n- Closet 0s 1s and 2s\n- Print adjacency list\n- Sum of upper and lower triangles\n- Print Matrix in snake Pattern\n- Transpose of Matrix\n- Interchanging the rows of a Matrix\n- Reversing the columns of a Matrix\n- Matrix Boundary Traversal\n- Exchange matrix columns\n- Separate chaining in Hashing\n- Naive Pattern Search\n- Linear Probing in Hashing\n- Quadratic Probing in Hashing\n- Check if a string is Isogram or not\n- Count Non-Repeated Elements\n- Print Non-Repeated Elements\n- Anagram\n- Winner of an election\n- String Rotated by 2 Places\n- Isomorphic Strings\n- Most Frequent Character\n- Reverse Words\n- Sum of numbers in string\n- Repeating Character\n- Non Repeating Character\n- Removing consecutive duplicates\n- Removing consecutive duplicates - 2\n- Parenthesis Checker\n- Minimum indexed character\n- Generate Binary Numbers\n- Count Digits in a Number\n- Power Set Using Recursion\n- Recursively Sum N Numbers\n- Factorial Using Recursion\n- Check Palindrome\n- Middle Of Stack\n- Uppercase to Lowercase\n- Deque deletion\n- Rotate Deque By K\n- First Repeating Element\n- Union of Arrays with Duplicates\n- Check Equal Arrays\n- Positive Negative Pair\n- Count Elements Greater Than X\n- Count Smaller Than X\n- Find Immediate Smaller Than X\n- Array Update At Index\n- Array Delete And Shift\n- Is Array Sorted\n- Find Immediate Greater Than X\n- Missing in Array\n- Reverse The Array\n- Find nCr\n- String Validation\n- Insert In Sorted Linked List\n- Delete Tail of Linked List\n- Delete Head of Linked List\n- Linked List Delete at Position\n- Is Linked List Sorted\n- Join Two Linked Lists\n- Circular Linked List Head Insert\n- Circular Linked List Tail Insert\n- Circular Linked List Insertion At Position\n- Delete Tail of Circular Linked List\n- Delete Head of Circular Linked List\n- Circular Linked List Delete at Position\n- Delete Tail of Doubly Linked List\n- Delete Head of Doubly Linked List\n- Is The Doubly Linked List Circular\n- Compare Circular Doubly Linked Lists\n- Find Middle of Circular Doubly Linked List\n- Intersection of Arrays with Distinct\n- Find the closest number\n- Left Index\n- String Duplicates Removal\n- Minimize the sum of product\n- Move all negative elements to end\n- Find Pair Given Difference\n- Alternate Positive Negative\n- Convert array into Zig-Zag fashion\n- At Least K Occurrences\n- Find the Highest number\n- Print Square Wall 2\n- Right Angle Triangle 2\n- Check Prime\n- Print Alphabets\n- Capitalize and Count\n- AP Term\n- GP Term\n- Smallest number with sum of digits as N and divisible by 10^N\n- Least Prime Factor\n- Juggler Sequence\n- Print the pattern\n- Sum of k smallest elements in BST\n- Find Union\n- Check Subset\n- Solving queries\n- Test if tuple is distinct\n- Find index\n- Implement Set in Python\n- Implement Dictionary in Python\n- Minimum Sum of Absolute Differences of Pairs\n- Move Last Element to Front of a Linked List\n- Yet another query problem\n- Make sum even\n- Max Min Sum\n- Divisor Game\n- Nearest Perfect Square\n- The Conversion To One\n- A Boolean Matrix Problem\n- Toggle The Middle\n- Without Adjacent\n- K Sum\n- XOR Pair\n- Kth Smallest Difference\n- Doubly Linked List Conversion\n- Average of String\n- Rolling Hash\n- Magic Array\n- Not a palindromic string\n- Chocolate Distribution\n- Equality\n- Minimum Number of Elements\n\n### EASY (181)\n- Quick Sort\n- Binary Tree from Inorder and Postorder\n- Intersection in Y Shaped Lists\n- Diameter of a Binary Tree\n- Heap Sort\n- Merge two sorted linked lists\n- Construct Binary Tree from Parent Array\n- Stack using Queue\n- Delete a node from BST\n- LCA in Binary Tree\n- Two Stacks in an Array\n- Binary Heap Operations\n- Find the number of islands\n- Linked List to Binary Tree\n- Generate IP Addresses\n- Remove loop in Linked List\n- Closest in BST\n- Find triplets with zero sum\n- Level order traversal\n- Peak element\n- Merge Sort for Linked List\n- Binary Tree to CDLL\n- Counting elements in two arrays\n- Foldable Binary Tree\n- Insert in Sorted way in a Sorted DLL\n- Predecessor and Successor\n- Children Sum in a Binary Tree\n- ZigZag Tree Traversal\n- Vertical Width of a Binary Tree\n- Floor in BST\n- Ceil in BST\n- Count set bits\n- Gray to Binary Conversion\n- Maximum AND Value\n- Tower Of Hanoi\n- Reverse array in groups\n- Smallest Positive Missing\n- Power Of Numbers\n- Rearrange an array with O(1) extra space\n- Maximum Index\n- Stock buy and sell\n- Rotate Array\n- Check if array is sorted and rotated\n- Kadane's Algorithm\n- Majority Element\n- Binary Array Sorting\n- Count Inversions\n- Two Repeated Elements\n- Smallest Positive missing number\n- Indexes of Subarray Sum\n- Count the number of possible triangles\n- Sort by Absolute Difference\n- Triplet Sum in Array\n- Merge three sorted arrays\n- Closer to sort\n- Boolean Matrix\n- Spirally traversing a matrix\n- Search in a sorted Matrix\n- Rotate by 90 degree\n- Determinant of a Matrix\n- Subarray with 0 sum\n- Subarray range with given sum\n- Sort Elements by Decreasing Frequency\n- Strings Rotations of Each Other\n- Stock span problem\n- Next Greater Element\n- Infix to Postfix\n- K Sized Subarray Maximum\n- Minimum Platforms\n- M-Coloring Problem\n- Minimum Jumps\n- Minimum number of jumps\n- Allocate Minimum Pages\n- Zero Sum Subarrays\n- Kth Smallest\n- Nth number made of prime digits\n- Count only Repeated\n- Longest Subarray Of Evens And Odds\n- Maximum Water Between Two Buildings\n- Sort 0s, 1s and 2s\n- Count pairs Sum in matrices\n- Check if frequencies can be equal\n- Next Smaller Element\n- Find the N-th character\n- K closest elements\n- Friends Pairing Problem\n- Modular Exponentiation\n- K-Palindrome\n- Next Prime Number\n- Minimum Cost To Make Two Strings Identical\n- Minimum steps to destination\n- Longest Bitonic subsequence\n- Game of Chocolates\n- Fact Digit Sum\n- Smallest sum contiguous subarray\n- Validate Stack Operations\n- Combination Sum Without Repetition\n- Partitions with Given Difference\n- Get the Shadow\n- Binary Tree to DLL\n- AVL Tree Insertion\n- Merge Sort on Doubly Linked List\n- Number of Turns in Binary Tree\n- Trapping Rain Water\n- Max Circular Subarray Sum\n- Pattern Search\n- Merge Without Extra Space\n- Longest repeating and non-overlapping substring\n- Boolean Parenthesization\n- Search Pattern (Rabin-Karp Algorithm)\n- Number of pairs\n- Minimize Max Distance to Gas Station\n- Median of the Subarrays\n- Rolling Hash\n- Find Length of Linked List\n- Queue using Linked List\n- Queue Using Array\n- Preorder Traversal\n- First Occurence\n- Search a node in BST\n- Linked List Insertion At End\n- Minimum element in BST\n- Identical Linked Lists\n- Insert in Middle of Linked List\n- Who has the majority?\n- Array insert at index\n- Array insert at end\n- Operations on Stack\n- Operations on Queue\n- Absolute Value\n- Convert Celsius To Fahrenheit\n- Quadratic Equation Roots\n- Bit Difference\n- Number is sparse or not\n- Binary To Gray Code Conversion\n- Print 1 To N Without Loop\n- Array Search\n- Sorted Array Search\n- Adding two matrices\n- Multiply the matrices\n- Binary String\n- Remove common characters and concatenate\n- Sum of Digits of a Number\n- Power Using Recursion\n- Fibonacci Using Recursion\n- Addition Under Modulo\n- Multiplication Under Modulo\n- Print Array Elements Using Recursion\n- The Sequence\n- GCD Euclid\n- Insert In Stack\n- Reverse Array Using Stack\n- Preorder in BST\n- Inorder in BST\n- Postorder in BST\n- Levelorder in BST\n- Length of String\n- Vowels in String\n- Count Distinct Vowels in String\n- Count Words in String\n- Reverse a String\n- Lowercase to Upercase\n- Panagram Checking\n- Missing Characters in Panagram\n- Insertion in deque\n- Deque Traversal\n- Keypad typing\n- Get Element At Index\n- Maximum and Minimum In Array\n- Print Linked List\n- Sum The Nodes of Linked List\n- Maximum And Minimum In Linked List\n- Search In Linked List\n- Linked List Insertion At Position\n- Display Circular Linked List\n- Length of Circular Linked List\n- Display Doubly Linked List\n- Doubly Linked List Head Insert\n- Doubly Linked List Tail Insert\n- Display Circular Doubly Linked List\n- Implement Dequeue Using Linked List\n- Rotate Array by One\n- Min and Max in Array\n- Swap The Numbers\n- Arithmetic Operators\n- Logical Operators\n- Bitwise Operators\n- Evaluate Formulae\n- Table Difference\n- Print Square\n- Print Square wall\n- Right Angle Triangle\n- Reverse String\n- Inverted Right AngleTriangle\n- Inverted Right Angle Triangle 2\n- Check Palindrome\n- Find Pattern\n- Slice The String\n- Sum of N Numbers\n- Factorial\n- Divisor\n- Function With No Arguments\n- Function With Arguments\n- Function With Return Value\n- Fibonacci Number\n- GCD\n- Change Case\n- For Loop - 1\n- For Loop - 2\n- While Loop\n- TypeCast And Double It\n- Concatenate Integers\n- Minimum At Pop\n- Time Travel\n\n### MEDIUM (99)\n- (List truncated for brevity - includes advanced topics like dynamic programming, graph algorithms, etc.)\n\n### HARD (15)\n- (List truncated for brevity - includes complex problems like advanced tree traversals, optimization, etc.)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/dbscan-clustering-in-ml-density-based-clustering/", "content": "# DBSCAN Clustering in ML - Density based clustering\n\nDBSCAN is a density-based clustering algorithm that groups data points that are closely packed together and marks outliers as noise based on their density in the feature space. It identifies clusters as dense regions in the data space separated by areas of lower density. Unlike K-Means or hierarchical clustering which assumes clusters are compact and spherical, DBSCAN perform well in handling real-world data irregularities such as:\n\n- **Arbitrary-Shaped Clusters**: Clusters can take any shape not just circular or convex.\n- **Noise and Outliers**: It effectively identifies and handles noise points without assigning them to any cluster.\n\n![Data Sets with clustering algorithms](https://media.geeksforgeeks.org/wp-content/uploads/20250912171108762993/frame_3073.webp)\n\nThe figure above shows a data set with clustering algorithms: K-Means and Hierarchical handling compact, spherical clusters with varying noise tolerance while DBSCAN manages arbitrary-shaped clusters and noise handling.\n\n## Key Parameters in DBSCAN\n\n### 1. eps\nThis defines the radius of the neighborhood around a data point. If the distance between two points is less than or equal to eps they are considered neighbors. A common method to determine eps is by analyzing the k-distance graph. Choosing the right eps is important:\n\n- If eps is too small most points will be classified as noise.\n- If eps is too large clusters may merge and the algorithm may fail to distinguish between them.\n\n### 2. MinPts\nThis is the minimum number of points required within the **eps** radius to form a dense region. A general rule of thumb is to set MinPts ≥ D+1 where **D** is the number of dimensions in the dataset.\n\n> For most cases a minimum value of **MinPts = 3** is recommended.\n\n## How Does DBSCAN Work?\n\nDBSCAN works by categorizing data points into three types:\n\n1. Core points which have a sufficient number of neighbors within a specified radius (eplison)\n2. Border points which are near core points but lack enough neighbors to be core points themselves\n3. Noise points which do not belong to any cluster.\n\nBy iteratively expanding clusters from core points and connecting density-reachable points, DBSCAN forms clusters without relying on rigid assumptions about their shape or size.\n\n![DBSCAN ALgorithm](https://media.geeksforgeeks.org/wp-content/uploads/20250912174514326431/4.webp)\n\n### Steps in the DBSCAN Algorithm\n\n1. **Identify Core Points**: For each point in the dataset count the number of points within its eps neighborhood. If the count meets or exceeds MinPts mark the point as a core point.\n2. **Form Clusters**: For each core point that is not already assigned to a cluster create a new cluster. Recursively find all density-connected points i.e points within the eps radius of the core point and add them to the cluster.\n3. **Density Connectivity**: Two points a and b are density-connected if there exists a chain of points where each point is within the eps radius of the next and at least one point in the chain is a core point. This chaining process ensures that all points in a cluster are connected through a series of dense regions.\n4. **Label Noise Points**: After processing all points any point that does not belong to a cluster is labeled as noise.\n\n## Implementation of DBSCAN Algorithm In Python\n\nHere we'll use the Python library sklearn to compute DBSCAN and matplotlib.pyplot library for visualizing clusters.\n\n### Step 1: Importing Libraries\n\nWe import all the necessary library like [numpy](https://www.geeksforgeeks.org/python/introduction-to-numpy/), [matplotlib](https://www.geeksforgeeks.org/python/python-introduction-matplotlib/) and [scikit-learn](https://www.geeksforgeeks.org/machine-learning/what-is-python-scikit-library/).\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import datasets\n```\n\n### Step 2: Preparing Dataset\n\nWe will create a dataset of 4 clusters using [make_blobs](https://www.geeksforgeeks.org/machine-learning/python-create-test-datasets-using-sklearn/). The dataset have 300 points that are grouped into 4 visible clusters.\n\n```python\nX, y_true = make_blobs(n_samples=300, centers=4,\n                       cluster_std=0.50, random_state=0)\n```\n\n### Step 3: Applying DBSCAN Clustering\n\nNow we apply DBSCAN clustering on our data, count it and visualize it using the matplotlib library.\n\n- **eps=0.3:** The radius to look for neighboring points.\n- **min_samples:** Minimum number of points required to form a dense region a cluster.\n- **labels:** Cluster numbers for each point. `-1` means the point is considered noise.\n\n```python\ndb = DBSCAN(eps=0.3, min_samples=10).fit(X)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n\nunique_labels = set(labels)\ncolors = ['y', 'b', 'g', 'r']\nprint(colors)\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        col = 'k'\n\n    class_member_mask = (labels == k)\n\n    xy = X[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n             markeredgecolor='k',\n             markersize=6)\n\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n             markeredgecolor='k',\n             markersize=6)\n\nplt.title('number of clusters: %d' % n_clusters_)\nplt.show()\n```\n\n**Output:**\n\n![Cluster of dataset](https://media.geeksforgeeks.org/wp-content/uploads/20230511201103/download-(2).png)\n\nAs shown in above output image cluster are shown in different colours like yellow, blue, green and red.\n\n### Step 4: Evaluation Metrics For DBSCAN Algorithm In Machine Learning\n\nWe will use the [****Silhouette score****](https://www.geeksforgeeks.org/machine-learning/silhouette-algorithm-to-determine-the-optimal-value-of-k/) and [****Adjusted rand score****](https://www.geeksforgeeks.org/machine-learning/rand-index-in-machine-learning/) for evaluating clustering algorithms.\n\n- Silhouette's score is in the range of -1 to 1. A score near 1 denotes the best meaning that the data point i is very compact within the cluster to which it belongs and far away from the other clusters. The worst value is -1. Values near 0 denote overlapping clusters.\n- Absolute Rand Score is in the range of 0 to 1. More than 0.9 denotes excellent cluster recovery and above 0.8 is a good recovery. Less than 0.5 is considered to be poor recovery.\n\n```python\nsc = metrics.silhouette_score(X, labels)\nprint(\"Silhouette Coefficient:%0.2f\" % sc)\nari = adjusted_rand_score(y_true, labels)\nprint(\"Adjusted Rand Index: %0.2f\" % ari)\n```\n\n**Output:**\n\n> Silhouette Coefficient:0.13  \n> Adjusted Rand Index: 0.31\n\nBlack points represent outliers. By changing the eps and the MinPts we can change the cluster configuration.\n\n## When Should We Use DBSCAN Over K-Means Clustering?\n\nDBSCAN and [K-Means](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/) are both clustering algorithms that group together data that have the same characteristic. However they work on different principles and are suitable for different types of data. We prefer to use DBSCAN when the data is not spherical in shape or the number of classes is not known beforehand.\n\n| DBSCAN | K-Means |\n| --- | --- |\n| In DBSCAN we need not specify the number of clusters. | It is very sensitive to the number of clusters so it need to specified |\n| Clusters formed in DBSCAN can be of any arbitrary shape. | Clusters formed are spherical or convex in shape |\n| It can work well with datasets having noise and outliers | It does not work well with outliers data. Outliers can skew the clusters in K-Means to a very large extent. |\n| In DBSCAN two parameters are required for training the Model | In K-Means only one parameter is required is for training the model |\n\n![DBSCAN Vs K-Means](https://media.geeksforgeeks.org/wp-content/uploads/20250129131614273689/p12.webp)\n\nAs it can identify clusters of arbitrary shapes and effectively handle noise. K-Means on the other hand is better suited for data with well-defined, spherical clusters and is less effective with noise or complex cluster structures."}
{"reference": "https://www.geeksforgeeks.org/r-language/r-tutorial/", "content": "# R Tutorial | Learn R Programming Language\n\n**Last Updated**: 23 Jul, 2025\n\n**R** is an **interpreted** programming language widely used for statistical computing, data analysis and visualization. R language is open-source with large community support. R provides structured approach to data manipulation, along with decent libraries and packages like Dplyr, Ggplot2, shiny, Janitor and more.\n\n## Hello World Program in R Language\n\nHere is an example of the first Hello World program in R Programming Language. To print in R language you just need to use a Print function.\n\n```r\n# Code\nprint(\"Hello World!\")\n```\n\n**Output**\n\n```\n[1] \"Hello World!\"\n```\n\n## Why Learn R?\n\nLearning R is a smart choice for anyone working with data due to its powerful statistical and graphical capabilities. It's widely used in academia and industry, backed by a large, active community and a vast library of packages. R excels at data manipulation, analysis, and creating high-quality visual reports.\n\n## Installation and Setup\n\nIn this section, we will explore the steps to install and set up R and RStudio on your system. We'll also cover the necessary configurations to get started with writing and executing R code.\n\n- [Installing R Studio on Windows and Linux?](https://www.geeksforgeeks.org/r-language/how-to-install-r-studio-on-windows-and-linux/)\n- [Creation and Execution of R File in R Studio](https://www.geeksforgeeks.org/r-language/creation-and-execution-of-r-file-in-r-studio/)\n- [Introduction to R Studio](https://www.geeksforgeeks.org/r-language/introduction-to-r-studio/)\n\n## Fundamentals of R\n\nIn this section, we will cover the basic concepts and syntax of R programming. This will include understanding variables, data types, and basic operations that form the foundation of programming in R.\n\n- [R Programming Language](https://www.geeksforgeeks.org/r-language/r-programming-language-introduction/)\n- [Basic Syntax](https://www.geeksforgeeks.org/r-language/basic-syntax-in-r-programming/)\n- [Comments](https://www.geeksforgeeks.org/r-language/comments-in-r/)\n- [Operators](https://www.geeksforgeeks.org/r-language/r-operators/)\n- [Keywords](https://www.geeksforgeeks.org/r-language/r-keywords/)\n- [Data Types](https://www.geeksforgeeks.org/r-language/r-data-types/)\n- [Variables](https://www.geeksforgeeks.org/r-language/r-variables/)\n\n## Data Structures\n\nIn this section, we will cover the core data structures in R, such as vectors, lists, matrices, data frames, and arrays. We will explain how to use and manipulate these structures to store and process data effectively.\n\n- [Data Structures](https://www.geeksforgeeks.org/r-language/data-structures-in-r-programming/)\n- [Vectors](https://www.geeksforgeeks.org/r-language/r-vector/)\n- [Lists](https://www.geeksforgeeks.org/r-language/r-lists/)\n- [Matrices](https://www.geeksforgeeks.org/r-language/r-matrices/)\n- [Data Frames](https://www.geeksforgeeks.org/r-language/r-data-frames/)\n- [Arrays](https://www.geeksforgeeks.org/r-language/r-array/)\n- [Factors](https://www.geeksforgeeks.org/r-language/r-factors/)\n- [Strings](https://www.geeksforgeeks.org/r-language/r-strings/)\n\n## Control Flow\n\nIn this section, we will learn about control flow mechanisms in R, including conditional statements **(if, else)** and looping structures **(for, while)**. These concepts allow you to control the flow of execution in your programs.\n\n- [Decision Making](https://www.geeksforgeeks.org/r-language/decision-making-in-r-programming-if-if-else-if-else-if-ladder-nested-if-else-and-switch/)\n- [Loops (for, while, repeat)](https://www.geeksforgeeks.org/r-language/loops-in-r-for-while-repeat/)\n\n## Functions and Object Oriented Programming\n\nIn this section, we will discuss the creation and use of **functions** in R for modular and reusable code. Additionally, we will touch on **Object-Oriented Programming (OOP)** in R, exploring the basics of class creation and inheritance.\n\n- [Functions](https://www.geeksforgeeks.org/r-language/functions-in-r-programming/)\n- [Object-Oriented Programming](https://www.geeksforgeeks.org/r-language/r-object-oriented-programming/)\n- [Classes](https://www.geeksforgeeks.org/r-language/classes-in-r-programming/)\n- [Objects](https://www.geeksforgeeks.org/r-language/r-objects/)\n- [Encapsulation](https://www.geeksforgeeks.org/r-language/encapsulation-in-r-programming/)\n- [Polymorphism](https://www.geeksforgeeks.org/r-language/polymorphism-in-r-programming/)\n- [Inheritance](https://www.geeksforgeeks.org/r-language/r-inheritance/)\n- [Abstraction](https://www.geeksforgeeks.org/r-language/abstraction-in-r-programming/)\n\n## File and Error Handling\n\nIn this section, we will focus on reading from and writing to files in R, such as text, CSV, and other formats. We will also cover error handling techniques to ensure that your code runs smoothly and handles exceptions effectively.\n\n- [File Handling](https://www.geeksforgeeks.org/r-language/file-handling-in-r-programming/)\n- [Data Handling](https://www.geeksforgeeks.org/r-language/data-handling-in-r-programming/)\n- [Error Handling](https://www.geeksforgeeks.org/r-language/handling-errors-in-r-programming/)\n\n## Data Visualization\n\nIn this section, we will explore how to visualize data in R using various plotting techniques. We will introduce popular visualization libraries like ggplot2 and cover how to create different types of charts, including histograms, bar charts, and scatter plots.\n\n- [Data Visualization](https://www.geeksforgeeks.org/r-language/data-visualization-in-r/)\n- [Bar Charts](https://www.geeksforgeeks.org/r-language/r-bar-charts/)\n- [Line Graphs](https://www.geeksforgeeks.org/r-language/r-line-graphs/)\n- [Histograms](https://www.geeksforgeeks.org/r-language/histograms-in-r-language/)\n- [Pie Charts](https://www.geeksforgeeks.org/r-language/r-pie-charts/)\n- [Scatter plots](https://www.geeksforgeeks.org/r-language/scatter-plots-in-r-language/)\n- [Heatmap](https://www.geeksforgeeks.org/r-language/create-a-heatmap-in-r-programming-heatmap-function/)\n\n## Statistics, Data Science and Machine Learning\n\nIn this section, we will dive into the statistical methods and machine learning algorithms that R offers. We will explore common statistical tests, regression models, and machine learning workflows to analyze and model data.\n\n- [Statistics](https://www.geeksforgeeks.org/r-language/r-statistics/)\n- [Mean, Median, and Mode](https://www.geeksforgeeks.org/r-language/mean-median-and-mode-in-r-programming/)\n- [Average, Variance, and Standard Deviation](https://www.geeksforgeeks.org/r-language/Statistical-Measures-in-R-Average-Variance-and-Standard-Deviation/)\n- [R Data Science Tutorial](https://www.geeksforgeeks.org/r-language/data-science-tutorial-with-r/)\n- [Machine Learning](https://www.geeksforgeeks.org/r-machine-learning/introduction-to-machine-learning-in-r/)\n- [Machine learning Tutorial In R](https://www.geeksforgeeks.org/machine-learning/machine-learning-with-r/)\n\n## Popular Packages in R\n\nIn this section, we will highlight some of the most commonly used R packages that extend its functionality. We'll introduce libraries such as dplyr, ggplot2, caret, and others to help you streamline your data analysis and visualization tasks.\n\n- [Packages](https://www.geeksforgeeks.org/r-language/packages-in-r-programming/)\n- [Top 15 Packages in R](https://www.geeksforgeeks.org/r-language/r-libraries-for-data-science/)\n- [Tidyverse Packages](https://www.geeksforgeeks.org/r-language/what-are-the-tidyverse-packages-in-r-language/)\n\n## Projects In R\n\nIn this section, we will discuss the practical application of R by building projects. These hands-on examples will help you apply the concepts you've learned and deepen your understanding of R in real-world scenarios.\n\n1. [Beginner R Projects](https://www.geeksforgeeks.org/r-language/top-r-project-ideas-for-beginners/)\n2. [Advanced R Projects](https://origin.geeksforgeeks.org/r-language/top-r-advanced-projects-in-2025/)\n3. [30+ R projects](https://origin.geeksforgeeks.org/r-language/30-r-projects-with-source-code-2025/)\n\n## Applications of R Programming Language\n\nR is widely used across many industries due to its strong capabilities in data analysis and visualization. Some key applications include:\n\n- **Data Analysis and Statistics**: R is widely used for statistical analysis and modeling with built-in functions and packages that simplify complex computations.\n- **Data Visualization**: With libraries like ggplot2 and lattice, R enables creation of detailed and customizable charts and graphs for effective data presentation.\n- **Data Cleaning and Preparation**: R provides tools to import, clean, and transform data from various sources, making it ready for analysis.\n- **Machine Learning and Data Science**: R supports machine learning through packages such as caret, **randomForest**, and **xgboost**, helping build predictive models.\n- **Reporting and Reproducible Research**: Tools like R Markdown and **knitr** allow dynamic report generation and sharing of reproducible data analyses.\n- **Bioinformatics and Healthcare**: R is commonly used to analyze biological and clinical data in genomics and medical research.\n- **Finance and Insurance**: R is used for risk analysis, portfolio management, and actuarial modeling in financial industries.\n- **Interactive Web Applications**: Frameworks like Shiny enable building interactive web apps directly from R for data visualization and dashboards."}
{"reference": "https://www.geeksforgeeks.org/courses/data-analytics-skill-up", "content": "# Data Analytics - Skill Up\n\nSelf-Paced Course\n\nThe Data Analytics Course is a practical, beginner-to-advanced course designed to build a strong foundation in analytics and business intelligence. Covering Python, statistics, EDA, visualization, SQL, Excel, Power BI, and Tableau, the course equips learners to handle real-world data and drive insights through analysis. Ideal for aspiring data analysts, business analysts, or anyone interested in data-driven decision making.\n\n**Duration:** 9 Weeks  \n**Interested:** 30k+ Geeks\n\n## Course Overview\n\nThis 9-week course offers a structured, hands-on curriculum to help you learn the complete data analytics pipeline from scratch. Through theory, coding practice, real-world tools, and guided projects, learners build analytical thinking, technical skills, and the ability to solve data problems with confidence.\n\n### Course Highlights\n\n- Learn Python programming for data analytics\n- Build strong foundations in statistics, probability and hypothesis testing\n- Perform EDA using Pandas, NumPy and Matplotlib\n- Handle missing values, outliers and duplicates\n- Master data visualization with Seaborn, Plotly, Power BI and Tableau\n- Perform Web Scraping using BeautifulSoup and Selenium\n- Conduct SQL-based data querying and aggregation\n- Explore Excel analytics: Pivot Tables, Functions, Dashboards\n- Build dynamic dashboards and reports in Power BI & Tableau\n- Complete multiple real-world projects for portfolio development\n\n## Course Content\n\n### Week 0: Basic Python\n\n- What is Data Analytics and its Importance\n- Python Installation & Setup\n- Input/Output, Variables, Keywords\n- Data Types, Operators, Conditional Statements\n- Loops and Functions\n- Strings, Lists, Dictionaries, Tuples, Sets\n- Python Collections, Comprehensions\n- Error Handling, File Handling, Generators, Decorators\n\n### Week 2: Maths for Data Analytics\n\n- Descriptive Statistics: Mean, Median, Mode, Variance, Standard Deviation\n- Range, Quartiles, Percentiles\n- Probability: Basic Concepts & Distributions (Normal, Binomial, Poisson, etc.)\n- Covariance and Correlation\n- Hypothesis Testing: CLT, Z-test, T-test, ANOVA, MANOVA\n- Non-parametric Tests: Mann-Whitney, Kruskal-Wallis\n- Data Skewness Detection and Handling\n\n### Week 3: NumPy and Pandas\n\n- NumPy Basics, Arrays, Indexing, Broadcasting\n- Getting Started with Pandas: Series & DataFrames\n- CRUD Operations\n- Data Exploration: info(), describe(), value_counts(), head(), tail()\n- Grouping, Aggregation, Sorting, Filtering, reset_index()\n- Handling Missing Data\n- Outlier Detection (IQR, Z-score)\n- Removing Duplicates\n\n### Week 4: Data Visualization\n\n- Visualization with Matplotlib and Seaborn\n- Interactive Charts using Plotly\n- Correlation Matrix & Heatmaps\n- Time Series Visualization\n- Project: Word Cloud Generation\n- Project: Zomato Data Analysis\n\n## Frequently Asked Questions\n\n### What is Data Analytics?\n\n### Who should take Data Analytics course?\n\n### Do I need prior experience in coding or math?\n\n### What roles can I apply for after Data Analytics course?"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/activation-functions-neural-networks/", "content": "# Activation Functions in Neural Networks\n\nWhile building a neural network, one key decision is selecting the Activation Function for both the hidden layer and the output layer. It is a mathematical function applied to the output of a neuron. It introduces non-linearity into the model, allowing the network to learn and represent complex patterns in the data. Without this non-linearity feature a neural network would behave like a linear regression model no matter how many layers it has.\n\nActivation function decides whether a neuron should be activated by calculating the weighted sum of inputs and adding a bias term. This helps the model make complex decisions and predictions by introducing non-linearities to the output of each neuron.\n\n> **Before diving into the activation function, you should have prior knowledge of the following topics:** [Neural Networks](https://www.geeksforgeeks.org/machine-learning/neural-networks-a-beginners-guide/), [Backpropagation](https://www.geeksforgeeks.org/machine-learning/backpropagation-in-neural-network/)\n\n![Activation-functions-in-Neural-Networks](https://media.geeksforgeeks.org/wp-content/uploads/20250528125143444422/Activation-functions-in-Neural-Networks.webp)\n\n*Activation Functions in neural Networks*\n\n## Introducing Non-Linearity in Neural Network\n\nNon-linearity means that the relationship between input and output is not a straight line. In simple terms the output does not change proportionally with the input. A common choice is the ReLU function defined as \\(\\sigma(x) = \\max(0, x)\\).\n\nImagine you want to classify apples and bananas based on their shape and color.\n\n- If we use a linear function it can only separate them using a straight line.\n- But real-world data is often more complex like overlapping colors, different lighting, etc.\n- By adding a non-linear activation function like ReLU, Sigmoid or Tanh the network can create curved decision boundaries to separate them correctly.\n\n### Effect of Non-Linearity\n\nThe inclusion of the ReLU activation function \\(\\sigma\\) allows \\(h_1\\) to introduce a non-linear decision boundary in the input space. This non-linearity enables the network to learn more complex patterns that are not possible with a purely linear model such as:\n\n- Modeling functions that are not linearly separable.\n- Increasing the capacity of the network to form multiple decision boundaries based on the combination of weights and biases.\n\n## Why is Non-Linearity Important in Neural Networks?\n\nNeural networks consist of neurons that operate using weights, biases and activation functions.\n\nIn the learning process these weights and biases are updated based on the error produced at the output—a process known as backpropagation. Activation functions enable backpropagation by providing gradients that are essential for updating the weights and biases.\n\nWithout non-linearity even deep networks would be limited to solving only simple, linearly separable problems. Activation functions help neural networks to model highly complex data distributions and solve advanced deep learning tasks. Adding non-linear activation functions introduce flexibility and enable the network to learn more complex and abstract patterns from data.\n\n### Mathematical Proof of Need of Non-Linearity in Neural Networks\n\nTo illustrate the need for non-linearity in neural networks with a specific example let's consider a network with two input nodes (\\(i_1\\) and \\(i_2\\)), a single hidden layer containing neurons \\(h_1\\) and \\(h_2\\) and an output neuron (out).\n\nWe will use \\(w_1, w_2\\) as weights connecting the inputs to the hidden neuron and \\(w_5\\) as the weight connecting the hidden neuron to the output. We'll also include biases (\\(b_1\\) for the hidden neuron and \\(b_2\\) for the output neuron) to complete the model.\n\n1. **Input Layer**: Two inputs \\(i_1\\) and \\(i_2\\).\n2. **Hidden Layer**: Two neuron \\(h_1\\) and \\(h_2\\)\n3. **Output Layer**: One output neuron.\n\n![NeuralNetwok](https://media.geeksforgeeks.org/wp-content/uploads/20240503121617/NeuralNetwok.png)\n\nThe input to the hidden neuron \\(h_1\\) is calculated as a weighted sum of the inputs plus a bias:\n\n\\[h_1 = i_1 \\cdot w_1 + i_2 \\cdot w_3 + b_1\\]\n\n\\[h_2 = i_1 \\cdot w_2 + i_2 \\cdot w_4 + b_2\\]\n\nThe output neuron is then a weighted sum of the hidden neuron's output plus a bias:\n\n\\[\\text{output} = h_1 \\cdot w_5 + h_2 \\cdot w_6 + \\text{bias}\\]\n\nHere, \\(h_1 , h_2\\) and output are linear expressions.\n\nIn order to add non-linearity, we will be using sigmoid activation function in the output layer:\n\n\\[\\sigma(x) = \\frac{1}{1+e^{-x}}\\]\n\n\\[\\text{final output} = \\sigma(h_1 \\cdot w_5 + h_2 \\cdot w_6 + \\text{bias})\\]\n\n\\[\\text{final output} = \\frac{1}{1+e^{-(h_1 \\cdot w_5 + h_2 \\cdot w_6 + \\text{bias})}}\\]\n\nThis gives the final output of the network after applying the sigmoid activation function in output layers, introducing the desired non-linearity.\n\n## Types of Activation Functions in Deep Learning\n\n### 1. Linear Activation Function\n\nLinear Activation Function resembles straight line define by \\(y=x\\). No matter how many layers the neural network contains if they all use linear activation functions the output is a linear combination of the input.\n\n- The range of the output spans from (-\\(\\infty\\) to \\(+\\infty\\)).\n- Linear activation function is used at just one place i.e. output layer.\n- Using linear activation across all layers makes the network's ability to learn complex patterns limited.\n\nLinear activation functions are useful for specific tasks but must be combined with non-linear functions to enhance the neural network’s learning and predictive capabilities.\n\n![Linear-Activation-Function](https://media.geeksforgeeks.org/wp-content/uploads/20241029115212560858/Linear-Activation-Function.png)\n\n*Linear Activation Function or Identity Function returns the input as the output*\n\n### 2. Non-Linear Activation Functions\n\n#### 1. Sigmoid Function\n\n[Sigmoid Activation Function](https://www.geeksforgeeks.org/machine-learning/derivative-of-the-sigmoid-function/) is characterized by 'S' shape. It is mathematically defined as \\(A = \\frac{1}{1 + e^{-x}}\\). This formula ensures a smooth and continuous output that is essential for gradient-based optimization methods.\n\n- It allows neural networks to handle and model complex patterns that linear equations cannot.\n- The output ranges between 0 and 1, hence useful for binary classification.\n- The function exhibits a steep gradient when x values are between -2 and 2. This sensitivity means that small changes in input x can cause significant changes in output y which is critical during the training process.\n\n![Sigmoid-Activation-Function](https://media.geeksforgeeks.org/wp-content/uploads/20241029120537926197/Sigmoid-Activation-Function.png)\n\n*Sigmoid or Logistic Activation Function Graph*\n\n#### 2. Tanh Activation Function\n\n[Tanh function](https://www.geeksforgeeks.org/deep-learning/tanh-activation-in-neural-network/)(hyperbolic tangent function) is a shifted version of the sigmoid, allowing it to stretch across the y-axis. It is defined as:\n\n\\[f(x) = \\tanh(x) = \\frac{2}{1 + e^{-2x}} - 1.\\]\n\nAlternatively, it can be expressed using the sigmoid function:\n\n\\[\\tanh(x) = 2 \\times \\text{sigmoid}(2x) - 1\\]\n\n- **Value Range**: Outputs values from -1 to +1.\n- **Non-linear**: Enables modeling of complex data patterns.\n- **Use in Hidden Layers**: Commonly used in hidden layers due to its zero-centered output, facilitating easier learning for subsequent layers.\n\n![Tanh-Activation-Function](https://media.geeksforgeeks.org/wp-content/uploads/20241029120618881107/Tanh-Activation-Function.png)\n\n*Tanh Activation Function*\n\n#### 3. ReLU (Rectified Linear Unit) Function\n\n[ReLU activation](https://www.geeksforgeeks.org/deep-learning/relu-activation-function-in-deep-learning/) is defined by \\(A(x) = \\max(0,x)\\), this means that if the input x is positive, ReLU returns x, if the input is negative, it returns 0.\n\n- **Value Range**: \\([0, \\infty)\\), meaning the function only outputs non-negative values.\n- **Nature**: It is a non-linear activation function, allowing neural networks to learn complex patterns and making backpropagation more efficient.\n- **Advantage over other Activation:** ReLU is less computationally expensive than tanh and sigmoid because it involves simpler mathematical operations. At a time only a few neurons are activated making the network sparse making it efficient and easy for computation.\n\n![relu-activation-function](https://media.geeksforgeeks.org/wp-content/uploads/20241029120652402777/relu-activation-function.png)\n\n*ReLU Activation Function*\n\n### 3. Exponential Linear Units\n\n#### 1. Softmax Function\n\n[Softmax function](https://www.geeksforgeeks.org/deep-learning/the-role-of-softmax-in-neural-networks-detailed-explanation-and-applications/) is designed to handle multi-class classification problems. It transforms raw output scores from a neural network into probabilities. It works by squashing the output values of each class into the range of 0 to 1 while ensuring that the sum of all probabilities equals 1.\n\n- Softmax is a non-linear activation function.\n- The Softmax function ensures that each class is assigned a probability, helping to identify which class the input belongs to.\n\n![softmax](https://media.geeksforgeeks.org/wp-content/uploads/20241029120724445438/softmax.png)\n\n*Softmax Activation Function*\n\n#### 2. SoftPlus Function\n\n[Softplus function](https://www.geeksforgeeks.org/deep-learning/softplus-function-in-neural-network/) is defined mathematically as: \\(A(x) = \\log(1 + e^x)\\).\n\nThis equation ensures that the output is always positive and differentiable at all points which is an advantage over the traditional ReLU function.\n\n- **Nature**: The Softplus function is non-linear.\n- **Range**: The function outputs values in the range (0, \\(\\infty\\)), similar to ReLU, but without the hard zero threshold that ReLU has.\n- **Smoothness**: Softplus is a smooth, continuous function, meaning it avoids the sharp discontinuities of ReLU which can sometimes lead to problems during optimization.\n\n![softplus](https://media.geeksforgeeks.org/wp-content/uploads/20241029120803898518/softplus.png)\n\n*Softplus Activation Function*\n\n## Impact of Activation Functions on Model Performance\n\nThe choice of activation function has a direct impact on the performance of a neural network in several ways:\n\n1. **Convergence Speed:** Functions like ReLU allow faster training by avoiding the vanishing gradient problem while Sigmoid and Tanh can slow down convergence in deep networks.\n2. **Gradient Flow:** Activation functions like ReLU ensure better gradient flow, helping deeper layers learn effectively. In contrast Sigmoid can lead to small gradients, hindering learning in deep layers.\n3. **Model Complexity:** Activation functions like Softmax allow the model to handle complex multi-class problems, whereas simpler functions like ReLU or Leaky ReLU are used for basic layers.\n\nActivation functions are the backbone of neural networks enabling them to capture non-linear relationships in data. From classic functions like Sigmoid and Tanh to modern variants like ReLU and Swish, each has its place in different types of neural networks. The key is to understand their behavior and choose the right one based on your model’s needs."}
{"reference": "https://www.geeksforgeeks.org/computer-vision/computer-vision/", "content": "# Computer Vision Tutorial\n\nComputer Vision (CV) is a branch of Artificial Intelligence (AI) that helps computers to interpret and understand visual information much like humans. This tutorial is designed for both beginners and experienced professionals and covers key concepts such as Image Processing, Feature Extraction, Object Detection, Image Segmentation and other core techniques in CV.\n\nBefore moving into computer vision, it is recommended to have a foundational understanding of:\n\n1. [Machine Learning](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\n2. [Deep Learning](https://www.geeksforgeeks.org/deep-learning/deep-learning-tutorial/)\n3. [OpenCV](https://www.geeksforgeeks.org/python/opencv-python-tutorial/)\n\nThese areas form the foundation of computer vision which helps us apply techniques and algorithms more effectively. If we're unfamiliar with any of these topics, we recommend checking out their respective tutorials to build a solid foundation.\n\n## Mathematical Prerequisites for Computer Vision\n\nBefore moving into Computer Vision, having a foundational understanding of certain mathematical concepts will help us which includes:\n\n### 1. Linear Algebra\n\n- [Linear Algebra](https://www.geeksforgeeks.org/machine-learning/ml-linear-algebra-operations/)\n- [Vectors](https://www.geeksforgeeks.org/python/how-to-create-a-vector-in-python-using-numpy/)\n- [Matrices and Tensors](https://www.geeksforgeeks.org/maths/differences-between-a-matrix-and-a-tensor/)\n- [Eigenvalues and Eigenvectors](https://www.geeksforgeeks.org/engineering-mathematics/eigen-values/)\n- [Singular Value Decomposition](https://www.geeksforgeeks.org/machine-learning/singular-value-decomposition-svd/)\n\n### 2. Probability and Statistics\n\n- [Probability and Statistics](https://www.geeksforgeeks.org/machine-learning/statistics-for-machine-learning/)\n- [Probability Distributions](https://www.geeksforgeeks.org/maths/probability-distribution/)\n- [Bayesian Inference and Bayes' Theorem](https://www.geeksforgeeks.org/machine-learning/bayes-theorem-in-machine-learning/)\n- [Markov Chains](https://www.geeksforgeeks.org/machine-learning/markov-chain/)\n- [Kalman Filters](https://www.geeksforgeeks.org/python/kalman-filter-in-python/)\n\n### 3. Signal Processing\n\n- [Signal Processing](https://www.geeksforgeeks.org/artificial-intelligence/signal-processing-and-artificial-intelligence-ai/)\n- [Image Filtering and Convolution](https://www.geeksforgeeks.org/python/image-filtering-using-convolution-in-opencv/)\n- [Discrete Fourier Transform (DFT)](https://www.geeksforgeeks.org/software-engineering/discrete-fourier-transform-and-its-inverse-using-matlab/)\n- [Fast Fourier Transform (FFT)](https://www.geeksforgeeks.org/computer-vision/fast-fourier-transform-in-image-processing/)\n- [Principal Component Analysis (PCA)](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)\n\n## Key Concepts in Computer Vision\n\n### 1. Image Processing\n\nIt refers to techniques for manipulating and analyzing digital images. Common image processing tasks include:\n\n1. Image Transformation\n\n- [Image Transformation](https://www.geeksforgeeks.org/python/image-transformations-using-opencv-in-python/)\n- [Geometric Transformations](https://www.geeksforgeeks.org/electronics-engineering/geometric-transformation-in-image-processing-1/)\n- [Fourier Transform](https://www.geeksforgeeks.org/python/how-to-find-the-fourier-transform-of-an-image-using-opencv-python/)\n- [Intensity Transformation](https://www.geeksforgeeks.org/python/python-intensity-transformation-operations-on-images/)\n\n2. Image Enhancement\n\n- [Image Enhancement](https://www.geeksforgeeks.org/machine-learning/image-enhancement-techniques-using-opencv-python/)\n- [Histogram Equalization](https://www.geeksforgeeks.org/computer-graphics/histogram-equalization-in-digital-image-processing/)\n- [Contrast Enhancement](https://www.geeksforgeeks.org/software-engineering/how-to-perform-contrast-enhancement-of-color-image-in-matlab/)\n- [Image Sharpening](https://www.geeksforgeeks.org/software-engineering/image-sharpening-using-laplacian-filter-and-high-boost-filtering-in-matlab/)\n- [Color Correction](https://www.geeksforgeeks.org/computer-vision/automatic-color-correction-with-opencv-and-python/)\n\n3. Noise Reduction Techniques\n\n- [Noise Reduction Techniques](https://www.geeksforgeeks.org/computer-vision/what-are-the-different-image-denoising-techniques-in-computer-vision/)\n- [Median Filtering](https://www.geeksforgeeks.org/python/spatial-filters-averaging-filter-and-median-filter-in-image-processing/)\n- [Bilateral Filtering](https://www.geeksforgeeks.org/python/python-bilateral-filtering/)\n- [Wavelet Denoising](https://www.geeksforgeeks.org/python/wand-wavelet_denoise-function-in-python/)\n\n4. Morphological Operations\n\n- [Morphological Operations](https://www.geeksforgeeks.org/python/python-opencv-morphological-operations/)\n- [Erosion and Dilation](https://www.geeksforgeeks.org/python/erosion-dilation-images-using-opencv-python/)\n- [Opening](https://www.geeksforgeeks.org/python/python-morphological-operations-in-image-processing-opening-set-1/)\n- [Closing](https://www.geeksforgeeks.org/python/python-morphological-operations-in-image-processing-closing-set-2/)\n- [Morphological Gradient](https://www.geeksforgeeks.org/python/python-morphological-operations-in-image-processing-gradient-set-3/)\n\n### 2. Feature Extraction\n\nIt involves identifying distinctive elements within an image for analysis and its techniques include:\n\n1. Edge Detection Techniques\n\n- [Computer Vision Algorithms](https://www.geeksforgeeks.org/computer-vision/computer-vision-algorithms/)\n- [Edge Detection Techniques](https://www.geeksforgeeks.org/computer-vision/comprehensive-guide-to-edge-detection-algorithms/)\n- [Canny Edge Detector](https://www.geeksforgeeks.org/machine-learning/implement-canny-edge-detector-in-python-using-opencv/)\n- [Sobel Operator](https://www.geeksforgeeks.org/software-engineering/edge-detection-using-prewitt-scharr-and-sobel-operator/)\n- [Laplacian of Gaussian (LoG)](https://www.geeksforgeeks.org/software-engineering/laplacian-of-gaussian-filter-in-matlab/)\n\n2. Corner and Interest Point Detection\n\n- [Harris Corner Detection](https://www.geeksforgeeks.org/python/python-corner-detection-with-harris-corner-detection-method-using-opencv/)\n\n3. Feature Descriptors\n\n- [Feature Descriptors](https://www.geeksforgeeks.org/computer-vision/feature-descriptor-in-image-processing/)\n- [SIFT (Scale-Invariant Feature Transform)](https://www.geeksforgeeks.org/machine-learning/sift-interest-point-detector-using-python-opencv/)\n- [SURF (Speeded-Up Robust Features)](https://www.geeksforgeeks.org/computer-vision/what-is-the-difference-between-sift-and-surf/)\n- [ORB (Oriented FAST and Rotated BRIEF)](https://www.geeksforgeeks.org/python/feature-matching-using-orb-algorithm-in-python-opencv/)\n- [HOG (Histogram of Oriented Gradients)](https://www.geeksforgeeks.org/python/pedestrian-detection-using-opencv-python/)\n\n## How Does Computer Vision Work?\n\n1. Computer Vision works much like the human eye and brain. First, our eyes capture the image and send the visual data to our brain. The brain then processes this information and transforms it into a meaningful interpretation, recognizing and categorizing the object based on its properties.\n2. In a similar way, Computer Vision uses a camera (acting like the human eye) to capture images. The visual data is then processed by algorithms to recognize and identify the objects based on patterns it has learned. However, before the system can recognize objects in new images, it needs to be trained on a large dataset of labeled images. This training enables the system to identify and associate various patterns with their corresponding labels.\n3. For example, imagine providing a computer with thousands of bird song recordings. The system learns by analyzing features like pitch, rhythm and duration. Once trained, it can then recognize whether a new sound resembles a bird song or not.\n\n> For more details you can refer to: [Steps in Computer Vision](https://www.geeksforgeeks.org/computer-vision/what-are-the-main-steps-in-a-typical-computer-vision-pipeline/)\n\n## Popular Libraries for Computer Vision\n\nTo implement computer vision tasks effectively, various libraries are used:\n\n1. **OpenCV**: Mostly used open-source library for computer vision tasks like image processing, video capture and real-time applications.\n2. **TensorFlow**: A popular deep learning framework that includes tools for building and training computer vision models.\n3. **PyTorch**: Another deep learning library that provides great flexibility for computer vision tasks for research and development.\n4. **scikit-image**: A part of the scikit-learn ecosystem, this library provides algorithms for image processing and computer vision.\n\n> For more details you can refer to: [Computer Vision Libraries](https://www.geeksforgeeks.org/computer-vision/computer-vision-libraries-for-python-features-applications-and-suitability/)\n\n## Deep Learning for Computer Vision\n\nDeep learning has greatly enhanced computer vision by allowing machines to understand and analyze visual data and its key deep learning models include:\n\n### 1. Convolutional Neural Networks (CNNs)\n\nConvolutional Neural Networks are designed for learning spatial hierarchies of features from images and its key components include:\n\n- [Deep Learning for Computer Vision](https://www.geeksforgeeks.org/computer-vision/deep-learning-for-computer-vision/)\n- [Deep learning](https://www.geeksforgeeks.org/deep-learning/introduction-deep-learning/)\n- [Convolutional Neural Networks](https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/)\n- [Convolutional Layers](https://www.geeksforgeeks.org/machine-learning/what-are-convolution-layers/)\n- [Pooling Layers](https://www.geeksforgeeks.org/deep-learning/cnn-introduction-to-pooling-layer/)\n- [Fully Connected Layers](https://www.geeksforgeeks.org/deep-learning/what-is-fully-connected-layer-in-deep-learning/)\n\n### 2. Generative Adversarial Networks (GANs)\n\nIt consists of two networks (generator and discriminator) that work against each other to create realistic images. There are various types of GANs each designed for specific tasks and improvements:\n\n- [Generative Adversarial Networks (GANs)](https://www.geeksforgeeks.org/machine-learning/basics-of-generative-adversarial-networks-gans/)\n- [Deep Convolutional GAN (DCGAN)](https://www.geeksforgeeks.org/machine-learning/deep-convolutional-gan-with-keras/)\n- [Conditional GAN (cGAN)](https://www.geeksforgeeks.org/deep-learning/conditional-generative-adversarial-network/)\n- [Cycle-Consistent GAN (CycleGAN)](https://www.geeksforgeeks.org/machine-learning/cycle-generative-adversarial-network-cyclegan-2/)\n- [Super-Resolution GAN (SRGAN)](https://www.geeksforgeeks.org/machine-learning/super-resolution-gan-srgan/)\n- [StyleGAN](https://www.geeksforgeeks.org/machine-learning/stylegan-style-generative-adversarial-networks/)\n\n### 3. Variational Autoencoders (VAEs)\n\nThey are the probabilistic version of autoencoders which forces the model to learn a distribution over the latent space rather than a fixed point, some other autoencoders used in computer vision are:\n\n- [Autoencoders](https://www.geeksforgeeks.org/machine-learning/auto-encoders/)\n- [Variational Autoencoders (VAEs)](https://www.geeksforgeeks.org/machine-learning/variational-autoencoders/)\n- [Denoising Autoencoders (DAE)](https://www.geeksforgeeks.org/machine-learning/denoising-autoencoders-in-machine-learning/)\n- [Convolutional Autoencoder (CAE)](https://www.geeksforgeeks.org/deep-learning/contractive-autoencoder-cae/)\n\n### 4. Vision Transformers (ViT)\n\nThey are inspired by transformers models to treat images and sequence of patches and process them using self-attention mechanisms, some common vision transformers include:\n\n- [Vision Transformers (ViT)](https://www.geeksforgeeks.org/deep-learning/vision-transformer-vit-architecture/)\n- [Swin Transformer](https://www.geeksforgeeks.org/computer-vision/swin-transformer/)\n- [CvT (Convolutional Vision Transformer)](https://www.geeksforgeeks.org/deep-learning/vision-transformers-vs-convolutional-neural-networks-cnns/)\n\n### 5. Vision Language Models\n\nThey integrate visual and textual information to perform image processing and natural language understanding.\n\n- [Vision language models](https://www.geeksforgeeks.org/artificial-intelligence/vision-language-models-vlms-explained/)\n- [CLIP (Contrastive Language-Image Pre-training)](https://www.geeksforgeeks.org/deep-learning/clip-contrastive-language-image-pretraining/)\n- [ALIGN (A Large-scale ImaGe and Noisy-text)](https://www.geeksforgeeks.org/artificial-intelligence/align-a-large-scale-image-and-noisy-text-model/)\n- [BLIP (Bootstrapping Language-Image Pre-training)](https://www.geeksforgeeks.org/artificial-intelligence/understanding-blip-a-huggingface-model/)\n\n## Computer Vision Tasks\n\n### 1. Image Classification\n\nIt involves analyzing an image and assigning it a specific label or category based on its content such as identifying whether an image contains a cat, dog or car.\n\n**Its techniques are as follows:**\n\n- [Computer Vision Tasks](https://www.geeksforgeeks.org/computer-vision/computer-vision-tasks/)\n- [Image Classification](https://www.geeksforgeeks.org/computer-vision/what-is-image-classification/)\n- [Image Classification using Support Vector Machine (SVM)](https://www.geeksforgeeks.org/machine-learning/image-classification-using-support-vector-machine-svm-in-python/)\n- [Image Classification using RandomForest](https://www.geeksforgeeks.org/machine-learning/random-forest-for-image-classification-using-opencv/)\n- [Image Classification using CNN](https://www.geeksforgeeks.org/machine-learning/image-classifier-using-cnn/)\n- [Image Classification using TensorFlow](https://www.geeksforgeeks.org/deep-learning/cifar-10-image-classification-in-tensorflow/)\n- [Image Classification using PyTorch Lightning](https://www.geeksforgeeks.org/deep-learning/image-classification-using-pytorch-lightning/)\n\n**There are various types for Image Classification which are as follows:**\n\n- [Dataset for Image Classification](https://www.geeksforgeeks.org/computer-vision/dataset-for-image-classification/).\n- [Multiclass classification](https://www.geeksforgeeks.org/machine-learning/multiclass-classification-using-scikit-learn/)\n- [Multilabel classification](https://www.geeksforgeeks.org/machine-learning/an-introduction-to-multilabel-classification/)\n- [Zero-shot classification](https://www.geeksforgeeks.org/deep-learning/zero-shot-learning-for-novel-class-recognition-using-clip-model/)\n\n> To learn about the datasets for image classification, we can go through the article on Dataset for Image Classification mentioned above.\n\n### 2. Object Detection\n\nIt involves identifying and locating objects within an image by drawing bounding boxes around them.\n\n**It includes below following Techniques:**\n\n- [Top Computer Vision Models](https://www.geeksforgeeks.org/computer-vision/top-computer-vision-models/)\n- [Object Detection](https://www.geeksforgeeks.org/computer-vision/what-is-object-detection-in-computer-vision/)\n- [YOLO (You Only Look Once)](https://www.geeksforgeeks.org/machine-learning/yolo-you-only-look-once-real-time-object-detection/)\n- [SSD (Single Shot Multibox Detector)](https://www.geeksforgeeks.org/computer-vision/how-single-shot-detector-ssd-works/)\n- [Region-Based Convolutional Neural Networks (R-CNNs)](https://www.geeksforgeeks.org/machine-learning/r-cnn-region-based-cnns/)\n- [Fast R-CNN](https://www.geeksforgeeks.org/machine-learning/fast-r-cnn-ml/)\n- [Faster R-CNN](https://www.geeksforgeeks.org/machine-learning/faster-r-cnn-ml/)\n- [Mask R-CNN](https://www.geeksforgeeks.org/machine-learning/mask-r-cnn-ml/)\n- [Object Detection using TensorFlow](https://www.geeksforgeeks.org/computer-vision/object-detection-using-tensorflow/)\n- [Object Detection using PyTorch](https://www.geeksforgeeks.org/computer-vision/yolov3-from-scratch-using-pytorch/)\n\n**Type of Object Detection Concepts are as follows:**\n\n- [Bounding Box Regression](https://www.geeksforgeeks.org/computer-vision/bounding-box-prediction-using-pytorch/)\n- [Intersection over Union (IoU)](https://www.geeksforgeeks.org/java/calculation-intersection-over-union-iou-for-evaluating-an-image-segmentation-model-using-java/)\n- [Region Proposal Networks (RPN)](https://www.geeksforgeeks.org/computer-vision/region-proposal-network-rpn-in-object-detection/)\n- [Non-Maximum Suppression (NMS)](https://www.geeksforgeeks.org/computer-vision/what-is-non-maximum-suppression/)\n\n### 3. Image Segmentation\n\nIt involves partitioning an image into distinct regions or segments to identify objects or boundaries at a pixel level.\n\n**Types of image segmentation are:**\n\n- [Image Segmentation](https://www.geeksforgeeks.org/computer-vision/explain-image-segmentation-techniques-and-applications/)\n- [Semantic Segmentation](https://www.geeksforgeeks.org/computer-vision/semantic-segmentation-vs-instance-segmentation/)\n- [Instance Segmentation](https://www.geeksforgeeks.org/computer-vision/semantic-segmentation-vs-instance-segmentation/)\n- [Panoptic Segmentation](https://www.geeksforgeeks.org/computer-vision/what-is-panoptic-segmentation/)\n\n**We can perform image segmentation using the following methods:**\n\n- [Image Segmentation using K Means Clustering](https://www.geeksforgeeks.org/machine-learning/image-segmentation-using-k-means-clustering/)\n- [Image Segmentation using UNet](https://www.geeksforgeeks.org/machine-learning/u-net-architecture-explained/)\n- [Image Segmentation using TensorFlow](https://www.geeksforgeeks.org/deep-learning/image-segmentation-using-tensorflow/)\n- [Image Segmentation with Mask R-CNN](https://www.geeksforgeeks.org/computer-vision/image-segmentation-with-mask-r-cnn-grabcut-and-opencv/)\n\n## Need for Computer Vision\n\n1. **High Demand in the Job Market:** Critical for careers in AI, machine learning and data science across industries like healthcare, automotive and robotics.\n2. **Revolutionizing Industries:** Powers advancements in self-driving cars, medical diagnostics, agriculture and manufacturing by automating visual tasks.\n3. **Solving Real-World Problems:** Enhances safety, improves medical imaging and optimizes industrial processes.\n4. **Improving Accessibility**: It helps people with disabilities through image recognition and sign language translation.\n5. **Enhancing Consumer Experiences**: It personalizes shopping and improves customer service in retail and entertainment.\n\n## Applications of Computer Vision\n\n1. **Healthcare:** Used for disease detection and medical image analysis (X-rays, MRIs).\n2. **Automotive**: Helps self-driving cars to detect objects, lane keeping and traffic sign recognition.\n3. **Retail**: It helps with inventory management, theft prevention and customer behavior analysis.\n4. **Agriculture**: It is used for crop monitoring and disease detection.\n5. **Security and Surveillance**: It recognizes faces and find suspicious activities in security footage.\n\n> For more details you can refer to: [Applications of Computer Vision](https://www.geeksforgeeks.org/computer-vision/applications-of-computer-vision/)"}
{"reference": "https://www.geeksforgeeks.org/geeksforgeeks-practice-best-online-coding-platform/", "content": "# GeeksforGeeks Practice - Leading Online Coding Platform\n\n**Last Updated**: 26 Jul, 2025\n\n**GeeksforGeeks Practice** is an **online coding platform** designed to help developers and students practice coding online and sharpen their programming skills with the following features.\n\n- **[GfG 160](https://www.geeksforgeeks.org/courses/gfg-160-series)**: This consists of most popular interview problems organized topic wise and difficulty with well written editorials and videos.\n- **[DSA 360°](https://www.geeksforgeeks.org/courses/dsa-skill-up)**: All-in-one DSA guide from basics to advanced — perfect for coding rounds, and building logic, with topic-wise problem sets.\n- **[Topic Wise and Company Wise](https://www.geeksforgeeks.org/explore?page=1&sortBy=submissions)**: You may browse coding practice problems by applying different filters, like topics and company name.\n- **[POTD](https://www.geeksforgeeks.org/problem-of-the-day)**: POTD is Problem of the Day to build your daily coding habits.\n\n## Language\n\n[C++](https://www.geeksforgeeks.org/explore?page=1&category=CPP&sortBy=submissions&itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=practice_header) [Java](https://www.geeksforgeeks.org/explore?page=1&category=Java&sortBy=submissions&itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=practice_header) [Python](https://www.geeksforgeeks.org/explore?page=1&category=python&sortBy=submissions&itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=practice_header)\n\n## Featured Sprints\n\n[Top DSA Sheet](https://www.geeksforgeeks.org/explore?page=1&sprint=ca8ae412173dbd8346c26a0295d098fd&sortBy=submissions&sprint_name=Beginner%27s%20DSA%20Sheet&utm_source=geeksforgeeks&utm_medium=main_header&utm_campaign=practice_header) [Top 50 Array Problems](https://www.geeksforgeeks.org/explore?page=1&sprint=50746f92a895c22a50504ac0c1fb9c84&sortBy=submissions&sprint_name=Top%2050%20Array%20Problems) [Top 50 String Problems](https://www.geeksforgeeks.org/explore?page=1&sprint=57184072610b884e5df3584cc534115d&sortBy=submissions&sprint_name=Top%2050%20String%20Problems) [Top 50 Tree Problems](https://www.geeksforgeeks.org/explore?page=1&sprint=5f24de84b65bf7c4f4399c8111e26b81&sortBy=submissions&sprint_name=Top%2050%20Tree%20Problems) [Top 50 DP Problems](https://www.geeksforgeeks.org/explore?page=1&sprint=93d672753b74440c7427214c8ebf866d&sortBy=submissions&sprint_name=Top%2050%20DP%20Problems) [SDE Sheet](https://www.geeksforgeeks.org/explore?page=1&sprint=a663236c31453b969852f9ea22507634&sortBy=submissions&sprint_name=SDE%20Sheet)\n\n## Different Levels of Problems\n\n[Easy Level](https://www.geeksforgeeks.org/explore?page=1&difficulty=Easy&sortBy=submissions&utm_source=geeksforgeeks&utm_medium=main_header&utm_campaign=practice_header) [Medium Level](https://www.geeksforgeeks.org/explore?page=1&difficulty=Medium&sortBy=submissions&utm_source=geeksforgeeks&utm_medium=main_header&utm_campaign=practice_header) [Hard Level](https://www.geeksforgeeks.org/explore?page=1&difficulty=Hard&sortBy=submissions&utm_source=geeksforgeeks&utm_medium=main_header&utm_campaign=practice_header)\n\n## Why Choose GeeksforGeeks Coding Platform?\n\n### 1. Vast Problem Library\n\n[GeeksforGeeks Practice](https://www.geeksforgeeks.org/explore?page=1&sortBy=submissions&utm_medium=content_team_seo&utm_source=geeksforgeeks) offers a comprehensive collection of coding problems spanning multiple topics and difficulty levels. With thousands of questions available, learners can continually challenge themselves and enhance their problem-solving skills.\n\n![GeeksforGeeks Practice Portal](https://media.geeksforgeeks.org/wp-content/uploads/20240904165926/SS.jpg)\n\n### 2. Company-Wise Preparation\n\n[GeeksforGeeks coding platform](https://www.geeksforgeeks.org/explore?page=1&sortBy=submissions&utm_medium=content_team_seo&utm_source=geeksforgeeks) provides tailored problem sets categorized by top tech companies, enabling students to focus on questions commonly asked in interviews by specific companies like Google, Microsoft, and Amazon. This helps learners prepare effectively for targeted job roles and company-specific interviews.\n\n![GeeksforGeeks practice portal](https://media.geeksforgeeks.org/wp-content/uploads/20240904170005/F66760A5-B7BC-49FB-964A-5EC2DB191DAB_1_201_a.jpeg)\n\n### 3. Contests (POTD)\n\n**GeeksforGeeks coding platform** offers regular coding contests, including the Problem of the Day (POTD), allowing learners to test their skills in real-time scenarios. Participants also have the exciting opportunity to win exclusive GeeksforGeeks goodies, adding a fun incentive while sharpening their competitive programming skills.\n\n![GeeksforGeeks practice portal](https://media.geeksforgeeks.org/wp-content/uploads/20240904170206/223E90EB-26F1-4B45-98A2-F2E2FB0D11FF_1_201_a.jpg)\n\n## Who Can Use Our Coding Platform?\n\n1. **Beginners:** Those new to coding can start with our easy-level problems to build a strong foundation in programming concepts and logic.\n2. **Intermediate Programmers:** With a solid grasp of the basics, intermediate learners can tackle medium-level challenges to enhance their skills and prepare for competitive programming.\n3. **Advanced Coders:** Experienced developers can dive into hard-level problems to push their limits and refine their problem-solving techniques for real-world applications.\n4. **Job Seekers:** Our company-specific problem sets and curated interview preparation sheets help job seekers efficiently prepare for technical interviews at top tech companies. [View more](https://www.geeksforgeeks.org/explore?page=1&category=Data%20Structures&sortBy=submissions)\n\n## Comprehensive Range of Problems\n\n### Data Structure\n\n[Arrays](https://www.geeksforgeeks.org/explore?page=1&category=Arrays&sortBy=submissions) [LinkedList](https://www.geeksforgeeks.org/explore?page=1&category=Linked%20List&sortBy=submissions) [Trees](https://www.geeksforgeeks.org/explore?page=1&category=Tree&sortBy=submissions) [Graphs](https://www.geeksforgeeks.org/explore?page=1&category=Graph&sortBy=submissions) [Hash](https://www.geeksforgeeks.org/explore?page=1&category=Hash&sortBy=submissions) [Strings](https://www.geeksforgeeks.org/explore?page=1&category=Strings&sortBy=submissions)\n\n[View more](https://www.geeksforgeeks.org/explore?page=1&category=Algorithms&sortBy=submissions)\n\n### Algorithms\n\n[Sorting](https://www.geeksforgeeks.org/explore?page=1&category=Sorting&sortBy=submissions) [Searching](https://www.geeksforgeeks.org/explore?page=1&category=Searching&sortBy=submissions) [Backtracking](https://www.geeksforgeeks.org/explore?page=1&category=Backtracking&sortBy=submissions) [Dynamic Programming](https://www.geeksforgeeks.org/explore?page=1&category=Dynamic%20Programming&sortBy=submissions) [Greedy](https://www.geeksforgeeks.org/explore?page=1&category=Greedy&sortBy=submissions) [Divide and Conquer](https://www.geeksforgeeks.org/explore?page=1&category=Divide%20and%20Conquer&sortBy=submissions)\n\n[View more](https://www.geeksforgeeks.org/explore?page=1&company=Amazon,Microsoft,Flipkart,Adobe,Google,Samsung,Accolite,MakeMyTrip,Zoho,Walmart,Goldman%20Sachs&sortBy=submissions)\n\n### Company\n\n[Microsoft](https://www.geeksforgeeks.org/explore?page=1&company=Microsoft&sortBy=submissions) [Google](https://www.geeksforgeeks.org/explore?page=1&company=Google&sortBy=submissions) [Amazon](https://www.geeksforgeeks.org/explore?page=1&company=Amazon&sortBy=submissions) [Adobe](https://www.geeksforgeeks.org/explore?page=1&company=Adobe&sortBy=submissions) [Atlassian](https://www.geeksforgeeks.org/explore?page=1&company=Atlassian&sortBy=submissions) [Samsung](https://www.geeksforgeeks.org/explore?page=1&company=Samsung&sortBy=submissions)"}
{"reference": "https://www.geeksforgeeks.org/courses/complete-java-script-skill-up", "content": "# Complete Java Script - Skill Up\n\nSelf-Paced Course\n\n**3k+ interested Geeks**\n\nThe Complete JavaScript Program takes you from beginner to advanced problem-solving. You'll start with variables, data types, functions and control flow, then work with arrays, strings, objects and the DOM to build interactive pages. The course covers ES6+, asynchronous programming, error handling and data structures like stacks, queues, trees, and graphs. Through coding challenges and projects, you'll gain practical skills and interview ready confidence.\n\n**10 Weeks**\n\n## Course Overview\n\nThis 4-week Complete JavaScript Program is designed to take you from a beginner to a confident JavaScript developer. You'll start with the foundations of JavaScript variables, operators, control flow and functions before moving into arrays, strings, and objects. Learn how to manipulate the DOM, handle browser events, and build interactive web pages.\n\nAs you progress, you'll explore advanced concepts like object-oriented programming, ES6+ features, asynchronous JavaScript (callbacks, promises, async/await) and error handling. The program also dedicates a complete module to covering arrays, strings, stacks, queues, trees, graphs and more strengthening your problem-solving and interview skills.\n\nFinally, you'll apply your knowledge in real-world projects and coding contests, gaining the confidence to build applications and solve complex problems with modern JavaScript.\n\n### Course Highlights:\n- Master the fundamentals: variables, data types, operators, control flow and functions\n- Work with arrays, strings, and objects for data manipulation\n- Build interactive web pages using DOM and event handling\n- Explore modern JavaScript (ES6+): let/const, arrow functions, classes, modules, and more\n- Write and manage asynchronous code with callbacks, promises, and async/await\n- Apply object-oriented programming principles in JavaScript\n- Debug effectively and handle errors using strict mode and try/catch\n- Strengthen DSA problem-solving with hashing, linked lists, stacks, queues, heaps, trees, and graphs\n- Practice with coding challenges and contests to sharpen interview readiness\n- Build and deploy real-world projects to showcase your skills\n\n## Course Content\n\n### WEEK-1: FUNDAMENTALS OF JAVASCRIPT\n- Introduction to JavaScript & Development Setup\n- Variables, Data Types & Operators\n- Control Flow & Loops\n- Functions (declaration, invocation, scope)\n- Array and String Manipulation\n- Working with Objects\n- Daily practice with MCQs\n\n### WEEK-2: FUNCTIONS & CORE JAVASCRIPT\n- Events & Event Handling\n- DOM & BOM Manipulation\n- Object-Oriented Programming (OOP)\n- Modern JavaScript (ES6+ Features)\n- Asynchronous JavaScript (callbacks, promises, async/await)\n- Strict Mode & Error Handling\n- Build real-world projects\n\n### WEEK-3: DATA STRUCTURES IN JAVASCRIPT\n- Recap of Arrays & Strings with Problem-Solving\n- Hashing & Applications\n- Linked Lists (implementation & problems)\n- Stacks (concept & problems)\n- Weekly Coding Contests to test skills\n\n### WEEK-4: ADVANCED DATA STRUCTURES IN JAVASCRIPT\n- Queues & Deques (implementations & problems)\n- Heap & Priority Queue\n- Trees (binary trees, traversal problems)\n- Graphs (BFS, DFS, adjacency list, island problem)\n- Final Contest & Problem-Solving Challenge"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/machine-learning-with-python/", "content": "# Machine Learning with Python Tutorial\n\nPython language is widely used in Machine Learning because it provides libraries like NumPy, Pandas, Scikit-learn, TensorFlow, and Keras. These libraries offer tools and functions essential for data manipulation, analysis, and building machine learning models. It is well-known for its readability and offers platform independence. These all things make it the perfect language of choice for Machine Learning.\n\n**Machine Learning** is a subdomain of artificial intelligence. It allows computers to learn and improve from experience without being explicitly programmed, and It is designed in such a way that allows systems to identify patterns, make predictions, and make decisions based on data.\n\nSo, let's start Python Machine Learning guide to learn more about ML.\n\n## Introduction\n\n- [Introduction to Machine Learning](https://www.geeksforgeeks.org/machine-learning/introduction-machine-learning/)\n- [What is Machine Learning?](https://www.geeksforgeeks.org/machine-learning/ml-machine-learning/)\n- [ML – Applications](https://www.geeksforgeeks.org/machine-learning/machine-learning-introduction/)\n- [Difference between ML and AI](https://www.geeksforgeeks.org/artificial-intelligence/difference-between-machine-learning-and-artificial-intelligence/)\n- [Best Python Libraries for Machine Learning](https://www.geeksforgeeks.org/machine-learning/best-python-libraries-for-machine-learning/)\n\n## Data Processing\n\n- [Understanding Data Processing](https://www.geeksforgeeks.org/machine-learning/ml-understanding-data-processing/)\n- [Generate test datasets](https://www.geeksforgeeks.org/machine-learning/python-generate-test-datasets-for-machine-learning/)\n- [Create Test DataSets using Sklearn](https://www.geeksforgeeks.org/machine-learning/python-create-test-datasets-using-sklearn/)\n- [Data Preprocessing](https://www.geeksforgeeks.org/machine-learning/data-preprocessing-machine-learning-python/)\n- [Data Cleansing](https://www.geeksforgeeks.org/data-analysis/data-cleansing-introduction/)\n- [Label Encoding of datasets](https://www.geeksforgeeks.org/machine-learning/ml-label-encoding-of-datasets-in-python/)\n- [One Hot Encoding of datasets](https://www.geeksforgeeks.org/machine-learning/ml-one-hot-encoding/)\n- [Handling Imbalanced Data with SMOTE and Near Miss Algorithm in Python](https://www.geeksforgeeks.org/machine-learning/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/)\n\n## Supervised learning\n\n- [Types of Learning – Supervised Learning](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/)\n- [Getting started with Classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/)\n- [Types of Regression Techniques](https://www.geeksforgeeks.org/machine-learning/types-of-regression-techniques/)\n- [Classification vs Regression](https://www.geeksforgeeks.org/machine-learning/ml-classification-vs-regression/)\n\n### Linear Regression\n\n- [Introduction to Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/)\n- [Implementing Linear Regression](https://www.geeksforgeeks.org/machine-learning/linear-regression-python-implementation/)\n- [Univariate Linear Regression](https://www.geeksforgeeks.org/python/univariate-linear-regression-in-python/)\n- [Multiple Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-multiple-linear-regression-using-python/)\n- [Linear Regression using sklearn](https://www.geeksforgeeks.org/machine-learning/python-linear-regression-using-sklearn/)\n- [Linear Regression Using Tensorflow](https://www.geeksforgeeks.org/python/linear-regression-using-tensorflow/)\n- [Linear Regression using PyTorch](https://www.geeksforgeeks.org/machine-learning/linear-regression-using-pytorch/)\n- [Boston Housing Kaggle Challenge with Linear Regression [Project]](https://www.geeksforgeeks.org/machine-learning/ml-boston-housing-kaggle-challenge-with-linear-regression/)\n\n### Polynomial Regression\n\n- [Polynomial Regression ( From Scratch using Python )](https://www.geeksforgeeks.org/machine-learning/polynomial-regression-from-scratch-using-python/)\n- [Polynomial Regression](https://www.geeksforgeeks.org/machine-learning/python-implementation-of-polynomial-regression/)\n- [Polynomial Regression for Non-Linear Data](https://www.geeksforgeeks.org/machine-learning/polynomial-regression-for-non-linear-data-ml/)\n- [Polynomial Regression using Turicreate](https://www.geeksforgeeks.org/machine-learning/polynomial-regression-using-turicreate/)\n\n### Logistic Regression\n\n- [Understanding Logistic Regression](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/)\n- [Implementing Logistic Regression](https://www.geeksforgeeks.org/machine-learning/ml-logistic-regression-using-python/)\n- [Logistic Regression using Tensorflow](https://www.geeksforgeeks.org/machine-learning/ml-logistic-regression-using-tensorflow/)\n- [Softmax Regression using TensorFlow](https://www.geeksforgeeks.org/python/softmax-regression-using-tensorflow/)\n- [Softmax Regression Using Keras](https://www.geeksforgeeks.org/machine-learning/softmax-regression-using-keras/)\n\n### Naive Bayes\n\n- [Naive Bayes Classifiers](https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/)\n- [Naive Bayes Scratch Implementation using Python](https://www.geeksforgeeks.org/machine-learning/ml-naive-bayes-scratch-implementation-using-python/)\n- [Complement Naive Bayes (CNB) Algorithm](https://www.geeksforgeeks.org/machine-learning/complement-naive-bayes-cnb-algorithm/)\n- [Applying Multinomial Naive Bayes to NLP Problems](https://www.geeksforgeeks.org/nlp/applying-multinomial-naive-bayes-to-nlp-problems/)\n\n### Support Vector\n\n- [Support Vector Machine Algorithm](https://www.geeksforgeeks.org/machine-learning/support-vector-machine-algorithm/)\n- [Support Vector Machines(SVMs) in Python](https://www.geeksforgeeks.org/machine-learning/classifying-data-using-support-vector-machinessvms-in-python/)\n- [SVM Hyperparameter Tuning using GridSearchCV](https://www.geeksforgeeks.org/machine-learning/svm-hyperparameter-tuning-using-gridsearchcv-ml/)\n- [Creating linear kernel SVM in Python](https://www.geeksforgeeks.org/python/creating-linear-kernel-svm-in-python/)\n- [Major Kernel Functions in Support Vector Machine (SVM)](https://www.geeksforgeeks.org/machine-learning/major-kernel-functions-in-support-vector-machine-svm/)\n- [Using SVM to perform classification on a non-linear dataset](https://www.geeksforgeeks.org/machine-learning/ml-using-svm-to-perform-classification-on-a-non-linear-dataset/)\n\n### Decision Tree\n\n- [Decision Tree](https://www.geeksforgeeks.org/machine-learning/decision-tree/)\n- [Implementing Decision tree](https://www.geeksforgeeks.org/machine-learning/decision-tree-implementation-python/)\n- [Decision Tree Regression using sklearn](https://www.geeksforgeeks.org/machine-learning/python-decision-tree-regression-using-sklearn/)\n\n### Random Forest\n\n- [Random Forest Regression in Python](https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/)\n- [Random Forest Classifier using Scikit-learn](https://www.geeksforgeeks.org/dsa/random-forest-classifier-using-scikit-learn/)\n- [Hyperparameters of Random Forest Classifier](https://www.geeksforgeeks.org/machine-learning/hyperparameters-of-random-forest-classifier/)\n- [Voting Classifier using Sklearn](https://www.geeksforgeeks.org/machine-learning/ml-voting-classifier-using-sklearn/)\n- [Bagging classifier](https://www.geeksforgeeks.org/machine-learning/What-is-Bagging-classifier/)\n\n### K-nearest neighbor (KNN)\n\n- [K Nearest Neighbors with Python | ML](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbors-with-python-ml/)\n- [Implementation of K-Nearest Neighbors from Scratch using Python](https://www.geeksforgeeks.org/machine-learning/implementation-of-k-nearest-neighbors-from-scratch-using-python/)\n- [K-nearest neighbor algorithm in Python](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbor-algorithm-in-python/)\n- [Implementation of KNN classifier using Sklearn](https://www.geeksforgeeks.org/machine-learning/ml-implementation-of-knn-classifier-using-sklearn/)\n- [Imputation using the KNNimputer()](https://www.geeksforgeeks.org/machine-learning/python-imputation-using-the-knnimputer/)\n- [Implementation of KNN using OpenCV](https://www.geeksforgeeks.org/machine-learning/implementation-of-knn-using-opencv/)\n\n## Unsupervised Learning\n\n- [Types of Learning – Unsupervised Learning](https://www.geeksforgeeks.org/machine-learning/unsupervised-learning/)\n- [Clustering in Machine Learning](https://www.geeksforgeeks.org/machine-learning/clustering-in-machine-learning/)\n- [Different Types of Clustering Algorithm](https://www.geeksforgeeks.org/machine-learning/different-types-clustering-algorithm/)\n- [K means Clustering – Introduction](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/)\n- [Elbow Method for optimal value of k in KMeans](https://www.geeksforgeeks.org/machine-learning/elbow-method-for-optimal-value-of-k-in-kmeans/)\n- [K-means++ Algorithm](https://www.geeksforgeeks.org/machine-learning/ml-k-means-algorithm/)\n- [Analysis of test data using K-Means Clustering in Python](https://www.geeksforgeeks.org/python/analysis-of-test-data-using-k-means-clustering-in-python/)\n- [Mini Batch K-means clustering algorithm](https://www.geeksforgeeks.org/machine-learning/ml-mini-batch-k-means-clustering-algorithm/)\n- [Mean-Shift Clustering](https://www.geeksforgeeks.org/machine-learning/ml-mean-shift-clustering/)\n- [DBSCAN – Density based clustering](https://www.geeksforgeeks.org/machine-learning/dbscan-clustering-in-ml-density-based-clustering/)\n- [Implementing DBSCAN algorithm using Sklearn](https://www.geeksforgeeks.org/machine-learning/implementing-dbscan-algorithm-using-sklearn/)\n- [Fuzzy Clustering](https://www.geeksforgeeks.org/machine-learning/ml-fuzzy-clustering/)\n- [Spectral Clustering](https://www.geeksforgeeks.org/machine-learning/ml-spectral-clustering/)\n- [OPTICS Clustering](https://www.geeksforgeeks.org/machine-learning/ml-optics-clustering-explanation/)\n- [OPTICS Clustering Implementing using Sklearn](https://www.geeksforgeeks.org/machine-learning/ml-optics-clustering-implementing-using-sklearn/)\n- [Hierarchical clustering (Agglomerative and Divisive clustering)](https://www.geeksforgeeks.org/machine-learning/hierarchical-clustering/)\n- [Implementing Agglomerative Clustering using Sklearn](https://www.geeksforgeeks.org/machine-learning/implementing-agglomerative-clustering-using-sklearn/)\n- [Gaussian Mixture Model](https://www.geeksforgeeks.org/machine-learning/gaussian-mixture-model/)\n\n## Projects using Machine Learning\n\n- [Rainfall prediction using Linear regression](https://www.geeksforgeeks.org/machine-learning/ml-rainfall-prediction-using-linear-regression/)\n- [Identifying handwritten digits using Logistic Regression in PyTorch](https://www.geeksforgeeks.org/machine-learning/identifying-handwritten-digits-using-logistic-regression-pytorch/)\n- [Kaggle Breast Cancer Wisconsin Diagnosis using Logistic Regression](https://www.geeksforgeeks.org/machine-learning/ml-kaggle-breast-cancer-wisconsin-diagnosis-using-logistic-regression/)\n- [Implement Face recognition using k-NN with scikit-learn](https://www.geeksforgeeks.org/machine-learning/ml-implement-face-recognition-using-k-nn-with-scikit-learn/)\n- [Credit Card Fraud Detection](https://www.geeksforgeeks.org/machine-learning/ml-credit-card-fraud-detection/)\n- [Image compression using K-means clustering](https://www.geeksforgeeks.org/machine-learning/image-compression-using-k-means-clustering/)\n\n## Applications of Machine Learning\n\n- [How Does Google Use Machine Learning?](https://www.geeksforgeeks.org/machine-learning/how-does-google-use-machine-learning/)\n- [How Does NASA Use Machine Learning?](https://www.geeksforgeeks.org/machine-learning/how-does-nasa-use-machine-learning/)\n- [Targeted Advertising using Machine Learning](https://www.geeksforgeeks.org/machine-learning/targeted-advertising-using-machine-learning/)\n- [How Machine Learning Is Used by Famous Companies?](https://www.geeksforgeeks.org/machine-learning/how-machine-learning-is-used-by-famous-companies/)\n\n## Applications Based on Machine Learning\n\nMachine Learning is the most rapidly evolving technology; we are in the era of AI and ML. It is used to solve many real-world problems which cannot be solved with the standard approach. Following are some applications of ML.\n\n- Sentiment analysis\n- Fraud detection\n- Error detection and prevention\n- Weather forecasting and prediction\n- Speech synthesis\n- Recommendation of products to customers in online shopping.\n- Stock market analysis and forecasting\n- Speech recognition\n- Fraud prevention\n- Customer segmentation\n- Object recognition\n- Emotion analysis\n\n### Conclusion\n\nWell, this is the end of this write-up here you will get all the details as well as all the resources about machine learning with Python tutorial. We are sure that this Python machine learning guide will provide a solid foundation in the field of machine learning."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/ai-ml-and-data-science-tutorial-learn-ai-ml-and-data-science/", "content": "# AI, ML and Data Science Tutorial\n\nThis article covers everything you need to learn about AI, ML and Data Science, starting with Python programming, statistics and probability. It also includes EDA, visualization, ML, deep learning, AI, projects and interview questions for career preparation.\n\n## 1. Learning Python\n\nPython is one of the most popular programming languages today, known for its simplicity, extensive features and library support. Its clean syntax makes it beginner-friendly, while its libraries and frameworks makes it perfect for developers.\n\n- [Python Tutorial](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/)\n- [Python Quizzes](https://www.geeksforgeeks.org/python/python-quizzes/)\n- [Python Interview Questions](https://www.geeksforgeeks.org/python/python-interview-questions/)\n\n## 2. Math For Data Science\n\nMath for Data Science is all about the fundamental mathematical tools and concepts you need to work effectively with data. It includes Statistics & Probability, Linear Algebra and Calculus.\n\n- [Linear Algebra for Data Science](https://www.geeksforgeeks.org/machine-learning/ml-linear-algebra-operations/)\n- [Statistics for Data Science](https://www.geeksforgeeks.org/data-science/statistics-for-data-science/)\n- [Probability for Data Science](https://www.geeksforgeeks.org/data-science/probability-data-distributions-in-data-science/)\n- [Calculus for Data Science](https://www.geeksforgeeks.org/machine-learning/mastering-calculus-for-machine-learning-key-concepts-and-applications/)\n- Practice [Linear Algebra](https://www.geeksforgeeks.org/quizzes/linear-algebra-gq/), [Statistics](https://www.geeksforgeeks.org/maths/statistics-questions/), [Probability](https://www.geeksforgeeks.org/quizzes/probability-gq/) and [Calculus](https://www.geeksforgeeks.org/quizzes/numerical-methods-and-calculus-gq/)\n\n## 3. Exploratory Data Analysis\n\nExploratory Data Analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often using visual methods. It involves understanding data, cleaning data, visualizing data and further analysis.\n\n- [Exploratory Data Analysis or EDA](https://www.geeksforgeeks.org/data-analysis/what-is-exploratory-data-analysis/)\n- [EDA with NumPy, Pandas, Matplotlib and Seaborn](https://www.geeksforgeeks.org/data-analysis/eda-with-NumPy-Pandas-Matplotlib-Seaborn/)\n\n## 4. Data Analysis\n\nData Analysis is the technique of collecting, transforming and organizing data to make future predictions and informed data-driven decisions. It also helps to find possible solutions for a business problem.  \nThere are six steps for Data Analysis which are: Ask or Specify Data Requirements, Prepare or Collect Data, Clean and Process, Analyze, Share, Act or Report.\n\n- [Data Analysis](https://www.geeksforgeeks.org/data-analysis/data-analysis-tutorial/)\n- [Data Analytics Projects](https://www.geeksforgeeks.org/quizzes/data-analysis-quiz/)\n- [Data Analysis Quiz](https://www.geeksforgeeks.org/quizzes/data-analysis-quiz/)\n- [Data Analytics Interview Questions](https://www.geeksforgeeks.org/data-science/data-analyst-interview-questions-and-answers/)\n\n## 5. Data Visualization\n\nData visualization is the process of turning data into visual representations like charts, graphs and maps. It helps us understand trends, patterns and outliers.\n\n- [Data Visualization Tutorial](https://www.geeksforgeeks.org/data-visualization/python-data-visualization-tutorial/)\n- [Data Visualization Projects](https://www.geeksforgeeks.org/data-visualization/data-visualization-project-ideas/)\n- [Data Visualization Quiz](https://www.geeksforgeeks.org/quizzes/advance-data-visualization-with-seaborn/)\n- [Data Visualization Interview Questions](https://www.geeksforgeeks.org/data-visualization/data-visualization-interview-questions/)\n\n## 6. Machine Learning\n\nMachine learning is a subset of Artificial Intelligence (AI) that enables computers to learn from data and make predictions without being explicitly programmed.\n\nIt can be categorized into three types: Supervised Learning, Unsupervised Learning and Reinforcement Learning.\n\n- [Machine Learning Tutorial](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\n- [Machine Learning Projects](https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/)\n- [Machine Learning Quiz](https://www.geeksforgeeks.org/quizzes/machine-learning-quiz-questions-and-answers/)\n- [Machine Learning Interview Questions](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n\n## 7. Data Science with Python\n\nData science enables organizations to make informed decisions, solve problems and understand human behavior. As the volume of data grows, so does the demand for skilled data scientists. The most common languages used for data science are Python and R, with Python being particularly popular.\n\n- [Data Science Tutorial](https://www.geeksforgeeks.org/data-science/data-science-with-python-tutorial/)\n- [Data Science Projects](https://www.geeksforgeeks.org/data-science/top-data-science-projects/)\n- [Data Science Quiz](https://www.geeksforgeeks.org/quizzes/data-science-quiz/)\n- [Data Science Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-interview-questions-and-answers/)\n\n## 8. Deep Learning\n\nDeep Learning is a branch of Artificial Intelligence (AI) that enables machines to learn from large amounts of data. It uses neural networks with many layers to automatically find patterns and make predictions.\n\n- [Deep Learning Tutorial](https://www.geeksforgeeks.org/deep-learning/deep-learning-tutorial/)\n- [Deep Learning Projects](https://www.geeksforgeeks.org/deep-learning/deep-learning-projects/)\n- [Deep Learning Quiz](https://www.geeksforgeeks.org/quizzes/introduction-to-deep-learning-and-neural-networks-1/)\n- [Deep Learning Interview Questions](https://www.geeksforgeeks.org/quizzes/introduction-to-deep-learning-and-neural-networks-1/)\n\n## 9. Artificial Intelligence\n\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and act like humans.\n\n- [AI Tutorial](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligence/)\n- [AI Interview Questions](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligenceai-interview-questions-and-answers/)\n- [AI Projects](https://www.geeksforgeeks.org/artificial-intelligence/best-artificial-intelligence-project-ideas/)\n\n## 10. Generative AI & LLM\n\nGenerative AI (Gen AI) is a branch of artificial intelligence that can create new content instead of just analyzing data. It uses machine learning models (like large language models, GANs, and diffusion models) to generate text, images, audio, code, or even video.\n\nLLM (Large Language Model) is a type of artificial intelligence model designed to understand and generate human-like language.\n\n- [Generative AI Tutorial](https://www.geeksforgeeks.org/artificial-intelligence/generative-ai-tutorial/)\n- [Generative AI Roadmap](https://www.geeksforgeeks.org/artificial-intelligence/roadmap-to-generative-ai-a-comprehensive-guide-for-beginners/)\n- [LLM Tutorial](https://www.geeksforgeeks.org/deep-learning/large-language-model-llm-tutorial/)\n\n## AI-ML-DS Interview Questions\n\nThe AI-ML-DS Interview Series is an essential resource designed for individuals aspiring to start or switch careers in the fields of Artificial Intelligence (AI), Machine Learning (ML) and Data Science (DS).\n\n- [AI-ML-DS Interview Series](https://www.geeksforgeeks.org/interview-experiences/ai-ml-ds-interview/)\n\n## Explore\n\n### Machine Learning Basics\n\n- [Introduction to Machine Learning (8 min read)](https://www.geeksforgeeks.org/machine-learning/introduction-machine-learning/)\n- [Types of Machine Learning (13 min read)](https://www.geeksforgeeks.org/machine-learning/types-of-machine-learning/)\n- [What is Machine Learning Pipeline? (7 min read)](https://www.geeksforgeeks.org/blogs/machine-learning-pipeline/)\n- [Applications of Machine Learning (3 min read)](https://www.geeksforgeeks.org/machine-learning/machine-learning-introduction/)\n\n### Python for Machine Learning\n\n- [Machine Learning with Python Tutorial (5 min read)](https://www.geeksforgeeks.org/machine-learning/machine-learning-with-python/)\n- [NumPy Tutorial - Python Library (3 min read)](https://www.geeksforgeeks.org/python/numpy-tutorial/)\n- [Pandas Tutorial (6 min read)](https://www.geeksforgeeks.org/pandas/pandas-tutorial/)\n- [Data Preprocessing in Python (4 min read)](https://www.geeksforgeeks.org/machine-learning/data-preprocessing-machine-learning-python/)\n- [EDA - Exploratory Data Analysis in Python (6 min read)](https://www.geeksforgeeks.org/data-analysis/exploratory-data-analysis-in-python/)\n\n### Feature Engineering\n\n- [What is Feature Engineering? (5 min read)](https://www.geeksforgeeks.org/machine-learning/what-is-feature-engineering/)\n- [Introduction to Dimensionality Reduction (4 min read)](https://www.geeksforgeeks.org/machine-learning/dimensionality-reduction/)\n- [Feature Selection Techniques in Machine Learning (6 min read)](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/)\n\n### Supervised Learning\n\n- [Supervised Machine Learning (7 min read)](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/)\n- [Linear Regression in Machine learning (15+ min read)](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/)\n- [Logistic Regression in Machine Learning (11 min read)](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/)\n- [Decision Tree in Machine Learning (9 min read)](https://www.geeksforgeeks.org/machine-learning/decision-tree-introduction-example/)\n- [Random Forest Algorithm in Machine Learning (5 min read)](https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/)\n- [K-Nearest Neighbor(KNN) Algorithm (8 min read)](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)\n- [Support Vector Machine (SVM) Algorithm (9 min read)](https://www.geeksforgeeks.org/machine-learning/support-vector-machine-algorithm/)\n- [Naive Bayes Classifiers (7 min read)](https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/)\n\n### Unsupervised Learning\n\n- [What is Unsupervised Learning (5 min read)](https://www.geeksforgeeks.org/machine-learning/unsupervised-learning/)\n- [K means Clustering – Introduction (6 min read)](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/)\n- [Hierarchical Clustering in Machine Learning (6 min read)](https://www.geeksforgeeks.org/machine-learning/hierarchical-clustering/)\n- [DBSCAN Clustering in ML - Density based clustering (6 min read)](https://www.geeksforgeeks.org/machine-learning/dbscan-clustering-in-ml-density-based-clustering/)\n- [Apriori Algorithm (6 min read)](https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/)\n- [Frequent Pattern Growth Algorithm (5 min read)](https://www.geeksforgeeks.org/machine-learning/frequent-pattern-growth-algorithm/)\n- [ECLAT Algorithm - ML (5 min read)](https://www.geeksforgeeks.org/machine-learning/ml-eclat-algorithm/)\n- [Principal Component Analysis(PCA) (7 min read)](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)\n\n### Model Evaluation and Tuning\n\n- [Evaluation Metrics in Machine Learning (9 min read)](https://www.geeksforgeeks.org/machine-learning/metrics-for-machine-learning-model/)\n- [Regularization in Machine Learning (5 min read)](https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/)\n- [Cross Validation in Machine Learning (5 min read)](https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/)\n- [Hyperparameter Tuning (7 min read)](https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning/)\n- [ML | Underfitting and Overfitting (5 min read)](https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/)\n- [Bias and Variance in Machine Learning (10 min read)](https://www.geeksforgeeks.org/machine-learning/bias-vs-variance-in-machine-learning/)\n\n### Advanced Techniques\n\n- [Reinforcement Learning (8 min read)](https://www.geeksforgeeks.org/machine-learning/what-is-reinforcement-learning/)\n- [Semi-Supervised Learning in ML (5 min read)](https://www.geeksforgeeks.org/machine-learning/ml-semi-supervised-learning/)\n- [Self-Supervised Learning (SSL) (6 min read)](https://www.geeksforgeeks.org/machine-learning/self-supervised-learning-ssl/)\n- [Ensemble Learning (8 min read)](https://www.geeksforgeeks.org/machine-learning/a-comprehensive-guide-to-ensemble-learning/)\n\n### Machine Learning Practice\n\n- [Machine Learning Interview Questions and Answers (15+ min read)](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n- [100+ Machine Learning Projects with Source Code [2025] (6 min read)](https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/)"}
{"reference": "https://www.geeksforgeeks.org/deep-learning/the-role-of-weights-and-bias-in-neural-networks/", "content": "# Weights and Bias in Neural Networks\n\nNeural networks learn from data and identify complex patterns that makes them important in areas such as image recognition, natural language processing and autonomous systems. It has two fundamental components: weights and biases that help in how neural networks learn and make predictions.\n\n## 1. Weights\n\nWeights are numerical values assigned to the connections between neurons. They find how much influence each input has on the network's final output.\n\n- **Purpose**: During forward propagation, inputs are multiplied by their respective weights before being passed through an [activation function](https://www.geeksforgeeks.org/machine-learning/activation-functions-neural-networks/). This helps decide how strongly an input will affect the output.\n- **Learning Mechanism**: During training, weights are updated iteratively through [optimization algorithms](https://www.geeksforgeeks.org/machine-learning/optimization-algorithms-in-machine-learning/) like gradient descent to minimize the difference between predicted and actual outcomes.\n- **Generalization**: Well-tuned weights help the network not only make accurate predictions on training data but also generalize to new, unseen data.\n- **Example**: In a neural network predicting house prices, the weight for the \"size of the house\" find how much the house size influences the price prediction. The larger the weight, the bigger the impact size will have on the final result.\n\n## 2. Biases\n\nBiases are additional parameters that adjust the output of a neuron. Unlike weights, they are not tied to any specific input but instead shift the activation function to better fit the data.\n\n- **Purpose**: Biases help neurons activate even when the weighted sum of inputs is not enough. This allows the network to recognize patterns that don't necessarily pass through the origin.\n- **Functionality**: Without biases, neurons would only activate when the input reaches a specific threshold. It makes the network more flexible by enabling activation across a wider range of conditions.\n- **Training**: During training, biases are updated alongside weights through backpropagation. Together, they fine-tune the model, improving prediction accuracy.\n- **Example**: In a house price prediction network, the bias might ensure that even for a house with a size of zero, the model predicts a non-zero price. This could reflect a fixed value such as land value or other baseline costs.\n\n## How Neural Networks Learn?\n\nNeural networks learn through a process involving forward propagation and backpropagation. Let's see each step:\n\n### 1. Forward Propagation\n\n[Forward propagation](https://www.geeksforgeeks.org/deep-learning/what-is-forward-propagation-in-neural-networks/) is the initial phase of processing input data through the neural network to produce an output or prediction. Let's see how it works:\n\n![Forward Propagation](https://media.geeksforgeeks.org/wp-content/uploads/20250822111100486293/activation_function.webp)\n\n1. **Input Layer**: The process starts with data entering the network's input layer. This could be anything from pixel values in an image to feature values in a dataset.\n2. **Weighted Sum**: Each neuron calculates the weighted sum of the inputs. Each input is multiplied by its corresponding weight which shows the importance of that input.\n3. **Adding Biases**: A bias is added to the weighted sum. Bias helps shift the output and provides flexibility, allowing the network to make better predictions even if all input values are zero.\n4. **Activation Function**: The sum of the weighted inputs plus bias is passed through an activation function (e.g ReLU, sigmoid). The activation function decides if the neuron should activate which means it will pass information to the next layer or stay inactive.\n5. **Propagation**: This process is repeated across multiple layers. The output of one layer becomes the input for the next, continuing until the network generates the final output or prediction.\n\n### 2. Backpropagation\n\nOnce the network has made a prediction, it's important to evaluate how accurate that prediction is and make adjustments to improve future predictions. This is where [backpropagation](https://www.geeksforgeeks.org/machine-learning/backpropagation-in-neural-network/) comes:\n\n![Backpropagation](https://media.geeksforgeeks.org/wp-content/uploads/20250822113222478925/2.webp)\n\n1. **Error Calculation**: Once the network generates an output, it's compared to the actual result (the target). The difference between the predicted and actual values is the error also called the loss.\n2. **Gradient Calculation**: The error is propagated back through the network and the gradient or slope of the error with respect to the weights and biases is calculated. This tells the network how to adjust the parameters to minimize the error.\n3. **Updating Weights and Biases**: Using the gradient, the network adjusts the weights and biases. The goal is to reduce the error in future predictions. This step is done through an optimization algorithm like [gradient descent](https://www.geeksforgeeks.org/machine-learning/gradient-descent-algorithm-and-its-variants/).\n4. **Iteration**: This process of forward and backward propagation is repeated many times on different batches of data. With each iteration, the network's weights and biases get closer to the optimal values, improving the model's performance.\n\n## Real-World Applications of Neural Networks\n\nNeural networks are increasingly used in various fields to solve complex problems. Let's see various examples of how weights and biases play an important role in below applications:\n\n### 1. Image Recognition\n\nNeural networks are efficient at tasks like object and image classification. For example, in detecting objects like cats, dogs or even specific facial features:\n\n- **Weights**: These find which pixels are important. For example, in a picture of a cat, the weights might give more importance to features like ears, whiskers and eyes, helping the network correctly identify the object.\n- **Biases**: They ensure the network remains adaptable despite changes in image conditions. For example, slight shifts in lighting, position or orientation won't stop the network from recognizing the object.\n\nBy adjusting weights and biases, the network learns to recognize patterns in data and improve its accuracy in classifying new, unseen images.\n\n### 2. Natural Language Processing (NLP)\n\nIn tasks such as sentiment analysis, language translation and chatbots, neural networks analyze and generate text. For example, understanding customer reviews or translating languages:\n\n- **Weights**: These decide how important specific words or phrases are in a given context. For example, recognizing the sentiment of the word \"happy\" in a review versus \"sad\" helps the network understand the sentiment of the sentence.\n- **Biases**: They help the network to adapt to different sentence structures and tones. This helps the model recognize meaning even when the sentence might be phrased differently.\n\nTraining the network on large datasets allows it to interpret language effectively, whether it's classifying emotions in reviews or translating text between languages.\n\n### 3. Autonomous Vehicles\n\nIn self-driving cars, neural networks process a range of sensor data (camera, radar, lidar) to make driving decision such as stopping at a red light or avoiding obstacles:\n\n- **Weights**: The weights help the network focus on important input data such as recognizing pedestrians, road signs and other vehicles, adjusting their significance based on the car's current needs.\n- **Biases**: Biases ensure that the car can adapt to different driving conditions like fog or night-time driving, ensuring safety and accuracy under varied circumstances.\n\nBy continuously adjusting the weights and biases, the system learns how to safely navigate complex environments and make real-time decisions.\n\n### 4. Healthcare and Medical Diagnosis\n\nNeural networks are also applied in healthcare such as in diagnosing diseases from medical images like X-rays, MRIs or CT scans:\n\n- **Weights**: These help the network focus on important features in medical images such as specific areas indicating a tumor or anomaly. This helps the network make more accurate predictions regarding health conditions.\n- **Biases**: Biases allow the network to remain flexible and adaptable to variations in imaging techniques or the patient's body type, making the system more reliable across different scenarios.\n\nBy training on thousands of medical images, the neural network learns to identify patterns and make precise diagnoses, aiding medical professionals in early disease detection.\n\n## Advantages of Weights and Biases\n\n1. **Learning from Data**: Weights and biases help the network adjust to data patterns, enabling it to make predictions based on input significance and flexibility.\n2. **Flexibility in Complex Data**: Biases allow the network to adjust outputs even when inputs are minimal, improving flexibility in tasks like image recognition or language processing.\n3. **Improved Accuracy**: Through iterative updates, weights and biases help reduce prediction errors, leading to more accurate results over time.\n4. **Better Generalization**: Properly tuned weights and biases help the network apply learned patterns to new, unseen data, ensuring it performs well outside the training set.\n5. **Enhanced Learning Capacity**: They allow the network to capture complex patterns, improving its ability to handle complex tasks that traditional algorithms struggle with.\n\n## Challenges of Weights and Biases\n\n1. **Initialization Issues**: Poor initialization of weights and biases can slow learning or lead to suboptimal results. Proper techniques are needed to avoid this.\n2. **Risk of Overfitting**: Over-adjusting weights can lead to overfitting where the model becomes too complex to the training data. Regularization techniques can help prevent this.\n3. **Complex Tuning**: Adjusting weights and biases is a time-consuming process that requires trial and error and substantial computational resources.\n4. **Black Box Nature**: The difficulty in interpreting the impact of individual weights and biases can make the model's decisions hard to explain which is a concern in certain applications.\n5. **High Computational Cost**: Training neural networks and optimizing weights and biases can be resource-intensive, requiring significant processing power and time."}
{"reference": "https://practice.geeksforgeeks.org/events/rec/job-a-thon/", "content": "# Job-a-Thon\n\nQuarterly Hiring Challenge by GfG\n\n## Overview\n\nGeeksforGeeks organizes quarterly recruitment contests suitable for both newcomers (Freshers) and seasoned professionals. Job-A-Thon is a platform to experience real-time hiring rounds and explore potential opportunities in companies.\n\nQuarterly Contest - Check the schedule above for upcoming contest dates.\n\n## Instructions\n\n### Guidelines for Job-A-Thon Candidates\n\n- Job-A-Thon welcomes both Freshers and Experienced professionals, including final-year students and recent pass-outs with 0 years of experience.\n- To participate, register for the live Job-A-Thon event.\n- Your performance does not guarantee getting a call back from Companies.\n- The score of this contest will allow you to prioritize the jobs currently live on GFG Jobs portal that match your skills and qualifications.\n- The contest covers questions on DSA, Programming Logic, Logical Reasoning, and Quantitative Aptitude.\n- Late entries post the contest closure will not be considered.\n- Only individual participation is allowed.\n- GeeksforGeeks reserves the right to disqualify participants for fraudulent actions.\n- In case of disputes regarding rankings and leaderboard, 'GeeksforGeeks' decision is final.\n- Interview shortlisting will be done by companies based on their criteria.\n\n### For Companies\n\n- If You are interested to hire through Job-a-Thon, Write to us at [hire@geeksforgeeks.org](mailto:hire@geeksforgeeks.org) and hire the best coders for your company!\n- Companies need to approach us at the beginning of the month.\n- The job descriptions need to be shared at the earliest. It should be detailed, with mention of Salary, Experience Level, Location, Roles and responsibilities, and Company website link.\n- As per the organization's request, the question paper will be shared in advance.\n- After the contest, a list of upto 30-50 suitable candidates will be shared with the organisation. i.e. - We will share the data of the top 30-50 candidates who performed well in the contest and registered for your company. After getting some update from your end the next batch of candidates will be shared.\n- We're expecting regular updates from the organization (capped for 5 working days.)\n\n## Solutions\n\nWe are going live on Youtube immediately after each contest. GfG Mentors will be live streaming the video editorials and also solving your doubts.\n\n[Head to GfG Practice Youtube Channel](https://www.youtube.com/@GeeksforGeeksPractice)"}
{"reference": "https://twitter.com/geeksforgeeks", "content": "JavaScript is not available.\n\nWe’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.\n\n[Help Center](https://help.x.com/using-x/x-supported-browsers)\n\n[Terms of Service](https://x.com/tos) [Privacy Policy](https://x.com/privacy) [Cookie Policy](https://support.x.com/articles/20170514) [Imprint](https://legal.twitter.com/imprint.html) [Ads info](https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html?ref=web-twc-ao-gbl-adsinfo&utm_source=twc&utm_medium=web&utm_campaign=ao&utm_content=adsinfo) © 2025 X Corp.\n\nSomething went wrong, but don’t fret — let’s give it another shot.\n\nTry again\n\nSome privacy related extensions may cause issues on x.com. Please disable them and try again."}
{"reference": "https://www.geeksforgeeks.org/about/contact-us/", "content": "# Contact Us - GeeksforGeeks\n\n## Feedback and Queries\n\nTo submit feedback or queries, use the contact form with options such as Feedback, Course Related Queries, Course Payment Related Issues, Any Issue in Purchased Course, Review Related Queries, Campus Event Sponsorship Related Queries, Content Improvement Related Queries, Content Internship/Payment Related Queries, DMCA Notice/Copyright Issue/Trademark Issue, DPO Related Queries, Hiring Related Queries, Advertise with us, Brand and Content Integration, Content List Suggestions, Premium Plans Related Queries, Institute/Company Page Related Queries, Collaborate with us if you have a Strong Social Media Presence, or Other.\n\nRequired fields include Email Address and Drop your feedback/query. Optional fields: Contact Number, Link of Original Work.\n\nTo contribute, please see the [contribute page](https://www.geeksforgeeks.org/contribute/).\n\n## Addresses\n\n### Corporate Address (For Communications)\nGeeksforGeeks  \nA-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)  \n08069289001 (Course related Queries)\n\n### Registered Address\nK 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautambuddha Nagar, Uttar Pradesh, 201305\n\n### Other Address\n**Bangalore:** Bhagyalaxmi Square, 2nd Floor, GeeksforGeeks.  \n17/N, 18th Cross Rd, Sector 3, HSR Layout, Bengaluru, Karnataka 560102\n\n### Corporate & Communications Address\nA-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)\n\n### Registered Address\nK 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/what-is-reinforcement-learning/", "content": "# Reinforcement Learning\n\nReinforcement Learning (RL) is a branch of machine learning that focuses on how agents can learn to make decisions through trial and error to maximize cumulative rewards. RL allows machines to learn by interacting with an environment and receiving feedback based on their actions. This feedback comes in the form of rewards or penalties.\n\n![Reinforcement Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250903150649221420/Reinforecement-Learning-in-ML.webp)\n\nReinforcement Learning revolves around the idea that an agent (the learner or decision-maker) interacts with an environment to achieve a goal. The agent performs actions and receives feedback to optimize its decision-making over time.\n\n- **Agent**: The decision-maker that performs actions.\n- **Environment**: The world or system in which the agent operates.\n- **State**: The situation or condition the agent is currently in.\n- **Action**: The possible moves or decisions the agent can make.\n- **Reward**: The feedback or result from the environment based on the agent’s action.\n\n## Core Components\n\n### 1. Policy\n- Defines the agent’s behavior i.e maps states for actions.\n- Can be simple rules or complex computations.\n- **Example**: An autonomous car maps pedestrian detection to make necessary stops.\n\n### 2. Reward Signal\n- Represents the goal of the RL problem.\n- Guides the agent by providing feedback (positive/negative rewards).\n- **Example**: For self-driving cars rewards can be fewer collisions, shorter travel time, lane discipline.\n\n### 3. Value Function\n- Evaluates long-term benefits, not just immediate rewards.\n- Measures desirability of a state considering future outcomes.\n- **Example**: A vehicle may avoid reckless maneuvers (short-term gain) to maximize overall safety and efficiency.\n\n### 4. Model\n- Simulates the environment to predict outcomes of actions.\n- Enables planning and foresight.\n- **Example**: Predicting other vehicles’ movements to plan safer routes.\n\n## Working of Reinforcement Learning\n\nThe agent interacts iteratively with its environment in a feedback loop:\n\n- The agent observes the current state of the environment.\n- It chooses and performs an action based on its policy.\n- The environment responds by transitioning to a new state and providing a reward (or penalty).\n- The agent updates its knowledge (policy, value function) based on the reward received and the new state.\n- This cycle repeats with the agent balancing exploration (trying new actions) and exploitation (using known good actions) to maximize the cumulative reward over time.\n\nThis process is mathematically framed as a [Markov Decision Process (MDP)](https://www.geeksforgeeks.org/machine-learning/markov-decision-process/) where future states depend only on the current state and action, not on the prior sequence of events.\n\n## Implementing Reinforcement Learning\n\nLet's see the working of reinforcement learning with a maze example:\n\n### Step 1: Import libraries and Define Maze, Start and Goal\n\nWe will import the required libraries such as [numpy](https://www.geeksforgeeks.org/python/introduction-to-numpy/) and [matplotlib](https://www.geeksforgeeks.org/python/matplotlib-tutorial/).\n\n- The maze is represented as a 2D NumPy array.\n- Zero values are safe paths; ones are obstacles the agent must avoid.\n- Start and goal define the positions where the agent begins and where it aims to reach.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nmaze = np.array([\n    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n    [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n    [1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n    [1, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n    [1, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n    [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n    [1, 0, 1, 0, 1, 0, 0, 0, 1, 1],\n    [1, 0, 1, 0, 1, 0, 1, 0, 0, 1],\n    [1, 1, 1, 0, 1, 1, 1, 1, 0, 0]\n])\n\nstart = (0, 0)\ngoal = (9, 9)\n```\n\n### Step 2: Define RL Parameters and Initialize Q-Table\n\nWe will define RL parameters;\n\n- **num_episodes**: Number of times the agent will attempt to navigate the maze.\n- **alpha**: Learning rate that controls how much new information overrides old information.\n- **gamma**: Discount factor giving more weight to immediate rewards.\n- **epsilon**: Probability of exploration vs exploitation; starts higher to explore more.\n- Rewards are set to penalize hitting obstacles, reward reaching the goal and slightly penalize each step to find shortest paths.\n- **actions define possible moves:** left, right, up, down.\n- **Q** is the Q-Table initialized to zero; it stores expected rewards for each state-action pair.\n\n```python\nnum_episodes = 5000\nalpha = 0.1\ngamma = 0.9\nepsilon = 0.5\n\nreward_fire = -10\nreward_goal = 50\nreward_step = -1\n\nactions = [(0, -1), (0, 1), (-1, 0), (1, 0)]\n\nQ = np.zeros(maze.shape + (len(actions),))\n```\n\n### Step 3: Helper Function for Maze Validity and Action Selection\n\nWe will define helper function,\n\n- **is_valid** ensures the agent can only move inside the maze and avoids obstacles.\n- **choose_action** implements exploration (random action) vs exploitation (best learned action) strategy.\n\n```python\ndef is_valid(pos):\n    r, c = pos\n    if r < 0 or r >= maze.shape[0]:\n        return False\n    if c < 0 or c >= maze.shape[1]:\n        return False\n    if maze[r, c] == 1:\n        return False\n    return True\n\ndef choose_action(state):\n    if np.random.random() < epsilon:\n        return np.random.randint(len(actions))\n    else:\n        return np.argmax(Q[state])\n```\n\n### Step 4: Train the Agent with Q-Learning Algorithm\n\nWe will train the agent:\n\n- Runs multiple episodes for the agent to learn.\n- During each episode, the agent selects actions and updates its [Q-Table](https://www.geeksforgeeks.org/machine-learning/q-learning-in-python/) using the Q-learning formula: Q(s,a) = Q(s,a) + α [r + γ max_a' Q(s',a') - Q(s,a)]\n- **total_rewards** tracks cumulative rewards per episode.\n- **epsilon** decays gradually to reduce randomness over time.\n\n```python\nrewards_all_episodes = []\n\nfor episode in range(num_episodes):\n    state = start\n    total_rewards = 0\n    done = False\n\n    while not done:\n        action_index = choose_action(state)\n        action = actions[action_index]\n\n        next_state = (state[0] + action[0], state[1] + action[1])\n\n        if not is_valid(next_state):\n            reward = reward_fire\n            done = True\n        elif next_state == goal:\n            reward = reward_goal\n            done = True\n        else:\n            reward = reward_step\n\n        old_value = Q[state][action_index]\n        next_max = np.max(Q[next_state]) if is_valid(next_state) else 0\n\n        Q[state][action_index] = old_value + alpha * \\\n            (reward + gamma * next_max - old_value)\n\n        state = next_state\n        total_rewards += reward\n\n    global epsilon\n    epsilon = max(0.01, epsilon * 0.995)\n    rewards_all_episodes.append(total_rewards)\n```\n\n### Step 5: Extract the Optimal Path after Training\n\n- This function follows the highest Q-values at each state to extract the best path.\n- It stops when the goal is reached or no valid next moves are available.\n- The visited set prevents cycles.\n\n```python\ndef get_optimal_path(Q, start, goal, actions, maze, max_steps=200):\n    path = [start]\n    state = start\n    visited = set()\n\n    for _ in range(max_steps):\n        if state == goal:\n            break\n        visited.add(state)\n\n        best_action = None\n        best_value = -float('inf')\n\n        for idx, move in enumerate(actions):\n            next_state = (state[0] + move[0], state[1] + move[1])\n\n            if (0 <= next_state[0] < maze.shape[0] and\n                0 <= next_state[1] < maze.shape[1] and\n                maze[next_state] == 0 and\n                next_state not in visited):\n\n                if Q[state][idx] > best_value:\n                    best_value = Q[state][idx]\n                    best_action = idx\n\n        if best_action is None:\n            break\n\n        move = actions[best_action]\n        state = (state[0] + move[0], state[1] + move[1])\n        path.append(state)\n\n    return path\n\noptimal_path = get_optimal_path(Q, start, goal, actions, maze)\n```\n\n### Step 6: Visualize the Maze, Robot Path, Start and Goal\n\n- The maze and path are visualized using a calming green color palette.\n- The start and goal positions are visually highlighted.\n- The learned path is drawn clearly to demonstrate the agent's solution.\n\n```python\ndef plot_maze_with_path(path):\n    cmap = ListedColormap(['#eef8ea', '#a8c79c'])\n\n    plt.figure(figsize=(8, 8))\n    plt.imshow(maze, cmap=cmap)\n\n    plt.scatter(start[1], start[0], marker='o', color='#81c784', edgecolors='black',\n                s=200, label='Start (Robot)', zorder=5)\n    plt.scatter(goal[1], goal[0], marker='*', color='#388e3c', edgecolors='black',\n                s=300, label='Goal (Diamond)', zorder=5)\n\n    rows, cols = zip(*path)\n    plt.plot(cols, rows, color='#60b37a', linewidth=4,\n             label='Learned Path', zorder=4)\n\n    plt.title('Reinforcement Learning: Robot Maze Navigation')\n    plt.gca().invert_yaxis()\n    plt.xticks(range(maze.shape[1]))\n    plt.yticks(range(maze.shape[0]))\n    plt.grid(True, alpha=0.2)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\nplot_maze_with_path(optimal_path)\n```\n\n**Output:**\n\n![Maze](https://media.geeksforgeeks.org/wp-content/uploads/20250903143559215634/reinforcement.webp)\n\nAs we can see that the model successfully reached the destination by finding the right path.\n\n### Step 7: Plot Rewards per Training\n\n- This plot shows how the agent's overall performance improves across training episodes.\n- We can observe the total reward trend increasing as the agent learns over time.\n\n```python\ndef plot_rewards(rewards):\n    plt.figure(figsize=(10, 5))\n    plt.plot(rewards)\n    plt.title('Total Rewards per Episode')\n    plt.xlabel('Episode')\n    plt.ylabel('Total Reward')\n    plt.grid(True)\n    plt.show()\n\nplot_rewards(rewards_all_episodes)\n```\n\n**Output:**\n\n![Rewards](https://media.geeksforgeeks.org/wp-content/uploads/20250903144640244897/rewards.webp)\n\n## Types of Reinforcements\n\n### 1. Positive Reinforcement\nPositive Reinforcement is defined as when an event, occurs due to a particular behavior, increases the strength and the frequency of the behavior. In other words, it has a positive effect on behavior.\n\n- **Advantages**: Maximizes performance, helps sustain change over time.\n- **Disadvantages**: Overuse can lead to excess states that may reduce effectiveness.\n\n### 2. Negative Reinforcement\nNegative Reinforcement is defined as strengthening of behavior because a negative condition is stopped or avoided.\n\n- **Advantages**: Increases behavior frequency, ensures a minimum performance standard.\n- **Disadvantages**: It may only encourage just enough action to avoid penalties.\n\n## Online vs. Offline Learning\n\nReinforcement Learning can be categorized based on how and when the learning agent acquires data from its environment, dividing the methods into online RL and offline RL (also known as batch RL).\n\n![Online vs Offline RL](https://media.geeksforgeeks.org/wp-content/uploads/20250903150536874632/_reinforcement-learning.webp)\n\n- In online RL, the agent learns by actively interacting with the environment in real-time. It collects fresh data during training by executing actions and observing immediate feedback as it learns.\n- Offline RL trains the agent exclusively on a pre-collected static dataset of interactions generated by other agents, human demonstrations or historical logs. The agent does not interact with the environment during learning.\n\n| Aspect          | Online RL                          | Offline RL                          |\n|-----------------|------------------------------------|-------------------------------------|\n| Data Acquisition | Direct, real-time interaction with environment | Static, pre-collected dataset       |\n| Adaptivity      | High, continuously adapts          | Limited, depends on dataset coverage |\n| Suitability     | When environment access or simulation is feasible | When environment interaction is costly or risky |\n| Challenges      | Resource-intensive, potentially unsafe | Distributional shift, counterfactual inference issues |\n\n## Application\n\n- **Robotics**: RL is used to automate tasks in structured environments such as manufacturing, where robots learn to optimize movements and improve efficiency.\n- **Games**: Advanced RL algorithms have been used to develop strategies for complex games like chess, Go and video games, outperforming human players in many instances.\n- **Industrial Control**: RL helps in real-time adjustments and optimization of industrial operations, such as refining processes in the oil and gas industry.\n- **Personalized Training Systems**: RL enables the customization of instructional content based on an individual's learning patterns, improving engagement and effectiveness.\n\n## Advantages\n\n- Solves complex sequential decision problems where other approaches fail.\n- Learns from real-time interaction, enabling adaptation to changing environments.\n- Does not require labeled data, unlike supervised learning.\n- Can innovate by discovering new strategies beyond human intuition.\n- Handles uncertainty and stochastic environments effectively.\n\n## Disadvantages\n\n- Computationally intensive, requiring large amounts of data and processing power.\n- Reward function design is critical; poor design leads to unintended behaviors.\n- Not suitable for simple problems where traditional methods are more efficient.\n- Challenging to debug and interpret, making it hard to explain decisions.\n- Exploration-exploitation trade-off requires careful balancing to optimize learning."}
{"reference": "https://www.geeksforgeeks.org/dsa/dsa-tutorial-learn-data-structures-and-algorithms/", "content": "# DSA Tutorial - Learn Data Structures and Algorithms\n\nDSA stands for **D**ata **S**tructures and **A**lgorithms. Data structures manage how data is stored and accessed. Algorithms focus on processing this data. Examples of data structures are Array, Linked List, Tree and Heap, and examples of algorithms are Binary Search, Quick Sort and Merge Sort.\n\n## Why to Learn DSA?\n\n- Foundation for almost every software like GPS, Search Engines, AI ChatBots, Gaming Apps, Databases, Web Applications, etc\n- Top Companies like Google, Microsoft, Amazon, Apple, Meta and many other heavily focus on DSA **i**n interviews.\n- Learning DSA boosts your problem-solving abilities and make you a stronger programmer.\n\n## How to learn DSA?\n\n1. Learn at-least one programming language ([C++](https://www.geeksforgeeks.org/cpp/c-plus-plus/), [Java](https://www.geeksforgeeks.org/java/java/), [Python](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/) or [JavaScript](https://www.geeksforgeeks.org/javascript/javascript-tutorial/)) and build your basic logic.\n2. Learn about Time and Space complexities\n3. Learn Data Structures (Arrays, Linked List, etc) and Algorithms (Searching, Sorting, etc).\n4. Once you learn main topics, it is important to [solve coding problems](https://www.geeksforgeeks.org/explore?page=1&sortBy=submissions&itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=practice_header) against some predefined test cases,\n5. Solve problems daily using [GfG Problem of the Day](https://www.geeksforgeeks.org/problem-of-the-day)\n\n> Try our free courses [GfG 160](https://www.geeksforgeeks.org/courses/gfg-160-series) and [DSA Skillup](https://www.geeksforgeeks.org/courses/dsa-skill-up) with daily topic coverage, notes, quizzes and most asked coding problems.\n\n### 1. Logic Building\n\nOnce you have learned basics of a programming language, it is recommended that you learn basic logic building\n\n- [Logic Building Guide](https://www.geeksforgeeks.org/dsa/logic-building-problems/)\n- [Quiz on Logic Building](https://www.geeksforgeeks.org/quizzes/dsa-tutorial-logic-building/)\n\n### 2. Learn about Complexities\n\nTo analyze algorithms, we mainly measure order of growth of time or space taken in terms of input size. We do this in the worst case scenario in most of the cases. Please refer the below links for a clear understanding of these concepts.\n\n- [Complexity Analysis Guide](https://www.geeksforgeeks.org/dsa/analysis-of-algorithms/)\n- [Quiz on Complexity Analysis](https://www.geeksforgeeks.org/quizzes/quiz-on-complexity-analysis-for-dsa/)\n\n### 3. Array\n\n**Array** is a linear data structure where elements are allocated **contiguous memory**, allowing for **constant-time access**.\n\n- [Array Guide](https://www.geeksforgeeks.org/dsa/array-data-structure-guide/)\n- [Quiz on Arrays](https://www.geeksforgeeks.org/quizzes/dsa-tutorial-array/)\n\n### 4. Searching Algorithms\n\n**Searching algorithms** are used to locate specific data within a large set of data. It helps **find a target value** within the data. There are various types of searching algorithms, each with its own approach and efficiency.\n\n- [Searching Guide](https://www.geeksforgeeks.org/dsa/searching-algorithms/)\n- [Quiz on Searching](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-searching-algorithm-with-answers/)\n\n### 5. Sorting Algorithm\n\n**Sorting algorithms** are used to **arrange** the elements of a list in a **specific order**, such as numerical or alphabetical. It organizes the items in a systematic way, making it easier to search for and access specific elements.\n\n- [Sorting Guide](https://www.geeksforgeeks.org/dsa/sorting-algorithms/)\n- [Quiz on Sorting](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-sorting-algorithms-with-answers/)\n\n### 6. Hashing\n\nHashing is a technique that generates a fixed-size output (hash value) from an input of variable size using mathematical formulas called hash functions. Hashing is commonly used in data structures for efficient searching, insertion and deletion.\n\n- [Hashing Guide](https://www.geeksforgeeks.org/dsa/hashing-data-structure/)\n- [Quiz on Hashing](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-hash-data-strcuture-with-answers/)\n\n### 7. Two Pointer Technique\n\n**I**n Two Pointer Technique, we typically use two index variables from two corners of an array. We use the two pointer technique for searching a required point or value in an array.\n\n- [Two Pointer Technique](https://www.geeksforgeeks.org/dsa/two-pointers-technique/)\n- [Quiz on Two Pointer Technique](https://www.geeksforgeeks.org/quizzes/quiz-on-two-pointer-technique-for-dsa/)\n\n### 8. Window Sliding Technique\n\n**I**n Window Sliding Technique, we use the result of previous subarray to quickly compute the result of current.\n\n- [Window Sliding Technique](https://www.geeksforgeeks.org/dsa/window-sliding-technique/)\n- [Quiz on Sliding Window](https://www.geeksforgeeks.org/quizzes/quiz-on-sliding-window-technique-for-dsa/)\n\n### 9. Prefix Sum Technique\n\n**I**n Prefix Sum Technique, we compute prefix sums of an array to quickly find results for a subarray.\n\n- [Prefix Sum Technique](https://www.geeksforgeeks.org/dsa/prefix-sum-array-implementation-applications-competitive-programming/)\n- [Quiz on Prefix Sum](https://www.geeksforgeeks.org/quizzes/quiz-on-prefix-sum-for-dsa/)\n\n### 10. String\n\nA sequence of characters, typically immutable and have limited set of elements (lower case or all English alphabets).\n\n- [Strings Guide](https://www.geeksforgeeks.org/dsa/string-data-structure/)\n- [Quiz on Strings](https://www.geeksforgeeks.org/quizzes/quiz-on-string-for-dsa/)\n\n### 11. Recursion\n\nA programming technique where a function **calls itself** within its own definition. It is usually used to solve problems that can be broken down into smaller instances of the same problem.\n\n- [Recursion Guide](https://www.geeksforgeeks.org/dsa/recursion-algorithms/)\n- [Quiz on Recursion](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-recursion-algorithm-with-answers/)\n\n### 12. Matrix/Grid\n\nA two-dimensional array of elements, arranged in **rows** and **columns**. It is represented as a rectangular grid, with each element at the intersection of a row and column.\n\n- [Matrix Guide](https://www.geeksforgeeks.org/dsa/matrix/)\n- [Quiz on Matrix/Grid.](https://www.geeksforgeeks.org/quizzes/quiz-on-matrixgrid-for-dsa/)\n\n### 13. Linked List\n\nA linear data structure that stores data in nodes, which are connected by pointers. Unlike arrays, nodes of linked lists are not stored in contiguous memory locations and can only be **accessed sequentially**, starting from the head of list.\n\n- [Linked List Guide](https://www.geeksforgeeks.org/dsa/linked-list-data-structure/)\n- [Quiz on Linked List](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-linked-list-data-structure-with-answers/)\n\n### 14. Stack\n\n**A** linear data structure that follows the **Last In, First Out (LIFO)** principle. Stacks play an important role in managing function calls, memory, and are widely used in algorithms like stock span problem, next greater element and largest area in a histogram.\n\n- [Stack Guide](https://www.geeksforgeeks.org/dsa/stack-data-structure/)\n- [Quiz on Stack](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-stack-data-strcuture-with-answers/)\n\n### 15. Queue\n\n**Queue** is a linear data structure that follows the **First In, First Out (FIFO)** principle. Queues play an important role in managing tasks or data in order, scheduling and message handling systems.\n\n- [Queue Guide](https://www.geeksforgeeks.org/dsa/queue-data-structure/)\n- [Quiz on Queue](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-queue-data-structure-with-answers/)\n\n### 16. Deque\n\nA Deque or double-ended queue is a data structure that allows elements to be added or removed from both ends efficiently.\n\n- [Deque Guide](https://www.geeksforgeeks.org/dsa/deque-set-1-introduction-applications/)\n- [Quiz on Deque](https://www.geeksforgeeks.org/quizzes/deque-960/)\n\n### 17. Tree\n\nA **non-linear, hierarchical** data structure consisting of nodes connected by edges, with a top node called the **root** and nodes having child nodes. It is widely used in **file systems**, **databases**, **decision-making algorithms**, etc.\n\n- [Tree Guide](https://www.geeksforgeeks.org/dsa/tree-data-structure/)\n- [Quiz on Tree](https://www.geeksforgeeks.org/quizzes/tree-22648/)\n\n### 18. Heap\n\nA **complete binary tree** that satisfies the **heap property**. Heaps are usually used to implement [priority queues](https://www.geeksforgeeks.org/dsa/priority-queue-set-1-introduction/), where the **smallest** or **largest** element is always at the root of the tree.\n\n- [Heap Guide](https://www.geeksforgeeks.org/dsa/heap-data-structure/)\n- [Quiz on Heap](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-heap-data-strcuture-with-answers/)\n\n### 19. Graph\n\nA **non-linear** data structure consisting of a finite set of **vertices**(or nodes) and a set of **edges**(or links)that connect a pair of nodes. Graphs are widely used to represent relationships between entities.\n\n- [Graph Guide](https://www.geeksforgeeks.org/dsa/graph-data-structure-and-algorithms/)\n- [Quiz on Graph](https://www.geeksforgeeks.org/quizzes/graph-12715/)\n\n### 20. Greedy Algorithm\n\nGreedy Algorithm builds up the solution one piece at a time and chooses the next piece which gives the most obvious and immediate benefit i.e., which is the most optimal choice at that moment. So the problems where choosing **locally optimal** also leads to the global solutions are best fit for Greedy.\n\n- [Greedy Algorithms Guide](https://www.geeksforgeeks.org/dsa/greedy-algorithms/)\n- [Quiz on Greedy](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-greedy-algorithms-with-answers/?page=3)\n\n### 21. Dynamic Programming\n\nDynamic Programming is a method used to solve complex problems by breaking them down into simpler **subproblems**. By solving each subproblem only once and storing the results, it avoids redundant computations, leading to more efficient solutions for a wide range of problems.\n\n- [Dynamic Programming Guide](https://www.geeksforgeeks.org/competitive-programming/dynamic-programming/)\n- [Quiz on DP](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-dynamic-programming-with-answers/)\n\n### 22. Advanced Data Structure and Algorithms\n\nAdvanced Data Structures like **Trie**, **Segment Tree**, **Red-Black Tree** and **Binary Indexed Tree** offer significant performance improvements for specific problem domains. They provide efficient solutions for tasks like fast prefix searches, range queries, dynamic updates, and maintaining balanced data structures, which are crucial for handling large datasets and real-time processing.\n\n- [Trie](https://www.geeksforgeeks.org/dsa/trie-insert-and-search/)\n- [Segment Tree](https://www.geeksforgeeks.org/dsa/segment-tree-data-structure/)\n- [Red-Black Tree](https://www.geeksforgeeks.org/dsa/introduction-to-red-black-tree/)\n- [Binary Indexed Tree](https://www.geeksforgeeks.org/dsa/binary-indexed-tree-or-fenwick-tree-2/)\n- [Practice Advanced Data Structures](https://www.geeksforgeeks.org/dsa/advance-data-structure/)\n\n### 23. Other Algorithms\n\n**Bitwise Algorithms:** Operate on individual bits of numbers.\n\n- [Bitwise Algorithms Guide](https://www.geeksforgeeks.org/dsa/bitwise-algorithms/)\n- [Quiz on Bit Magic](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-bitwise-algorithms-and-bit-manipulations-with-answers/)\n\n**Backtracking Algorithm :** Follow Recursion with the option to **revert and traces back** if the solution from current point is not feasible.\n\n- [Backtracking Guide](https://www.geeksforgeeks.org/dsa/backtracking-algorithms/)\n- [Quiz on Backtracking](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-backtracking-algorithm-with-answers/)\n\n**Divide and conquer:** A strategy to solve problems by dividing them into **smaller subproblems**, solving those subproblems, and combining the solutions to obtain the final solution.\n\n- [Divide and Conquer Guide](https://www.geeksforgeeks.org/dsa/divide-and-conquer/)\n- [Quiz on Divide and Conquer](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-divide-and-conquer-algrithm-with-answers/)\n\n**Branch and Bound :** Used in combinatorial optimization problems to systematically search for the best solution. It works by dividing the problem into smaller subproblems, or branches, and then eliminating certain branches based on bounds on the optimal solution. This process continues until the best solution is found or all branches have been explored.\n\n- [Branch and Bound Algorithm](https://www.geeksforgeeks.org/dsa/branch-and-bound-algorithm/)\n\n**Geometric algorithms** are a set of algorithms that solve problems related to shapes, points, lines and polygons.\n\n- [Geometric Algorithms](https://www.geeksforgeeks.org/dsa/geometric-algorithms/)\n- [Practice Geometric Algorithms](https://www.geeksforgeeks.org/explore?page=1&category=Geometric&sortBy=submissions)\n\n**Randomized algorithms** are algorithms that use randomness to solve problems. They make use of random input to achieve their goals, often leading to simpler and more efficient solutions. These algorithms may not product same result but are particularly useful in situations when a probabilistic approach is acceptable.\n\n- [Randomized Algorithms](https://www.geeksforgeeks.org/dsa/randomized-algorithms/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/metrics-for-machine-learning-model/", "content": "# Evaluation Metrics in Machine Learning\n\nWhen building machine learning models, it's important to understand how well they perform. Evaluation metrics help us to measure the effectiveness of our models. Whether we are solving a classification problem, predicting continuous values or clustering data, selecting the right evaluation metric allows us to assess how well the model meets our goals.\n\n## Classification Metrics\n\nClassification problems aim to predict discrete categories. To evaluate the performance of classification models, we use the following metrics:\n\n### 1. Accuracy\n\n**Accuracy** is a fundamental metric used for evaluating the performance of a classification model. It tells us the proportion of correct predictions made by the model out of all predictions.\n\n> $$ \\rm{Accuracy} = \\frac{\\rm{Number\\ of\\ Correct \\ Predictions}}{\\rm{Total\\ Number \\ of \\ Predictions}} $$\n\nWhile accuracy provides a quick snapshot, it can be misleading in cases of imbalanced datasets. For example, in a dataset with 90% class A and 10% class B, a model predicting only class A will still achieve 90% accuracy but it will fail to identify any class B instances.\n\nAccuracy is good but it gives a False Positive sense of achieving high accuracy. The problem arises due to the possibility of misclassification of minor class samples being very high.\n\n### 2. Precision\n\nIt measures how many of the positive predictions made by the model are actually correct. It's useful when the cost of false positives is high such as in medical diagnoses where predicting a disease when it's not present can have serious consequences.\n\n> $$ \\rm{Precision} = \\frac{TP}{TP + FP} $$\n\nWhere:\n\n- TP = True Positives\n- FP = False Positives\n\n[Precision](https://www.geeksforgeeks.org/physics/accuracy-and-precision/) helps ensure that when the model predicts a positive outcome, it's likely to be correct.\n\n### 3. Recall\n\n[Recall](https://www.geeksforgeeks.org/machine-learning/precision-recall-curve-ml/) or Sensitivity measures how many of the actual positive cases were correctly identified by the model. It is important when missing a positive case (false negative) is more costly than false positives.\n\n> $$ \\rm{Recall} = \\frac{TP}{TP + FN} $$\n\nWhere:\n\n- FN = False Negatives\n\nIn scenarios where catching all positive cases is important (like disease detection), recall is a key metric.\n\n### 4. F1 Score\n\nThe [F1 Score](https://www.geeksforgeeks.org/machine-learning/f1-score-in-machine-learning/) is the harmonic mean of **precision** and **recall**. It is useful when we need a balance between precision and recall as it combines both into a single number. A high F1 score means the model performs well on both metrics. Its range is [0,1].\n\nLower recall and higher precision gives us great accuracy but then it misses a large number of instances. More the F1 score better will be performance. It can be expressed mathematically in this way:\n\n> $$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n\n### 5. Logarithmic Loss (Log Loss)\n\n[Log loss](https://www.geeksforgeeks.org/machine-learning/ml-log-loss-and-mean-squared-error/) measures the uncertainty of the model's predictions. It is calculated by penalizing the model for assigning low probabilities to the correct classes. This metric is used in multi-class classification and is helpful when we want to assess a model's confidence in its predictions. If there are N samples belonging to the M class, then we calculate the Log loss in this way:\n\n> $$ \\text{Logarithmic Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{M} y_{ij} \\cdot \\log(p_{ij}) $$\n\nWhere:\n\n- $y_{ij}$ = Actual class (0 or 1) for sample i and class j\n- $p_{ij}$ = Predicted probability for sample i and class j\n\nThe goal is to minimize Log Loss, as a lower Log Loss shows higher prediction accuracy.\n\n### 6. Area Under Curve (AUC) and ROC Curve\n\nIt is useful for binary classification tasks. The [AUC](https://www.geeksforgeeks.org/machine-learning/auc-roc-curve/) value represents the probability that the model will rank a randomly chosen positive example higher than a randomly chosen negative example. AUC ranges from 0 to 1 with higher values showing better model performance.\n\n#### 1. True Positive Rate (TPR)\n\nAlso known as **sensitivity** or **recall**, the True Positive Rate measures how many actual positive instances were correctly identified by the model. It answers the question: \"Out of all the actual positive cases, how many did the model correctly identify?\"\n\nFormula:\n\n> $$ \\rm{TPR} = \\frac{TP}{TP + FN} $$\n\nWhere:\n\n- TP = True Positives (correctly predicted positive cases)\n- FN = False Negatives (actual positive cases incorrectly predicted as negative)\n\n#### 2. True Negative Rate (TNR)\n\nAlso called **specificity**, the True Negative Rate measures how many actual negative instances were correctly identified by the model. It answers the question: \"Out of all the actual negative cases, how many did the model correctly identify as negative?\"\n\nFormula:\n\n> $$ \\rm{TNR} = \\frac{TN}{TN + FP} $$\n\nWhere:\n\n- TN = True Negatives (correctly predicted negative cases)\n- FP = False Positives (actual negative cases incorrectly predicted as positive)\n\n#### 3. False Positive Rate (FPR)\n\nIt measures how many actual negative instances were incorrectly classified as positive. It's a key metric when the cost of false positives is high such as in fraud detection.\n\nFormula:\n\n> $$ \\rm{FPR} = \\frac{\\rm{FP}}{\\rm{FP + TN}} $$\n\nWhere:\n\n- FP = False Positives (incorrectly predicted positive cases)\n- TN = True Negatives (correctly predicted negative cases)\n\n#### 4. False Negative Rate (FNR)\n\nIt measures how many actual positive instances were incorrectly classified as negative. It answers: \"Out of all the actual positive cases, how many were misclassified as negative?\"\n\nFormula:\n\n> $$ \\rm{FNR} = \\frac{\\rm{FN}}{\\rm{FN + TP}} $$\n\nWhere:\n\n- FN = False Negatives (incorrectly predicted negative cases)\n- TP = True Positives (correctly predicted positive cases)\n\n#### ROC Curve\n\nIt is a graphical representation of the True Positive Rate (TPR) vs the False Positive Rate (FPR) at different classification thresholds. The curve helps us visualize the trade-offs between sensitivity (TPR) and specificity (1 - FPR) across various thresholds. Area Under Curve (AUC) quantifies the overall ability of the model to distinguish between positive and negative classes.\n\n- AUC = 1: Perfect model (always correctly classifies positives and negatives).\n- AUC = 0.5: Model performs no better than random guessing.\n- AUC < 0.5: Model performs worse than random guessing (showing that the model is inverted).\n\n![ROC Curve for Evaluation of Classification Models](https://media.geeksforgeeks.org/wp-content/uploads/20200812084536/auc.png)\n\n*ROC Curve for Evaluation of Classification Models*\n\n### 7. Confusion Matrix\n\n[Confusion matrix](https://www.geeksforgeeks.org/machine-learning/confusion-matrix-machine-learning/) creates a N X N matrix, where N is the number of classes or categories that are to be predicted. Here we have N = 2, so we get a 2 X 2 matrix. Suppose there is a problem with our practice which is a [binary classification](https://www.geeksforgeeks.org/deep-learning/binary-cross-entropy-log-loss-for-binary-classification/). Samples of that classification belong to either Yes or No. So, we build our classifier which will predict the class for the new input sample. After that, we tested our model with 165 samples and we get the following result.\n\n| n=165 | Predicted No | Predicted Yes |\n|-------|--------------|---------------|\n| Actual No | 50 | 10 |\n| Actual Yes | 5 | 100 |\n\nThere are 4 terms we should keep in mind:\n\n1. **True Positives:** It is the case where we predicted Yes and the real output was also Yes.\n2. **True Negatives:** It is the case where we predicted No and the real output was also No.\n3. **False Positives:** It is the case where we predicted Yes but it was actually No.\n4. **False Negatives:** It is the case where we predicted No but it was actually Yes.\n\n## Regression Metrics\n\nIn the regression task, we are supposed to predict the target variable which is in the form of continuous values. To evaluate the performance of such a model below metrics are used:\n\n### 1. Mean Absolute Error (MAE)\n\n[MAE](https://www.geeksforgeeks.org/python/how-to-calculate-mean-absolute-error-in-python/) calculates the average of the absolute differences between the predicted and actual values. It gives a clear view of the model's prediction accuracy but it doesn't shows whether the errors are due to over- or under-prediction. It is simple to calculate and interpret helps in making it a good starting point for model evaluation.\n\n> $$ \\rm{MAE} = \\frac{1}{N} \\sum_{j=1}^{N} \\| y_{j} - \\hat{y}_{j} \\| $$\n\nWhere:\n\n- $y_j$ = Actual value\n- $\\hat{y}_j$ = Predicted value\n\n### 2. Mean Squared Error (MSE)\n\n[MSE](https://www.geeksforgeeks.org/python/python-mean-squared-error/) calculates the average of the squared differences between the predicted and actual values. Squaring the differences ensures that larger errors are penalized more heavily helps in making it sensitive to outliers. This is useful when large errors are undesirable but it can be problematic when outliers are not relevant to the model's purpose.\n\nFormula:\n\n> $$ \\rm{MSE} = \\frac{1}{N} \\sum_{j=1}^{N} (y_{j} - \\hat{y}_{j})^2 $$\n\nWhere:\n\n- $y_j$ = Actual value\n- $\\hat{y}_j$ = Predicted value\n\n### 3. Root Mean Squared Error (RMSE)\n\n[RMSE](https://www.geeksforgeeks.org/r-language/root-mean-square-error-in-r-programming/) is the square root of MSE, bringing the metric back to the original scale of the data. Like MSE, it heavily penalizes larger errors but is easier to interpret as it's in the same units as the target variable. It's useful when we want to know how much our predictions deviate from the actual values in terms of the same scale.\n\nFormula:\n\n> $$ \\rm{RMSE} = \\sqrt{ \\frac{ \\sum_{j=1}^{N} (y_{j} - \\hat{y}_{j})^2 }{N} } $$\n\nWhere:\n\n- $y_j$ = Actual value\n- $\\hat{y}_j$ = Predicted value\n\n### 4. Root Mean Squared Logarithmic Error (RMSLE)\n\nRMSLE is useful when the target variable spans a wide range of values. Unlike RMSE, it penalizes underestimations more than overestimations helps in making it ideal for situations where the model is predicting quantities that vary greatly in scale like predicting prices or population.\n\nFormula:\n\n> $$ \\rm{RMSLE} = \\sqrt{ \\frac{ \\sum_{j=1}^{N} ( \\log(y_{j}+1) - \\log (\\hat{y}_{j}+1) )^2 }{N} } $$\n\nWhere:\n\n- $y_j$ = Actual value\n- $\\hat{y}_j$ = Predicted value\n\n### 5. R² (R-squared)\n\n[R2 score](https://www.geeksforgeeks.org/machine-learning/python-coefficient-of-determination-r2-score/) represents the proportion of the variance in the dependent variable that is predictable from the independent variables. An R² value close to 1 shows a model that explains most of the variance while a value close to 0 shows that the model does not explain much of the variability in the data. R² is used to assess the goodness-of-fit of regression models.\n\nFormula:\n\n> $$ R^2 = 1 - \\frac{ \\sum_{j=1}^{n} (y_j - \\hat{y}_j)^2 }{ \\sum_{j=1}^{n} (y_j - \\bar{y})^2 } $$\n\nWhere:\n\n- $y_j$ = Actual value\n- $\\hat{y}_j$ = Predicted value\n- $\\bar{y}$ = Mean of the actual values\n\n## Clustering Metrics\n\nIn unsupervised learning tasks such as clustering, the goal is to group similar data points together. Evaluating clustering performance is often more challenging than supervised learning since there is no explicit ground truth. However, clustering metrics provide a way to measure how well the model is grouping similar data points.\n\n### 1. Silhouette Score\n\n[Silhouette Score](https://www.geeksforgeeks.org/machine-learning/what-is-silhouette-score/) evaluates how well a data point fits within its assigned cluster considering how close it is to points in its own cluster (cohesion) and how far it is from points in other clusters (separation). A higher silhouette score (close to +1) shows well-clustered data while a score near -1 suggests that the data point is in the wrong cluster.\n\nFormula:\n\n> $$ \\text{Silhouette Score} = \\frac{b - a}{\\max(a, b)} $$\n\nWhere:\n\n- a = Average distance between a sample and all other points in the same cluster\n- b = Average distance between a sample and all points in the nearest cluster\n\n### 2. Davies-Bouldin Index\n\n[Davies-Bouldin Index](https://www.geeksforgeeks.org/machine-learning/davies-bouldin-index/) measures the average similarity between each cluster and its most similar cluster. A lower Davies-Bouldin index shows better clustering as it suggests the clusters are well-separated and compact. The goal is to minimize the Davies-Bouldin index to achieve optimal clustering.\n\nFormula:\n\n> $$ \\text{Davies-Bouldin Index} = \\frac{1}{N} \\sum_{i=1}^{N} \\max_{i \\neq j} \\left( \\frac{\\sigma_i + \\sigma_j}{d(c_i, c_j)} \\right) $$\n\nWhere:\n\n- $\\sigma _ i$ = Average distance of points in cluster i from the cluster centroid\n- $d(c_i, c_j)$ = Distance between centroids of clusters i and j\n\nBy mastering the appropriate evaluation metrics, we upgrade ourselves to fine-tune machine learning models which helps in ensuring they meet the needs of diverse applications and deliver optimal performance."}
{"reference": "https://www.geeksforgeeks.org/courses/gfg-160-series", "content": "# GfG 160 - 160 Days of Problem Solving\n\n**Self-Paced Course**\n\n**Beginner to Advance**  \n**22 Weeks**\n\nMaster one DSA problem daily with **GfG 160!** Join this free 160-Day program which will help you practice DSA problems in a structured and organized manner. Get **in-depth articles, step-by-step video explanations and access to additional bonus problems** with video solutions. Recommended for: Students & Professionals.\n\n## Course Overview\n\n**What is GfG 160:** Solve handpicked coding problems daily for the next 160 days and master DSA in a structured and organized manner. No need for random SDE sheets anymore! Practice topic-wise DSA Problems with this 160 Day roadmap that will help you improve your DSA skills with additional problems and teach you approaches in a structured manner. So for the next 160 days, just solve the problems in the order recommended in this course to enhance your DSA skills. (See the Detailed Course Syllabus PDF below to check out the flow in which problems will be solved).\n\n**Recommended for**: Anyone looking to prepare for coding interviews, improve their DSA knowledge, or enhance their programming abilities. The additional Career workshops are a bonus for you to learn about the trending tech stacks and their career scopes.\n\n**What's New: Summer Skill Up Sprint Series** - Register today to know the full schedule of the workshops!\n\nWhat else you are getting in this:\n\n* 160 Handpicked DSA Problems: Each problem comes with a detailed article and a video explanation for thorough understanding.\n* 90 Bonus Problems: Extra practice problems with video solutions which makes a **total of 250 Problems.**\n* **Completion Certificate:** Receive a certificate upon successfully finishing the course, validating your skills and knowledge in the field.\n* Concept Coverage: Includes problems on key topics like Arrays, Strings, Sorting, Searching, Matrix, Hashing, Two Pointer Technique, Prefix Sum, and more.\n* Perfect for Coding Interviews: Ideal for those preparing for interviews or looking to deepen their knowledge of DSA.\n* Assured Rewards: Get rewarded for your consistency.\n* Organized Learning: Solve in a structured manner created for best learning outcome.\n* Career Roadmap Sessions: Free extra workshops on trending techs such as DevOps, Software testing, Full Stack & more for a complete guided experience.\n\n## Course Content\n\n01 Arrays: Lay the Foundation (Days 1–13)  \n02 Strings: Master Text Processing (Days 14–20)  \n03 Sorting: Organize Data Efficiently (Days 21–27)  \n04 Searching: Find What You Need Fast (Days 28–35)\n\nLogin to view detailed syllabus\n\n## Pricing\n\n## Frequently Asked Questions\n\n01 ### What is GfG 160\n\n02 ### What if I have already claimed a Bag?\n\n03 ### Who is this course for?\n\n04 ### Is DSA hard to learn?\n\n05 ### Is GfG 160 Free?\n\n06 ### What programming languages are best for learning DSA?\n\n07 ### How does DSA help in coding interviews?\n\n08 ### Is there a contact number available for inquiries?"}
{"reference": "https://www.geeksforgeeks.org/courses/system-design-skill-up", "content": "# System Design - Skill Up\n\nSelf-Paced Course\n\n![course-thumbnail](/_next/image?url=https%3A%2F%2Fmedia.geeksforgeeks.org%2Fimg-practice%2Fprod%2Fcourses%2F963%2FMobile%2FContent%2Fsystem-design_1754979276.png&w=3840&q=75)\n\n7k+ interested Geeks\n\nThis **System Design course** is made to help you learn how to build software systems that can grow, handle lots of users, and work well over time. You'll start with the basics of design and object-oriented programming, then move on to how to make systems faster and more reliable. You'll also learn about how big companies design systems that work across many servers and how to use cloud tools. By the end, you'll know how to design real-world apps like chat apps, ride-sharing, and online stores.\n\n16 Weeks\n\n## Course Overview\n\nThis course runs for about 80 days. Each day focuses on one important topic. You'll get clear explanations, examples, and projects to practice. We begin with basic programming and design ideas, then cover important system parts like databases, caching, and messaging. After that, you'll learn about big systems that run on many machines and how to keep them safe and working. The last part teaches cloud tools and how to keep your systems running smoothly with modern tools.\n\n### Course Highlights\n\n* Learn the basics of system design and object-oriented programming\n* Understand common design patterns used in software development\n* Get hands-on practice with small projects to apply your knowledge\n* Master concepts of scaling systems and improving performance\n* Dive into databases, caching, and messaging for real systems\n* Explore distributed systems and how large systems stay reliable\n* Get familiar with cloud technologies, containers, and deployment tools\n* Build and design popular real-world systems step-by-step\n* Prepare for system design interviews with solid foundational knowledge\n\n## Course Content\n\n### 01 Stage 1: Basics and Object-Oriented Design\n\n* Introduction to System Design: What system design is and why it's important\n* Object-Oriented Programming (OOP) Principles: Encapsulation, Inheritance, Polymorphism, Abstraction\n* SOLID Principles: Simple rules for writing good code\n* Coding Best Practices: DRY, KISS, YAGNI\n* UML Diagrams and Low-Level Design (LLD): Class diagrams, sequence diagrams, workflow\n* Common Design Patterns: Singleton, Factory, Abstract Factory, Builder, Prototype, Adapter, Decorator, Composite, Proxy, Facade, Observer, Strategy, Command, State, Template Method\n* Practice Projects: Library Management System, Parking Lot, Vending Machine, Elevator, Tic-Tac-Toe, Snake and Ladder games\n\n### 02 Stage 2: Scalability and Performance\n\n* Scalability Concepts: Vertical vs Horizontal scaling\n* Stateless vs Stateful Services: What they mean and when to use them\n* Load Balancing: Basics and types\n* Caching Strategies: How caching speeds up systems\n* Databases: SQL vs NoSQL basics\n* Database Optimization: Indexing, query optimization, replication, sharding, partitioning\n* Messaging Systems: Message queues (RabbitMQ, Kafka), publish-subscribe model\n* API Design: Requirements gathering, API contracts, data modeling\n* Architecture Design: Creating diagrams, analyzing trade-offs and bottlenecks\n* Real-World System Designs: URL Shortener, Chat Application, News Feed, Ride-Hailing (Uber), E-commerce backend\n\n### 03 Stage 3: Distributed Systems and Reliability\n\n* Distributed Systems Fundamentals: CAP Theorem, PACELC, consistency models\n* Coordination & Consensus: Leader election, Paxos and Raft algorithm\n* Distributed Transactions: Keeping data consistent across multiple servers\n* API Gateways and Microservices Communication\n* Distributed Caching: Using Redis Cluster and similar tools\n* Search Systems: Elasticsearch fundamentals\n* Stream Processing: Kafka, Flink architecture and use cases\n* Cloud Storage Types: Block, Object, and File storage\n* Fault Tolerance and Resilience: Circuit breaker, retry patterns, rate limiting, throttling, chaos engineering, failover strategies, disaster recovery\n* Monitoring and Incident Management: Centralized logging (ELK stack), metrics (Prometheus, Grafana), distributed tracing (Jaeger, Zipkin), alerting, and incident response\n\n### 04 Stage 4: Cloud and Modern Deployment Tools\n\n* Cloud Computing Basics: Overview of AWS, GCP, Azure\n* Compute Services: EC2, Google Compute Engine introduction\n* Managed Databases: Amazon RDS vs DynamoDB\n* Cloud Networking: VPC, subnets, security essentials\n* Security Basics: IAM and permissions management\n* Containers and Orchestration: Docker basics, Kubernetes fundamentals, Helm charts\n* CI/CD Pipelines: Automating builds and deployments\n* Deployment Strategies: Blue-Green and Canary deployments\n* Large-Scale System Designs: YouTube-like video streaming, Food delivery app, Google Drive-like cloud storage, Distributed search engines\n\n## Frequently Asked Questions\n\n### Q: Who should take this System Design course?\n\n### Q: Do I need prior experience to join this course?\n\n### How hands-on is the course?\n\n### Will I learn about cloud and deployment tools?"}
{"reference": "https://www.geeksforgeeks.org/category/ai-ml-ds/", "content": "# AI-ML-DS Archives\n\n**6.5K+ posts**\n\n## Recent Articles\n\n### Building a Math Application with LangChain Agents\n*Last Updated: 30 September 2025*\n\nMath Application with LangChain Agents is built to make solving math problems from images easier. Instead of having to type out a question from a book, worksheet or even h... [read more](https://www.geeksforgeeks.org/artificial-intelligence/building-a-math-application-with-langchain-agents/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250926175258065141/MS-IM1.png)\n\n**Category:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/)\n\n### Indexing in Langchain\n*Last Updated: 29 September 2025*\n\nIndexing in LangChain is the process of organizing documents in a vector database such that a language model can quickly find and use them. It works by turning documents i... [read more](https://www.geeksforgeeks.org/artificial-intelligence/indexing-in-langchain/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250924113331243437/components_of_indexing.webp)\n\n**Category:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/)\n\n### Knowledge Graphs using LangChain\n*Last Updated: 27 September 2025*\n\nKnowledge graphs provide a structured way to represent entities and their relationships making data easier to query and reason over. They are used to capture and organize ... [read more](https://www.geeksforgeeks.org/artificial-intelligence/knowledge-graphs-using-langchain/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250923114711918353/team.webp)\n\n**Category:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/)\n\n### Retrieval Chains in LangChain\n*Last Updated: 23 September 2025*\n\nRetrieval chains enable Large Language Model to use external data sources. LLMs only generate responses on their own based on training data which can be outdated or incomp... [read more](https://www.geeksforgeeks.org/artificial-intelligence/retrieval-chains-in-langchain/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250923160935535818/characteristics_of_retrieval_chain.webp)\n\n**Category:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/)\n\n### Self RAG (Retrieval Augmented Generation)\n*Last Updated: 22 September 2025*\n\nRetrieval Augmented Generation combines a Large Language Model (LLM) with an external knowledge source to improve response accuracy and reduce hallucinations. Self Reflect... [read more](https://www.geeksforgeeks.org/artificial-intelligence/self-rag-retrieval-augmented-generation/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250922104246394900/self_rag_s_reflection_mechanism.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [NLP](https://www.geeksforgeeks.org/tag/nlp-blogs/), [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### CrewAI Flow\n*Last Updated: 15 September 2025*\n\nCrewAI Flows are used for building, orchestrating and managing AI workflows in a structured, event-driven manner. It allows developers to combine tasks, Crews (groups of a... [read more](https://www.geeksforgeeks.org/artificial-intelligence/crewai-flow/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250915124934338794/flow.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [NLP](https://www.geeksforgeeks.org/tag/nlp-blogs/), [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### Fraud Detection Using CrewAI\n*Last Updated: 15 September 2025*\n\nFraud detection in finance requires analyzing large volumes of transactions and identifying anomalies. CrewAI helps streamline this process by assigning specialized AI age... [read more](https://www.geeksforgeeks.org/artificial-intelligence/Fraud-Detection-Using-CrewAI/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250913163719664023/crewproj1.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [NLP](https://www.geeksforgeeks.org/tag/nlp-blogs/), [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### Vector Stores in LangChain\n*Last Updated: 13 September 2025*\n\nVector stores are specialized databases that store embeddings (numeric vectors that capture semantic meaning) and provide fast similarity search. In LangChain, vector stor... [read more](https://www.geeksforgeeks.org/artificial-intelligence/vector-stores-in-langchain/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250911174531478488/vector-stores.webp)\n\n**Category:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/)\n\n### CrewAI CLI\n*Last Updated: 15 September 2025*\n\nA Command-Line Interface (CLI) is a way to interact with software by typing commands into a terminal or shell. Unlike graphical interfaces the CLI allows us to directly in... [read more](https://www.geeksforgeeks.org/artificial-intelligence/crewai-cli/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250905122807513195/my_crew.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [NLP](https://www.geeksforgeeks.org/tag/nlp-blogs/), [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### MATLAB Tutorial\n*Last Updated: 06 September 2025*\n\nMATLAB is a programming platform used for mathematics, engineering and scientific computing. It provides built-in tools for calculations, visualization and application dev... [read more](https://www.geeksforgeeks.org/data-science/matlab-tutorial/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250906121252233577/MatLab.webp)\n\n**Categories:** [Data Science](https://www.geeksforgeeks.org/category/ai-ml-ds/data-science/), [MATLAB](https://www.geeksforgeeks.org/tag/matlab/)\n\n### CrewAI Planning and Reasoning\n*Last Updated: 15 September 2025*\n\nCrewAI provides reasoning and planning parameters that influence how outputs are generated. These two features are distinct but when used together, they can lead to more s... [read more](https://www.geeksforgeeks.org/artificial-intelligence/crewai-planning-and-reasoning/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250904131635268634/false_1.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [NLP](https://www.geeksforgeeks.org/tag/nlp-blogs/), [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### CrewAI Knowledge\n*Last Updated: 15 September 2025*\n\nKnowledge in CrewAI enables agents to reference explicit facts when performing tasks. Knowledge sources supply structured or unstructured information directly, allowing ag... [read more](https://www.geeksforgeeks.org/artificial-intelligence/crewai-knowledge/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250903121555752856/crewai_knowledge.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [NLP](https://www.geeksforgeeks.org/tag/nlp-blogs/), [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### Creating Custom Tools for CrewAI\n*Last Updated: 01 September 2025*\n\nCrewAI is a framework that allows multiple AI agents to work together to complete tasks. One useful feature is the ability to create custom tools that agents can use to pe... [read more](https://www.geeksforgeeks.org/artificial-intelligence/creating-custom-tools-for-crewai/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250901125852950937/custom_tool.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [NLP](https://www.geeksforgeeks.org/tag/nlp-blogs/), [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### Sequential Chains in LangChain\n*Last Updated: 01 September 2025*\n\nSequential chains are a type of prompt or model chaining in LangChain which multiple sub-chains (or steps) are linked so that the output from one step becomes the input fo... [read more](https://www.geeksforgeeks.org/artificial-intelligence/sequential-chains-in-langchain/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250901142636159365/Simple-Sequential-chain-.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [Large Language Model(LLM)](https://www.geeksforgeeks.org/tag/large-language-modelllm/)\n\n### Agents and Tools in LangChain\n*Last Updated: 01 September 2025*\n\nLangChain is a framework for building applications with Large Language Models (LLMs). Its core components are Tools and Agents. Tools extend the capabilities of LLMs, whil... [read more](https://www.geeksforgeeks.org/artificial-intelligence/agents-and-tools-in-langchain/)\n\n![article_image](https://media.geeksforgeeks.org/wp-content/uploads/20250901134237758860/Agents-in-LangChain.webp)\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [Large Language Model(LLM)](https://www.geeksforgeeks.org/tag/large-language-modelllm/)"}
{"reference": "https://www.geeksforgeeks.org/courses/dsa-skill-up", "content": "# DSA 360\n\n**Self-Paced Course**\n\n**DSA 360** Preparation is a week-wise course under the **Skill Up Program**, designed to build strong problem-solving skills. It combines in-depth theory through articles, daily coding practice, quizzes, and weekly contests. Covering key DSA topics like arrays, trees, graphs, and DP, it's ideal for interview prep, placements, and competitive programming.\n\n**20 Weeks**\n\n**64k+ interested Geeks**\n\n## Course Overview\n\nDSA 360 Preparation is a structured, week-wise Data Structures and Algorithms (DSA) course launching under the Skill Up Program. It is designed to help learners master core programming concepts through continuous learning and consistent practice. The course follows a logical progression, with each week dedicated to a key topic such as arrays, strings, recursion, searching, sorting, linked lists, stacks, queues, trees, graphs, and dynamic programming.\n\nEach week starts with detailed concept articles that explain the fundamentals in a clear and beginner-friendly way. These are followed by daily practice problems and quizzes that help reinforce the concepts and build consistency. At the end of the week, a coding contest allows you to test your understanding under time constraints, similar to actual coding interviews.\n\nThe course is designed to provide a complete learning experience, starting from reading and understanding to applying and evaluating. Along with topic-wise problems, it also includes Problem of the Day challenges to strengthen your daily coding habits and develop problem-solving speed.\n\nWhether you are preparing for tech interviews, campus placements, or competitive coding, this course offers a guided path with the right balance of theory, practice, and assessment to help you become confident in DSA.\n\n### DSA Skill Up Highlights\n\n- Learn Data Structures and Algorithms from scratch in C++, Java, Python, C#, and JavaScript\n- Weekly topic-based structure covering Arrays, Strings, Recursion, Sorting, Searching, Trees, Graphs, and more\n- Concept-wise learning with high-quality articles written for clarity and depth\n- Daily practice problems and quizzes to build consistency and reinforce learning\n- Real-time application through weekly coding contests for hands-on experience\n- Coverage of both foundational and advanced topics like Greedy, Backtracking, Graphs, and Dynamic Programming\n- Detailed explanation of time and space complexities with problem-solving strategies\n- Ideal preparation for coding interviews, online assessments, and placement drives\n- Structured content designed and reviewed by experts from GeeksforGeeks\n\n## Course Content\n\n### Week 1: Mathematics & Combinatorics\n\n- Number systems, divisibility rules, prime numbers, and factorization\n- HCF, LCM, and modular arithmetic with applications in coding\n- Fast exponentiation and modular inverse techniques\n- Practice problems, quiz, and a contest focused on maths-based logic\n\n### Week 2: Arrays - 1D & 2D\n\n- Solve basic 1D array problems like sum, max, and reverse\n- Learn key algorithms like Kadane, Moore voting\n- Work on classic 2D array problems like transpose, spiral print, and matrix rotation\n- Daily problems, quiz, and a weekly contest on array-based logic\n\n### Week 3: Hashing & Prefix Sums\n\n- Understand the basics of hashing and frequency counting\n- Apply hashing in element lookup, counting, and index mapping\n- Learn the prefix sum technique for range-based subarray analysis\n- Explore applications of prefix arrays in optimization and pattern detection\n- Daily problems, topic quiz, and a contest on hashing and prefix-based logic\n\n### Week 4: Strings\n\n- Understand string fundamentals including character access and manipulation\n- Learn advanced string matching algorithms like Z-Algorithm, KMP, and Rabin-Karp\n- Explore palindromic techniques with Manacher's algorithm and center expansion\n- Daily practice, quiz, and a contest focused on string algorithms and concepts"}
{"reference": "https://www.geeksforgeeks.org/copyright-information/", "content": "# Copyright Information\n\nThis to Affirm that GeeksforGeeks is the Copyright Holder/ Owner of the Contents (such as Videos, Photos, Visuals, Questions or any other Literary work) which are Created or Published on its website under the Copy Right Act 1957 and that any Unauthorized Transmission, Publication or Usage of the said Contents without any prior knowledge or written permission shall be treated as the illegal use of the same, which is strictly prohibited under the eyes of Law. Where the same shall be treated as Infringement of our rights inferred by the Copy Right Act, therefore shall attract appropriate Legal Proceedings against the said Infringer without any prior information.\n\nHowever,\n\n## Plagiarism & AI Abuse Policy\n\nAuthors are not permitted to employ bots or other forms of artificial intelligence while creating content. If bots, artificial intelligence, or other sources are utilized for a phrase/idea, proper acknowledgment must be given to the exact source, otherwise it may be considered plagiarism or copyright infringement.\n\nAuthors are only allowed to reference material from other sources, bots, and artificial intelligence up to 20% of the time, and if they are discovered to be copying content from such sources more than 20% of the time, they will be requested to modify the article. If the author fails to rectify the content, action (as deemed appropriate) will be taken against them, which might also result in rejection of the said article.\n\nIf an author is found to be copying content from bots, artificial intelligence of any kind or any other source (online or offline), they shall face the following consequences:\n\n1. **First time:** If an author is found to be copying content from other sources or using bots/AI for generating content for the first time, the said article shall not be published and no remunerations shall be given for the same. The author shall be informed of the reason their article was rejected.\n2. **Second time:** If an author is found to be copying content from elsewhere or using bots/AI for generating content the second time, the article shall not be considered, no remuneration shall be given and a warning will be issued.\n3. **Third time:** If an author is caught copying content from elsewhere for the third time, the work will not be published and the author’s contract will be terminated.\n\nIf an author is found to have copied an article retrospectively, following actions shall be taken:\n\n1. If **one article** is found to be plagiarized retrospectively or it is found that the author used bots/AI of any kind, the article shall be deleted and payment for the same shall be adjusted in future payments.\n2. If **two articles** are found to be plagiarized retrospectively or it is found that the author used bots/AI of any kind, the articles shall be deleted and payment for the same shall be adjusted in future payments.\n3. If **three or more articles** are discovered to be retrospectively plagiarized, or if the author used bots/AI of any type, the articles will be removed, and the author’s contract will be reviewed. Payment will be adjusted accordingly, either by the author or in the current payment cycle.\n\nTherefore we believe you will comply with the above-said points to attribute the content in the right spirit."}
{"reference": "https://www.geeksforgeeks.org/nation-skill-up/", "content": "# A Mission To Upskill The Nation - FREE Learning!\n\n## New Releases\n\n### Gen AI\nExplore Now\n\n### Agentic AI\nExplore Now\n\n### NextJS\nExplore Now\n\n### Git\nExplore Now\n\n### C#\nExplore Now\n\n### Product Management\nExplore Now\n\n### COA\nExplore Now\n\n### School Maths\nExplore Now\n\n## Explore Now\n\n### DSA 160\nExplore Now\n\n### DSA 360\nExplore Now\n\n### System Design\nExplore Now\n\n### Aptitude & Reasoning\nExplore Now\n\n### CS Core Subjects\nExplore Now\n\n### Interview Q&A Series Course\nExplore Now\n\n### DevOps\nExplore Now\n\n### Web Development [MERN]\nExplore Now\n\n### Complete JS with DSA\nExplore Now\n\n### SQL\nExplore Now\n\n### Interview Puzzles\nExplore Now\n\n### CyberSecurity\nExplore Now\n\n### Complete Machine Learning & Data Science\nExplore Now\n\n### Engineering Mathematics\nExplore Now\n\n### Data Analysis\nExplore Now\n\n### AI Tools\nExplore Now\n\n### Advanced Java\nExplore Now\n\n### Software Testing\nExplore Now\n\n### Maths for Computer Science\nExplore Now\n\n### Computer Fundamentals\nExplore Now\n\n### MS Excel & Google Sheets\nExplore Now\n\n### MS Word and Google Docs\nExplore Now\n\n### Python\nExplore Now\n\n### Java\nExplore Now\n\n### C\nExplore Now\n\n### C++\nExplore Now\n\n## Partner Courses & Workshops\n\n### AWS\nWorkshop\n\n### Salesforce\nWorkshop - 01:30 PM, 30th August 2025  \nWatch Now\n\n### LambdaTest\n- Playwright\n- Selenium\n- AI Testing\n- Appium  \nExplore Now\n\n### Lyzr AI\nExplore Now\n\n### MongoDB\nExplore Now\n\n### OpenCV\nExplore Now\n\n## Skill Up. Get Certified. Stand Out.\n\n## Testimonial\n\n> GeeksforGeeks has truly transformed my learning journey! As someone passionate about improving in coding and computer science, GeeksforGeeks has been an incredible resource. Huge thanks to the GFG team for making quality tech education so accessible!  \n>   \n> Aurobinda Chainy\n\n> I am incredibly grateful to the GeeksForGeeks platform for being such an important part of my learning journey. The platform’s easy-to-understand content, regular weekly classes, contests, and quizzes kept me motivated and on track throughout my preparation.  \n>   \n> Anjum Kureshi\n\n> GeeksforGeeks has truly been a game-changer in my learning journey! I’m grateful for the support and opportunities GfG provides - especially the motivation that comes with rewards! A big thank you to the entire GfG team—you're helping so many of us move one step closer to our dream tech careers!  \n>   \n> MD Ashraf Khan\n\n> GeeksforGeeks has been an incredible part of my learning journey. Their well-structured tutorials, coding challenges, and detailed explanations made complex topics easy to understand. Thanks to their resources, I strengthened my programming skills, prepared effectively for interviews, and eventually landed a great job in tech.  \n>   \n> Sakshi Shandilya\n\n> GFG has been a constant support in my learning journey. The platform covers concepts from basics to advanced in a very clear and structured way, which makes even tough topics easier to understand. Highly recommended for anyone serious about learning and growing in tech!  \n>   \n> Vinayak Jaybhaye\n\n> I’ve been using GeeksforGeeks for a while now, and it’s honestly one of the best resources out there for learning coding and computer science topics. The articles are easy to follow, and the coding problems really help reinforce the concepts. It’s helped me a lot in preparing for interviews too.  \n>   \n> Priyanshu Rawat"}
{"reference": "https://www.geeksforgeeks.org/python/opencv-python-tutorial/", "content": "# OpenCV Tutorial in Python\n\n**Last Updated: 12 Jul, 2025**\n\nOpenCV (Open Source Computer Vision Library) is an open-source computer vision and machine learning library. It allows us to process images and videos, detect objects, faces and even handwriting. This tutorial will guide us through image and video processing from the basics to advanced topics using Python and OpenCV. We'll learn how to handle image transformations, feature extraction, object detection and more.\n\n## Why Learn OpenCV?\n\n1. **Comprehensive Image Processing:** OpenCV has a range of functions to manipulate and analyze images helps in making it ideal for various applications.\n2. **Real-Time Video Processing:** It supports video capture and real-time video processing.\n3. **Cross-Platform:** Works on multiple platforms like Windows, Linux, macOS and Android.\n4. **Open-Source:** It is free to use and has a large community support.\n5. **Integration with Deep Learning:** It integrates with popular deep learning libraries like TensorFlow and PyTorch.\n\n## Introduction to OpenCV\n\nBefore moving into OpenCV, make sure we have set it up correctly in our environment. Whether we're working on Windows, Linux, macOS or using Anaconda.\n\n- [Introduction to OpenCV](https://www.geeksforgeeks.org/machine-learning/introduction-to-opencv/)\n- [Install OpenCV for Python on Windows](https://www.geeksforgeeks.org/python/how-to-install-opencv-for-python-in-windows/)\n- [Install OpenCV for Python on Linux](https://www.geeksforgeeks.org/python/how-to-install-opencv-for-python-in-linux/)\n- [Set up Opencv with anaconda environment](https://www.geeksforgeeks.org/python/set-opencv-anaconda-environment/)\n- [Getting started with OpenCV](https://www.geeksforgeeks.org/python/getting-started-with-python-opencv/)\n- [Essential OpenCV Functions](https://www.geeksforgeeks.org/computer-vision/essential-opencv-functions-to-get-started-into-computer-vision/)\n\n## Working with Images\n\nHere we see how to manipulate and process images with OpenCV in Python. This section will introduce basic image operations like loading, saving and displaying images followed by more advanced image processing tasks.\n\n- [Color Spaces](https://www.geeksforgeeks.org/python/color-spaces-in-opencv-python/)\n- [Arithmetic operations on Images](https://www.geeksforgeeks.org/python/arithmetic-operations-on-images-using-opencv-set-1-addition-and-subtraction/)\n- [Bitwise Operations on Binary Images](https://www.geeksforgeeks.org/python/arithmetic-operations-on-images-using-opencv-set-2-bitwise-operations-on-binary-images/)\n\n### 1. Image Processing and Enhancement\n\nThis includes techniques that transform or enhance images for better visual quality and manipulation:\n\n- [Blurring an Image](https://www.geeksforgeeks.org/python/python-image-blurring-using-opencv/)\n- [Grayscaling of Images](https://www.geeksforgeeks.org/python/python-grayscaling-of-images-using-opencv/)\n- [Scaling, Rotating, Shifting and Edge Detection](https://www.geeksforgeeks.org/python/image-processing-in-python/)\n- [Intensity Transformation Operations on Images](https://www.geeksforgeeks.org/python/python-intensity-transformation-operations-on-images/)\n- [Image Translation](https://www.geeksforgeeks.org/python/image-translation-using-opencv-python/)\n- [Image Pyramid](https://www.geeksforgeeks.org/python/image-pyramid-using-opencv-python/)\n- [Histograms Equalization](https://www.geeksforgeeks.org/python/histograms-equalization-opencv/)\n- [Convert an image from one color space to another](https://www.geeksforgeeks.org/python/python-opencv-cv2-cvtcolor-method/)\n- [Visualizing image in different color spaces](https://www.geeksforgeeks.org/python/python-visualizing-image-in-different-color-spaces/)\n- [Create Border around Images](https://www.geeksforgeeks.org/python/python-opencv-cv2-copymakeborder-method/)\n\n### 2. Image Segmentation and Thresholding\n\nTechniques that help in dividing an image into meaningful regions or objects:\n\n- [Simple Thresholding](https://www.geeksforgeeks.org/python/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/)\n- [Adaptive Thresholding](https://www.geeksforgeeks.org/python/python-thresholding-techniques-using-opencv-set-2-adaptive-thresholding/)\n- [Otsu Thresholding](https://www.geeksforgeeks.org/python/python-thresholding-techniques-using-opencv-set-3-otsu-thresholding/)\n- [Image segmentation using Morphological operations](https://www.geeksforgeeks.org/python/image-segmentation-using-morphological-operation/)\n\n### 3. Morphological Operations & Filtering\n\nOperations focused on structuring objects and reducing noise or unwanted features:\n\n- [Erosion and Dilation of images](https://www.geeksforgeeks.org/python/erosion-dilation-images-using-opencv-python/)\n- [Bilateral Filtering](https://www.geeksforgeeks.org/python/python-bilateral-filtering/)\n- [Denoising of colored images](https://www.geeksforgeeks.org/python/python-denoising-of-colored-images-using-opencv/)\n- [Filter Color with OpenCV](https://www.geeksforgeeks.org/python/filter-color-with-opencv/)\n- [Python OpenCV - Morphological Operations](https://www.geeksforgeeks.org/python/python-opencv-morphological-operations/)\n- [Morphological Operations in Image Processing (Opening)](https://www.geeksforgeeks.org/python/python-morphological-operations-in-image-processing-opening-set-1/)\n- [Morphological Operations in Image Processing (Closing)](https://www.geeksforgeeks.org/python/python-morphological-operations-in-image-processing-closing-set-2/)\n- [Morphological Operations in Image Processing (Gradient)](https://www.geeksforgeeks.org/python/python-morphological-operations-in-image-processing-gradient-set-3/)\n\n### 4. Advanced Image Manipulation & Background Subtraction\n\nMore advanced techniques for handling complex image manipulations and background removal:\n\n- [Image Inpainting using OpenCV](https://www.geeksforgeeks.org/python/image-inpainting-using-opencv/)\n- [Image Registration](https://www.geeksforgeeks.org/python/image-registration-using-opencv-python/)\n- [Background subtraction](https://www.geeksforgeeks.org/python/python-background-subtraction-using-opencv/)\n- [Background Subtraction in an Image using Concept of Running Average](https://www.geeksforgeeks.org/python/background-subtraction-in-an-image-using-concept-of-running-average/)\n- [Foreground Extraction in an Image using Grabcut Algorithm](https://www.geeksforgeeks.org/python/python-foreground-extraction-in-an-image-using-grabcut-algorithm/)\n\n### 5. Feature Detection and Description\n\nTechniques to detect key features like lines, corners and shapes in an image:\n\n- [Line detection using Houghline method](https://www.geeksforgeeks.org/python/line-detection-python-opencv-houghline-method/)\n- [Circle Detection](https://www.geeksforgeeks.org/python/circle-detection-using-opencv-python/)\n- [Detect corner of an image](https://www.geeksforgeeks.org/python/python-detect-corner-of-an-image-using-opencv/)\n- [Corner Detection with Shi-Tomasi method](https://www.geeksforgeeks.org/python/python-corner-detection-with-shi-tomasi-corner-detection-method-using-opencv/)\n- [Corner detection with Harris Corner Detection](https://www.geeksforgeeks.org/python/python-corner-detection-with-harris-corner-detection-method-using-opencv/)\n- [Find Circles and Ellipses in an Image](https://www.geeksforgeeks.org/python/find-circles-and-ellipses-in-an-image-using-opencv-python/)\n- [Document field detection](https://www.geeksforgeeks.org/python/python-document-field-detection-using-template-matching/)\n- [Smile detection](https://www.geeksforgeeks.org/machine-learning/python-smile-detection-using-opencv/)\n- [Feature extraction and image classification using OpenCV](https://www.geeksforgeeks.org/computer-vision/feature-extraction-and-image-classification-using-opencv/)\n\n### 6. Feature Detection & Analysis\n\nTechniques to detect and analyze key features or patterns in an image:\n\n- [Find Co-ordinates of Contours](https://www.geeksforgeeks.org/python/find-co-ordinates-of-contours-using-opencv-python/)\n- [Analyze an image using Histogram](https://www.geeksforgeeks.org/python/opencv-python-program-analyze-image-using-histogram/)\n\n## Working with Videos\n\nThis section focuses on how to handle videos using OpenCV. We'll learn everything from loading videos to advanced processing and creating new videos.\n\n### 1. Basic Video Operations\n\nThese are foundational tasks for handling video input and output including loading and saving video files and capturing video from a webcam.\n\n- [OpenCV | Loading Video](https://www.geeksforgeeks.org/cpp/opencv-loading-video/)\n- [Play a video using OpenCV](https://www.geeksforgeeks.org/python/python-play-a-video-using-opencv/)\n- [Click response on video output using Events in OpenCV](https://www.geeksforgeeks.org/python/click-response-on-video-output-using-events-in-opencv-python/)\n- [Display date and time in videos using OpenCV](https://www.geeksforgeeks.org/python/display-date-and-time-in-videos-using-python-opencv/)\n- [Get video duration using Python OpenCV](https://www.geeksforgeeks.org/python/get-video-duration-using-python-opencv/)\n\n### 2. Video Transformation and Effects\n\nThese tasks involve modifying the video content such as adjusting speed, blending videos and converting between color spaces.\n\n- [Creating a Slow Motion Video Using OpenCV](https://www.geeksforgeeks.org/python/creating-a-slow-motion-video-using-opencv-python/)\n- [Converting Color video to grayscale using OpenCV in Python](https://www.geeksforgeeks.org/machine-learning/converting-color-video-to-grayscale-using-opencv-in-python/)\n- [Blending of two videos using Python](https://www.geeksforgeeks.org/python/blending-of-two-videos-using-python/)\n- [How to change video resolution in OpenCV in Python](https://www.geeksforgeeks.org/python/how-to-change-video-resolution-in-opencv-in-python/)\n- [Faster video file FPS with cv2.VideoCapture and OpenCV](https://www.geeksforgeeks.org/python/faster-video-file-fps-with-cv2-videocapture-and-opencv/)\n- [Faces Blur in Videos using OpenCV](https://www.geeksforgeeks.org/python/faces-blur-in-videos-using-opencv-in-python/)\n- [How to draw Filled rectangle to every frame of video by using Python OpenCV?](https://www.geeksforgeeks.org/python/how-to-draw-filled-rectangle-to-every-frame-of-video-by-using-python-opencv/)\n\n### 3. Video Processing and Advanced Tasks\n\nAdvanced video processing techniques such as creating videos from images, extracting frames and saving key event clips using OpenCV.\n\n- [Create video using multiple images](https://www.geeksforgeeks.org/python/python-create-video-using-multiple-images-using-opencv/)\n- [Extract images from video](https://www.geeksforgeeks.org/python/extract-images-from-video-in-python/)\n- [Saving key event video clips with OpenCV](https://www.geeksforgeeks.org/computer-vision/saving-key-event-video-clips-with-opencv/)\n\n## Important functions in OpenCV\n\nLets see some important functions in OpenCV that are important for performing various image and video operations such as handling images, applying transformations and detecting features.\n\n### 1. Image Handling Functions:\n\nThese functions allow us to load and display images which helps in basic image operations in OpenCV.\n\n- [cv2.imread() method](https://www.geeksforgeeks.org/python/python-opencv-cv2-imread-method/)\n- [cv2.imshow()](https://www.geeksforgeeks.org/python/python-opencv-cv2-imshow-method/)\n- [cv2.imwrite()](https://www.geeksforgeeks.org/python/python-opencv-cv2-imwrite-method/)\n\n### 2. Image Transformations:\n\nThese functions help in resizing, rotating and changing the color space of images which are important for image manipulation in OpenCV.\n\n- [cv2.resize()](https://www.geeksforgeeks.org/python/image-resizing-using-opencv-python/)\n- [cv2.rotate()](https://www.geeksforgeeks.org/python/python-opencv-cv2-rotate-method/)\n- [cv2.cvtColor()](https://www.geeksforgeeks.org/python/python-opencv-cv2-cvtcolor-method/)\n\n### 3. Drawing Functions:\n\nThese functions allow us to draw various shapes and text on images which is useful for visualizing data, marking regions of interest and annotation.\n\n- [cv2.line()](https://www.geeksforgeeks.org/python/python-opencv-cv2-line-method/)\n- [cv2.circle()](https://www.geeksforgeeks.org/python/python-opencv-cv2-circle-method/)\n- [cv2.rectangle()](https://www.geeksforgeeks.org/python/python-opencv-cv2-rectangle-method/)\n- [Draw a triangle with centroid](https://www.geeksforgeeks.org/python/draw-a-triangle-with-centroid-using-opencv/)\n- [Find and Draw Contours](https://www.geeksforgeeks.org/python/find-and-draw-contours-using-opencv-python/)\n- [cv2.putText()](https://www.geeksforgeeks.org/python/python-opencv-cv2-puttext-method/)\n- [cv2.ellipse()](https://www.geeksforgeeks.org/python/python-opencv-cv2-ellipse-method/)\n- [cv2.arrowedLine()](https://www.geeksforgeeks.org/python/python-opencv-cv2-arrowedline-method/)\n- [drawMatchesKnn()](https://www.geeksforgeeks.org/python/python-opencv-drawmatchesknn-function/)\n- [cv2.polylines()](https://www.geeksforgeeks.org/python/python-opencv-cv2-polylines-method/)\n\n### 4. Image Processing:\n\nThese functions are used to enhance images, detect edges and apply various transformations to refine visual data and extract meaningful features.\n\n- [cv2.GaussianBlur()](https://www.geeksforgeeks.org/python/opencv-python-program-to-blur-an-image/)\n- [cv2.Canny()](https://www.geeksforgeeks.org/python/python-opencv-canny-function/)\n- [cv2.threshold()](https://www.geeksforgeeks.org/python/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/)\n- [cv2.erode()](https://www.geeksforgeeks.org/python/python-opencv-cv2-erode-method/)\n\n### 5. Object Detection:\n\nThese functions are important for detecting objects and contours within images.\n\n- [cv2.CascadeClassifier()](https://www.geeksforgeeks.org/python/face-detection-using-cascade-classifier-using-opencv-python/)\n- [cv2.findContours()](https://www.geeksforgeeks.org/python/find-and-draw-contours-using-opencv-python/)\n- [cv2.HoughCircles()](https://www.geeksforgeeks.org/python/circle-detection-using-opencv-python/)\n- [cv2.ContourArea()](https://www.geeksforgeeks.org/python/measure-size-of-an-object-using-python-opencv/)\n- [cv2.approxPolyDP()](https://www.geeksforgeeks.org/python/python-detect-polygons-in-an-image-using-opencv/)\n\n### 6. Feature Detection:\n\nThese functions are used to detect and match keypoints, descriptors and patterns in images for tasks like object recognition and tracking.\n\n- [cv2.SIFT()](https://www.geeksforgeeks.org/machine-learning/sift-interest-point-detector-using-python-opencv/)\n- [cv2.ORB()](https://www.geeksforgeeks.org/python/feature-matching-using-orb-algorithm-in-python-opencv/)\n- [cv2.BFMatcher()](https://www.geeksforgeeks.org/python/python-opencv-bfmatcher-function/)\n\n### 7. Tracking and Motion:\n\nThese functions helps in tracking of moving objects and background subtraction used in motion detection and real-time video analysis.\n\n- [cv2.calcOpticalFlowPyrLK()](https://www.geeksforgeeks.org/python/python-opencv-optical-flow-with-lucas-kanade-method/)\n- [cv2.backgroundSubtractorMOG2()](https://www.geeksforgeeks.org/python/python-opencv-background-subtraction/)\n- [cv2.calcOpticalFlowFarneback()](https://www.geeksforgeeks.org/python/python-opencv-dense-optical-flow/)\n- [cv2.createBackgroundSubtractorMOG2()](https://www.geeksforgeeks.org/python/python-opencv-background-subtraction/)\n\n## Applications of OpenCV\n\nOpenCV is used in various real-world applications like object detection, facial recognition and real-time video analysis.\n\n- [Extract frames using OpenCV](https://www.geeksforgeeks.org/python/python-program-extract-frames-using-opencv/)\n- [Displaying the coordinates of the points clicked on the image using Python-OpenCV](https://www.geeksforgeeks.org/python/displaying-the-coordinates-of-the-points-clicked-on-the-image-using-python-opencv/)\n- [White and black dot detection](https://www.geeksforgeeks.org/python/white-and-black-dot-detection-using-opencv-python/)\n- [OpenCV BGR color palette with trackbars](https://www.geeksforgeeks.org/python/python-opencv-bgr-color-palette-with-trackbars/)\n- [Draw rectangular shape and extract objects](https://www.geeksforgeeks.org/python/python-draw-rectangular-shape-and-extract-objects-using-opencv/)\n- [Face Detection using Python and OpenCV with webcam](https://www.geeksforgeeks.org/python/face-detection-using-python-and-opencv-with-webcam/)\n- [Opening multiple color windows](https://www.geeksforgeeks.org/python/opening-multiple-color-windows-to-capture-using-opencv-in-python/)\n- [Play a video in reverse mode](https://www.geeksforgeeks.org/python/python-play-video-reverse-mode-using-opencv/)\n- [Saving Operated Video from a webcam](https://www.geeksforgeeks.org/python/saving-operated-video-from-a-webcam-using-opencv/)\n\n> For more applications refer to [Some Amazing Applications of OpenCV Library](https://www.geeksforgeeks.org/python/some-amazing-applications-of-opencv-library/)\n\n## Projects of OpenCV\n\n- [Invisible Cloak using OpenCV](https://www.geeksforgeeks.org/python/invisible-cloak-using-opencv-python-project/)\n- [Unsupervised Face Clustering Pipeline](https://www.geeksforgeeks.org/machine-learning/ml-unsupervised-face-clustering-pipeline/)\n- [Vehicle detection in a Video frame using Python – OpenCV](https://www.geeksforgeeks.org/python/opencv-python-program-vehicle-detection-video-frame/)\n- [Count number of Faces using Python – OpenCV](https://www.geeksforgeeks.org/python/count-number-of-faces-using-python-opencv/)\n- [Live Webcam Drawing using OpenCV](https://www.geeksforgeeks.org/python/live-webcam-drawing-using-opencv/)\n- [Detect and Recognize Car License Plate from a video in real time](https://www.geeksforgeeks.org/python/detect-and-recognize-car-license-plate-from-a-video-in-real-time/)\n- [Template matching using OpenCV in Python](https://www.geeksforgeeks.org/python/template-matching-using-opencv-in-python/)\n- [Cartooning an Image using OpenCV – Python](https://www.geeksforgeeks.org/blogs/cartooning-an-image-using-opencv-python/)\n\n> For more Projects refer to [15 OpenCV Projects Ideas for Beginners to Practice in 2025](https://www.geeksforgeeks.org/computer-vision/opencv-projects-ideas-for-beginners/)\n\nWith these foundational OpenCV skills, we're ready to get more advanced projects and upgrade our image and video processing capabilities."}
{"reference": "https://write.geeksforgeeks.org/posts-new", "content": "You need to enable JavaScript to run this app."}
{"reference": "https://www.geeksforgeeks.org/courses/cs-core-subjects-skill-up", "content": "# CS Core Subjects - Skill Up\n\nSelf-Paced Course\n\n18k+ interested Geeks\n\nThis program is a comprehensive guide through all core Computer Science subjects, including DBMS, OS, CN, and OOP. It covers foundational and advanced topics, helping learners build solid theoretical understanding and practical problem-solving skills. Perfect for students preparing for technical interviews, university exams, or enhancing core subject knowledge.\n\n**16 Weeks**\n\n## Course Overview\n\nEach subject is taught week-wise with focused content, relevant links, quizzes, and real-world insights.\n\n### Course Highlights\n\n- Learn core Computer Science subjects including DBMS, Operating Systems, Networking, and OOP in C++\n- Understand the fundamentals of databases, ER modeling, normalization, SQL, transactions, indexing, and NoSQL\n- Master operating system concepts like process scheduling, memory management, deadlocks, file systems, and OS security\n- Dive deep into networking layers, protocols, IP addressing, routing, and explore modern topics like VPNs, 5G, Cloud, and IoT\n- Get hands-on with object-oriented programming in C++ including inheritance, polymorphism, templates, and exception handling\n- Explore advanced topics like distributed databases, data warehousing, real-time OS, and SDN\n- Apply learning through structured progression and integrated theoretical + practical concepts\n\n## Course Content\n\n### Week 1–5: Database Management Systems (DBMS)\n\n- Introduction to DBMS, its characteristics and advantages\n- DBMS architecture, schemas, and data independence\n- Database languages, interfaces, user roles\n- ER Modeling and Enhanced ER Concepts (attributes, relationships, specialization, aggregation)\n- Relational Model: keys, constraints, functional dependencies, normalization\n- Lossless joins, dependency preservation, anomalies, denormalization\n- Relational Algebra and Relational Calculus\n- SQL basics: commands, clauses, joins, nested queries\n- Views, indexing, transactions, triggers, cursors\n- Transactions, ACID, states, scheduling, serializability\n- Locking mechanisms, concurrency control, deadlocks\n- File organization, indexing (B-Trees, Hashing)\n- Distributed Databases and NoSQL\n- Data Warehousing, Mining, Big Data, Hive, HBase, Multimedia, GIS\n\n### Week 6–10: Operating Systems (OS)\n\n- OS Introduction, types, and functionalities\n- Booting, kernel types, system calls\n- Process and thread management, scheduling techniques\n- Multithreading, synchronization, inter-process communication\n- Deadlocks: detection, prevention, recovery\n- Memory Management: allocation, fragmentation, paging, segmentation\n- Virtual memory, demand paging, page replacement, thrashing\n- Disk scheduling and file system management\n- File attributes, directories, access methods\n- I/O management, buffering, spooling, caching\n- OS security: threats, protection, authentication\n- Real-Time and Distributed OS concepts\n\n### Week 11–14: Computer Networks (CN)\n\n- Introduction to networking, types, topologies, and goals\n- OSI and TCP/IP models\n- Transmission media and communication techniques\n- Data Link Layer: framing, switching, flow & error control\n- MAC techniques and channel access protocols\n- Advanced link protocols (PPP, HDLC, etc.)\n- Network Layer: IP addressing, subnetting, VLSM, routing algorithms\n- Transport Layer: TCP, UDP, SCTP, DCCP, RUDP\n- Application Layer: DNS, HTTP, FTP, SMTP, IMAP\n- Security, VPN, firewalls, QoS, 4G vs 5G\n- Future technologies: Cloud, IoT, NFV, SDN\n\n### Week 15–16: Object-Oriented Programming in C++ (OOP)\n\n- Introduction to OOP concepts and benefits\n- C++ syntax, data types, control structures\n- Classes and Objects, constructors, destructors\n- Encapsulation, data hiding, inheritance\n- Polymorphism, abstraction, virtual functions\n- Dynamic memory management, smart pointers\n- Operator overloading, templates\n- Exception handling and file handling in OOP\n- Advanced C++: namespaces, const, RTTI, lambdas\n\n## Frequently Asked Questions\n\n### Who should enroll in the CS Core Subjects Course\n\n### What materials are provided in the Course?\n\n### Does this follow a college syllabus?"}
{"reference": "https://www.geeksforgeeks.org/programming-language-tutorials/", "content": "# Programming Languages Tutorials\n\n**Last Updated: 11 Sep, 2025**\n\nProgramming languages are how we tell computers what to do. The following are quick links to tutorials of the most common programming languages.\n\n- [C Language](https://www.geeksforgeeks.org/c/c-programming-language/)\n- [C++](https://www.geeksforgeeks.org/cpp/c-plus-plus/)\n- [Java](https://www.geeksforgeeks.org/java/java/)\n- [Python](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/)\n- [JavaScript](https://www.geeksforgeeks.org/javascript/javascript-tutorial/)\n- [TypeScript](https://www.geeksforgeeks.org/typescript/typescript-tutorial/)\n- [PHP](https://www.geeksforgeeks.org/php/php-tutorial/)\n- [R](https://www.geeksforgeeks.org/r-language/r-programming-language-introduction/)\n- [Ruby](https://www.geeksforgeeks.org/ruby/ruby-programming-language/)\n\n## How to Learn a Programming Language?\n\n- Pick a language based on your goals (e.g., Python for data science, JavaScript for web development).\n- Understand syntax, variables, data types, control flow, functions, and data structures.\n- Write Code and [Solve Problems](https://www.geeksforgeeks.org/blogs/geeksforgeeks-practice-best-online-coding-platform/).\n- Build Projects\n- Review code examples on GitHub and learn to use official documentation to understand libraries and functions.\n- Join a Community\n- Stay updated with trends in the language.\n- Progress takes time. Keep practicing and stay persistent even when faced with challenges.\n\n## Applications of Different Programming Languages\n\n- **C Language**: Used for designing software that work close to hardware and that work in low resource environment (less memory and CPU power) like embedded systems. C is also considered as mother of all languages and used as a first language to be taught in engineering so that students learn fundamentals.\n- **C++**: C++ is considered as a superset of C as it supports almost all syntax of C with additional features like Object Oriented Programming, Generic Programming and Exception Handling. C++ also has richer library and has wider applications compared to C. Both C and C++ are considered as faster languages compared to other popular programming languages like Java, Python and JavaScript.\n- **Java**: Java is a high-level, object-oriented programming language known for its platform independence, thanks to the Java Virtual Machine (JVM). It is widely used in enterprise-level applications, mobile development (especially Android apps) and large systems. Java is popular for its robustness, security features and scalability, making it a go-to choice for building reliable and high-performance systems.\n- **Python**: Python is a high-level, interpreted language known for its simplicity and readability. It's widely used for rapid application development, scripting, data analysis, artificial intelligence and web development. Python has an extensive collection of libraries and frameworks, making it versatile for various applications.\n- **JavaScript**: JavaScript is a dynamic, interpreted language that is primarily used for building interactive and dynamic websites. Initially designed for web development, JavaScript now has wide applications through frameworks and libraries such as Node.js, React and Angular. It runs in browsers, making it essential for client-side scripting.\n- **R**: R is a programming language and environment specifically designed for statistical computing and data analysis. It is widely used by statisticians, data scientists and researchers for analyzing and visualizing large datasets. R has a rich set of libraries and tools for data manipulation, statistical modeling and visualization, making it ideal for tasks such as machine learning, data analysis and data visualization.\n- **PHP**: PHP is a server-side, scripting language mainly used for web development. It is widely used to create dynamic web pages and web applications. Known for its deep integration with HTML and database management systems like MySQL, PHP powers a significant portion of the web, including popular content management systems like WordPress.\n- **Swift**: Swift is a powerful, high-level language developed by Apple for creating applications for iOS, macOS, watchOS and tvOS. It is known for its clean syntax, safety features and high performance. Swift is intended to be an easier and safer alternative to Objective-C for iOS and macOS development.\n- **[Kotlin](https://www.geeksforgeeks.org/kotlin/kotlin-programming-language/)**: Kotlin is a modern, statically typed language that runs on the Java Virtual Machine (JVM). It is fully interoperable with Java but provides more concise syntax and additional features, such as null safety, which helps avoid common programming errors. Kotlin is officially supported for Android development and is becoming increasingly popular due to its enhanced developer productivity and safety features.\n- **[Rust](https://www.geeksforgeeks.org/rust/introduction-to-rust-programming-language/)**: Rust is a systems programming language focused on safety, speed and concurrency. It’s designed to prevent memory safety issues like null pointer dereferencing and buffer overflows, which are common in languages like C and C++. Rust is particularly popular for developing high-performance, memory-efficient applications, such as operating systems, game engines and blockchain systems.\n- **TypeScript**: TypeScript is a superset of JavaScript that adds static typing, making it easier to catch errors during development. It compiles down to plain JavaScript, ensuring compatibility with existing JavaScript libraries and frameworks. TypeScript is widely used in large-scale web applications, as its type system helps with maintainability and scalability.\n- **Ruby**: Ruby is a high-level, interpreted language known for its elegant and readable syntax. It is primarily used for web development, with Ruby on Rails being its most well-known framework for building scalable, dynamic websites. Ruby emphasizes simplicity and productivity, allowing developers to build web applications quickly. Its dynamic typing and flexible syntax make it a popular choice for startups and rapid application development."}
{"reference": "https://www.geeksforgeeks.org/courses/skill-up-cpp", "content": "# C++ Skill Up\n\n**Self-Paced Course**\n\nThe Nation Skill Up C++ Program is a structured, hands-on course to build strong programming fundamentals. Covering C++ basics, object-oriented programming, and STL, it equips learners with practical coding skills essential for internships, placements, and future technical growth. This program empowers students to write clean, efficient, and industry-ready C++ code with confidence.\n\n**Duration:** 7 Weeks\n\n## Course Overview\n\nStart your journey in C++ programming with the GeeksforGeeks Nation Skill Up Program for C++. This 7-week structured program combines theory, coding, and hands-on practice to build strong programming fundamentals.\n\nThe course begins with C++ basics including input-output, loops, functions, arrays, and strings, then advances to object-oriented programming concepts like classes, inheritance, and polymorphism. It also covers the Standard Template Library (STL) comprehensively, enabling learners to implement vectors, stacks, queues, maps, sets, and algorithms effectively.\n\nFrom writing clean, efficient code to mastering OOPS and STL for real-world development, this program equips students and professionals with the confidence and skills needed for internships, placements, advanced C++ learning weekly projects and many more.\n\n### C++ Course - Highlights\n\n- Master C++ programming fundamentals from scratch\n- Understand input-output, loops, functions, arrays, and strings\n- Learn object-oriented programming: classes, inheritance, polymorphism\n- Dive deep into constructors, destructors, and operator overloading\n- Gain expertise in the Standard Template Library (STL)\n- Work with vectors, stacks, queues, maps, sets, and algorithms\n- Write clean, efficient, and industry-standard C++ code\n- Hands-on coding practice and real-world implementation problems\n- Strengthen programming skills for internships, placements, and projects\n\n## Course Content\n\n### Week 1: Introduction to C++ Programming\n\n- Overview of C++, its history, and applications\n- Setting up the compiler and writing your first program\n- Understanding data types, variables, and constants\n- Using input/output, operators, and expressions\n- Implementing conditional statements and loops with practical problems\n\n### Week 2: Functions, Arrays, Vectors, and Strings\n\n- Understanding functions: parameters, return types, prototypes, recursion, and overloading\n- Exploring arrays: 1D and multidimensional arrays with traversals and operations\n- Introduction to vectors, their advantages over arrays, and multidimensional vectors\n- Working with strings: C++ strings, input handling, and string functions\n- Hands-on practice problems on recursion, arrays, vectors, and strings\n\n### Week 3: User-Defined Data Types, Pointers, and Memory Management\n\n- Understanding user-defined data types: structures, unions, enums, and bitfields\n- Working with pointers: memory addressing, pointer arithmetic, and pointers with arrays\n- Learning references, parameter passing techniques, and swapping using references\n- Dynamic memory allocation, memory layout, and preventing memory leaks\n- Smart pointers, RAII principles, and move semantics for efficient memory management\n\n### Week 4: Object-Oriented Programming in C++\n\n- Introduction to OOP concepts: classes, objects, access specifiers, and encapsulation\n- Exploring class member types: constructors, destructors, static and const members, friend functions\n- Understanding polymorphism: method overloading and operator overloading techniques\n- Deep dive into constructors: default, parameterized, copy, move constructors, and constructor delegation\n- Learning inheritance: types, access modes, method overriding, virtual functions, and diamond problem"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/machine-learning/", "content": "# Machine Learning Tutorial\n\n**Machine learning** is a branch of Artificial Intelligence that focuses on developing models and algorithms that let computers learn from data without being explicitly programmed for every task. In simple words, ML teaches the systems to think and understand like humans by learning from the data.\n\nMachine Learning is mainly divided into three core types: Supervised, Unsupervised and Reinforcement Learning along with two additional types, Semi-Supervised and Self-Supervised Learning.\n\n- **[Supervised Learning](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/)**: Trains models on labeled data to predict or classify new, unseen data.\n- **[Unsupervised Learning](https://www.geeksforgeeks.org/machine-learning/unsupervised-learning/)**: Finds patterns or groups in unlabeled data, like clustering or dimensionality reduction.\n- **[Reinforcement Learning](https://www.geeksforgeeks.org/machine-learning/what-is-reinforcement-learning/)**: Learns through trial and error to maximize rewards, ideal for decision-making tasks.\n\n**Note:** The following are not part of the original three core types of ML, but they have become increasingly important in real-world applications, especially in deep learning.\n\n**Additional Types**:\n\n- **[Self-Supervised Learning](https://www.geeksforgeeks.org/machine-learning/self-supervised-learning-ssl/)**: Self-supervised learning is often considered as a subset of unsupervised learning, but it has grown into its own field due to its success in training large-scale models. It generates its own labels from the data, without any manual labeling.\n- **[Semi-Supervised Learning](https://www.geeksforgeeks.org/machine-learning/ml-semi-supervised-learning/)**: This approach combines a small amount of labeled data with a large amount of unlabeled data. It's useful when labeling data is expensive or time-consuming.\n\n## Module 1: Machine Learning Pipeline\n\nThis section covers preprocessing, exploratory data analysis and model evaluation to prepare data, uncover insights and build reliable models.\n\n### 1. Data Preprocessing\n\n- [ML workflow](https://www.geeksforgeeks.org/machine-learning/machine-learning-lifecycle/)\n- [Data Cleaning](https://www.geeksforgeeks.org/data-analysis/data-cleansing-introduction/)\n- [Data Preprocessing in Python](https://www.geeksforgeeks.org/machine-learning/data-preprocessing-machine-learning-python/)\n- [Feature Scaling](https://www.geeksforgeeks.org/machine-learning/ml-feature-scaling-part-2/)\n- [Feature Extraction](https://www.geeksforgeeks.org/machine-learning/what-is-feature-extraction/)\n- [Feature Engineering](https://www.geeksforgeeks.org/machine-learning/what-is-feature-engineering/)\n- [Feature Selection Techniques](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/)\n\n### 2. Exploratory Data Analysis\n\n- [Exploratory Data Analysis](https://www.geeksforgeeks.org/what-is-exploratory-data-analysis/)\n- [Exploratory Data Analysis in Python](https://www.geeksforgeeks.org/exploratory-data-analysis-in-python/)\n- [Advance EDA](https://www.geeksforgeeks.org/data-science/advanced-eda/)\n- [Time Series Data Visualization](https://www.geeksforgeeks.org/time-series-data-visualization-in-python/)\n\n### 3. Model Evaluation\n\n- [Regularization in Machine Learning](https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/)\n- [Confusion Matrix](https://www.geeksforgeeks.org/confusion-matrix-machine-learning/)\n- [Precision, Recall](https://www.geeksforgeeks.org/machine-learning/precision-and-recall-in-machine-learning/) and [F1-Score](https://www.geeksforgeeks.org/f1-score-in-machine-learning/)\n- [AUC-ROC Curve](https://www.geeksforgeeks.org/auc-roc-curve/)\n- [Cross-validation](https://www.geeksforgeeks.org/cross-validation-machine-learning/)\n- [Hyperparameter Tuning](https://www.geeksforgeeks.org/hyperparameter-tuning/)\n\n## Module 2: Supervised Learning\n\nSupervised learning algorithms are generally categorized into two main types:\n\n- [Classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/)- where the goal is to predict discrete labels or categories\n- [Regression](https://www.geeksforgeeks.org/machine-learning/regression-in-machine-learning/) - where the aim is to predict continuous numerical values.\n\n![Supervised Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250521155019101269/Supervised-learning.png)\n\nThere are many algorithms used in supervised learning each suited to different types of problems. Some of the most commonly used supervised learning algorithms are:\n\n### 1. Linear Regression\n\nThis is one of the simplest ways to predict numbers using a straight line. It helps find the relationship between input and output.\n\n- [Introduction to Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/)\n- [Gradient Descent in Linear Regression](https://www.geeksforgeeks.org/machine-learning/gradient-descent-in-linear-regression/)\n- [Multiple Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-multiple-linear-regression-using-python/)\n\n### 2. Logistic Regression\n\nUsed when the output is a \"yes or no\" type answer. It helps in predicting categories like pass/fail or spam/not spam.\n\n- [Understanding Logistic Regression](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/)\n- [Cost function in Logistic Regression](https://www.geeksforgeeks.org/machine-learning/ml-cost-function-in-logistic-regression/)\n\n### 3. Decision Trees\n\nA model that makes decisions by asking a series of simple questions, like a flowchart. Easy to understand and use.\n\n- [Decision Tree in Machine Learning](https://www.geeksforgeeks.org/machine-learning/decision-tree-introduction-example/)\n- [Types of Decision tree algorithms](https://www.geeksforgeeks.org/machine-learning/decision-tree-algorithms/)\n- [Decision Tree - Regression (Implementation)](https://www.geeksforgeeks.org/machine-learning/python-decision-tree-regression-using-sklearn/)\n- [Decision tree - Classification (Implementation)](https://www.geeksforgeeks.org/machine-learning/building-and-implementing-decision-tree-classifiers-with-scikit-learn-a-comprehensive-guide/)\n\n### 4. Support Vector Machines (SVM)\n\nA bit more advanced—it tries to draw the best line (or boundary) to separate different categories of data.\n\n- [Understanding SVMs](https://www.geeksforgeeks.org/machine-learning/support-vector-machine-algorithm/)\n- [SVM Hyperparameter Tuning - GridSearchCV](https://www.geeksforgeeks.org/machine-learning/svm-hyperparameter-tuning-using-gridsearchcv-ml/)\n- [Non-Linear SVM](https://www.geeksforgeeks.org/machine-learning/ml-non-linear-svm/)\n\n### 5. k-Nearest Neighbors (k-NN)\n\nThis model looks at the closest data points (neighbors) to make predictions. Super simple and based on similarity.\n\n- [Introduction to KNN](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)\n- [Decision Boundaries in K-Nearest Neighbors (KNN)](https://www.geeksforgeeks.org/machine-learning/understanding-decision-boundaries-in-k-nearest-neighbors-knn/)\n\n### 6. Naïve Bayes\n\nA quick and smart way to classify things based on probability. It works well for text and spam detection.\n\n- [Introduction to Naive Bayes](https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/)\n- [Gaussian Naive Bayes](https://www.geeksforgeeks.org/machine-learning/gaussian-naive-bayes/)\n- [Multinomial Naive Bayes](https://www.geeksforgeeks.org/machine-learning/multinomial-naive-bayes/)\n- [Bernoulli Naive Bayes](https://www.geeksforgeeks.org/machine-learning/bernoulli-naive-bayes/)\n- [Complement Naive Bayes](https://www.geeksforgeeks.org/machine-learning/complement-naive-bayes-cnb-algorithm/)\n\n### 7. Random Forest (Bagging Algorithm)\n\nA powerful model that builds lots of decision trees and combines them for better accuracy and stability.\n\n- [Introduction to Random forest](https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/)\n- [Random Forest Classifier](https://www.geeksforgeeks.org/dsa/random-forest-classifier-using-scikit-learn/)\n- [Random Forest Regression](https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/)\n- [Hyperparameter Tuning in Random Forest](https://www.geeksforgeeks.org/machine-learning/random-forest-hyperparameter-tuning-in-python/)\n\n### Introduction to Ensemble Learning\n\n[Ensemble learning](https://www.geeksforgeeks.org/machine-learning/a-comprehensive-guide-to-ensemble-learning/) combines multiple simple models to create a stronger, smarter model. There are mainly two types of ensemble learning:\n\n- [Bagging](https://www.geeksforgeeks.org/machine-learning/What-is-Bagging-classifier/) that combines multiple models trained independently.\n- [Boosting](https://www.geeksforgeeks.org/machine-learning/boosting-in-machine-learning-boosting-and-adaboost/) that builds models sequentially each correcting the errors of the previous one.\n\n## Module 3: Unsupervised learning\n\nUnsupervised learning are again divided into three main categories based on their purpose:\n\n- [Clustering](https://www.geeksforgeeks.org/machine-learning/clustering-in-machine-learning/)\n- [Association Rule Mining](https://www.geeksforgeeks.org/machine-learning/association-rule/)\n- [Dimensionality Reduction](https://www.geeksforgeeks.org/machine-learning/dimensionality-reduction/).\n\n![Unsupervised learning](https://media.geeksforgeeks.org/wp-content/uploads/20250521155109313768/Unsupervised-learning.png)\n\n### 1. Clustering\n\nClustering algorithms group data points into clusters based on their similarities or differences. Types of clustering algorithms are:\n\n**Centroid-based Methods:**\n\n- [K-Means clustering](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/)\n- [Elbow Method for optimal value of k in KMeans](https://www.geeksforgeeks.org/machine-learning/elbow-method-for-optimal-value-of-k-in-kmeans/)\n- [K-Means++ clustering](https://www.geeksforgeeks.org/machine-learning/ml-k-means-algorithm/)\n- [K-Mode clustering](https://www.geeksforgeeks.org/machine-learning/k-mode-clustering-in-python/)\n- [Fuzzy C-Means (FCM) Clustering](https://www.geeksforgeeks.org/machine-learning/ml-fuzzy-clustering/)\n\n**Distribution-based Methods**:\n\n- [Gaussian mixture models](https://www.geeksforgeeks.org/machine-learning/gaussian-mixture-model/)\n- [Expectation-Maximization Algorithm](https://www.geeksforgeeks.org/machine-learning/ml-expectation-maximization-algorithm/)\n- [Dirichlet process mixture models (DPMMs)](https://www.geeksforgeeks.org/machine-learning/dirichlet-process-mixture-models-dpmms/)\n\n**Connectivity based methods:**\n\n- [Hierarchical clustering](https://www.geeksforgeeks.org/machine-learning/hierarchical-clustering/)\n- [Agglomerative Clustering](https://www.geeksforgeeks.org/machine-learning/implementing-agglomerative-clustering-using-sklearn/)\n- [Divisive clustering](https://www.geeksforgeeks.org/machine-learning/difference-between-agglomerative-clustering-and-divisive-clustering/)\n- [Affinity propagation](https://www.geeksforgeeks.org/machine-learning/affinity-propagation-in-ml-to-find-the-number-of-clusters/)\n\n**Density Based methods:**\n\n- [DBSCAN (Density-Based Spatial Clustering of Applications with Noise)](https://www.geeksforgeeks.org/machine-learning/dbscan-clustering-in-ml-density-based-clustering/)\n- [OPTICS (Ordering Points To Identify the Clustering Structure)](https://www.geeksforgeeks.org/machine-learning/ml-optics-clustering-explanation/)\n\n### 2. Dimensionality Reduction\n\nDimensionality reduction is used to simplify datasets by reducing the number of features while retaining the most important information.\n\n- [Principal Component Analysis (PCA)](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)\n- [t-distributed Stochastic Neighbor Embedding (t-SNE)](https://www.geeksforgeeks.org/machine-learning/ml-t-distributed-stochastic-neighbor-embedding-t-sne-algorithm/)\n- [Non-negative Matrix Factorization (NMF)](https://www.geeksforgeeks.org/machine-learning/non-negative-matrix-factorization/)\n- [Independent Component Analysis (ICA)](https://www.geeksforgeeks.org/machine-learning/ml-independent-component-analysis/)\n- [Isomap](https://www.geeksforgeeks.org/machine-learning/isomap-a-non-linear-dimensionality-reduction-technique/)\n- [Locally Linear Embedding (LLE)](https://www.geeksforgeeks.org/machine-learning/swiss-roll-reduction-with-lle-in-scikit-learn/)\n\n### 3. Association Rule\n\nFind patterns between items in large datasets typically in [market basket analysis](https://www.geeksforgeeks.org/data-science/market-basket-analysis-in-data-mining/).\n\n- [Apriori algorithm](https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/)\n- [Implementing apriori algorithm](https://www.geeksforgeeks.org/machine-learning/implementing-apriori-algorithm-in-python/)\n- [FP-Growth (Frequent Pattern-Growth)](https://www.geeksforgeeks.org/machine-learning/frequent-pattern-growth-algorithm/)\n- [ECLAT (Equivalence Class Clustering and bottom-up Lattice Traversal)](https://www.geeksforgeeks.org/machine-learning/ml-eclat-algorithm/)\n\n## Module 4: Reinforcement Learning\n\nReinforcement learning interacts with environment and learn from them based on rewards.\n\n![Reinforcement Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250521155154550118/reinforcement-learning.png)\n\n### 1. Model-Based Methods\n\nThese methods use a model of the environment to predict outcomes and help the agent plan actions by simulating potential results.\n\n- [Markov decision processes (MDPs)](https://www.geeksforgeeks.org/machine-learning/markov-decision-process/)\n- [Bellman equation](https://www.geeksforgeeks.org/machine-learning/bellman-equation/)\n- [Value iteration algorithm](https://www.geeksforgeeks.org/python/implement-value-iteration-in-python/)\n- [Monte Carlo Tree Search](https://www.geeksforgeeks.org/machine-learning/ml-monte-carlo-tree-search-mcts/)\n\n### 2. Model-Free Methods\n\nThe agent learns directly from experience by interacting with the environment and adjusting its actions based on feedback.\n\n- [Q-Learning](https://www.geeksforgeeks.org/machine-learning/q-learning-in-python/)\n- [SARSA](https://www.geeksforgeeks.org/machine-learning/sarsa-reinforcement-learning/)\n- [Monte Carlo Methods](https://www.geeksforgeeks.org/python/monte-carlo-integration-in-python/)\n- [Reinforce Algorithm](https://www.geeksforgeeks.org/machine-learning/reinforce-algorithm/)\n- [Actor-Critic Algorithm](https://www.geeksforgeeks.org/machine-learning/actor-critic-algorithm-in-reinforcement-learning/)\n- [Asynchronous Advantage Actor-Critic (A3C)](https://www.geeksforgeeks.org/machine-learning/asynchronous-advantage-actor-critic-a3c-algorithm/)\n\n## Module 5: Semi Supervised Learning\n\nIt uses a mix of labeled and unlabeled data making it helpful when labeling data is costly or it is very limited.\n\n![Semi Supervised Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250521155224944296/Semi-Supervised-Learning.png)\n\n- [Semi Supervised Classification](https://www.geeksforgeeks.org/machine-learning/semi-supervised-classification-in-data-mining/)\n- [Self-Training in Semi-Supervised Learning](https://www.geeksforgeeks.org/machine-learning/self-training-in-semi-supervised-learning/)\n- [Few-shot learning in Machine Learning](https://www.geeksforgeeks.org/machine-learning/few-shot-learning-in-machine-learning/)\n\n## Module 6: Forecasting Models\n\nForecasting models analyze past data to predict future trends, commonly used for time series problems like sales, demand or stock prices.\n\n- [ARIMA (Auto-Regressive Integrated Moving Average)](https://www.geeksforgeeks.org/r-language/model-selection-for-arima/)\n- [SARIMA (Seasonal ARIMA)](https://www.geeksforgeeks.org/machine-learning/sarima-seasonal-autoregressive-integrated-moving-average/)\n- [Exponential Smoothing (Holt-Winters)](https://www.geeksforgeeks.org/artificial-intelligence/exponential-smoothing-for-time-series-forecasting/)\n\n## Module 7: Deployment of ML Models\n\nThe trained ML model must be integrated into an application or service to make its predictions accessible.\n\n- [Machine learning deployment](https://www.geeksforgeeks.org/machine-learning/machine-learning-deployment/)\n- [Deploy ML Model using Streamlit Library](https://www.geeksforgeeks.org/machine-learning/deploy-a-machine-learning-model-using-streamlit-library/)\n- [Deploy ML web app on Heroku](https://www.geeksforgeeks.org/machine-learning/deploy-your-machine-learning-web-app-streamlit-on-heroku/)\n- [Create UIs for prototyping Machine Learning model with Gradio](https://www.geeksforgeeks.org/machine-learning/python-create-uis-for-prototyping-machine-learning-model-with-gradio/)\n\nAPIs allow other applications or systems to access the ML model's functionality and integrate them into larger workflows.\n\n- [Deploy Machine Learning Model using Flask](https://www.geeksforgeeks.org/machine-learning/deploy-machine-learning-model-using-flask/)\n- [Deploying ML Models as API using FastAPI](https://www.geeksforgeeks.org/machine-learning/deploying-ml-models-as-api-using-fastapi/)\n\nMLOps ensure they are deployed, monitored and maintained efficiently in real-world production systems.\n\n- [MLOps](https://www.geeksforgeeks.org/machine-learning/mlops-everything-you-need-to-know/)\n- [Continuous Integration and Continuous Deployment (CI/CD) in MLOps](https://www.geeksforgeeks.org/machine-learning/continuous-integration-and-continuous-deployment-ci-cd-in-mlops/)\n- [End-to-End MLOps](https://www.geeksforgeeks.org/machine-learning/end-to-end-mlops-pipeline-a-comprehensive-project/)\n\n**For project ideas refer to:** [100+ Machine Learning Projects with Source Code [2025]](https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/) for hands-on implementation on projects\n\nAfter machine learning and have hands on experience in it we can start with deep learning from here: [Deep Learning Tutorial](https://www.geeksforgeeks.org/deep-learning/deep-learning-tutorial/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/introduction-machine-learning/", "content": "# Introduction to Machine Learning\n\n****Machine learning (ML)**** allows computers to learn and make decisions without being explicitly programmed. It involves feeding data into algorithms to identify patterns and make predictions on new data. It is used in various applications like image recognition, speech processing, language translation, recommender systems, etc. In this article, we will see more about ML and its core concepts.\n\n## Why do we need Machine Learning?\n\nTraditional programming requires exact instructions and doesn’t handle complex tasks like understanding images or language well. It can’t efficiently process large amounts of data. Machine Learning solves these problems by learning from examples and making predictions without fixed rules. Let's see various reasons why it is important:\n\n### 1. Solving Complex Business Problems\n\nTraditional programming struggles with tasks like language understanding and medical diagnosis. ML learns from data and predicts outcomes easily.\n\n****Examples****:\n\n+ Image and speech recognition in healthcare.\n+ Language translation and sentiment analysis.\n\n### 2. Handling Large Volumes of Data\n\nThe internet generates huge amounts of data every day. Machine Learning processes and analyzes this data quickly by providing valuable insights and real-time predictions.\n\n****Examples:****\n\n+ Fraud detection in financial transactions.\n+ Personalized feed recommendations on Facebook and Instagram from billions of interactions.\n\n### 3. Automate Repetitive Tasks\n\nML automates time-consuming, repetitive tasks with high accuracy hence reducing manual work and errors.\n\n****Examples****:\n\n+ Gmail filtering spam emails automatically.\n+ Chatbots handling order tracking and password resets.\n+ Automating large-scale invoice analysis for key insights.\n\n### 4. Personalized User Experience\n\nML enhances user experience by tailoring recommendations to individual preferences. It analyze user behavior to deliver highly relevant content.\n\n****Examples:****\n\n+ Netflix suggesting movies and TV shows based on our viewing history.\n+ E-commerce sites recommending products we're likely to buy.\n\n### 5. Self Improvement in Performance\n\nML models evolve and improve with more data helps in making them smarter over time. They adapt to user behavior and increase their performance.\n\n****Examples****:\n\n+ Voice assistants like Siri and Alexa learning our preferences and accents.\n+ Search engines refining results based on user interaction.\n+ Self-driving cars improving decisions using millions of miles of driving data.\n\n## What Makes a Machine \"Learn\"?\n\nA machine \"learns\" by identifying patterns in data and improving its ability to perform specific tasks without being explicitly programmed for every scenario. This learning process helps machines to make accurate predictions or decisions based on the information they receive. Unlike traditional programming where instructions are fixed, ML allows models to adapt and improve through experience.\n\nHere is how the learning process works:\n\n1. ****Data Input:**** Machine needs data like text, images or numbers to analyze. Good quality and enough quantity of data are important for effective learning.\n2. ****Algorithms:**** Algorithms are mathematical methods that help the machine find patterns in data. Different algorithms help different tasks such as classification or regression.\n3. ****Model Training:**** During training, the machine adjusts its internal settings to better predict outcomes. It learns by reducing the difference between its predictions and actual results.\n4. ****Feedback Loop:**** Machine compares its predictions with true outcomes and uses this feedback to correct errors. Techniques like [gradient descent](https://www.geeksforgeeks.org/machine-learning/gradient-descent-algorithm-and-its-variants/) help it update and improve.\n5. ****Experience and Iteration:**** Machine repeats training many times with data helps in refining its predictions with each pass, more data and iterations improve accuracy.\n6. ****Evaluation and Generalization:**** Model is tested on unseen data to ensure it performs well on real-world tasks.\n\nMachines \"learn\" by continuously increasing their understanding through data-driven iterations like how humans learn from experience.\n\n## Importance of Data in Machine Learning\n\nData is the foundation of machine learning (ML) without quality data ML models cannot learn, perform or make accurate predictions.\n\n+ Data provides the examples from which models learn patterns and relationships.\n+ High-quality and diverse data improves how well models perform and generalize to new situations.\n+ It helps models to understand real-world scenarios and adapt to practical uses.\n+ Features extracted from data are important for effective training.\n+ Separate datasets for validation and testing measure how well the model works on unseen data.\n+ Data drives continuous improvements in models through feedback loops.\n\n## Types of Machine Learning\n\nThere are three main types of machine learning which are as follows:\n\n### 1. Supervised learning\n\n[****Supervised learning****](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/) trains a model using labeled data where each input has a known correct output. The model learns by comparing its predictions with these correct answers and improves over time. It is used for both [classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/) and [regression](https://www.geeksforgeeks.org/machine-learning/regression-in-machine-learning/) problems.\n\n****Example:**** Consider the following data regarding patients entering a clinic. The data consists of the gender and age of the patients and each patient is labeled as \"healthy\" or \"sick\".\n\n| Gender | Age | Label    |\n|--------|-----|----------|\n| M      | 48  | sick     |\n| M      | 67  | sick     |\n| F      | 53  | healthy  |\n| M      | 49  | sick     |\n| F      | 32  | healthy  |\n| M      | 34  | healthy  |\n| M      | 21  | healthy  |\n\nIn this example, supervised learning is to use this labeled data to train a model that can predict the label (\"healthy\" or \"sick\") for new patients based on their gender and age. For example if a new patient i.e Male with 50 years old visits the clinic, model can classify whether the patient is \"healthy\" or \"sick\" based on the patterns it learned during training.\n\n### 2. Unsupervised learning:\n\n[****Unsupervised learning****](https://www.geeksforgeeks.org/machine-learning/unsupervised-learning/) works with unlabeled data where no correct answers or categories are provided. The model's job is to find the data, hidden patterns, similarities or groups on its own. This is useful in scenarios where labeling data is difficult or impossible. Common applications are [clustering](https://www.geeksforgeeks.org/machine-learning/clustering-in-machine-learning/) and [association](https://www.geeksforgeeks.org/machine-learning/association-rule/).\n\n****Example:**** Consider the following data regarding patients. The dataset has a unlabeled data where only the gender and age of the patients are available with no health status labels.\n\n| Gender | Age |\n|--------|-----|\n| M      | 48  |\n| M      | 67  |\n| F      | 53  |\n| M      | 49  |\n| F      | 34  |\n| M      | 21  |\n\nHere unsupervised learning looks for patterns or groups within the data on its own. For example it might cluster patients by age or gender and grouping them into categories like \"younger healthy patients\" or \"older patients\" without knowing their health status.\n\n### 3. Reinforcement Learning\n\n[****Reinforcement Learning (RL)****](https://www.geeksforgeeks.org/machine-learning/what-is-reinforcement-learning/) trains an agent to make decisions by interacting with an environment. Instead of being told the correct answers, agent learns by trial and error method and gets rewards for good actions and penalties for bad ones. Over time it develops a strategy to maximize rewards and achieve goals. This approach is good for problems having sequential decision making such as robotics, gaming and autonomous systems.\n\nExample: While Identifying a Fruit, system receives an input for example an apple and initially makes an incorrect prediction like \"It's a mango\". Feedback is provided to correct the error \"Wrong! It's an apple\" and the system updates its model based on this feedback.\n\nOver time it learns to respond correctly that \"It's an apple\" when getting similar inputs and also improves accuracy.\n\n![Reinforcement-Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250122123323289178/Reinforcement-Learning.png)\n\nBesides these three main types, modern machine learning also includes two other important approaches: [****Self-Supervised Learning****](https://www.geeksforgeeks.org/machine-learning/self-supervised-learning-ssl/) and [****Semi-Supervised Learning****](https://www.geeksforgeeks.org/machine-learning/ml-semi-supervised-learning/).\n\n> To learn more, refer to the article: [****Types of Machine Learning****](https://www.geeksforgeeks.org/machine-learning/types-of-machine-learning/)\n\n## Benefits of Machine Learning\n\n1. ****Enhanced Efficiency and Automation:**** ML automates repetitive tasks, freeing up human resources for more complex work. This leads to faster, smoother processes and higher productivity.\n2. ****Data-Driven Insights:**** It can analyze large amounts of data to identify patterns and trends that might be missed by people and help businesses make better decisions.\n3. ****Improved Personalization:**** It customizes user experiences by tailoring recommendations and ads based on individual preferences.\n4. ****Advanced Automation and Robotics:**** It helps robots and machines to perform complex tasks with greater accuracy and adaptability. This is transforming industries like manufacturing and logistics.\n\n## Challenges of Machine Learning\n\n1. ****Data Bias and Fairness:**** ML models learn from training data and if the data is biased, model’s decisions can be unfair so it’s important to select and monitor data carefully.\n2. ****Security and Privacy Concerns:**** Since it depends on large amounts of data, there is a risk of sensitive information being exposed so protecting privacy is important.\n3. ****Interpretability and Explainability:**** Complex ML models can be difficult to understand which makes it difficult to explain why they make certain decisions. This can affect trust and accountability.\n4. ****Job Displacement and Automation:**** Automation may replace some jobs so retraining and helping workers learn new skills is important to adapt to these changes.\n\n## Applications of Machine Learning\n\nMachine Learning is used in many industries to solve problems and improve services. Here are some common real-world applications:\n\n1. ****Healthcare:**** It helps doctors to diagnose diseases from medical images like X-rays and MRIs. It also predicts patient outcomes and personalizes treatments which improves healthcare quality.\n2. ****Finance:**** In finance it detects fraudulent transactions in real time and supports algorithmic trading. It also helps to assess credit risk helps in making lending safer and faster.\n3. ****Retail and E-Commerce:**** It helps in personalized product recommendations and forecasts demand to optimize inventory and also analyzes customer sentiment to improve shopping experiences.\n4. ****Transportation and Automotive:**** Self-driving cars rely on ML to navigate and make decisions. It optimizes delivery routes and predicts vehicle maintenance needs which reduces downtime.\n5. ****Social Media and Entertainment:**** Platforms like Netflix and YouTube use ML to recommend content we'll enjoy. It enables image and speech recognition for better user interaction.\n6. ****Manufacturing:**** It improves quality control by detecting defects in products automatically and predicts machine failures in advance and helps in production processes.\n\nMachine learning continues to evolve which helps in opening new possibilities and transforming industries by helping smarter, data-driven decisions and automation which was not possible earlier."}
{"reference": "https://www.geeksforgeeks.org/about/", "content": "# About GeeksforGeeks\n\n## 1. Company Profile and Brand\n\nGeeksforGeeks is a comprehensive educational portal that empowers learners across domains—spanning computer science, school-level subjects, commerce, essential software tools (Excel, Word, etc.), exam preparation resources (GATE, JEE, NEET etc.), and provides them with top notch interview preparation services. With over 50 million registered users globally, and millions of daily visitors, GfG provides a vast and growing collection of tutorials, interview guides, concept explainers, coding challenges, practice problems, and structured courses, catering to both academic and professional needs.\n\nWe’re especially known for our in-depth resources on interview preparation, helping thousands land roles at top tech companies with our curated content, mock interviews, and company-wise interview experiences.\n\nOur courses and learning paths for high demand technologies like DSA, System Design, Web Development, Machine Learning- are ideal for professionals aiming to level up or switch domains. Our certifications ensure to add credibility and enhance our learners’ career prospects.\n\nOur content is created and curated by top mentors from renowned institutions and organizations, ensuring quality and relevance. With a focus on clarity, accessibility, and impact, we help students and professionals alike turn curiosity into expertise. GeeksforGeeks has become a trusted name in education—offering well-structured tutorials, hands-on practice problems, conceptual articles, and guided courses.\n\nAt GeeksforGeeks, we’re more than just a platform—we’re a community. A space to learn, grow, and stay ahead in an ever-evolving world of education and technology.\n\n## 2. Corporate History, Mission, Vision, and Motto\n\n### Corporate History\nFounded in 2008 by Mr. Sandeep Jain, a visionary computer science educator, GeeksforGeeks began as a platform to simplify complex coding concepts. Over the years, it has evolved into a full-spectrum educational portal—supporting learners not only in programming but also in academics, skill-building, and professional growth.\n\n### Mission\nTo empower learners across domains by providing accessible, high-quality educational content that bridges the gap between theory and practical application—helping them excel in academics, careers, and beyond.\n\n### Vision\nTo be the most comprehensive, inclusive, and trusted learning platform—enabling individuals from all walks of life to access knowledge, gain confidence, and succeed in their educational and career journeys.\n\n### Motto\n\"Learn, Practice, and Excel\" - A commitment to lifelong learning, hands-on experience, and achieving personal growth, no matter the field.\n\n## 3. Company Founder\n\nOur founder Sandeep Jain is a visionary entrepreneur and esteemed computer science expert. Fueled by his unwavering passion for coding and education, laid the very bedrock upon which GeeksforGeeks stands today, and his indomitable spirit has been instrumental in its remarkable growth and resounding success. As the steadfast driving force behind the company, Sandeep remains a beacon of guidance and inspiration, propelling the team to constantly challenging limits and craft transformative learning experiences.\n\n## Corporate & Communications Address\nA-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)\n\n## Registered Address\nK 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305"}
{"reference": "https://www.geeksforgeeks.org/courses/computer-fundamentals-skill-up", "content": "# Computer Fundamentals Skill - Up\n\nSelf-Paced Course\n\nThe Computer Fundamentals Program is a comprehensive course designed to provide learners with a solid foundation in computer systems, **operating systems**, **programming basics** (**Python**), **logic building**, and essential productivity tools like MS Excel and MS Word. Over 6 weeks, participants will gain hands-on experience with core computing concepts, problem-solving techniques, and practical applications in real-world scenarios.\n\n**Duration:** 6 Weeks\n\n## Course Overview\n\nThis 6-week computer fundamentals program blends theory, hands-on exercises, and real-world applications to provide a complete understanding of computer systems, programming logic, and productivity tools. By the end of the course, participants will gain practical proficiency in computer hardware and software, operating systems and file management, writing basic Python programs, solving logic-based problems, analyzing data with MS Excel, and creating professional documents in MS Word. Designed for beginners and professionals, the course ensures a strong foundational knowledge to excel in both academic and professional environments.\n\n## Course Highlights\n\n- Master computer hardware, software, and data representation\n- Learn operating systems (Windows) and file management\n- Learn the basics of programming with Python\n- Develop strong logic-building skills with algorithmic problems\n- Learn MS Excel (formulas, pivot tables, data visualization)\n- Explore fundamentals of MS Word\n\n## Course Content\n\n### Week 1: Introduction to Computers\n\n- What is a Computer?\n- Generations of Computers\n- Classification of Computers\n- Applications of Computers\n- Core Components of a Computer System\n- Input and Output Devices\n- Data Representation\n- Memory and Storage Devices\n- Software Overview\n- AI in the Computer World\n\n### Week 2: Operating Systems & Networking\n\n- Introduction to Operating Systems\n- User Interface\n- File Management\n- Computer Networks\n- Internet Basics\n- Cyber Security Basics\n\n### Week 3: Programming Fundamentals with Python\n\n- Introduction to Python\n- Basic Python Syntax & Arithmetic\n- Strings & String Manipulation\n- Conditional Statements\n- Data Structures\n- Functions\n\n### Week 4: Logic Building Problems\n\n- Basic Arithmetic\n- Sequences & Number Theory\n- Number Properties\n- Advanced Number Theory\n- Geometric Problems\n- Advanced Sequences\n- Advanced Algorithms"}
{"reference": "https://www.geeksforgeeks.org/courses/category/dsa-placements", "content": "### We couldn't find what you're looking for"}
{"reference": "https://www.geeksforgeeks.org/geeksforgeeks-school/", "content": "# School Tutorials\n\nThe following are Subject-Wise Tutorials made to help students build a strong foundation. Whether you are reviewing important concepts or learning from the beginning, these tutorials provide easy-to-follow guidance to help you study smarter and do better.\n\n## Subjects\n\nExplore subject-wise tutorials designed to simplify concepts and make learning step-by-step. Each subject builds a strong base for school academics and beyond.\n\n- [Mathematics](https://www.geeksforgeeks.org/maths/maths/)\n- [Physics](https://www.geeksforgeeks.org/physics/physics/)\n- [Biology](https://www.geeksforgeeks.org/biology/biology/)\n- [Chemistry](https://www.geeksforgeeks.org/chemistry/chemistry/)\n- [English](https://www.geeksforgeeks.org/english/english-grammar/)\n- [Commerce](https://www.geeksforgeeks.org/business-studies/commerce/)\n- [Computer Fundamentals](https://www.geeksforgeeks.org/computer-science-fundamentals/computer-fundamentals-tutorial/)\n\n### Bonus Resources\n\nIn addition to the main subjects, here are some extra resources that make learning easier and more engaging. From formula guides to puzzles, these tools help in quick revision and smart practice.\n\n- [All Maths Formulas Guide](https://www.geeksforgeeks.org/maths/basic-math-formulas/)\n- [Useful Maths Calculators](https://www.geeksforgeeks.org/utilities/maths-calculators/)\n- [Mathematical Riddles](https://www.geeksforgeeks.org/maths/35-mathematical-riddles-with-answers/)\n- [Maths Puzzles](https://www.geeksforgeeks.org/maths/mathematical-puzzles/)\n\n## Test your knowledge\n\nLearning is best reinforced through practice. Use these subject-wise quizzes to check your understanding, identify weak areas, and prepare for exams with confidence.\n\n- [Maths Quizzes](https://www.geeksforgeeks.org/quizzes/?category=Maths)\n- [Physics Quizzes](https://www.geeksforgeeks.org/quizzes/?category=physics)\n- [Biology Quizzes](https://www.geeksforgeeks.org/quizzes/?category=biology)\n- [Chemistry Quizzes](https://www.geeksforgeeks.org/quizzes/?category=chemistry)\n- [Computer Science Quizzes](https://www.geeksforgeeks.org/quizzes/?category=computer-science-fundamentals)\n\n## Tech & Digital Literacy\n\nIn today’s world, digital skills are as important as academics. These beginner-friendly tutorials introduce students to essential software, programming basics, and emerging technologies like AI.\n\n- [Introduction to MS Word](https://www.geeksforgeeks.org/excel/introduction-to-ms-excel/)\n- [Introduction to MS Excel](https://www.geeksforgeeks.org/excel/introduction-to-ms-excel/)\n- [Introduction to MS PowerPoint](https://www.geeksforgeeks.org/websites-apps/ms-powerpoint-tutorial-basic-to-advanced/)\n- [Basics of Programming](https://www.geeksforgeeks.org/blogs/basics-of-computer-programming-for-beginners/)\n- [What is AI?](https://www.geeksforgeeks.org/artificial-intelligence/what-is-ai/)\n\n## Exams Syllabus\n\nCompetitive exams often require early preparation. Here you can find detailed syllabus guides for popular exams to help you plan and study in a structured way.\n\n- [SAT Syllabus](https://www.geeksforgeeks.org/sat/sat-syllabus/)\n- [ACT (American College Testing)](https://www.geeksforgeeks.org/maths/act-exam-2025-2026-exam-dates-maths-syllabus-study-guide/)\n- [GMAT (Graduate Management Admission Test)](https://www.geeksforgeeks.org/maths/gmat-math-study-guide/)\n\n## Tips for Parents & Teachers\n\n- Encourage kids to explore coding early, but balance screen time.\n- Guide them in setting goals and choosing areas of interest.\n- Monitor progress using structured resources and timelines to ensure effective management.\n- Help children set a daily schedule with dedicated time for studies, breaks, and hobbies.\n\n> CBSE Class-wise Study Materials → [Check Here](https://www.geeksforgeeks.org/school-resources/cbse-class-wise-learning-resources/)\n\n> NCERT Solutions Class 8 to 12 → [Check Here](https://www.geeksforgeeks.org/maths/ncert-solutions/)\n\n## Explore\n\n### Physics\n\n- [Force](https://www.geeksforgeeks.org/physics/force/) (11 min read)\n- [What is Motion?](https://www.geeksforgeeks.org/physics/what-is-motion/) (9 min read)\n- [Energy](https://www.geeksforgeeks.org/physics/what-is-energy/) (10 min read)\n- [Thermodynamics](https://www.geeksforgeeks.org/physics/thermodynamics/) (15+ min read)\n- [Electrostatics](https://www.geeksforgeeks.org/physics/electrostatics/) (13 min read)\n\n### Chemistry\n\n- [Atomic Structure](https://www.geeksforgeeks.org/physics/atomic-structure/) (15+ min read)\n- [Chemical Bonding](https://www.geeksforgeeks.org/chemistry/chemical-bonding/) (12 min read)\n- [Acids, Bases and Salts](https://www.geeksforgeeks.org/chemistry/acids-bases-and-salts/) (15+ min read)\n- [Stoichiometry and Stoichiometric Calculations](https://www.geeksforgeeks.org/chemistry/stoichiometry-and-stoichiometric-calculations/) (7 min read)\n\n### Mathematics\n\n- [Algebra in Math - Definition, Branches, Basics and Examples](https://www.geeksforgeeks.org/maths/algebra/) (4 min read)\n- [Trigonometry in Math](https://www.geeksforgeeks.org/maths/math-trigonometry/) (3 min read)\n- [Number Theory](https://www.geeksforgeeks.org/engineering-mathematics/number-theory/) (2 min read)\n- [Calculus | Differential and Integral Calculus](https://www.geeksforgeeks.org/maths/math-calculus/) (4 min read)\n- [Probability and Statistics](https://www.geeksforgeeks.org/maths/probability-and-statistics/) (15+ min read)\n\n### Computer Science\n\n- [Basics of Computer Programming For Beginners](https://www.geeksforgeeks.org/blogs/basics-of-computer-programming-for-beginners/) (8 min read)\n- [Components of Computer](https://www.geeksforgeeks.org/computer-organization-architecture/computer-and-its-components/) (7 min read)\n- [System Software](https://www.geeksforgeeks.org/computer-science-fundamentals/system-software/) (9 min read)\n- [Introduction to Programming Languages](https://www.geeksforgeeks.org/computer-science-fundamentals/introduction-to-programming-languages/) (7 min read)\n\n### Other Subject\n\n- [Biology](https://www.geeksforgeeks.org/biology/biology/) (7 min read)\n- [Commerce Tutorial](https://www.geeksforgeeks.org/business-studies/commerce/) (3 min read)\n- [Social Science: Meaning, Branches, Resources](https://www.geeksforgeeks.org/social-science/social-science/) (8 min read)\n- [English Grammar : Learn Rules of Grammar and Basics](https://www.geeksforgeeks.org/english/english-grammar/) (3 min read)\n- [CBSE Notes](https://www.geeksforgeeks.org/cbse-notes/) (4 min read)\n- [NCERT Solutions for Class 8 to 12](https://www.geeksforgeeks.org/maths/ncert-solutions/) (7 min read)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/machine-learning-introduction/", "content": "# Applications of Machine Learning\n\nMachine Learning (ML) is one of the most significant advancements in the field of technology. It gives machines the ability to learn from data and improve over time without being explicitly programmed. ML models identify patterns from data and use them to make predictions or decisions.\n\nOrganizations use machine learning to automate tasks, make smarter decisions and gain valuable insights. ML is shaping the world around us. Here are few real-world applications of Machine Learning:\n\n## 1. Healthcare and Medical Diagnosis\n\nML algorithms can analyze large volumes of patient data, medical scans and genetic information to aid in diagnosis and treatment.\n\n### Applications:\n\n- **Disease Detection**: ML models are used to identify diseases like cancer, pneumonia and Parkinson’s from medical images. They often achieve accuracy comparable to or better than human doctors.\n- **Predictive Analytics**: By analyzing patient history and symptoms, models can predict the risk of certain diseases or potential complications.\n- **Drug Discovery**: ML accelerates the drug development process by predicting how different compounds will interact, reducing the time and cost of research.\n\n## 2. Smart Assistants and Human-Machine Interaction\n\nVirtual assistants systems rely on [natural language processing (NLP)](https://www.geeksforgeeks.org/nlp/natural-language-processing-overview/) and [speech recognition](https://www.geeksforgeeks.org/machine-learning/python-speech-recognition-module/) to understand commands and respond intelligently.\n\n### Applications:\n\n- **Voice Assistants**: Tools like Siri, Alexa and Google Assistant convert spoken input into actionable commands.\n- **Voice Search & Transcription**: ML enables users to perform hands-free web searches and get transcription during meetings or phone calls.\n- **Chatbots**: Businesses use AI-powered chatbots for 24/7 customer support, helping resolve queries faster and more efficiently.\n\n## 3. Personalized Recommendations and User Experience\n\nModern digital platforms uses personalization which is done by using [recommender systems](https://www.geeksforgeeks.org/machine-learning/what-are-recommender-systems/). Machine learning models analyze user behavior to deliver relevant content, improving engagement and satisfaction.\n\n### Applications:\n\n- **Streaming Platforms**: Netflix and Spotify suggest shows and songs based on your watching or listening history.\n- **E-commerce**: Sites like Amazon recommend products tailored to your preferences, browsing patterns and past purchases.\n- **Social Media**: Algorithms curate content feeds, prioritize posts and suggest friends or pages.\n\nThese systems use techniques like [collaborative filtering](https://www.geeksforgeeks.org/machine-learning/collaborative-filtering-ml/) and [content-based filtering](https://www.geeksforgeeks.org/machine-learning/ml-content-based-recommender-system/) to create personalized digital experiences.\n\n## 4. Fraud Detection and Financial Forecasting\n\nIn finance, vast sums of money move digitally and machine learning plays a important role in fraud detection and market analysis.\n\n### Applications:\n\n- **Transaction Monitoring**: Banks use ML models to detect unusual spending behavior and flag suspicious transactions.\n- **Loan Risk Assessment**: Credit scoring models analyze customer profiles and predict the likelihood of default.\n- **Stock Market Prediction**: ML is used to analyze historical stock data and forecast price movements. Stock markets are complex, algorithmic trading uses these predictions for better decision-making.\n\n## 5. Autonomous Vehicles and Smart Mobility\n\n[Self-driving vehicles](https://www.geeksforgeeks.org/blogs/self-driving-car-technology/) use ML to understand their environment, navigate safely and make immediate decisions.\n\n### Key Components:\n\n- **Computer Vision**: Recognizing lanes, pedestrians, traffic signals and obstacles.\n- **Sensor Fusion**: Combining data from cameras, LiDAR and radar for a 360-degree view.\n- **Behavior Prediction**: Anticipating how other drivers or pedestrians may act.\n\nAutonomous vehicles are capable of operating with minimal human input. Beyond cars, ML is also being used in traffic optimization, smart navigation systems and predictive maintenance in transportation."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/", "content": "# Naive Bayes Classifiers\n\nNaive Bayes is a machine learning classification algorithm that predicts the category of a data point using probability. It assumes that all features are independent of each other. Naive Bayes performs well in many real-world applications such as spam filtering, document categorization and sentiment analysis.\n\nHere:\n\n- Original data has two classes: green circles ($y=1$) and red squares ($y=2$).\n- Estimate probability distribution along the first dimension i.e $P(x_1 \\mid y=1)$, $P(x_1 \\mid y=2)$\n- Estimate probability distribution along the second dimension i.e $P(x_2 \\mid y=1)$, $P(x_2 \\mid y=2)$\n- Combine both dimensions using conditional independence i.e $P(x \\mid y) = \\prod_{\\alpha} P(x_{\\alpha} \\mid y)$\n\n## Key Features of Naive Bayes Classifiers\n\nThe main idea behind the Naive Bayes classifier is to use [**Bayes' Theorem**](https://www.geeksforgeeks.org/maths/bayes-theorem/) to classify data based on the probabilities of different classes given the features of the data. It is used mostly in high-dimensional text classification\n\n- The Naive Bayes Classifier is a simple probabilistic classifier and it has very few number of parameters which are used to build the ML models that can predict at a faster speed than other classification algorithms.\n- It is a probabilistic classifier because it assumes that one feature in the model is independent of existence of another feature. In other words, each feature contributes to the predictions with no relation between each other.\n- Naive Bayes Algorithm is used in spam filtration, Sentimental analysis, classifying articles and many more.\n\n## Why it is Called Naive Bayes?\n\nIt is named as \"Naive\" because it assumes the presence of one feature does not affect other features. The \"Bayes\" part of the name refers to its basis in Bayes' Theorem.\n\nConsider a fictional dataset that describes the weather conditions for playing a game of golf. Given the weather conditions, each tuple classifies the conditions as fit(\"Yes\") or unfit(\"No\") for playing golf. Here is a tabular representation of our dataset.\n\n|   | Outlook   | Temperature | Humidity | Windy | Play Golf |\n|---|-----------|-------------|----------|-------|-----------|\n| 0 | Rainy     | Hot         | High     | False | No        |\n| 1 | Rainy     | Hot         | High     | True  | No        |\n| 2 | Overcast  | Hot         | High     | False | Yes       |\n| 3 | Sunny     | Mild        | High     | False | Yes       |\n| 4 | Sunny     | Cool        | Normal   | False | Yes       |\n| 5 | Sunny     | Cool        | Normal   | True  | No        |\n| 6 | Overcast  | Cool        | Normal   | True  | Yes       |\n| 7 | Rainy     | Mild        | High     | False | No        |\n| 8 | Rainy     | Cool        | Normal   | False | Yes       |\n| 9 | Sunny     | Mild        | Normal   | False | Yes       |\n| 10| Rainy     | Mild        | Normal   | True  | Yes       |\n| 11| Overcast  | Mild        | High     | True  | Yes       |\n| 12| Overcast  | Hot         | Normal   | False | Yes       |\n| 13| Sunny     | Mild        | High     | True  | No        |\n\nThe dataset is divided into two parts i.e feature matrix and the response vector.\n\n- Feature matrix contains all the vectors(rows) of dataset in which each vector consists of the value of dependent features. In above dataset, features are 'Outlook', 'Temperature', 'Humidity' and 'Windy'.\n- Response vector contains the value of class variable (prediction or output) for each row of feature matrix. In above dataset, the class variable name is 'Play golf'.\n\n## Assumption of Naive Bayes\n\nThe fundamental Naive Bayes assumption is that each feature makes an:\n\n- **Feature independence:** This means that when we are trying to classify something, we assume that each feature (or piece of information) in the data does not affect any other feature.\n- **Continuous features are normally distributed:** If a feature is continuous, then it is assumed to be normally distributed within each class.\n- **Discrete features have multinomial distributions:** If a feature is discrete, then it is assumed to have a multinomial distribution within each class.\n- **Features are equally important:** All features are assumed to contribute equally to the prediction of the class label.\n- **No missing data:** The data should not contain any missing values.\n\n## Introduction to Bayes' Theorem\n\n**Bayes' Theorem** provides a principled way to reverse conditional probabilities. It is defined as:\n\n> $P(y|X) = \\frac{P(X|y) \\cdot P(y)}{P(X)}$\n\nWhere:\n\n- $P(y|X)$: Posterior probability, probability of class y given features X\n- $P(X|y)$: Likelihood, probability of features X given class y\n- $P(y)$: Prior probability of class y\n- $P(X)$: Marginal likelihood or evidence\n\n## Naive Bayes Working\n\n### 1. Terminology\n\nConsider a classification problem (like predicting if someone plays golf based on weather). Then:\n\n- y is the class label (e.g. \"Yes\" or \"No\" for playing golf)\n- $X = (x_1, x_2, ..., x_n)$ is the feature vector (e.g. Outlook, Temperature, Humidity, Wind)\n\nA sample row from the dataset:\n\n> $X = \\text{(Rainy, Hot, High, False)}$, $\\quad y = \\text{No}$\n\nThis represents:\n\n**What is the probability that someone will not play golf given that the weather is Rainy, Hot, High humidity, and No wind?**\n\n### 2. The Naive Assumption\n\nThe \"naive\" in Naive Bayes comes from the assumption that all features are independent given the class. That is:\n\n> $P(x_1, x_2, ..., x_n \\mid y) = P(x_1 \\mid y) \\cdot P(x_2 \\mid y) \\cdots P(x_n \\mid y)$\n\nThus, Bayes' theorem becomes:\n\n> $P(y|x_1, ..., x_n) = \\frac{P(y) \\cdot \\prod_{i=1}^{n} P(x_i \\mid y)}{P(x_1)P(x_2)...P(x_n)}$\n\nSince the denominator is constant for a given input, we can write:\n\n> $P(y|x_1, ..., x_n) \\propto P(y) \\cdot \\prod_{i=1}^{n} P(x_i \\mid y)$\n\n### 3. Constructing the Naive Bayes Classifier\n\nWe compute the posterior for each class y and choose the class with the highest probability:\n\n> $\\hat{y} = \\arg\\max_{y} P(y) \\cdot \\prod_{i=1}^{n} P(x_i \\mid y)$\n\nThis becomes our Naive Bayes classifier.\n\n### 4. Example: Weather Dataset\n\nLet’s take a dataset used for predicting if golf is played based on:\n\n- **Outlook**: Sunny, Rainy, Overcast\n- **Temperature**: Hot, Mild, Cool\n- **Humidity**: High, Normal\n- **Wind**: True, False\n\n**Example Input:** $X = \\text{(Sunny, Hot, Normal, False)}$\n\n**Goal:** Predict if golf will be played (`Yes` or `No`).\n\n### 5. Pre-computation from Dataset\n\n**Class Probabilities:**\n\nFrom dataset of 14 rows:\n\n- $P(\\text{Yes}) = \\frac{9}{14}$\n- $P(\\text{No}) = \\frac{5}{14}$\n\n**Conditional Probabilities (Tables 1–4):**\n\n| Feature     | Value  | P (Value \\| Yes) | P (Value \\| No) |\n|-------------|--------|------------------|-----------------|\n| Outlook     | Sunny  | 2/9              | 3/5             |\n| Temperature | Hot    | 2/9              | 2/5             |\n| Humidity    | Normal | 6/9              | 1/5             |\n| Wind        | False  | 6/9              | 2/5             |\n\n### 6. Calculate Posterior Probabilities\n\n**For Class = Yes:**\n\n> $P(\\text{Yes | today}) \\propto \\frac{2}{9} \\cdot \\frac{2}{9} \\cdot \\frac{6}{9} \\cdot \\frac{6}{9} \\cdot \\frac{9}{14}$\n\n> $P(\\text{Yes | today}) \\approx 0.02116$\n\n**For Class = No:**\n\n> $P(\\text{No | today}) \\propto \\frac{3}{5} \\cdot \\frac{2}{5} \\cdot \\frac{1}{5} \\cdot \\frac{2}{5} \\cdot \\frac{5}{14}$\n\n> $P(\\text{No | today}) \\approx 0.0068$\n\n### 7. Normalize Probabilities\n\nTo compare:\n\n> $P(\\text{Yes | today}) = \\frac{0.02116}{0.02116 + 0.0068} \\approx 0.756$\n\n> $P(\\text{No | today}) = \\frac{0.0068}{0.02116 + 0.0068} \\approx 0.244$\n\n### 8. Final Prediction\n\nSince:\n\n> $P(\\text{Yes | today}) > P(\\text{No | today})$\n\nThe model predicts: **Yes (Play Golf)**\n\n### Naive Bayes for Continuous Features\n\nFor continuous features, we assume a Gaussian distribution:\n\n> $P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left( -\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y} \\right)$\n\nWhere:\n\n- $\\mu_y$ is the mean of feature $x_i$ for class y\n- $\\sigma^2_y$ is the variance of feature $x_i$ for class y\n\nThis leads to what is called **Gaussian Naive Bayes**.\n\n## Types of Naive Bayes Model\n\nThere are three types of Naive Bayes Model :\n\n### 1. Gaussian Naive Bayes\n\nIn [**Gaussian Naive Bayes**](https://www.geeksforgeeks.org/machine-learning/gaussian-naive-bayes/), continuous values associated with each feature are assumed to be distributed according to a Gaussian distribution. A Gaussian distribution is also called [Normal distribution](https://www.geeksforgeeks.org/maths/normal-distribution/) When plotted, it gives a bell shaped curve which is symmetric about the mean of the feature values as shown below:\n\n### 2. Multinomial Naive Bayes\n\n[**Multinomial Naive Bayes**](https://www.geeksforgeeks.org/machine-learning/multinomial-naive-bayes/)is used when features represent the frequency of terms (such as word counts) in a document. It is commonly applied in text classification, where term frequencies are important.\n\n### 3. Bernoulli Naive Bayes\n\n[**Bernoulli Naive Bayes**](https://www.geeksforgeeks.org/machine-learning/bernoulli-naive-bayes/) deals with binary features, where each feature indicates whether a word appears or not in a document. It is suited for scenarios where the presence or absence of terms is more relevant than their frequency. Both models are widely used in document classification tasks\n\n## Advantages of Naive Bayes Classifier\n\n- Easy to implement and computationally efficient.\n- Effective in cases with a large number of features.\n- Performs well even with limited training data.\n- It performs well in the presence of categorical features.\n- For numerical features data is assumed to come from normal distributions\n\n## Disadvantages of Naive Bayes Classifier\n\n- Assumes that features are independent, which may not always hold in real-world data.\n- Can be influenced by irrelevant attributes.\n- May assign zero probability to unseen events, leading to poor generalization.\n\n## Applications of Naive Bayes Classifier\n\n- **Spam Email Filtering**: Classifies emails as spam or non-spam based on features.\n- **Text Classification**: Used in sentiment analysis, document categorization, and topic classification.\n- **Medical Diagnosis:** Helps in predicting the likelihood of a disease based on symptoms.\n- **Credit Scoring:** Evaluates creditworthiness of individuals for loan approval.\n- **Weather Prediction**: Classifies weather conditions based on various factors."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/types-of-machine-learning/", "content": "# Types of Machine Learning\n\nMachine learning is the branch of [Artificial Intelligence](https://www.geeksforgeeks.org/artificial-intelligence/what-is-artificial-intelligence-ai/) that focuses on developing models and algorithms that let computers learn from data and improve from previous experience without being explicitly programmed for every task. In simple words, ML teaches the systems to think and understand like humans by learning from the data.\n\nIn this article, we will explore the various **types of** [****machine learning algorithms****](https://www.geeksforgeeks.org/machine-learning/machine-learning-algorithms/) that are important for future requirements. ****Machine learning**** is generally a training system to learn from past experiences and improve performance over time. [Machine learning](https://www.geeksforgeeks.org/machine-learning/ml-machine-learning/) helps to predict massive amounts of data. It helps to deliver fast and accurate results to get profitable opportunities.\n\n## Types of Machine Learning\n\nThere are several types of machine learning, each with special characteristics and applications. Some of the main types of machine learning algorithms are as follows:\n\n1. Supervised Machine Learning  \n2. Unsupervised Machine Learning  \n3. Reinforcement Learning  \n\nAdditionally, there is a more specific category called semi-supervised learning, which combines elements of both supervised and unsupervised learning.\n\n![Types-of-Machine Leaning-Geeksforgeesk](https://media.geeksforgeeks.org/wp-content/uploads/20230913114022/Types-of-Machine-Leaning-(3).gif)\n\n*Types of Machine Learning*\n\n### 1. Supervised Machine Learning\n\n[Supervised learning](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/) is defined as when a model gets trained on a ****\"Labelled Dataset\"****. Labelled datasets have both input and output parameters. In ****Supervised Learning**** algorithms learn to map points between inputs and correct outputs. It has both training and validation datasets labelled.\n\n![Supervised-learning](https://media.geeksforgeeks.org/wp-content/uploads/20231123085213/Supervised-learning.png)\n\n*Supervised Learning*\n\nLet's understand it with the help of an example.\n\n****Example:**** Consider a scenario where you have to build an image classifier to differentiate between cats and dogs. If you feed the datasets of dogs and cats labelled images to the algorithm, the machine will learn to classify between a dog or a cat from these labeled images. When we input new dog or cat images that it has never seen before, it will use the learned algorithms and predict whether it is a dog or a cat. This is how ****supervised learning**** works, and this is particularly an image classification.\n\nThere are two main categories of supervised learning that are mentioned below:\n\n+ [Classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/)  \n+ [Regression](https://www.geeksforgeeks.org/machine-learning/types-of-regression-techniques/)\n\n#### Classification\n\n[****Classification****](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/)deals with predicting ****categorical**** target variables, which represent discrete classes or labels. For instance, classifying emails as spam or not spam, or predicting whether a patient has a high risk of heart disease. Classification algorithms learn to map the input features to one of the predefined classes.\n\nHere are some classification algorithms:\n\n+ [****Logistic Regression****](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/)  \n+ [****Support Vector Machine****](https://www.geeksforgeeks.org/machine-learning/support-vector-machine-algorithm/)  \n+ [****Random Forest****](https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/)  \n+ [****Decision Tree****](https://www.geeksforgeeks.org/machine-learning/decision-tree/)  \n+ [****K-Nearest Neighbors (KNN)****](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)  \n+ [****Naive Bayes****](https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/)\n\n#### Regression\n\n[****Regression****](https://www.geeksforgeeks.org/machine-learning/regression-in-machine-learning/), on the other hand, deals with predicting ****continuous**** target variables, which represent numerical values. For example, predicting the price of a house based on its size, location, and amenities, or forecasting the sales of a product. Regression algorithms learn to map the input features to a continuous numerical value.\n\nHere are some regression algorithms:\n\n+ [****Linear Regression****](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/)  \n+ [****Polynomial Regression****](https://www.geeksforgeeks.org/videos/polynomial-regression-algorithm-machine-learning/)  \n+ [****Ridge Regression****](https://www.geeksforgeeks.org/videos/lasso-ridge-regression-algorithm-machine-learning/)  \n+ [****Lasso Regression****](https://www.geeksforgeeks.org/videos/lasso-ridge-regression-algorithm-machine-learning/)  \n+ [****Decision tree****](https://www.geeksforgeeks.org/machine-learning/decision-tree-introduction-example/)  \n+ [****Random Forest****](https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/)\n\n#### Advantages of Supervised Machine Learning\n\n+ ****Supervised Learning**** models can have high accuracy as they are trained on ****labelled data****.  \n+ The process of decision-making in supervised learning models is often interpretable.  \n+ It can often be used in pre-trained models which saves time and resources when developing new models from scratch.\n\n#### Disadvantages of Supervised Machine Learning\n\n+ It has limitations in knowing patterns and may struggle with unseen or unexpected patterns that are not present in the training data.  \n+ It can be time-consuming and costly as it relies on ****labeled**** data only.  \n+ It may lead to poor generalizations based on new data.\n\n#### Applications of Supervised Learning\n\nSupervised learning is used in a wide variety of applications, including:\n\n+ ****Image classification****: Identify objects, faces, and other features in images.  \n+ ****Natural language processing:**** Extract information from text, such as sentiment, entities, and relationships.  \n+ ****Speech recognition****: Convert spoken language into text.  \n+ ****Recommendation systems****: Make personalized recommendations to users.  \n+ ****Predictive analytics****: Predict outcomes, such as sales, customer churn, and stock prices.  \n+ ****Medical diagnosis****: Detect diseases and other medical conditions.  \n+ ****Fraud detection****: Identify fraudulent transactions.  \n+ ****Autonomous vehicles****: Recognize and respond to objects in the environment.  \n+ ****Email spam detection****: Classify emails as spam or not spam.  \n+ ****Quality control in manufacturing****: Inspect products for defects.  \n+ ****Credit scoring****: Assess the risk of a borrower defaulting on a loan.  \n+ ****Gaming****: Recognize characters, analyze player behavior, and create NPCs.  \n+ ****Customer support****: Automate customer support tasks.  \n+ ****Weather forecasting****: Make predictions for temperature, precipitation, and other meteorological parameters.  \n+ ****Sports analytics****: Analyze player performance, make game predictions, and optimize strategies.\n\n### 2. Unsupervised Machine Learning\n\n[Unsupervised Learning](https://www.geeksforgeeks.org/machine-learning/unsupervised-machine-learning-the-future-of-cybersecurity/) Unsupervised learning is a type of machine learning technique in which an algorithm discovers patterns and relationships using unlabeled data. Unlike supervised learning, unsupervised learning doesn't involve providing the algorithm with labeled target outputs. The primary goal of Unsupervised learning is often to discover hidden patterns, similarities, or clusters within the data, which can then be used for various purposes, such as data exploration, visualization, dimensionality reduction, and more.\n\n![Unsupervised-learning](https://media.geeksforgeeks.org/wp-content/uploads/20231123085148/Unsupervised-learning.png)\n\n*Unsupervised Learning*\n\nLet's understand it with the help of an example.\n\n****Example:**** Consider that you have a dataset that contains information about the purchases you made from the shop. Through clustering, the algorithm can group the same purchasing behavior among you and other customers, which reveals potential customers without predefined labels. This type of information can help businesses get target customers as well as identify outliers.\n\nThere are two main categories of unsupervised learning that are mentioned below:\n\n+ [Clustering](https://www.geeksforgeeks.org/machine-learning/clustering-in-machine-learning/)  \n+ [Association](https://www.geeksforgeeks.org/machine-learning/association-rule/)\n\n#### Clustering\n\n[Clustering](https://www.geeksforgeeks.org/machine-learning/clustering-in-machine-learning/) is the process of grouping data points into clusters based on their similarity. This technique is useful for identifying patterns and relationships in data without the need for labeled examples.\n\nHere are some clustering algorithms:\n\n+ [****K-Means Clustering algorithm****](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/)  \n+ [****Mean-shift algorithm****](https://www.geeksforgeeks.org/machine-learning/ml-mean-shift-clustering/)  \n+ [****DBSCAN Algorithm****](https://www.geeksforgeeks.org/machine-learning/dbscan-clustering-in-ml-density-based-clustering/)  \n+ [****Principal Component Analysis****](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)  \n+ [****Independent Component Analysis****](https://www.geeksforgeeks.org/machine-learning/ml-independent-component-analysis/)\n\n#### Association\n\n[Association rule learn](https://www.geeksforgeeks.org/machine-learning/association-rule/)ing is a technique for discovering relationships between items in a dataset. It identifies rules that indicate the presence of one item implies the presence of another item with a specific probability.\n\nHere are some association rule learning algorithms:\n\n+ [****Apriori Algorithm****](https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/)  \n+ [****Eclat****](https://www.geeksforgeeks.org/machine-learning/ml-eclat-algorithm/)  \n+ [****FP-growth Algorithm****](https://www.geeksforgeeks.org/machine-learning/frequent-pattern-growth-algorithm/)\n\n#### Advantages of Unsupervised Machine Learning\n\n+ It helps to discover hidden patterns and various relationships between the data.  \n+ Used for tasks such as ****customer segmentation, anomaly detection,**** and ****data exploration****.  \n+ It does not require labeled data and reduces the effort of data labeling.\n\n#### Disadvantages of Unsupervised Machine Learning\n\n+ Without using labels, it may be difficult to predict the quality of the model's output.  \n+ Cluster Interpretability may not be clear and may not have meaningful interpretations.  \n+ It has techniques such as [autoencoders](https://www.geeksforgeeks.org/machine-learning/auto-encoders/) and [dimensionality reduction](https://www.geeksforgeeks.org/machine-learning/dimensionality-reduction/) that can be used to extract meaningful features from raw data.\n\n#### Applications of Unsupervised Learning\n\nHere are some common applications of unsupervised learning:\n\n+ ****Clustering****: Group similar data points into clusters.  \n+ ****Anomaly detection****: Identify outliers or anomalies in data.  \n+ ****Dimensionality reduction****: Reduce the dimensionality of data while preserving its essential information.  \n+ ****Recommendation systems****: Suggest products, movies, or content to users based on their historical behavior or preferences.  \n+ ****Topic modeling****: Discover latent topics within a collection of documents.  \n+ ****Density estimation****: Estimate the probability density function of data.  \n+ ****Image and video compression****: Reduce the amount of storage required for multimedia content.  \n+ ****Data preprocessing****: Help with data preprocessing tasks such as data cleaning, imputation of missing values, and data scaling.  \n+ ****Market basket analysis****: Discover associations between products.  \n+ ****Genomic data analysis****: Identify patterns or group genes with similar expression profiles.  \n+ ****Image segmentation****: Segment images into meaningful regions.  \n+ ****Community detection in social networks****: Identify communities or groups of individuals with similar interests or connections.  \n+ ****Customer behavior analysis****: Uncover patterns and insights for better marketing and product recommendations.  \n+ ****Content recommendation****: Classify and tag content to make it easier to recommend similar items to users.  \n+ ****Exploratory data analysis (EDA)****: Explore data and gain insights before defining specific tasks.\n\n### 3. Reinforcement Machine Learning\n\n[Reinforcement machine learning](https://www.geeksforgeeks.org/machine-learning/what-is-reinforcement-learning/)algorithm is a learning method that interacts with the environment by producing actions and discovering errors. ****Trial, error, and delay**** are the most relevant characteristics of reinforcement learning. In this technique, the model keeps on increasing its performance using Reward Feedback to learn the behavior or pattern. These algorithms are specific to a particular problem e.g. Google Self Driving car, AlphaGo where a bot competes with humans and even itself to get better and better performers in Go Game. Each time we feed in data, they learn and add the data to their knowledge which is training data. So, the more it learns the better it gets trained and hence experienced.\n\nHere are some of most common reinforcement learning algorithms:\n\n+ [****Q-learning:****](https://www.geeksforgeeks.org/machine-learning/q-learning-in-python/) Q-learning is a model-free RL algorithm that learns a Q-function, which maps states to actions. The Q-function estimates the expected reward of taking a particular action in a given state.  \n+ [****SARSA (State-Action-Reward-State-Action):****](https://www.geeksforgeeks.org/machine-learning/sarsa-reinforcement-learning/) SARSA is another model-free RL algorithm that learns a Q-function. However, unlike Q-learning, SARSA updates the Q-function for the action that was actually taken, rather than the optimal action.  \n+ [****Deep Q-learning****](https://www.geeksforgeeks.org/deep-learning/deep-q-learning/)****:**** Deep Q-learning is a combination of Q-learning and deep learning. Deep Q-learning uses a neural network to represent the Q-function, which allows it to learn complex relationships between states and actions.\n\n![1-(2)](https://media.geeksforgeeks.org/wp-content/uploads/20231123085353/1-(2).png)\n\n*Reinforcement Machine Learning*\n\nLet's understand it with the help of examples.\n\n****Example:**** Consider that you are training an [AI](https://www.geeksforgeeks.org/artificial-intelligence/what-is-artificial-intelligence-ai/) agent to play a game like chess. The agent explores different moves and receives positive or negative feedback based on the outcome. Reinforcement Learning also finds applications in which they learn to perform tasks by interacting with their surroundings.\n\n#### Types of Reinforcement Machine Learning\n\nThere are two main types of reinforcement learning:\n\n****Positive reinforcement****\n\n+ Rewards the agent for taking a desired action.  \n+ Encourages the agent to repeat the behavior.  \n+ Examples: Giving a treat to a dog for sitting, providing a point in a game for a correct answer.\n\n****Negative reinforcement****\n\n+ Removes an undesirable stimulus to encourage a desired behavior.  \n+ Discourages the agent from repeating the behavior.  \n+ Examples: Turning off a loud buzzer when a lever is pressed, avoiding a penalty by completing a task.\n\n#### Advantages of Reinforcement Machine Learning\n\n+ It has autonomous decision-making that is well-suited for tasks and that can learn to make a sequence of decisions, like robotics and game-playing.  \n+ This technique is preferred to achieve long-term results that are very difficult to achieve.  \n+ It is used to solve a complex problems that cannot be solved by conventional techniques.\n\n#### Disadvantages of Reinforcement Machine Learning\n\n+ Training Reinforcement Learning agents can be computationally expensive and time-consuming.  \n+ Reinforcement learning is not preferable to solving simple problems.  \n+ It needs a lot of data and a lot of computation, which makes it impractical and costly.\n\n#### Applications of Reinforcement Machine Learning\n\nHere are some applications of reinforcement learning:\n\n+ ****Game Playing****: RL can teach agents to play games, even complex ones.  \n+ ****Robotics****: RL can teach robots to perform tasks autonomously.  \n+ ****Autonomous Vehicles****: RL can help self-driving cars navigate and make decisions.  \n+ ****Recommendation Systems****: RL can enhance recommendation algorithms by learning user preferences.  \n+ ****Healthcare****: RL can be used to optimize treatment plans and drug discovery.  \n+ ****Natural Language Processing (NLP)****: RL can be used in dialogue systems and chatbots.  \n+ ****Finance and Trading****: RL can be used for algorithmic trading.  \n+ ****Supply Chain and Inventory Management****: RL can be used to optimize supply chain operations.  \n+ ****Energy Management****: RL can be used to optimize energy consumption.  \n+ ****Game AI****: RL can be used to create more intelligent and adaptive NPCs in video games.  \n+ ****Adaptive Personal Assistants****: RL can be used to improve personal assistants.  \n+ ****Virtual Reality (VR) and Augmented Reality (AR):**** RL can be used to create immersive and interactive experiences.  \n+ ****Industrial Control****: RL can be used to optimize industrial processes.  \n+ ****Education****: RL can be used to create adaptive learning systems.  \n+ ****Agriculture****: RL can be used to optimize agricultural operations.\n\n### Semi-Supervised Learning: Supervised + Unsupervised Learning\n\n[Semi-Supervised learning](https://www.geeksforgeeks.org/machine-learning/ml-semi-supervised-learning/)is a machine learning algorithm that works between the supervised and unsupervised learning so it uses both ****labelled and unlabelled**** data. It's particularly useful when obtaining labeled data is costly, time-consuming, or resource-intensive. This approach is useful when the dataset is expensive and time-consuming. Semi-supervised learning is chosen when labeled data requires skills and relevant resources in order to train or learn from it.\n\nWe use these techniques when we are dealing with data that is a little bit labeled and the rest large portion of it is unlabeled. We can use the unsupervised techniques to predict labels and then feed these labels to supervised techniques. This technique is mostly applicable in the case of image data sets where usually all images are not labeled.\n\n![2](https://media.geeksforgeeks.org/wp-content/uploads/20231123085101/2.png)\n\n*Semi-Supervised Learning*\n\nLet's understand it with the help of an example.\n\n****Example****: Consider that we are building a language translation model, having labeled translations for every sentence pair can be resources intensive. It allows the models to learn from labeled and unlabeled sentence pairs, making them more accurate. This technique has led to significant improvements in the quality of machine translation services.\n\n#### Types of Semi-Supervised Learning Methods\n\nThere are a number of different semi-supervised learning methods each with its own characteristics. Some of the most common ones include:\n\n+ ****Graph-based semi-supervised learning:****This approach uses a graph to represent the relationships between the data points. The graph is then used to propagate labels from the labeled data points to the unlabeled data points.  \n+ ****Label propagation:****This approach iteratively propagates labels from the labeled data points to the unlabeled data points, based on the similarities between the data points.  \n+ ****Co-training:****This approach trains two different machine learning models on different subsets of the unlabeled data. The two models are then used to label each other's predictions.  \n+ ****Self-training:****This approach trains a machine learning model on the labeled data and then uses the model to predict labels for the unlabeled data. The model is then retrained on the labeled data and the predicted labels for the unlabeled data.  \n+ [****Generative adversarial networks (GANs)****](https://www.geeksforgeeks.org/deep-learning/generative-adversarial-network-gan/)****:****GANs are a type of deep learning algorithm that can be used to generate synthetic data. GANs can be used to generate unlabeled data for semi-supervised learning by training two neural networks, a generator and a discriminator.\n\n#### Advantages of Semi- Supervised Machine Learning\n\n+ It leads to better generalization as compared to ****supervised learning,**** as it takes both labeled and unlabeled data.  \n+ Can be applied to a wide range of data.\n\n#### Disadvantages of Semi-Supervised Machine Learning\n\n+ ****Semi-supervised**** methods can be more complex to implement compared to other approaches.  \n+ It still requires some ****labeled data**** that might not always be available or easy to obtain.  \n+ The unlabeled data can impact the model performance accordingly.\n\n#### Applications of Semi-Supervised Learning\n\nHere are some common applications of semi-supervised learning:\n\n+ ****Image Classification and Object Recognition****: Improve the accuracy of models by combining a small set of labeled images with a larger set of unlabeled images.  \n+ ****Natural Language Processing (NLP)****: Enhance the performance of language models and classifiers by combining a small set of labeled text data with a vast amount of unlabeled text.  \n+ ****Speech Recognition:**** Improve the accuracy of speech recognition by leveraging a limited amount of transcribed speech data and a more extensive set of unlabeled audio.  \n+ ****Recommendation Systems****: Improve the accuracy of personalized recommendations by supplementing a sparse set of user-item interactions (labeled data) with a wealth of unlabeled user behavior data.  \n+ ****Healthcare and Medical Imaging****: Enhance medical image analysis by utilizing a small set of labeled medical images alongside a larger set of unlabeled images.\n\n> ****Must check, our detailed article on****: [Machine Learning Algorithms](https://www.geeksforgeeks.org/machine-learning/machine-learning-algorithms/)\n\n## Conclusion\n\nIn conclusion, each type of machine learning serves its own purpose and contributes to the overall role in development of enhanced data prediction capabilities, and it has the potential to change various industries like [Data Science](https://www.geeksforgeeks.org/data-science/python-for-data-science/). It helps deal with massive data production and management of the datasets."}
{"reference": "https://www.geeksforgeeks.org/problem-of-the-day", "content": "# Problem Of The Day\n\nSolve one problem based on Data Structures and Algorithms every day and win exciting prizes.\n\n## Previous Problems\n\n**2025**\n\n**October**\n\nSelect your desired date to view the problem status of that day."}
{"reference": "https://www.geeksforgeeks.org/data-analysis/exploratory-data-analysis-in-python/", "content": "# EDA - Exploratory Data Analysis in Python\n\n**Last Updated**: 31 Jul, 2025\n\n**Exploratory Data Analysis (EDA)** is an important step in data analysis which focuses on understanding patterns, trends and relationships through statistical tools and visualizations. Python offers various libraries like pandas, NumPy, matplotlib, seaborn and plotly which enables effective exploration and insights generation to help in further modeling and analysis. In this article, we will see how to perform EDA using python.\n\n## Key Steps for Exploratory Data Analysis (EDA)\n\nLets see various steps involved in Exploratory Data Analysis:\n\n### Step 1: Importing Required Libraries\n\nWe need to install [Pandas](https://www.geeksforgeeks.org/pandas/pandas-tutorial/), [NumPy](https://www.geeksforgeeks.org/numpy/python-numpy/), [Matplotlib](https://www.geeksforgeeks.org/data-visualization/data-visualization-using-matplotlib/) and [Seaborn](https://www.geeksforgeeks.org/python/introduction-to-seaborn-python/) libraries in python to proceed further.\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings as wr\nwr.filterwarnings('ignore')\n```\n\n### Step 2: Reading Dataset\n\nLets read the dataset using pandas.\n\n> Download the dataset from this [link](https://media.geeksforgeeks.org/wp-content/uploads/20250731152112425017/WineQT.csv)\n\n```python\ndf = pd.read_csv(\"/content/WineQT.csv\")\nprint(df.head())\n```\n\n**Output:**\n\n*First 5 rows*\n\n### Step 3: Analyzing the Data\n\n**1. df.shape():** This function is used to understand the number of rows (observations) and columns (features) in the dataset. This gives an overview of the dataset's size and structure.\n\n```python\ndf.shape\n```\n\n**Output:**\n\n> (1143, 13)\n\n**2. df.info():** This function helps us to understand the dataset by showing the number of records in each column, type of data, whether any values are missing and how much memory the dataset uses.\n\n```python\ndf.info()\n```\n\n**Output:**\n\n*info()*\n\n**3. df.describe().T:** This method gives a statistical summary of the DataFrame (Transpose) showing values like count, mean, standard deviation, minimum and quartiles for each numerical column. It helps in summarizing the central tendency and spread of the data.\n\n```python\ndf.describe().T\n```\n\n**Output:**\n\n*describe*\n\n**4. df.columns.tolist():** This converts the column names of the DataFrame into a Python list making it easy to access and manipulate the column names.\n\n```python\ndf.columns.tolist()\n```\n\n**Output:**\n\n*column names*\n\n### Step 4: Checking Missing Values\n\n**df.isnull().sum():** This checks for missing values in each column and returns the total number of null values per column helping us to identify any gaps in our data.\n\n```python\ndf.isnull().sum()\n```\n\n**Output:**\n\n*Missing values in each column*\n\n### Step 5: Checking for the duplicate values\n\n**df.nunique():** This function tells us how many unique values exist in each column which provides insight into the variety of data in each feature.\n\n```python\ndf.nunique()\n```\n\n**Output:**\n\n*nunique()*\n\n### Step 6: Univariate Analysis\n\nIn [Univariate analysis](https://www.geeksforgeeks.org/data-analysis/univariate-bivariate-and-multivariate-data-and-its-analysis/) plotting the right charts can help us to better understand the data making the data visualization so important.\n\n**1. Bar Plot for evaluating the count of the wine with its quality rate.**\n\n```python\nquality_counts = df['quality'].value_counts()\n\nplt.figure(figsize=(8, 6))\nplt.bar(quality_counts.index, quality_counts, color='deeppink')\nplt.title('Count Plot of Quality')\nplt.xlabel('Quality')\nplt.ylabel('Count')\nplt.show()\n```\n\n**Output:**\n\n*Bar Plot*\n\nHere, this count plot graph shows the count of the wine with its quality rate.\n\n**2.** [Kernel density plot](https://www.geeksforgeeks.org/data-visualization/kde-plot-visualization-with-pandas-and-seaborn/) **for understanding variance in the dataset**\n\n```python\nsns.set_style(\"darkgrid\")\n\nnumerical_columns = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n\nplt.figure(figsize=(14, len(numerical_columns) * 3))\nfor idx, feature in enumerate(numerical_columns, 1):\n    plt.subplot(len(numerical_columns), 2, idx)\n    sns.histplot(df[feature], kde=True)\n    plt.title(f\"{feature} | Skewness: {round(df[feature].skew(), 2)}\")\n\nplt.tight_layout()\nplt.show()\n```\n\n**Output:**\n\n*Kernel density plot*\n\nThe features in the dataset with a skewness of **0** shows a symmetrical distribution. If the skewness is 1 or above it suggests a positively skewed (right-skewed) distribution. In a right-skewed distribution the tail extends more to the right which shows the presence of extremely high values.\n\n**3.** [Swarm Plot](https://www.geeksforgeeks.org/python/swarmplot-using-seaborn-in-python/) **for showing the outlier in the data**\n\n```python\nplt.figure(figsize=(10, 8))\n\nsns.swarmplot(x=\"quality\", y=\"alcohol\", data=df, palette='viridis')\n\nplt.title('Swarm Plot for Quality and Alcohol')\nplt.xlabel('Quality')\nplt.ylabel('Alcohol')\nplt.show()\n```\n\n**Output:**\n\n*Swarm Plot*\n\nThis graph shows the swarm plot for the 'Quality' and 'Alcohol' columns. The higher point density in certain areas shows where most of the data points are concentrated. Points that are isolated and far from these clusters represent outliers highlighting uneven values in the dataset.\n\n### Step 7: Bivariate Analysis\n\nIn [bivariate analysis](https://www.geeksforgeeks.org/data-analysis/univariate-bivariate-and-multivariate-data-and-its-analysis/) two variables are analyzed together to identify patterns, dependencies or interactions between them. This method helps in understanding how changes in one variable might affect another.\n\nLet's visualize these relationships by plotting various plot for the data which will show how the variables interact with each other across multiple dimensions.\n\n**1. Pair Plot for showing the distribution of the individual variables**\n\n```python\nsns.set_palette(\"Pastel1\")\n\nplt.figure(figsize=(10, 6))\n\nsns.pairplot(df)\n\nplt.suptitle('Pair Plot for DataFrame')\nplt.show()\n```\n\n**Output:**\n\n*Pair Plot*\n\n- If the plot is diagonal , histograms of kernel density plots shows the distribution of the individual variables.\n- If the scatter plot is in the lower triangle, it displays the relationship between the pairs of the variables.\n- If the scatter plots above and below the diagonal are mirror images indicating symmetry.\n- If the histogram plots are more centered, it represents the locations of peaks.\n- Skewness is found by observing whether the histogram is symmetrical or skewed to the left or right.\n\n**2.** [Violin Plot](https://www.geeksforgeeks.org/data-visualization/violin-plot-for-data-analysis/) **for examining the relationship between alcohol and Quality.**\n\n```python\ndf['quality'] = df['quality'].astype(str)\n\nplt.figure(figsize=(10, 8))\n\nsns.violinplot(x=\"quality\", y=\"alcohol\", data=df, palette={\n    '3': 'lightcoral', '4': 'lightblue', '5': 'lightgreen', '6': 'gold', '7': 'lightskyblue', '8': 'lightpink'}, alpha=0.7)\n\nplt.title('Violin Plot for Quality and Alcohol')\nplt.xlabel('Quality')\nplt.ylabel('Alcohol')\nplt.show()\n```\n\n**Output:**\n\n*Violin Plot*\n\nFor interpreting the Violin Plot:\n\n- If the width is wider, it shows higher density suggesting more data points.\n- Symmetrical plot shows a balanced distribution.\n- Peak or bulge in the violin plot represents most common value in distribution.\n- Longer tails shows great variability.\n- Median line is the middle line inside the violin plot. It helps in understanding central tendencies.\n\n**3. Box Plot for examining the relationship between alcohol and Quality**\n\n```python\nsns.boxplot(x='quality', y='alcohol', data=df)\n```\n\n**Output:**\n\n*Box Plot*\n\nBox represents the [IQR](https://www.geeksforgeeks.org/dsa/interquartile-range-iqr/) i.e longer the box, greater the variability.\n\n- Median line in the box shows central tendency.\n- [Whiskers](https://www.geeksforgeeks.org/data-visualization/box-and-whisker-plot-meaning-uses-and-example/) extend from box to the smallest and largest values within a specified range.\n- Individual points beyond the whiskers represents outliers.\n- A compact box shows low variability while a stretched box shows higher variability.\n\n### Step 8: Multivariate Analysis\n\nIt involves finding the interactions between three or more variables in a dataset at the same time. This approach focuses to identify complex patterns, relationships and interactions which provides understanding of how multiple variables collectively behave and influence each other.\n\nHere, we are going to show the multivariate analysis using a [correlation matrix plot](https://www.geeksforgeeks.org/python/plotting-correlation-matrix-using-python/).\n\n```python\nplt.figure(figsize=(15, 10))\n\nsns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='Pastel2', linewidths=2)\n\nplt.title('Correlation Heatmap')\nplt.show()\n```\n\n**Output:**\n\n*Correlation Matrix*\n\nValues close to +1 shows strong positive correlation, -1 shows a strong negative correlation and 0 suggests no linear correlation.\n\n- Darker colors signify strong correlation, while light colors represents weaker correlations.\n- Positive correlation variable move in same directions. As one increases, the other also increases.\n- Negative correlation variable move in opposite directions. An increase in one variable is associated with a decrease in the other.\n\nWith these insights from the EDA, we are now ready to undertsand the data and explore more advanced modeling techniques."}
{"reference": "https://www.geeksforgeeks.org/videos/category/data-science/", "content": "# Data Science Videos\n\n## Support Vector Regression Intuition\n- **Duration**: 10:50\n- **Views**: 179.1K\n- **Date**: 21/01/2025\n- **Tags**: Python, Data Science, linear-regression\n- **Link**: [Watch Video](/videos/support-vector-regression-intuition/)\n\n## Prompt Engineering for Summarization\n- **Duration**: 06:35\n- **Views**: 23.5K\n- **Date**: 17/01/2025\n- **Tags**: Data Science\n- **Link**: [Watch Video](/videos/prompt-engineering-for-summarization/)\n\n## PandasAI Library from OpenAI\n- **Duration**: 08:19\n- **Views**: 1.3K\n- **Date**: 17/01/2025\n- **Tags**: Data Science\n- **Link**: [Watch Video](/videos/pandasai-library-from-openai/)\n\n## Bidirectional Recurrent Neural Network\n- **Duration**: 09:58\n- **Views**: 17.7K\n- **Date**: 15/01/2025\n- **Tags**: Data Science\n- **Link**: [Watch Video](/videos/bidirectional-recurrent-neural-network/)\n\n## How to Blur an Image using OpenCV?\n- **Duration**: 10:57\n- **Views**: 3.9K\n- **Date**: 06/12/2024\n- **Tags**: Data Science\n- **Link**: [Watch Video](/videos/how-to-blur-an-image-using-opencv/)\n\n## How to Display an Image using OpenCV\n- **Duration**: 11:24\n- **Views**: 12.6K\n- **Date**: 06/12/2024\n- **Tags**: Data Science\n- **Link**: [Watch Video](/videos/how-to-display-an-image-using-opencv/)\n\n## Master Boosting in Machine Learning\n- **Duration**: 11:04\n- **Views**: 1.7K\n- **Date**: 06/12/2024\n- **Tags**: ML, Data Science, Machine Learning\n- **Link**: [Watch Video](/videos/master-boosting-in-machine-learning/)\n\n## Master Bagging in Machine Learning\n- **Duration**: 27:55\n- **Views**: 2.8K\n- **Date**: 06/12/2024\n- **Tags**: ML, Data Science, Machine Learning\n- **Link**: [Watch Video](/videos/master-bagging-in-machine-learning/)\n\n## Transformers in Machine Learning\n- **Duration**: 13:25\n- **Views**: 49.2K\n- **Date**: 06/12/2024\n- **Tags**: Data Science, artificial-intelligence, Artificial Intelligence\n- **Link**: [Watch Video](/videos/transformers-in-machine-learning/)\n\n## Types of Neural Networks\n- **Duration**: 10:33\n- **Views**: 7.3K\n- **Date**: 06/12/2024\n- **Tags**: Data Science, artificial-intelligence, Artificial Intelligence\n- **Link**: [Watch Video](/videos/types-of-neural-networks/)\n\n## What is Neural Networks\n- **Duration**: 09:20\n- **Views**: 6.5K\n- **Date**: 06/12/2024\n- **Tags**: Data Science, artificial-intelligence, Artificial Intelligence\n- **Link**: [Watch Video](/videos/what-is-neural-networks/)\n\n## Introduction of Generative AI\n- **Duration**: 06:19\n- **Views**: 26.0K\n- **Date**: 06/12/2024\n- **Tags**: Data Science, artificial-intelligence, Artificial Intelligence\n- **Link**: [Watch Video](/videos/introduction-of-generative-ai/)\n\n*Showing 1 to 17 videos. Additional pages available for more content.*"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/neural-networks-a-beginners-guide/", "content": "# What is a Neural Network?\n\nNeural networks are machine learning models that mimic the complex functions of the human brain. These models consist of interconnected nodes or neurons that process data, learn patterns and enable tasks such as pattern recognition and decision-making.\n\nNeural networks are capable of learning and identifying patterns directly from data without pre-defined rules. These networks are built from several key components:\n\n- **Neurons**: The basic units that receive inputs, each neuron is governed by a threshold and an activation function.\n- **Connections**: Links between neurons that carry information, regulated by weights and biases.\n- **Weights and Biases**: These parameters determine the strength and influence of connections.\n- **Propagation Functions**: Mechanisms that help process and transfer data across layers of neurons.\n- **Learning Rule**: The method that adjusts weights and biases over time to improve accuracy.\n\n**Learning in neural networks follows a structured, three-stage process:**\n\n1. **Input Computation**: Data is fed into the network.\n2. **Output Generation**: Based on the current parameters, the network generates an output.\n3. **Iterative Refinement**: The network refines its output by adjusting weights and biases, gradually improving its performance on diverse tasks.\n\n**In an adaptive learning environment:**\n\n- The neural network is exposed to a simulated scenario or dataset.\n- Parameters such as weights and biases are updated in response to new data or conditions.\n- With each adjustment, the network's response evolves allowing it to adapt effectively to different tasks or environments.\n\n![Artificial Neural Networks](https://media.geeksforgeeks.org/wp-content/uploads/20241106171024318092/Artificial-Neural-Networks.webp)\n\n*The image illustrates the analogy between a biological neuron and an artificial neuron, showing how inputs are received and processed to produce outputs in both systems.*\n\n## Importance of Neural Networks\n\n- **Identify Complex Patterns**: Recognize intricate structures and relationships in data; adapt to dynamic and changing environments.\n- **Learn from Data**: Handle vast datasets efficiently; improve performance with experience and retraining.\n- **Drive Key Technologies**: Power natural language processing (NLP); enable self-driving vehicles; support automated decision-making systems.\n- **Boost Efficiency**: Streamline workflows and processes; enhance productivity across industries.\n- **Backbone of AI**: Serve as the core driver of artificial intelligence progress; continue shaping the future of technology and innovation.\n\n## Layers in Neural Network Architecture\n\n![Neural Networks Architecture](https://media.geeksforgeeks.org/wp-content/uploads/20250923121847731542/Neural-Networks-Architecture.webp)\n\n*Layers*\n\n1. **Input Layer**: This is where the network receives its input data. Each input neuron in the layer corresponds to a feature in the input data.\n2. **Hidden Layers**: These layers perform most of the computational heavy lifting. A neural network can have one or multiple hidden layers. Each layer consists of units (neurons) that transform the inputs into something that the output layer can use.\n3. **Output Layer**: The final layer produces the output of the model. The format of these outputs varies depending on the specific task like classification, regression.\n\n## Working of Neural Networks\n\n### 1. Forward Propagation\n\nWhen data is input into the network, it passes through the network in the forward direction, from the input layer through the hidden layers to the output layer. This process is known as forward propagation. Here's what happens during this phase:\n\n**1. Linear Transformation**: Each neuron in a layer receives inputs which are multiplied by the weights associated with the connections. These products are summed together and a bias is added to the sum. This can be represented mathematically as:\n\n> z = w₁x₁ + w₂x₂ + … + wₙxₙ + b\n\nwhere\n\n- w represents the weights\n- x represents the inputs\n- b is the bias\n\n**2. Activation**: The result of the linear transformation (denoted as z) is then passed through an activation function. The activation function is crucial because it introduces non-linearity into the system, enabling the network to learn more complex patterns. Popular activation functions include ReLU, sigmoid and tanh.\n\n### 2. Backpropagation\n\nAfter forward propagation, the network evaluates its performance using a loss function which measures the difference between the actual output and the predicted output. The goal of training is to minimize this loss. This is where backpropagation comes into play:\n\n- **Loss Calculation**: The network calculates the loss which provides a measure of error in the predictions. The loss function could vary; common choices are mean squared error for regression tasks or cross-entropy loss for classification.\n- **Gradient Calculation**: The network computes the gradients of the loss function with respect to each weight and bias in the network. This involves applying the chain rule of calculus to find out how much each part of the output error can be attributed to each weight and bias.\n- **Weight Update**: Once the gradients are calculated, the weights and biases are updated using an optimization algorithm like stochastic gradient descent (SGD). The weights are adjusted in the opposite direction of the gradient to minimize the loss. The size of the step taken in each update is determined by the learning rate.\n\n### 3. Iteration\n\nThis process of forward propagation, loss calculation, backpropagation and weight update is repeated for many iterations over the dataset. Over time, this iterative process reduces the loss and the network's predictions become more accurate.\n\nThrough these steps, neural networks can adapt their parameters to better approximate the relationships in the data, thereby improving their performance on tasks such as classification, regression or any other predictive modeling.\n\n## Example of Email Classification\n\nLet's consider a record of an email dataset:\n\n| Email ID | Email Content            | Sender            | Subject Line     | Label |\n|----------|--------------------------|-------------------|------------------|-------|\n| 1        | \"Get free gift cards now!\" | spam@example.com | \"Exclusive Offer\" | 1     |\n\nTo classify this email, we will create a feature vector based on the analysis of keywords such as \"free\" \"win\" and \"offer\"\n\nThe feature vector of the record can be presented as:\n\n- \"free\": Present (1)\n- \"win\": Absent (0)\n- \"offer\": Present (1)\n\n### How Neurons Process Data in a Neural Network\n\nIn a neural network, input data is passed through multiple layers, including one or more hidden layers. Each neuron in these hidden layers performs several operations, transforming the input into a usable output.\n\n**1. Input Layer**: The input layer contains 3 nodes that indicates the presence of each keyword.\n\n**2. Hidden Layer**: The input vector is passed through the hidden layer. Each neuron in the hidden layer performs two primary operations: a weighted sum followed by an activation function.\n\n**Weights**:\n\n- Neuron H1: [0.5,−0.2,0.3]\n- Neuron H2: [0.4,0.1,−0.5]\n\n**Input Vector: [1,0,1]**\n\n**Weighted Sum Calculation**\n\n- **For H1**: (1×0.5)+(0×−0.2)+(1×0.3)=0.5+0+0.3=0.8\n- **For H2**: (1×0.4)+(0×0.1)+(1×−0.5)=0.4+0−0.5=−0.1\n\n**Activation Function**\n\nHere we will use [ReLu activation function](https://www.geeksforgeeks.org/deep-learning/relu-activation-function-in-deep-learning/):\n\n- **H1 Output**: ReLU(0.8)= 0.8\n- **H2 Output**: ReLu(-0.1) = 0\n\n**3. Output Layer**: The activated values from the hidden neurons are sent to the output neuron where they are again processed using a weighted sum and an activation function.\n\n- **Output Weights**: [0.7, 0.2]\n- **Input from Hidden Layer**: [0.8, 0]\n- **Weighted Sum**: (0.8×0.7)+(0×0.2)=0.56+0=0.56\n- **Activation (Sigmoid)**: σ(0.56) = 1/(1 + e^{-0.56}) ≈ 0.636\n\n**4. Final Classification**:\n\n- The output value of approximately **0.636** indicates the probability of the email being spam.\n- Since this value is greater than 0.5, the neural network classifies the email as spam (1).\n\n![Neural Network for Email Classification Example](https://media.geeksforgeeks.org/wp-content/uploads/20241106184728862313/Neural-Network.png)\n\n*Neural Network for Email Classification Example*\n\n## Learning of a Neural Network\n\n### 1. Learning with Supervised Learning\n\nIn supervised learning, a neural network learns from labeled input-output pairs provided by a teacher. The network generates outputs based on inputs and by comparing these outputs to the known desired outputs, an error signal is created. The network iteratively adjusts its parameters to minimize errors until it reaches an acceptable performance level.\n\n### 2. Learning with Unsupervised Learning\n\nUnsupervised learning involves data without labeled output variables. The primary goal is to understand the underlying structure of the input data (X). Unlike supervised learning, there is no instructor to guide the process. Instead, the focus is on modeling data patterns and relationships, with techniques like clustering and association commonly used.\n\n### 3. Learning with Reinforcement Learning\n\nReinforcement learning enables a neural network to learn through interaction with its environment. The network receives feedback in the form of rewards or penalties, guiding it to find an optimal policy or strategy that maximizes cumulative rewards over time. This approach is widely used in applications like gaming and decision-making.\n\n## Types of Neural Networks\n\nThere are seven types of neural networks that can be used.\n\n- **[Feedforward Networks](https://www.geeksforgeeks.org/nlp/feedforward-neural-network/)**: It is a simple artificial neural network architecture in which data moves from input to output in a single direction.\n- **[Singlelayer Perceptron](https://www.geeksforgeeks.org/python/single-layer-perceptron-in-tensorflow/)**: It has one layer and it applies weights, sums inputs and uses activation to produce output.\n- **[Multilayer Perceptron (MLP)](https://www.geeksforgeeks.org/deep-learning/multi-layer-perceptron-learning-in-tensorflow/)**: It is a type of feedforward neural network with three or more layers, including an input layer, one or more hidden layers and an output layer. It uses nonlinear activation functions.\n- **[Convolutional Neural Network (CNN)](https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/)**: It is designed for image processing. It uses convolutional layers to automatically learn features from input images, enabling effective image recognition and classification.\n- **[Recurrent Neural Network (RNN)](https://www.geeksforgeeks.org/machine-learning/introduction-to-recurrent-neural-network/)**: Handles sequential data using feedback loops to retain context over time.\n- **[Long Short-Term Memory (LSTM)](https://www.geeksforgeeks.org/deep-learning/deep-learning-introduction-to-long-short-term-memory/)**: A type of RNN with memory cells and gates to handle long-term dependencies and avoid vanishing gradients.\n\n## Implementation of Neural Network using TensorFlow\n\nHere, we implement simple feedforward neural network that trains on a sample dataset and makes predictions using following steps:\n\n### Step 1: Import Necessary Libraries\n\nImport necessary libraries, primarily [TensorFlow](https://www.geeksforgeeks.org/python/introduction-to-tensorflow/) and [Keras](https://www.geeksforgeeks.org/deep-learning/what-is-keras/), along with other required packages such as [NumPy](https://www.geeksforgeeks.org/python/introduction-to-numpy/) and [Pandas](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/) for data handling.\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n```\n\n### Step 2: Create and Load Dataset\n\n- Create or load a dataset. Convert the data into a format suitable for training (usually NumPy arrays).\n- Define features (X) and labels (y).\n\n```python\ndata = {\n    'feature1': [0.1, 0.2, 0.3, 0.4, 0.5],\n    'feature2': [0.5, 0.4, 0.3, 0.2, 0.1],\n    'label': [0, 0, 1, 1, 1]\n}\n\ndf = pd.DataFrame(data)\nX = df[['feature1', 'feature2']].values\ny = df['label'].values\n```\n\n### Step 3: Create a Neural Network\n\nInstantiate a Sequential model and add layers. The input layer and hidden layers are typically created using `Dense` layers, specifying the number of neurons and activation functions.\n\n```python\nmodel = Sequential()\nmodel.add(Dense(8, input_dim=2, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n```\n\n### Step 4: Compiling the Model\n\nCompile the model by specifying the loss function, optimizer and metrics to evaluate during training. Here we will use [binary crossentropy](https://www.geeksforgeeks.org/deep-learning/binary-cross-entropy-log-loss-for-binary-classification/) and [adam optimizer](https://www.geeksforgeeks.org/deep-learning/adam-optimizer/).\n\n```python\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam', metrics=['accuracy'])\n```\n\n### Step 5: Train the Model\n\nFit the model on the training data, specifying the number of epochs and batch size. This step trains the neural network to learn from the input data.\n\n```python\nmodel.fit(X, y, epochs=100, batch_size=1, verbose=1)\n```\n\n### Step 6: Make Predictions\n\nUse the trained model to make predictions on new data. Process the output to interpret the predictions like converting probabilities to binary outcomes.\n\n```python\ntest_data = np.array([[0.2, 0.4]])\nprediction = model.predict(test_data)\npredicted_label = (prediction > 0.5).astype(int)\n```\n\n**Output**:\n\n> Predicted label: 1\n\n## Advantages\n\nNeural networks are widely used in many different applications because of their many benefits:\n\n- **Adaptability**: Neural networks are useful for activities where the link between inputs and outputs is complex or not well defined because they can adapt to new situations and learn from data.\n- **Pattern Recognition**: Their proficiency in pattern recognition renders them efficacious in tasks like as audio and image identification, natural language processing and other intricate data patterns.\n- **Parallel Processing**: Because neural networks are capable of parallel processing by nature, they can process numerous jobs at once which speeds up and improves the efficiency of computations.\n- **Non-Linearity**: Neural networks are able to model and comprehend complicated relationships in data by virtue of the non-linear activation functions found in neurons which overcome the drawbacks of linear models.\n\n## Limitations\n\nNeural networks while powerful, are not without drawbacks and difficulties:\n\n- **Computational Intensity**: Large neural network training can be a laborious and computationally demanding process that demands a lot of computing power.\n- **Black box Nature**: As \"black box\" models, neural networks pose a problem in important applications since it is difficult to understand how they make decisions.\n- **Overfitting**: Overfitting is a phenomenon in which neural networks commit training material to memory rather than identifying patterns in the data. Although regularization approaches help to alleviate this, the problem still exists.\n- **Need for Large datasets**: For efficient training, neural networks frequently need sizable, labeled datasets; otherwise, their performance may suffer from incomplete or skewed data.\n\n## Applications\n\nNeural networks have numerous applications across various fields:\n\n1. **Image and Video Recognition**: CNNs are extensively used in applications such as facial recognition, autonomous driving and medical image analysis.\n2. **Natural Language Processing (NLP)**: RNNs and transformers power language translation, chatbots and sentiment analysis.\n3. **Finance**: Predicting stock prices, fraud detection and risk management.\n4. **Healthcare**: Neural networks assist in diagnosing diseases, analyzing medical images and personalizing treatment plans.\n5. **Gaming and Autonomous Systems**: Neural networks enable real-time decision-making, enhancing user experience in video games and enabling autonomous systems like self-driving cars."}
{"reference": "https://geeksforgeeksapp.page.link/gfg-app", "content": "# Official GeeksforGeeks App\n\nBoost your productivity and break free from all your technical limitations.\n\nYour Geeky friend, next door, is now, in your pocket. Introducing our GeeksforGeeks app!\n\nDownload for Android | Download for iOS\n\n![Mobile Mock Image for Website with QR code](https://media.geeksforgeeks.org/auth-dashboard-uploads/CompressedHeroSectionImage_.png)\n\n![Dots Pattern](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39156.png)\n\n## Our Vision and Impact\n\nOur vision is to bind all our geeky members as one community!\n\n**Learn**  \nHigh-quality, free resources and courses for beginners to experienced professionals.\n\n**Upskill**  \nAcquire and upgrade the skills needed to pursue a career in tech.\n\n**Connect**  \nConnect with the global community of experts and learn from their experiences.\n\n**Grow**  \nApply for various job opportunities and grow in your career.\n\n## Why Choose GeeksforGeeks\n\n1. **Download Functionality**  \n   Learn on the go with offline videos and articles. Feed your curiosity wherever and whenever you want!\n\n2. **Personalized Feed**  \n   Discover a personalized feed that prioritizes your interests. An enhanced user experience awaits you.\n\n3. **Programming Questions**  \n   Improve your programming practice with the ability to edit and run your code from any location you desire.\n\n![Mobile Mock Image for Website](https://media.geeksforgeeks.org/auth-dashboard-uploads/secondPhoneImageComp.png)\n\n4. **Advance Your Skills**  \n   Elevate your interviewing skills and expand your knowledge with our courses and abundant collection of free resources.\n\n## Words from Our Geeks!\n\n11K+ reviews on our application—see what users are talking about.\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Ganesh**  \nI usually read from this app when I cannot use my laptop. Useful App to Learn DS & Algo, Programming while travelling. It has access to all content I can read from my laptop and is....\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Diksha Moon**  \nExcellent app. Beneficial for both beginners & advanced programmers. Huge content available & also there is an option to add topics from our interest. Interview experiences are shared of....\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Vaibhav Alur**  \nI'm really lazy when it comes to rating of applications but this app forced me to give feedback. Very less apps provide such good facility. Thankyou very much for understanding our....\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **IT103 - Divyesh Rathod**  \nThe best app for learning, especially for beginners. I'm IT student in well known uni., My all friends using GFG for practice. Thanks to GfG team for making this wonder. ❤️ →This app is made by an indian so I'm feeling very proud for that. → please make more, like this amazing creation.\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Kishan Rout**  \nReally this app is too much helping for any campus preparation. By properly doing every coding question from this application is enough for to get placed in top MNCs no need to join any online or offline course. Amazing app it really deserves 5star.\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Alireza**  \nGeeksforGeeks is the best app that you can find to improve your knowledge in computer science by some short and easy to learn articles. I use it before sleep to feed my brain :) After all of these I can just say it is the best.\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Rahul Kumar**  \nThe app will be perfect. I also want this type of app it is also very helpful for the students who wants to learn DS and Algorithms. Thank you for the developer to providing such a nice app... 😍😍 You have to also make this app offline. I hope you make it as soon as possible....\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Sangeet Baruah**  \nThe app is too grand now. Its similar to the web version.\n\n![Testimonial user Avatar](https://media.geeksforgeeks.org/auth-dashboard-uploads/Group-39219-%281%29.png) **Sanjna Chauhan**  \nIt's a nice application for programmers and have better UI design 👌 and information about the topics is great. Love it. ❤️\n\nScan the QR code to download the GeeksforGeeks App Or Select your App Store\n\n[![PlayStore Button](https://media.geeksforgeeks.org/auth-dashboard-uploads/googleplay.svg)](https://play.google.com/store/apps/details?id=free.programming.programming) [![AppStore Button](https://media.geeksforgeeks.org/auth-dashboard-uploads/appstore.svg)](https://apps.apple.com/in/app/geeksforgeeks-learn-coding/id1641848816)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/", "content": "# Apriori Algorithm\n\nApriori Algorithm is a basic method used in data analysis to find groups of items that often appear together in large sets of data. It helps to discover useful patterns or rules about how items are related which is particularly valuable in market basket analysis.\n\n> Like in a grocery store if many customers buy bread and butter together, the store can use this information to place these items closer or create special offers. This helps the store sell more and make customers happy.\n\n## How the Apriori Algorithm Works?\n\nThe Apriori Algorithm operates through a systematic process that involves several key steps:\n\n### 1. Identifying Frequent Item-Sets\n\n- The Apriori algorithm starts by looking through all the data to count how many times each single item appears. These single items are called 1-Item-Sets.\n- Next it uses a rule called minimum support this is a number that tells us how often an item or group of items needs to appear to be important. If an item appears often enough meaning its count is above this minimum support it is called a frequent Item-Set.\n\n### 2. Creating Possible Item Group\n\n- After finding the single items that appear often enough (frequent 1-item groups) the algorithm combines them to create pairs of items (2-item groups). Then it checks which pairs are frequent by seeing if they appear enough times in the data.\n- This process keeps going step by step making groups of 3 items, then 4 items and so on. The algorithm stops when it can't find any bigger groups that happen often enough.\n\n### 3. Removing Infrequent Item Groups\n\n- The Apriori algorithm uses a helpful rule to save time. This rule says: if a group of items does not appear often enough then any larger group that includes these items will also not appear often.\n- Because of this, the algorithm does not check those larger groups. This way it avoids wasting time looking at groups that won't be important make the whole process faster.\n\n### 4. Generating Association Rules\n\n- The algorithm makes rules to show how items are related.\n- It checks these rules using support, confidence and lift to find the strongest ones.\n\n## Key Metrics of Apriori Algorithm\n\n- **Support**: This metric measures how frequently an item appears in the dataset relative to the total number of transactions. A higher support indicates a more significant presence of the Item-Set in the dataset. Support tells us how often a particular item or combination of items appears in all the transactions like Bread is bought in 20% of all transactions.\n- **Confidence**: Confidence assesses the likelihood that an item Y is purchased when item X is purchased. It provides insight into the strength of the association between two items. Confidence tells us how often items go together i.e If bread is bought, butter is bought 75% of the time.\n- **Lift**: Lift evaluates how much more likely two items are to be purchased together compared to being purchased independently. A lift greater than 1 suggests a strong positive association. Lift shows how strong the connection is between items. Like Bread and butter are much more likely to be bought together than by chance.\n\nLets understand the concept of apriori Algorithm with the help of an example. Consider the following dataset and we will find frequent Item-Sets and generate association rules for them:\n\n![Transactions of a Grocery Shop](https://media.geeksforgeeks.org/wp-content/uploads/20250107120257362837/Screenshot-2025-01-07-120244.png)\n\n### Step 1 : Setting the parameters\n\n- **Minimum Support Threshold:** 50% (item must appear in at least 3/5 transactions). This threshold is formulated from this formula:\n\n$$\\text{Support}(A) = \\frac{\\text{Number of transactions containing itemset } A}{\\text{Total number of transactions}}$$\n\n- **Minimum Confidence Threshold:** 70% ( You can change the value of parameters as per the use case and problem statement ). This threshold is formulated from this formula:\n\n$$\\text{Confidence}(X \\rightarrow Y) = \\frac{\\text{Support}(X \\cup Y)}{\\text{Support}(X)}$$\n\n### Step 2: Find Frequent 1-Item-Sets\n\nLets count how many transactions include each item in the dataset (calculating the frequency of each item).\n\n![Frequent 1-Itemsets](https://media.geeksforgeeks.org/wp-content/uploads/20250107120713435589/Screenshot-2025-01-07-120700.png)\n\nAll items have support% ≥ 50%, so they qualify as frequent 1-Item-Sets. if any item has support% < 50%, It will be omitted out from the frequent 1- Item-Sets.\n\n### Step 3: Generate Candidate 2-Item-Sets\n\nCombine the frequent 1-Item-Sets into pairs and calculate their support. For this use case we will get 3 item pairs ( bread,butter) , (bread,milk) and (butter,milk) and will calculate the support similar to step 2\n\n![Candidate 2-Itemsets](https://media.geeksforgeeks.org/wp-content/uploads/20250405170247560988/freq-1.png)\n\n**Frequent 2-Item-Sets:** {Bread, Milk} meet the 50% threshold but {Butter, Milk} and {Bread ,Butter} doesn't meet the threshold, so will be committed out.\n\n### Step 4: Generate Candidate 3-Item-Sets\n\nCombine the frequent 2-Item-Sets into groups of 3 and calculate their support. for the triplet we have only got one case i.e {bread,butter,milk} and we will calculate the support.\n\n![Candidate 3-Itemsets](https://media.geeksforgeeks.org/wp-content/uploads/20250405220128027871/Screenshot-2025-04-05-220010.png)\n\nSince this does not meet the 50% threshold, there are no frequent 3-Item-Sets.\n\n### Step 5: Generate Association Rules\n\nNow we generate rules from the frequent Item-Sets and calculate confidence.\n\n#### Rule 1: If Bread → Butter (if customer buys bread, the customer will buy butter also)\n\n- Support of {Bread, Butter} = 2.\n- Support of {Bread} = 4.\n- Confidence = 2/4 = 50% (Failed threshold).\n\n#### Rule 2: If Butter → Bread (if customer buys butter, the customer will buy bread also)\n\n- Support of {Bread, Butter} = 3.\n- Support of {Butter} = 3.\n- Confidence = 3/3 = 100% (Passes threshold).\n\n#### Rule 3: If Bread → Milk (if customer buys bread, the customer will buy milk also)\n\n- Support of {Bread, Milk} = 3.\n- Support of {Bread} = 4.\n- Confidence = 3/4 = 75% (Passes threshold).\n\nThe Apriori Algorithm, as demonstrated in the bread-butter example, is widely used in modern startups like Zomato, Swiggy and other food delivery platforms. These companies use it to perform [market basket analysis](https://www.geeksforgeeks.org/data-science/market-basket-analysis-in-data-mining/) which helps them identify customer behaviour patterns and optimise recommendations.\n\n## Applications of Apriori Algorithm\n\nBelow are some applications of Apriori algorithm used in today's companies and startups\n\n1. **E-commerce:** Used to recommend products that are often bought together like laptop + laptop bag, increasing sales.\n2. **Food Delivery Services:** Identifies popular combos such as burger + fries to offer combo deals to customers.\n3. **Streaming Services:** Recommends related movies or shows based on what users often watch together like action + superhero movies.\n4. **Financial Services:** Analyzes spending habits to suggest personalised offers such as credit card deals based on frequent purchases.\n5. **Travel & Hospitality:** Creates travel packages like flight + hotel by finding commonly purchased services together.\n6. **Health & Fitness:** Suggests workout plans or supplements based on users past activities like protein shakes + workouts.\n\n### Related Articles:\n\n- [Apriori algorithm in Python](https://www.geeksforgeeks.org/machine-learning/implementing-apriori-algorithm-in-python/)"}
{"reference": "https://www.geeksforgeeks.org/courses/ds-16", "content": "# Complete Machine Learning & Data Science - Skill Up\n\nSelf-Paced Course\n\n**Complete Machine Learning & Data Science Program** - **With Python, Deep Learning** is a structured, hands-on program designed to help learners build a solid foundation and expertise in the data science field. Covering everything from programming in Python to advanced deep learning techniques and reinforcement learning, this course provides end-to-end knowledge for aspiring data science students.\n\n**Duration:** 16 Weeks\n\n**Interested:** 41k+ Geeks\n\n## Course Overview\n\nStart your journey in data science and machine learning with the **GeeksforGeeks Skill Up Program for** **Complete Machine Learning & Data Science**. This 16-week intensive course combines theory, coding, and hands-on practice to take you through all critical areas of modern data science.\n\nThe course kicks off with a solid foundation in Python, statistics, and exploratory data analysis, then builds up to machine learning, deep learning, and model deployment. Also gain experience with libraries like Pandas, NumPy, Matplotlib, Scikit-learn, TensorFlow, Keras, PyTorch, and more.\n\nFrom building predictive models to deploying them using Streamlit and Flask, this course offers everything needed to become a confident and capable data scientist.\n\n### Complete Machine Learning & Data Science - Highlights\n\n* Master Python programming from scratch\n* Dive deep into statistics and probability for data science\n* Perform exploratory data analysis using Pandas and NumPy\n* Learn data visualization using Matplotlib, Seaborn, and Plotly\n* Build, evaluate, deploy and optimize machine learning models\n* Hands-on projects using real-world datasets\n* Advanced deep learning with CNN, RNN, Transformers, GANs\n* Introduction to Reinforcement Learning and real-world use cases\n* Deploy ML models using Streamlit and Flask\n\n## Course Content\n\n### Week 0: Data Science Overview\n* What is Data Science and its Overview\n\n### Week 1: Getting Started with Python\n* Installing Python and setting up the environment\n* Input/Output, Variables, Keywords\n* Data Types, Operators, Conditional Statements\n* Loops and Functions\n* Strings, Lists, Dictionaries, Tuples, Sets\n* Python Collections and Comprehensions\n* Error Handling, File Handling, Advanced Python (Generators, Decorators)\n\n### Week 2: Statistics for Data Science\n* Descriptive Statistics, Bayes' Theorem\n* Covariance, Correlation, Distributions (Normal, Binomial, Poisson)\n* Inferential Statistics: Hypothesis Testing\n* Z-test, T-test, Chi-Square, ANOVA\n* Confidence Intervals, A/B Testing, MANOVA\n* Feature selection with ANOVA, Chi-Square\n\n### Week 3: Exploratory Data Analysis (EDA)\n* NumPy for numerical analysis\n* Data Analysis with Pandas\n* Handling Missing & Duplicate Data\n* Groupby Operations, Outlier Handling\n* Correlation Matrix, Time Series Visualization\n* Hands-on Contest Problems with Pandas and NumPy"}
{"reference": "https://www.geeksforgeeks.org/videos/category/c/", "content": "# C Videos\n\n## Program to Find the Sum of All Digits of a Number\n**Duration:** 10:14  \n**Views:** 68.2K | 11/01/2025  \n**Tags:** CPP, Maths, C++, C++ Programs  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/cpp-program-to-find-the-sum-of-all-digits-of-a-number/)\n\n## Graham Scan Algorithm\n**Duration:** 10:37  \n**Views:** 22.9K | 09/01/2025  \n**Tags:** CPP, Maths, C++  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/graham-scan-algorithm/)\n\n## Primality Test (Introduction and School Method)\n**Duration:** 03:53  \n**Views:** 16.9K | 08/01/2025  \n**Tags:** CPP, prime numbers  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/primality-test-introduction-and-school-method/)\n\n## C++ Program to Find Roots of a Quadratic Equation\n**Duration:** 04:41  \n**Views:** 9.7K | 08/01/2025  \n**Tags:** CPP, Maths, C++ Programs  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/cpp-program-to-find-roots-of-a-quadratic-equation/)\n\n## C++ Program on Multiplication of Two Matrices\n**Duration:** 08:23  \n**Views:** 6.0K | 03/01/2025  \n**Tags:** CPP, Basics of CPP, matrix, CPP Programs  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/cpp-program-on-multiplication-of-two-matrices/)\n\n## JavaScript Program to Check if Two Strings are Anagrams\n**Duration:** 08:00  \n**Views:** 3.8K | 03/01/2025  \n**Tags:** CPP, Basics of CPP, C++ Programs, anagram, CPP Programs  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/cpp-program-to-check-if-two-strings-are-anagrams/)\n\n## Assignment Operators in C++\n**Duration:** 01:59  \n**Views:** 1.6K | 20/12/2024  \n**Tags:** CPP, C++  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/assignment-operators-in-c/)\n\n## C++ Program to Return Maximum occurring Character in an Input String\n**Duration:** 03:36  \n**Views:** 3.0K | 16/08/2024  \n**Tags:** CPP, C++, Basics of CPP, C++ Programs, String, CPP Programs  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/cpp-program-to-return-maximum-occurring-character-in-an-input-string/)\n\n## C++ Program to Find GCD\n**Duration:** 03:12  \n**Views:** 109.9K | 18/07/2024  \n**Tags:** CPP, Maths, Basics of CPP, CPP Programs  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/c-program-to-find-gcd/)\n\n## C++ Program to Calculate Power of a Number\n**Duration:** 10:49  \n**Views:** 43.4K | 17/07/2024  \n**Tags:** CPP, Maths, C++ Programs, maths-power  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/c-program-to-calculate-power-of-a-number/)\n\n## JavaScript Program to Find the Factorial of a Number\n**Duration:** 04:45  \n**Views:** 57.4K | 12/07/2024  \n**Tags:** CPP, C++ Programs, factorial  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/c-program-to-find-factorial-of-a-number/)\n\n## Pangram Checking\n**Duration:** 06:01  \n**Views:** 17.5K | 12/07/2024  \n**Tags:** CPP, Basics of CPP, CPP Programs  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/pangram-checking/)\n\n*Showing 1 of 22 videos*"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/100-days-of-machine-learning/", "content": "# 100 Days of Machine Learning - A Complete Guide For Beginners\n\nMachine learning is a rapidly growing field within the broader domain of **Artificial Intelligence**. It involves developing algorithms that can automatically learn patterns and insights from data without being explicitly programmed. Machine learning has become increasingly popular in recent years as businesses have discovered its potential to drive innovation, improve decision-making, and gain a competitive advantage.\n\n## ML in the Job Industry\n\nIf you're interested in pursuing a career in machine learning, you may be wondering about the salary and career options available to you. Machine learning professionals are in **high demand** and can earn **competitive salaries**. According to Glassdoor, the average base pay for a machine learning engineer in the United States is around **$114,000 per year**, with some earning well over **$150,000 per year**. The field also offers a variety of career paths, including roles such as **Data Scientist**, **Machine Learning Engineer**, and **AI researcher**.\n\nWhen it comes to finding a job in machine learning, some companies are more actively hiring than others. Some of the top companies in this field include **Google, Microsoft, Amazon, IBM,** and **Facebook**. These companies are known for their innovative use of machine learning and AI and offer exciting opportunities for those looking to advance their careers.\n\nWhether you're just starting to explore machine learning or you're already well-versed in the subject, there are many resources available to help you learn and grow in this exciting field. This guide is intended to serve as a roadmap for your journey, providing an overview of the basics and pointing you in the direction of more advanced topics and resources.\n\n## Day 1 - 10: Linear Algebra\n\nThe first 10 days of your Machine Learning journey should focus on understanding the basics of Linear Algebra. You should start by learning about the different **types of Linear equations, matrices, mathematical operations,** and their applications. You should also familiarize yourself with the key concepts and terminologies used in Linear algebra. Here are the key topics to be covered in Linear Algebra:\n\n- [System of Linear Equation](https://www.geeksforgeeks.org/engineering-mathematics/system-linear-equations/)\n- [Matrix Operation](https://www.geeksforgeeks.org/engineering-mathematics/matrices/)\n  - [Addition, Multiplication, and Division](https://www.geeksforgeeks.org/python/python-program-multiply-two-matrices/)\n  - [Inverse](https://www.geeksforgeeks.org/python/compute-the-inverse-of-a-matrix-using-numpy/)\n  - [Transpose](https://www.geeksforgeeks.org/python/transpose-matrix-single-line-python/)\n- [Properties of Matrix](https://www.geeksforgeeks.org/maths/matrix-addition/)\n- [Solving Linear Equations using Gaussian Elimination](https://www.geeksforgeeks.org/dsa/gaussian-elimination/)\n- [LU Decomposition of Linear Equation](https://www.geeksforgeeks.org/engineering-mathematics/l-u-decomposition-system-linear-equations/)\n- [Row Echelon Form](https://www.geeksforgeeks.org/machine-learning/row-echelon-form/)\n- [Determinant](https://www.geeksforgeeks.org/dsa/determinant-of-a-matrix/)\n- [Eigenvalues and Eigenvectors](https://www.geeksforgeeks.org/engineering-mathematics/eigen-values/)\n- [Eigenspace](https://www.geeksforgeeks.org/dsa/eigenspace-and-eigenspectrum-values-in-a-matrix/)\n- [Orthogonal and Orthonormal Vectors](https://www.geeksforgeeks.org/dsa/orthogonal-and-orthonormal-vectors-in-linear-algebra/)\n- [Eigen Decomposition](https://www.geeksforgeeks.org/machine-learning/singular-value-decomposition/)\n- [Diagonalization](https://www.geeksforgeeks.org/dsa/matrix-diagonalization/)\n- [Singular Value Decomposition](https://www.geeksforgeeks.org/machine-learning/singular-value-decomposition/) — [Implementation](https://www.geeksforgeeks.org/numpy/compute-the-factor-of-a-given-array-by-singular-value-decomposition-using-numpy/)\n- Matrix Approximation\n- [Vector Operations](https://www.geeksforgeeks.org/maths/dot-and-cross-products-on-vectors/)\n- Differentiation\n- Minima and Maxima\n- Area Under Curve\n\n## Day 11 - 20: Statistics\n\nAfter a decent understanding of linear algebra and its operations, it's time to move forward one step ahead with Statistics in order to deal with data. Having good knowledge of Stats will eventually help in Data analysis, modeling, and evaluation in your journey of machine learning. There are numerous applications of statistics in machine learning such as Data exploration and preprocessing, Feature selection, Model selection and evaluation, uncertainty estimation, etc. So let's dive into the core of statistics:\n\n- [Mean, Standard Deviation, and Variance](https://www.geeksforgeeks.org/maths/mathematics-mean-variance-and-standard-deviation/) — [Implementation](https://www.geeksforgeeks.org/data-science/calculate-the-average-variance-and-standard-deviation-in-python-using-numpy/)\n- [Descriptive Statistics](https://www.geeksforgeeks.org/data-science/descriptive-statistic/)\n- [Descriptive and Inferential Statistics](https://www.geeksforgeeks.org/engineering-mathematics/difference-between-descriptive-and-inferential-statistics/)\n- [Probability Theory and Distribution](https://www.geeksforgeeks.org/maths/probability-distribution/)\n  - Normal Distribution\n  - Binomial Distribution\n  - Uniform Distribution\n- Types of Sampling Distribution\n  - Degrees of Freedom\n  - Z-Test\n  - t-Test\n  - Chi-Square Test\n- [Linear Regression](https://www.geeksforgeeks.org/machine-learning/linear-regression-python-implementation/)\n- [Sample Error and True Error](https://www.geeksforgeeks.org/data-science/true-error-vs-sample-error/)\n- [Bias Vs Variance](https://www.geeksforgeeks.org/machine-learning/bias-vs-variance-in-machine-learning/) and [Its Trade-Off](https://www.geeksforgeeks.org/machine-learning/ml-bias-variance-trade-off/)\n- [Hypothesis Testing](https://www.geeksforgeeks.org/software-testing/understanding-hypothesis-testing/)\n- [Confidence Intervals](https://www.geeksforgeeks.org/dsa/confidence-interval/)\n- [Correlation and Covariance](https://www.geeksforgeeks.org/engineering-mathematics/mathematics-covariance-and-correlation/)\n- [Correlation Coefficient](https://www.geeksforgeeks.org/dsa/program-find-correlation-coefficient/)\n- [Covariance Matrix](https://www.geeksforgeeks.org/python/compute-the-covariance-matrix-of-two-given-numpy-arrays/)\n- [Pearson Correlation](https://www.geeksforgeeks.org/python/python-pearson-correlation-test-between-two-variables/)\n- [Spearman’s Rank Correlation Measure](https://www.geeksforgeeks.org/data-science/spearmans-rank-correlation/)\n- [Kendall Rank Correlation Measure](https://www.geeksforgeeks.org/python/python-kendall-rank-correlation-coefficient/)\n- [Robust Correlations](https://www.geeksforgeeks.org/machine-learning/robust-correlation/)\n- Maximum Likelihood Estimation\n\n## Day 21 - 27 Python Programming\n\nFor the implementation of machine learning techniques, one needs to know a language that the device can understand and here Python comes to play. Whenever there is a need of selecting a language for programming, the first language that pops out is PYTHON. It can be used in Machine Learning in several ways such as Data preprocessing and manipulation, building ML models, Data visualization, etc.\n\nTo learn Python programming, you should have the knowledge of the following topics:\n\n- Python Basics\n  - [Data Types](https://www.geeksforgeeks.org/python/python-data-types/)\n  - [Expressions](https://www.geeksforgeeks.org/computer-science-fundamentals/expressions-in-python/)\n  - [Variables](https://www.geeksforgeeks.org/python/global-local-variables-python/)\n  - [String Methods](https://www.geeksforgeeks.org/python/python-string-methods/)\n- Python Data Structures\n  - [List and Tuple](https://www.geeksforgeeks.org/python/python-list-vs-array-vs-tuple/)\n  - [Set](https://www.geeksforgeeks.org/python/python-sets/)\n  - [Dictionary](https://www.geeksforgeeks.org/python/python-dictionary/)\n- Python Programming Fundamentals\n  - [Conditional Statements](https://www.geeksforgeeks.org/python/python3-if-if-else-nested-if-if-elif-statements/)\n  - [Looping Statements](https://www.geeksforgeeks.org/python/looping-techniques-python/)\n  - [Functions](https://www.geeksforgeeks.org/python/python-functions/)\n    - [User Defined Functions](https://www.geeksforgeeks.org/python/python-user-defined-functions/)\n    - [Built-In Functions](https://www.geeksforgeeks.org/python/python-built-in-functions/)\n  - [Objects and Classes](https://www.geeksforgeeks.org/python/python-classes-and-objects/)\n- Working with Data in Python\n  - [Reading Files With Python](https://www.geeksforgeeks.org/python/how-to-read-from-a-file-in-python/)\n  - [Writing to a file in Python](https://www.geeksforgeeks.org/python/writing-to-file-in-python/)\n  - [Pandas for Data Handling](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/)\n  - [NumPy Arrays for Loading Data](https://www.geeksforgeeks.org/python/how-to-read-a-numerical-data-or-file-in-python-with-numpy/)\n\n> You can also explore the some of the best courses to learn Python and Machine Learning\n>\n> - [Python Programming - Self Paced Course](https://www.geeksforgeeks.org/courses/master-python-complete-beginner-to-advanced?utm_campaign=256_100_days_of_machine_learning&utm_medium=gfgcontent_cp&utm_source=geeksforgeeks)\n> - [Complete Machine Learning and Data Science Program](https://www.geeksforgeeks.org/courses/data-science-live?utm_campaign=405_100_days_of_machine_learning&utm_medium=gfgcontent_cp&utm_source=geeksforgeeks)\n\n## Day 28 - 45: Data Preprocessing and Visualization\n\nIt is imperative to comprehend the significance of Data preprocessing and visualization. These procedures aid in readying your data for analysis and detecting patterns and trends that can be instrumental in shaping your models. It is advisable to acquaint yourself with techniques such as **Data cleansing**, **Data normalization**, and **Data transformation**. Additionally, learning how to use visualization tools such as **Matplotlib** and **Seaborn** to represent your data and gain valuable insights from it is crucial.\n\n### Libraries for Data Handling and Visualization in Python\n\n- [NumPy](https://www.geeksforgeeks.org/numpy/python-numpy/)\n- [Pandas](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/)\n- [Matplotlib](https://www.geeksforgeeks.org/python/python-introduction-matplotlib/)\n- [Seaborn](https://www.geeksforgeeks.org/python/python-seaborn-tutorial/)\n\n### Data Preprocessing:\n\n- [Introduction to Data Preprocessing](https://www.geeksforgeeks.org/dbms/data-preprocessing-in-data-mining/)\n- [Data Cleaning](https://www.geeksforgeeks.org/data-analysis/what-is-data-scrubbing/)\n- [Missing Values](https://www.geeksforgeeks.org/machine-learning/ml-handling-missing-values/)\n- [Inconsistent Data](https://www.geeksforgeeks.org/machine-learning/difference-between-data-cleaning-and-data-processing/)\n- [Data Transformation](https://www.geeksforgeeks.org/dbms/data-transformation-in-data-mining/)\n- [Data Reduction](https://www.geeksforgeeks.org/dbms/data-reduction-in-data-mining/)\n  - [Principal Components Analysis](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)\n  - [Bar Graphs and Histograms](https://www.geeksforgeeks.org/maths/bar-graphs-and-histograms/)\n  - [Under Sampling and Over Sampling](https://www.geeksforgeeks.org/machine-learning/how-to-handle-imbalanced-classes-in-machine-learning/)\n- [Feature extraction](https://www.geeksforgeeks.org/data-analysis/feature-extraction-in-data-mining/)\n- [Feature Transformation](https://www.geeksforgeeks.org/machine-learning/feature-transformation-techniques-in-machine-learning/)\n- [Feature Selection](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/)\n\n### Data Visualization:\n\n- [Introduction to data visualization](https://www.geeksforgeeks.org/data-visualization/data-visualization-and-its-importance/)\n- [Exploratory Data Analysis](https://www.geeksforgeeks.org/data-analysis/what-is-exploratory-data-analysis/)\n- [Descriptive Statistical Analysis](https://www.geeksforgeeks.org/data-science/descriptive-statistic/)\n- [Data Visualization with Different Charts](https://www.geeksforgeeks.org/data-science/data-visualization-different-charts-python/)\n- Visualization using Matplotlib\n  - [Line plots](https://www.geeksforgeeks.org/python/line-chart-in-matplotlib-python/)\n  - [Scatter Plots](https://www.geeksforgeeks.org/python/matplotlib-pyplot-scatter-in-python/)\n  - [Bar Plots](https://www.geeksforgeeks.org/pandas/bar-plot-in-matplotlib/)\n  - [Pie Charts](https://www.geeksforgeeks.org/data-science/plot-a-pie-chart-in-python-using-matplotlib/)\n  - [Donut Chart](https://www.geeksforgeeks.org/python/donut-chart-using-matplotlib-in-python/)\n  - [Gantt Chart](https://www.geeksforgeeks.org/python/python-basic-gantt-chart-using-matplotlib/)\n  - [Error Bar Graph](https://www.geeksforgeeks.org/python/errorbar-graph-in-python-using-matplotlib/)\n- Advanced visualization using Matplotlib\n  - [stacked plots](https://www.geeksforgeeks.org/python/create-a-stacked-bar-plot-in-matplotlib/)\n  - [area plots](https://www.geeksforgeeks.org/python/how-to-create-stacked-area-plot-using-plotly-in-python/)\n  - [3D plots](https://www.geeksforgeeks.org/python/introduction-to-3d-plotting-with-matplotlib/)\n  - [Boxplots](https://www.geeksforgeeks.org/r-language/boxplots-in-r-language/)\n- [Visualization using Seaborn](https://www.geeksforgeeks.org/data-visualization/data-visualization-with-python-seaborn/)\n  - [heatmaps](https://www.geeksforgeeks.org/python/seaborn-heatmap-a-comprehensive-guide/)\n  - [pair plots](https://www.geeksforgeeks.org/data-visualization/python-seaborn-pairplot-method/)\n  - [swarm plots](https://www.geeksforgeeks.org/python/swarmplot-using-seaborn-in-python/)\n  - [Point plot](https://www.geeksforgeeks.org/python/python-seaborn-pointplot-method/)\n  - [Count plot](https://www.geeksforgeeks.org/python/countplot-using-seaborn-in-python/)\n  - [Violin plot](https://www.geeksforgeeks.org/python/violinplot-using-seaborn-in-python/)\n  - [KDE Plot](https://www.geeksforgeeks.org/data-science/seaborn-kdeplot-a-comprehensive-guide/)\n\nIn conclusion, data preprocessing and visualization are crucial steps in the machine learning pipeline, and days 28-45 of the \"100 days of Machine Learning\" challenge focus on these fundamental topics. Preprocessing helps in preparing data for analysis by handling missing values, outliers, and duplicates, normalizing data through scaling and standardization, and transforming data by encoding categorical variables, selecting features, and reducing dimensionality. Visualization, on the other hand, helps in gaining insights from data by representing it through charts and graphs, and tools such as Matplotlib and Seaborn can be used to create a variety of visualizations. By mastering these techniques, learners can gain a solid foundation in data preprocessing and visualization, which will help them in their future machine-learning projects.\n\n## Day 46 - 76: Introduction to Machine Learning and its Algorithms\n\nThe next few days of your machine learning journey should focus on understanding the **basics of machine learning**. You should start by learning about the different **types of machine learning** and their applications. You should also familiarize yourself with the key concepts and terminologies used in machine learning. After that, it is time to delve into the realm of algorithms. There exist several **machine learning algorithms** to opt from, and the selection of an **algorithm** hinges on the nature of the problem you seek to resolve.  \nHere are the key topics to be covered in the Introduction to Machine Learning and its Algorithms:\n\n- [What is Machine Learning?](https://www.geeksforgeeks.org/machine-learning/ml-machine-learning/)\n- [Types of Machine Learning](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/)\n  - [Differences between supervised learning, unsupervised learning](https://www.geeksforgeeks.org/machine-learning/difference-between-supervised-and-unsupervised-learning/)\n  - [Reinforcement learning](https://www.geeksforgeeks.org/machine-learning/what-is-reinforcement-learning/)\n- [ML – Applications](https://www.geeksforgeeks.org/machine-learning/machine-learning-introduction/)\n- [Getting Started with Classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/)\n- [Basic Concept of Classification](https://www.geeksforgeeks.org/machine-learning/basic-concept-classification-data-mining/)\n- [Types of Regression Techniques](https://www.geeksforgeeks.org/machine-learning/types-of-regression-techniques/)\n- [Classification vs Regression](https://www.geeksforgeeks.org/machine-learning/ml-classification-vs-regression/)\n- [ML | Types of Learning – Supervised Learning](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/)\n- [Multiclass classification using scikit-learn](https://www.geeksforgeeks.org/machine-learning/multiclass-classification-using-scikit-learn/)\n- Gradient Descent:\n  - [Gradient Descent algorithm and its variants](https://www.geeksforgeeks.org/machine-learning/gradient-descent-algorithm-and-its-variants/)\n  - [Stochastic Gradient Descent (SGD)](https://www.geeksforgeeks.org/machine-learning/ml-stochastic-gradient-descent-sgd/)\n  - [Mini-Batch Gradient Descent with Python](https://www.geeksforgeeks.org/machine-learning/ml-mini-batch-gradient-descent-with-python/)\n  - [Optimization Techniques for Gradient Descent](https://www.geeksforgeeks.org/dsa/optimization-techniques-for-gradient-descent/)\n  - [Introduction to Momentum-based Gradient Optimizer](https://www.geeksforgeeks.org/machine-learning/ml-momentum-based-gradient-optimizer-introduction/)\n- **Linear Regression**\n  - [Introduction to Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/)\n  - [Gradient Descent in Linear Regression](https://www.geeksforgeeks.org/machine-learning/gradient-descent-in-linear-regression/)\n  - [Mathematical explanation for Linear Regression working](https://www.geeksforgeeks.org/machine-learning/mathematical-explanation-for-linear-regression-working/)\n  - [Normal Equation in Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-normal-equation-in-linear-regression/)\n  - [Linear Regression (Python Implementation)](https://www.geeksforgeeks.org/machine-learning/linear-regression-python-implementation/)\n  - [Univariate Linear Regression in Python](https://www.geeksforgeeks.org/python/univariate-linear-regression-in-python/)\n  - [Multiple Linear Regression using Python](https://www.geeksforgeeks.org/machine-learning/ml-multiple-linear-regression-using-python/)\n  - [Locally weighted Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-locally-weighted-linear-regression/)\n  - [Python | Linear Regression using sklearn](https://www.geeksforgeeks.org/machine-learning/python-linear-regression-using-sklearn/)\n- **Logistic Regression**\n  - [Understanding Logistic Regression](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/)\n  - [Why Logistic Regression in Classification?](https://www.geeksforgeeks.org/machine-learning/ml-why-logistic-regression-in-classification/)\n  - [Logistic Regression using Python](https://www.geeksforgeeks.org/machine-learning/ml-logistic-regression-using-python/)\n  - [Cost function in Logistic Regression](https://www.geeksforgeeks.org/machine-learning/ml-cost-function-in-logistic-regression/)\n  - [Logistic Regression using Tensorflow](https://www.geeksforgeeks.org/machine-learning/ml-logistic-regression-using-tensorflow/)\n- [Naive Bayes Classifiers](https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/)\n- **Support Vector Machine**\n  - [Support Vector Machines(SVMs) in Python](https://www.geeksforgeeks.org/machine-learning/classifying-data-using-support-vector-machinessvms-in-python/)\n  - [SVM Hyperparameter Tuning using GridSearchCV](https://www.geeksforgeeks.org/machine-learning/svm-hyperparameter-tuning-using-gridsearchcv-ml/)\n  - [Using SVM to perform classification on a non-linear dataset](https://www.geeksforgeeks.org/machine-learning/ml-using-svm-to-perform-classification-on-a-non-linear-dataset/)\n- **Decision Tree**\n  - [Decision Tree](https://www.geeksforgeeks.org/machine-learning/decision-tree/)\n  - [Decision Tree Regression using sklearn](https://www.geeksforgeeks.org/machine-learning/python-decision-tree-regression-using-sklearn/)\n  - [Decision tree implementation using Python](https://www.geeksforgeeks.org/machine-learning/decision-tree-implementation-python/)\n- **Random Forest**\n  - [Random Forest Regression in Python](https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/)\n  - [Ensemble Classifier](https://www.geeksforgeeks.org/machine-learning/ensemble-classifier-data-mining/)\n  - [Voting Classifier using Sklearn](https://www.geeksforgeeks.org/machine-learning/ml-voting-classifier-using-sklearn/)\n  - [Bagging classifier](https://www.geeksforgeeks.org/machine-learning/What-is-Bagging-classifier/)\n\n> For the complete Tutorial, refer to - [Machine Learning Tutorial](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\n\n## Day 77 - 84: Evaluation and Model Selection\n\nOnce you have trained your models, you need to evaluate their performance and select the best one for your problem.\n\n- [Bias Variance Trade-Off](https://www.geeksforgeeks.org/machine-learning/bias-vs-variance-in-machine-learning/)\n- [Model evaluation techniques](https://www.geeksforgeeks.org/machine-learning/machine-learning-model-evaluation/)\n- [Importance of Splitting the data into training, validation, and testing](https://www.geeksforgeeks.org/machine-learning/splitting-data-for-machine-learning-models/)\n- [Cross-validation techniques](https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/)\n- [ML Evaluation Metrics](https://www.geeksforgeeks.org/machine-learning/metrics-for-machine-learning-model/)\n- Classification Evaluation Metrics\n  - Accuracy Score\n  - [Precision, recall, and F1 score](https://www.geeksforgeeks.org/r-language/precision-recall-and-f1-score-using-r/)\n  - Confusion Matrix\n  - [ROC curve](https://www.geeksforgeeks.org/machine-learning/auc-roc-curve/)\n- Regression Evaluation Metrics\n  - Mean Absolute Error\n  - Mean Squared Error\n  - Mean Absolute Percentage Error\n  - R2 Score\n- [Hyperparameter tuning](https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning/)\n  - [GridSearchCV](https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning-using-gridsearchcv-and-kerasclassifier/)\n  - [RandomizedSearchCV](https://www.geeksforgeeks.org/machine-learning/comparing-randomized-search-and-grid-search-for-hyperparameter-estimation-in-scikit-learn/)\n\nIn conclusion, days 77-84 of the \"100 days of Machine Learning\" challenge focus on the crucial steps of evaluating and selecting the best model for a given problem. Evaluation is the process of measuring a model's performance using various metrics such as precision, recall, and F1 score, and techniques such as cross-validation and ROC curves can be used for this purpose. Model selection involves choosing the best model from a set of candidate models, and hyperparameter tuning can be used to optimize the performance of these models. Techniques such as GridSearchCV and RandomizedSearchCV can be used to automate the hyperparameter tuning process. By mastering these techniques, learners can develop the ability to evaluate and select the best model for a given problem, which is a crucial skill in the field of machine learning.\n\n## Day 85 - 94: ML Projects\n\nNow, it's time to get some hands-on experience with machine learning. So, here are some projects mentioned below that will help you to understand the functionality and practical implementation of machine learning techniques.\n\n### Regression-Based Projects\n\n- [Boston House Price Prediction](https://www.geeksforgeeks.org/machine-learning/ml-boston-housing-kaggle-challenge-with-linear-regression/)\n- [Waiter Tip Prediction](https://www.geeksforgeeks.org/machine-learning/waiters-tip-prediction-using-machine-learning/)\n- [Calories Burnt Prediction](https://www.geeksforgeeks.org/machine-learning/calories-burnt-prediction-using-machine-learning/)\n\n### Classification Based Projects\n\n- [Titanic Classification](https://www.geeksforgeeks.org/machine-learning/spaceship-titanic-project-using-machine-learning-python/)\n- [Breast Cancer Prediction](https://www.geeksforgeeks.org/machine-learning/ml-kaggle-breast-cancer-wisconsin-diagnosis-using-knn/)\n- [Diabetes Prediction](https://www.geeksforgeeks.org/videos/diabetes-prediction-in-machine-learning/)\n\n## Day 95 - 100: Introduction to Deep Learning\n\nDeep learning is a specialized area of machine learning that deploys neural networks to assimilate knowledge from data. Its impact has been transformative in numerous domains such as **computer vision**, **natural language processing**, and **speech recognition**. To gain a comprehensive understanding, it is advisable to study in the final days of your ML journey:\n\n- [Biological Neurons Vs Artificial Neurons](https://www.geeksforgeeks.org/machine-learning/difference-between-ann-and-bnn/)\n- [Single Layer Perceptron](https://www.geeksforgeeks.org/python/single-layer-perceptron-in-tensorflow/)\n- [Multi-Layer Perceptron](https://www.geeksforgeeks.org/deep-learning/multi-layer-perceptron-learning-in-tensorflow/)\n- [Forward and backward propagation](https://www.geeksforgeeks.org/python/deep-neural-net-with-forward-and-back-propagation-from-scratch-python/)\n- [Feed-forward neural networks](https://www.geeksforgeeks.org/machine-learning/understanding-multi-layer-feed-forward-networks/)\n- [Neural Network layers](https://www.geeksforgeeks.org/deep-learning/ml-list-of-deep-learning-layers/)\n- [Introduction to Activation Function](https://www.geeksforgeeks.org/engineering-mathematics/activation-functions/)\n- [Types Of Activation Function](https://www.geeksforgeeks.org/machine-learning/types-of-activation-function-in-ann/)\n- [Understanding Activation Functions in Depth](https://www.geeksforgeeks.org/python/understanding-activation-functions-in-depth/)\n- Cost function in Neural Networks\n- [How does Gradient Descent work](https://www.geeksforgeeks.org/python/gradient-descent-optimization-in-tensorflow/)\n- Vanishing or Exploding Gradients Problems\n- [Choose the optimal number of epochs](https://www.geeksforgeeks.org/deep-learning/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/)\n- [Fine-Tuning & Hyperparameters](https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning/)\n\n**Deep learning** utilizes neural networks to extract knowledge from data and has produced remarkable results in several complex tasks. To develop a comprehensive understanding of this area, learners need to study the architecture of neural networks. By mastering these concepts, learners can gain a solid foundation in deep learning and neural networks, which will enable them to work on exciting and challenging projects in this field.\n\n## Conclusion\n\nMachine learning is a rapidly growing field with immense potential to revolutionize almost everything around us. By grasping the fundamentals of machine learning, data preprocessing, and visualization, one can start creating their own machine learning models to tackle real-world situations and provide effective self-sustaining solutions for them. There are numerous algorithms available, from linear regression to deep learning, and selecting the appropriate one depends on the nature of the problem you are attempting to solve.\n\nIn conclusion, the journey of 100 days of Machine Learning will be an incredible learning experience. Through this process, one can gain a strong foundation in Machine Learning and its applications in various fields. The article covered several topics: Machine Learning, Data Preparation, Regression, Classification, Clustering, Natural Language Processing, and Deep Learning, etc.\n\nThe skills acquired during the 100 days of Machine Learning are valuable in today's world, where data is becoming increasingly important in decision-making processes across industries. By going through this article, you will take this important step towards being proficient in Machine Learning and are now better equipped to tackle complex problems in their respective fields. Overall, the 100 days of Machine Learning will be an excellent investment in terms of time and effort, and the you can expect to reap the rewards of their hard work for years to come."}
{"reference": "https://www.geeksforgeeks.org/python/single-layer-perceptron-in-tensorflow/", "content": "# Single Layer Perceptron in TensorFlow\n\n**Single Layer Perceptron** is inspired by biological neurons and their ability to process information. To understand the SLP we first need to break down the workings of a single artificial neuron which is the fundamental building block of neural networks. An **artificial neuron** is a simplified computational model that mimics the behavior of a biological neuron. It takes inputs, processes them and produces an output. Here's how it works step by step:\n\n- Receive signal from outside.\n- Process the signal and decide whether we need to send information or not.\n- Communicate the signal to the target cell, which can be another neuron or gland.\n\n![Structure of a biological neuron](https://media.geeksforgeeks.org/wp-content/uploads/20221219111342/Biological-Neuron-and-similarity-with-neural-network.png)\n\n*Structure of a biological neuron*\n\nSimilarly, neural networks also function in a similar manner.\n\n![Neural Network in Machine Learning](https://media.geeksforgeeks.org/wp-content/uploads/nodeNeural.jpg)\n\n*Neural Network in Machine Learning*\n\n## Single Layer Perceptron\n\nIt is one of the oldest and first introduced neural networks. It was proposed by **Frank Rosenblatt** in **1958**. Perceptron is also known as an artificial neural network. Perceptron is mainly used to compute the [logical gate](https://www.geeksforgeeks.org/physics/logic-gates/) like **AND, OR and NOR** which has binary input and binary output.\n\nThe main functionality of the perceptron is:\n\n- Takes input from the input layer\n- Weight them up and sum it up.\n- Pass the sum to the nonlinear function to produce the output.\n\n![Single-layer neural network](https://media.geeksforgeeks.org/wp-content/uploads/20221219111343/Single-Layer-Perceptron.png)\n\n*Single-layer neural network*\n\nHere activation functions can be anything like **sigmoid, tanh, relu** based on the requirement we will be choosing the most appropriate nonlinear [activation function](https://www.geeksforgeeks.org/machine-learning/activation-functions-neural-networks/) to produce the better result. Now let us implement a single-layer perceptron.\n\n## Implementation of Single-layer Perceptron\n\nLet's build a simple **single-layer perceptron** using **TensorFlow**. This model will help you understand how neural networks work at the most basic level.\n\n### Step 1: Import necessary libraries\n\n- **[Scikit-learn](https://www.geeksforgeeks.org/machine-learning/what-is-python-scikit-library/)** – Scikit-learn provides easy-to-use and efficient tools for data mining and machine learning, enabling quick implementation of algorithms for classification, regression, clustering, and more.\n- **[TensorFlow](https://www.geeksforgeeks.org/python/introduction-to-tensorflow/)** – This is an open-source library that is used for Machine Learning and Artificial intelligence and provides a range of functions to achieve complex functionalities with single lines of code.\n\n```python\nimport tensorflow as tf\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n```\n\n### Step 2: Create and split synthetic dataset\n\nWe will create a simple 2-feature synthetic binary-classification dataset for our demonstration and then split it into training and testing.\n\n```python\nX, y = make_classification(\n    n_samples=1000,\n    n_features=2,\n    n_informative=2,\n    n_redundant=0,\n    n_repeated=0,\n    n_classes=2,\n    random_state=42\n)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n\n### Step 3: Standardize the Dataset\n\nNow standardize the dataset to enable faster and more precise computations. [Standardization](https://www.geeksforgeeks.org/machine-learning/what-is-standardization-in-machine-learning/) helps the model converge more quickly and often enhances accuracy.\n\n```python\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n```\n\n### Step 4: Building a neural network\n\nNext, we build the single-layer model using a Sequential architecture with one Dense layer. The **Dense(1)** indicates that this layer contains a single neuron. We apply the sigmoid activation function, which maps the output to a value between 0 and 1, suitable for binary classification. The original perceptron used a step function that only gave 0 or 1 as output and trained differently. But modern models use sigmoid because it's smooth and helps the model learn better with gradient-based methods. The **input_shape=(2,)** specifies that each input sample consists of two features.\n\n```python\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(2,))\n])\n```\n\n### Step 5: Compile the Model\n\nNext, we compile the model using the Adam optimizer, which is a popular and efficient algorithm for optimizing neural networks. We use binary cross-entropy as the loss function, which is well-suited for binary classification tasks with sigmoid activation. Additionally, we track the model's performance using accuracy as the evaluation metric during training and testing.\n\n```python\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n```\n\n### Step 6: Train the Model\n\nNow, we train the model by iterating over the entire training dataset a specified number of times, called epochs. During training, the data is divided into smaller batches of samples, known as the batch size, which determines how many samples are processed before updating the model's weights. We also set aside a fraction of the training data as validation data to monitor the model's performance on unseen data during training.\n\n```python\nhistory = model.fit(X_train, y_train,\n                    epochs=50,\n                    batch_size=16,\n                    validation_split=0.1,\n                    verbose=0)\n```\n\n### Step 7: Model Evaluation\n\nAfter training we test the model's performance on unseen data.\n\n```python\nloss, accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test Accuracy: {accuracy:.2f}\")\n```\n\n**Output:**\n\n> **Test Accuracy: 0.88**\n\nEven with such a **simple model** we achieved close to **88% accuracy.** That's quite impressive for a neural network with just one layer. However for even better results we could add **hidden layers** or use more complex architectures like [CNNs (Convolutional Neural Networks)](https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/)."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/", "content": "# K means Clustering – Introduction\n\nK-Means Clustering is an unsupervised machine learning algorithm that helps group data points into clusters based on their inherent similarity. Unlike supervised learning, where we train models using labeled data, K-Means is used when we have data that is not labeled and the goal is to uncover hidden patterns or structures. For example, an online store can use K-Means to segment customers into groups like \"Budget Shoppers,\" \"Frequent Buyers,\" and \"Big Spenders\" based on their purchase history.\n\n## Working of K-Means Clustering\n\nSuppose we are given a data set of items with certain features and values for these features like a vector. The task is to categorize those items into groups. To achieve this we will use the K-means algorithm. \"k\" represents the number of groups or clusters we want to classify our items into.\n\nThe algorithm will categorize the items into \"k\" groups or clusters of similarity. To calculate that similarity we will use the [Euclidean distance](https://www.geeksforgeeks.org/maths/euclidean-distance/) as a measurement. The algorithm works as follows:\n\n1. **Initialization:** We begin by randomly selecting k cluster centroids.\n2. **Assignment Step:** Each data point is assigned to the nearest centroid, forming clusters.\n3. **Update Step:** After the assignment, we recalculate the centroid of each cluster by averaging the points within it.\n4. **Repeat:** This process repeats until the centroids no longer change or the maximum number of iterations is reached.\n\nThe goal is to partition the dataset into k clusters such that data points within each cluster are more similar to each other than to those in other clusters.\n\n> Selecting the right number of clusters is important for meaningful segmentation to do this we use [Elbow Method for optimal value of k in KMeans](https://www.geeksforgeeks.org/machine-learning/elbow-method-for-optimal-value-of-k-in-kmeans/) which is a graphical tool used to determine the optimal number of clusters (k) in K-means.\n\n## Why Use K-Means Clustering?\n\nK-Means is popular in a wide variety of applications due to its simplicity, efficiency and effectiveness. Here’s why it is widely used:\n\n1. **Data Segmentation:** One of the most common uses of K-Means is segmenting data into distinct groups. For example, businesses use K-Means to group customers based on behavior, such as purchasing patterns or website interaction.\n2. **Image Compression**: K-Means can be used to reduce the complexity of images by grouping similar pixels into clusters, effectively compressing the image. This is useful for image storage and processing.\n3. **Anomaly Detection:** K-Means can be applied to detect anomalies or outliers by identifying data points that do not belong to any of the clusters.\n4. **Document Clustering:** In natural language processing (NLP), K-Means is used to group similar documents or articles together. It’s often used in applications like recommendation systems or news categorization.\n5. **Organizing Large Datasets:** When dealing with large datasets, K-Means can help in organizing the data into smaller, more manageable chunks based on similarities, improving the efficiency of data analysis.\n\n## Implementation of K-Means Clustering\n\nWe will be using blobs datasets and show how clusters are made using [Python](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/) programming language.\n\n### Step 1: Importing the necessary libraries\n\nWe will be importing the following libraries.\n\n- [Numpy](https://www.geeksforgeeks.org/python/introduction-to-numpy/)**:** for numerical operations (e.g., distance calculation).\n- [Matplotlib](https://www.geeksforgeeks.org/python/matplotlib-tutorial/): for plotting data and results.\n- [Scikit learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/)**:** to create a synthetic dataset using **make_blobs**\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\n```\n\n### Step 2: Creating Custom Dataset\n\nWe will generate a synthetic dataset with make_blobs.\n\n- **make_blobs(n_samples=500, n_features=2, centers=3):** Generates 500 data points in a 2D space, grouped into 3 clusters.\n- **plt.scatter(X[:, 0], X[:, 1]):** Plots the dataset in 2D, showing all the points.\n- **plt.show():** Displays the plot\n\n```python\nX,y = make_blobs(n_samples = 500,n_features = 2,centers = 3,random_state = 23)\n\nfig = plt.figure(0)\nplt.grid(True)\nplt.scatter(X[:,0],X[:,1])\nplt.show()\n```\n\n![Clustering dataset - Geeksforgeeks](https://media.geeksforgeeks.org/wp-content/uploads/20230320171738/download-(25).png)\n\n*Clustering dataset*\n\n### Step 3: Initializing Random Centroids\n\nWe will randomly initialize the centroids for K-Means clustering\n\n- **np.random.seed(23):** Ensures reproducibility by fixing the random seed.\n- The for loop initializes k random centroids, with values between -2 and 2, for a 2D dataset.\n\n```python\nk = 3\n\nclusters = {}\nnp.random.seed(23)\n\nfor idx in range(k):\n    center = 2*(2*np.random.random((X.shape[1],))-1)\n    points = []\n    cluster = {\n        'center' : center,\n        'points' : []\n    }\n\nclusters[idx] = cluster\n\nclusters\n```\n\n![Screenshot-2025-05-08-120956](https://media.geeksforgeeks.org/wp-content/uploads/20250508120940807304/Screenshot-2025-05-08-120956.png)\n\n*Random Centroids*\n\n### Step 4: Plotting Random Initialized Center with Data Points\n\nWe will now plot the data points and the initial centroids.\n\n- **plt.grid()**: Plots a grid.\n- **plt.scatter(center[0], center[1], marker='*', c='red'):** Plots the cluster center as a red star (* marker).\n\n```python\nplt.scatter(X[:,0],X[:,1])\nplt.grid(True)\nfor i in clusters:\n    center = clusters[i]['center']\n    plt.scatter(center[0],center[1],marker = '*',c = 'red')\nplt.show()\n```\n\n![Data points with random center - Geeksforgeeks](https://media.geeksforgeeks.org/wp-content/uploads/20230320172346/download-(27).png)\n\n*Data points with random center*\n\n### Step 5: Defining Euclidean Distance\n\nTo assign data points to the nearest centroid, we define a distance function:\n\n- **np.sqrt():** Computes the square root of a number or array element-wise.\n- **np.sum():** Sums all elements in an array or along a specified axis\n\n```python\ndef distance(p1,p2):\n    return np.sqrt(np.sum((p1-p2)**2))\n```\n\n### Step 6: Creating Assign and Update Functions\n\nNext, we define functions to assign points to the nearest centroid and update the centroids based on the average of the points assigned to each cluster.\n\n- **dist.append(dis):** Appends the calculated distance to the list dist.\n- **curr_cluster = np.argmin(dist):** Finds the index of the closest cluster by selecting the minimum distance.\n- **new_center = points.mean(axis=0):** Calculates the new centroid by taking the mean of the points in the cluster.\n\n```python\ndef assign_clusters(X, clusters):\n    for idx in range(X.shape[0]):\n        dist = []\n\ncurr_x = X[idx]\n\nfor i in range(k):\n            dis = distance(curr_x,clusters[i]['center'])\n            dist.append(dis)\n        curr_cluster = np.argmin(dist)\n        clusters[curr_cluster]['points'].append(curr_x)\n    return clusters\n\ndef update_clusters(X, clusters):\n    for i in range(k):\n        points = np.array(clusters[i]['points'])\n        if points.shape[0] > 0:\n            new_center = points.mean(axis =0)\n            clusters[i]['center'] = new_center\n\n    clusters[i]['points'] = []\n    return clusters\n```\n\n### Step 7: Predicting the Cluster for the Data Points\n\nWe create a function to predict the cluster for each data point based on the final centroids.\n\n- **pred.append(np.argmin(dist)):** Appends the index of the closest cluster (the one with the minimum distance) to pred.\n\n```python\ndef pred_cluster(X, clusters):\n    pred = []\n    for i in range(X.shape[0]):\n        dist = []\n        for j in range(k):\n            dist.append(distance(X[i],clusters[j]['center']))\n        pred.append(np.argmin(dist))\n    return pred\n```\n\n### Step 8: Assigning, Updating and Predicting the Cluster Centers\n\nWe assign points to clusters, update the centroids and predict the final cluster labels.\n\n- **assign_clusters(X, clusters):** Assigns data points to the nearest centroids.\n- **update_clusters(X, clusters):** Recalculates the centroids.\n- **pred_cluster(X, clusters):** Predicts the final clusters for all data points.\n\n```python\nclusters = assign_clusters(X,clusters)\nclusters = update_clusters(X,clusters)\npred = pred_cluster(X,clusters)\n```\n\n### Step 9: Plotting Data Points with Predicted Cluster Centers\n\nFinally, we plot the data points, colored by their predicted clusters, along with the updated centroids.\n\n- **center = clusters[i]['center']:** Retrieves the center (centroid) of the current cluster.\n- **plt.scatter(center[0], center[1], marker='^', c='red'):** Plots the cluster center as a red triangle (^ marker).\n\n```python\nplt.scatter(X[:,0],X[:,1],c = pred)\nfor i in clusters:\n    center = clusters[i]['center']\n    plt.scatter(center[0],center[1],marker = '^',c = 'red')\nplt.show()\n```\n\n![K-means Clustering - Geeksforgeeks](https://media.geeksforgeeks.org/wp-content/uploads/20230320173915/download-(28).png)\n\n*K-means Clustering*\n\n## Challenges with K-Means Clustering\n\nK-Means algorithm has the following limitations:\n\n- **Choosing the Right Number of Clusters** (k): One of the biggest challenges is deciding how many clusters to use.\n- **Sensitive to Initial Centroids:** The final clusters can vary depending on the initial random placement of centroids.\n- **Non-Spherical Clusters:** K-Means assumes that the clusters are spherical and equally sized. This can be a problem when the actual clusters in the data are of different shapes or densities.\n- **Outliers**: K-Means is sensitive to outliers, which can distort the centroid and, ultimately, the clusters."}
{"reference": "https://www.geeksforgeeks.org/ai-ml-and-data-science-tutorial-learn-ai-ml-and-data-science/", "content": "# AI, ML and Data Science Tutorial\n\nThis article covers everything you need to learn about AI, ML and Data Science, starting with Python programming, statistics and probability. It also includes EDA, visualization, ML, deep learning, AI, projects and interview questions for career preparation.\n\n## 1. Learning Python\n\nPython is one of the most popular programming languages today, known for its simplicity, extensive features and library support. Its clean syntax makes it beginner-friendly, while its libraries and frameworks makes it perfect for developers.\n\n- [Python Tutorial](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/)\n- [Python Quizzes](https://www.geeksforgeeks.org/python/python-quizzes/)\n- [Python Interview Questions](https://www.geeksforgeeks.org/python/python-interview-questions/)\n\n## 2. Math For Data Science\n\nMath for Data Science is all about the fundamental mathematical tools and concepts you need to work effectively with data. It includes Statistics & Probability, Linear Algebra and Calculus.\n\n- [Linear Algebra for Data Science](https://www.geeksforgeeks.org/machine-learning/ml-linear-algebra-operations/)\n- [Statistics for Data Science](https://www.geeksforgeeks.org/data-science/statistics-for-data-science/)\n- [Probability for Data Science](https://www.geeksforgeeks.org/data-science/probability-data-distributions-in-data-science/)\n- [Calculus for Data Science](https://www.geeksforgeeks.org/machine-learning/mastering-calculus-for-machine-learning-key-concepts-and-applications/)\n- Practice [Linear Algebra](https://www.geeksforgeeks.org/quizzes/linear-algebra-gq/), [Statistics](https://www.geeksforgeeks.org/maths/statistics-questions/), [Probability](https://www.geeksforgeeks.org/quizzes/probability-gq/) and [Calculus](https://www.geeksforgeeks.org/quizzes/numerical-methods-and-calculus-gq/)\n\n## 3. Exploratory Data Analysis\n\nExploratory Data Analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often using visual methods. It involves understanding data, cleaning data, visualizing data and further analysis.\n\n- [Exploratory Data Analysis or EDA](https://www.geeksforgeeks.org/data-analysis/what-is-exploratory-data-analysis/)\n- [EDA with NumPy, Pandas, Matplotlib and Seaborn](https://www.geeksforgeeks.org/data-analysis/eda-with-NumPy-Pandas-Matplotlib-Seaborn/)\n\n## 4. Data Analysis\n\nData Analysis is the technique of collecting, transforming and organizing data to make future predictions and informed data-driven decisions. It also helps to find possible solutions for a business problem.  \nThere are six steps for Data Analysis which are: Ask or Specify Data Requirements, Prepare or Collect Data, Clean and Process, Analyze, Share, Act or Report.\n\n- [Data Analysis](https://www.geeksforgeeks.org/data-analysis/data-analysis-tutorial/)\n- [Data Analytics Projects](https://www.geeksforgeeks.org/quizzes/data-analysis-quiz/)\n- [Data Analysis Quiz](https://www.geeksforgeeks.org/quizzes/data-analysis-quiz/)\n- [Data Analytics Interview Questions](https://www.geeksforgeeks.org/data-science/data-analyst-interview-questions-and-answers/)\n\n## 5. Data Visualization\n\nData visualization is the process of turning data into visual representations like charts, graphs and maps. It helps us understand trends, patterns and outliers.\n\n- [Data Visualization Tutorial](https://www.geeksforgeeks.org/data-visualization/python-data-visualization-tutorial/)\n- [Data Visualization Projects](https://www.geeksforgeeks.org/data-visualization/data-visualization-project-ideas/)\n- [Data Visualization Quiz](https://www.geeksforgeeks.org/quizzes/advance-data-visualization-with-seaborn/)\n- [Data Visualization Interview Questions](https://www.geeksforgeeks.org/data-visualization/data-visualization-interview-questions/)\n\n## 6. Machine Learning\n\nMachine learning is a subset of Artificial Intelligence (AI) that enables computers to learn from data and make predictions without being explicitly programmed.\n\nIt can be categorized into three types: Supervised Learning, Unsupervised Learning and Reinforcement Learning.\n\n- [Machine Learning Tutorial](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\n- [Machine Learning Projects](https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/)\n- [Machine Learning Quiz](https://www.geeksforgeeks.org/quizzes/machine-learning-quiz-questions-and-answers/)\n- [Machine Learning Interview Questions](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n\n## 7. Data Science with Python\n\nData science enables organizations to make informed decisions, solve problems and understand human behavior. As the volume of data grows, so does the demand for skilled data scientists. The most common languages used for data science are Python and R, with Python being particularly popular.\n\n- [Data Science Tutorial](https://www.geeksforgeeks.org/data-science/data-science-with-python-tutorial/)\n- [Data Science Projects](https://www.geeksforgeeks.org/data-science/top-data-science-projects/)\n- [Data Science Quiz](https://www.geeksforgeeks.org/quizzes/data-science-quiz/)\n- [Data Science Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-interview-questions-and-answers/)\n\n## 8. Deep Learning\n\nDeep Learning is a branch of Artificial Intelligence (AI) that enables machines to learn from large amounts of data. It uses neural networks with many layers to automatically find patterns and make predictions.\n\n- [Deep Learning Tutorial](https://www.geeksforgeeks.org/deep-learning/deep-learning-tutorial/)\n- [Deep Learning Projects](https://www.geeksforgeeks.org/deep-learning/deep-learning-projects/)\n- [Deep Learning Quiz](https://www.geeksforgeeks.org/quizzes/introduction-to-deep-learning-and-neural-networks-1/)\n- [Deep Learning Interview Questions](https://www.geeksforgeeks.org/quizzes/introduction-to-deep-learning-and-neural-networks-1/)\n\n## 9. Artificial Intelligence\n\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and act like humans.\n\n- [AI Tutorial](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligence/)\n- [AI Interview Questions](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligenceai-interview-questions-and-answers/)\n- [AI Projects](https://www.geeksforgeeks.org/artificial-intelligence/best-artificial-intelligence-project-ideas/)\n\n## 10. Generative AI & LLM\n\nGenerative AI (Gen AI) is a branch of artificial intelligence that can create new content instead of just analyzing data. It uses machine learning models (like large language models, GANs, and diffusion models) to generate text, images, audio, code, or even video.\n\nLLM (Large Language Model) is a type of artificial intelligence model designed to understand and generate human-like language.\n\n- [Generative AI Tutorial](https://www.geeksforgeeks.org/artificial-intelligence/generative-ai-tutorial/)\n- [Generative AI Roadmap](https://www.geeksforgeeks.org/artificial-intelligence/roadmap-to-generative-ai-a-comprehensive-guide-for-beginners/)\n- [LLM Tutorial](https://www.geeksforgeeks.org/deep-learning/large-language-model-llm-tutorial/)\n\n## AI-ML-DS Interview Questions\n\nThe AI-ML-DS Interview Series is an essential resource designed for individuals aspiring to start or switch careers in the fields of Artificial Intelligence (AI), Machine Learning (ML) and Data Science (DS).\n\n- [AI-ML-DS Interview Series](https://www.geeksforgeeks.org/interview-experiences/ai-ml-ds-interview/)\n\n## Explore\n\n### Machine Learning Basics\n\n- [Introduction to Machine Learning](https://www.geeksforgeeks.org/machine-learning/introduction-machine-learning/)\n- [Types of Machine Learning](https://www.geeksforgeeks.org/machine-learning/types-of-machine-learning/)\n- [What is Machine Learning Pipeline?](https://www.geeksforgeeks.org/blogs/machine-learning-pipeline/)\n- [Applications of Machine Learning](https://www.geeksforgeeks.org/machine-learning/machine-learning-introduction/)\n\n### Python for Machine Learning\n\n- [Machine Learning with Python Tutorial](https://www.geeksforgeeks.org/machine-learning/machine-learning-with-python/)\n- [NumPy Tutorial - Python Library](https://www.geeksforgeeks.org/python/numpy-tutorial/)\n- [Pandas Tutorial](https://www.geeksforgeeks.org/pandas/pandas-tutorial/)\n- [Data Preprocessing in Python](https://www.geeksforgeeks.org/machine-learning/data-preprocessing-machine-learning-python/)\n- [EDA - Exploratory Data Analysis in Python](https://www.geeksforgeeks.org/data-analysis/exploratory-data-analysis-in-python/)\n\n### Feature Engineering\n\n- [What is Feature Engineering?](https://www.geeksforgeeks.org/machine-learning/what-is-feature-engineering/)\n- [Introduction to Dimensionality Reduction](https://www.geeksforgeeks.org/machine-learning/dimensionality-reduction/)\n- [Feature Selection Techniques in Machine Learning](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/)\n\n### Supervised Learning\n\n- [Supervised Machine Learning](https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/)\n- [Linear Regression in Machine learning](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/)\n- [Logistic Regression in Machine Learning](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/)\n- [Decision Tree in Machine Learning](https://www.geeksforgeeks.org/machine-learning/decision-tree-introduction-example/)\n- [Random Forest Algorithm in Machine Learning](https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/)\n- [K-Nearest Neighbor(KNN) Algorithm](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)\n- [Support Vector Machine (SVM) Algorithm](https://www.geeksforgeeks.org/machine-learning/support-vector-machine-algorithm/)\n- [Naive Bayes Classifiers](https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/)\n\n### Unsupervised Learning\n\n- [What is Unsupervised Learning](https://www.geeksforgeeks.org/machine-learning/unsupervised-learning/)\n- [K means Clustering – Introduction](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/)\n- [Hierarchical Clustering in Machine Learning](https://www.geeksforgeeks.org/machine-learning/hierarchical-clustering/)\n- [DBSCAN Clustering in ML - Density based clustering](https://www.geeksforgeeks.org/machine-learning/dbscan-clustering-in-ml-density-based-clustering/)\n- [Apriori Algorithm](https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/)\n- [Frequent Pattern Growth Algorithm](https://www.geeksforgeeks.org/machine-learning/frequent-pattern-growth-algorithm/)\n- [ECLAT Algorithm - ML](https://www.geeksforgeeks.org/machine-learning/ml-eclat-algorithm/)\n- [Principal Component Analysis(PCA)](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)\n\n### Model Evaluation and Tuning\n\n- [Evaluation Metrics in Machine Learning](https://www.geeksforgeeks.org/machine-learning/metrics-for-machine-learning-model/)\n- [Regularization in Machine Learning](https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/)\n- [Cross Validation in Machine Learning](https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/)\n- [Hyperparameter Tuning](https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning/)\n- [ML | Underfitting and Overfitting](https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/)\n- [Bias and Variance in Machine Learning](https://www.geeksforgeeks.org/machine-learning/bias-vs-variance-in-machine-learning/)\n\n### Advanced Techniques\n\n- [Reinforcement Learning](https://www.geeksforgeeks.org/machine-learning/what-is-reinforcement-learning/)\n- [Semi-Supervised Learning in ML](https://www.geeksforgeeks.org/machine-learning/ml-semi-supervised-learning/)\n- [Self-Supervised Learning (SSL)](https://www.geeksforgeeks.org/machine-learning/self-supervised-learning-ssl/)\n- [Ensemble Learning](https://www.geeksforgeeks.org/machine-learning/a-comprehensive-guide-to-ensemble-learning/)\n\n### Machine Learning Practice\n\n- [Machine Learning Interview Questions and Answers](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n- [100+ Machine Learning Projects with Source Code [2025]](https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/)"}
{"reference": "https://www.geeksforgeeks.org/interview-prep/interview-corner/", "content": "# Interview Corner\n\nLast Updated: 20 Sep, 2025\n\nThis article serves as your **one-stop guide to interview preparation**, designed to help you succeed across different experience levels and company expectations. Here is what you should expect in a Tech Interview, please remember the following points:\n\n- Tech Interview Preparation does not have any fixed syllabus. Different companies, roles, and hiring managers have their own approaches. However, a few patterns have become standard over the years.\n- One thing is, most of the companies take an online round first where they check your problem-solving skills using coding problems. Once you qualify the online coding round, you go to the next face-to-face technical rounds, that includes live coding and domain specific discussions.\n- **For students**, the most important topics are Data Structures and Algorithms (DSA), Object Oriented Programming (OOP), DBMS, OS, SQL, Web Development basics, AI, ML, and Data Science basics. Some companies ask Aptitude, Puzzle, and Design (Low Level and High Level) as well for internship.\n- **For early working professionals**, the process and topics are almost same as freshers, with addition of questions related to previous work experience and technologies they've previously used.\n- For more **experienced working professionals**, the process varies a lot. Some top product-based companies like Google ask DSA for all levels. However, there is going to be a lot more focus on System Design and technologies used in the previous companies.\n\nLet us now explore different interview resources.\n\n## DSA\n\n- [GFG 160](https://www.geeksforgeeks.org/courses/gfg-160-series) - A complete list of top 160 questions + 90 bonus questions with editorials and video explanations.\n- [DSA 360](https://www.geeksforgeeks.org/courses/dsa-skill-up) - Try our ongoing free course with weekly topic coverage with mock contests, short notes, daily problems and quizzes.\n\n## LLD and HLD\n\n- [System Design Tutorial](https://www.geeksforgeeks.org/system-design/system-design-tutorial/)\n- [Design Patterns Interview Questions](https://www.geeksforgeeks.org/system-design/top-design-patterns-interview-questions/)\n- [System Design SkillUp](https://www.geeksforgeeks.org/courses/system-design-skill-up) - Try our ongoing free course with weekly topic coverage with mock contests, short notes, daily problems and quizzes.\n\n## DevOps\n\nHere are top resources to prepare for DevOps interviews, including cloud computing and AWS-specific roles\n\n- [DevOps Interview Questions](https://www.geeksforgeeks.org/devops/devops-interview-questions/)\n- [AWS Interview Questions](https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/)\n- [Google Cloud Platform (GCP) Interview Questions](https://www.geeksforgeeks.org/devops/google-cloud-platform-interview-questions/)\n- [DevOps SkillUp](https://www.geeksforgeeks.org/courses/devops-skill-up) - Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Interview Experiences\n\n- [Interview Experiences for all roles](https://www.geeksforgeeks.org/category/experiences/interview-experiences/)\n\n## Web Development\n\n- [Full Stack Interview Questions](https://www.geeksforgeeks.org/html/full-stack-developer-interview-questions-and-answers/)\n- [MERN Skillup](https://www.geeksforgeeks.org/courses/full-stack-web-dev-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Aptitude & Puzzles\n\n- [Aptitude Questions and Answers](https://www.geeksforgeeks.org/aptitude/aptitude-questions-and-answers/)\n- [Puzzles for Interviews](https://www.geeksforgeeks.org/aptitude/puzzles/)\n- [Aptitude & Reasoning Skillup](https://www.geeksforgeeks.org/courses/aptitude-and-reasoning-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n- [100 Days of Interview Puzzles SkillUp](https://www.geeksforgeeks.org/courses/100-days-of-interview-puzzles-skill-up) - Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Computer Subjects\n\n- [Commonly asked Computer Subject Interview Questions](https://www.geeksforgeeks.org/courses/cs-core-subjects-skill-up)\n- [CS Core SkillUp](https://www.geeksforgeeks.org/courses/cs-core-subjects-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Python\n\n- [Python Interview Questions](https://www.geeksforgeeks.org/python/python-interview-questions/)\n- [Python SkillUp](https://www.geeksforgeeks.org/courses/python-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Data Science and Machine Learning\n\n- [Data Science Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-interview-questions-and-answers/)\n- [Data Science Coding Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-coding-interview-questions/)\n- [Machine Learning Interview Questions](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n- [Data Science SkillUp](https://www.geeksforgeeks.org/courses/ds-16): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Data Analytics\n\n- [Data Analyst Interview Questions](https://www.geeksforgeeks.org/data-science/data-analyst-interview-questions-and-answers/)\n- [Data Analytics SkillUp](https://www.geeksforgeeks.org/courses/data-analytics-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Software Testing\n\n- [Software Testing Interview Questions](https://www.geeksforgeeks.org/software-testing/software-testing-interview-questions/)\n- [Software Testing SkillUp](https://www.geeksforgeeks.org/courses/software-testing-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Mobile App Development (Android Development)\n\n- [Application Developer Interview Questions](https://www.geeksforgeeks.org/interview-experiences/application-developer-interview-questions/)\n- [Android Interview Questions for SDE I to SDE III](https://www.geeksforgeeks.org/android/top-50-android-interview-questions-answers-sde-i-to-sde-iii/)\n\nArticle Tags:\n\n- [Experiences](https://www.geeksforgeeks.org/category/experiences/)\n- [Interview Preparation](https://www.geeksforgeeks.org/category/interview-preparation/)\n- [Interview Prep](https://www.geeksforgeeks.org/category/interview-prep/)"}
{"reference": "https://www.geeksforgeeks.org/courses/100-days-of-interview-puzzles-skill-up", "content": "# 100 Days of Interview Puzzles - Skill Up\n\n**Self-Paced Course**\n\n## Course Description\n\nGet ready to conquer technical interviews with **\"Skill Up - 100 Days of Interview Puzzles\"**—a dynamic 100-day journey that sharpens your problem-solving skills, one puzzle at a time. Perfect for aspiring software engineers, data scientists, or anyone aiming to excel in high-stakes interviews, this course delivers daily challenges to keep you on your toes.\n\n**Duration**: 15 Weeks\n\n**Interested**: 13k+ Geeks\n\n## Course Overview\n\n### What's Inside\n\n- **One Puzzle Per Day**: Dive into a fresh, random puzzle each day for 100 days, designed to boost your logical reasoning and algorithmic thinking.\n- **Variety Keeps It Fresh**: With no set theme, expect a diverse mix of brain teasers that test your creativity and adaptability.\n- **Skill-Building Made Simple**: Commit to daily practice and watch your problem-solving prowess grow steadily over time.\n\n## Pricing\n\n## Frequently Asked Questions\n\n### 01. What is the structure of the course?\n\n### 02. What types of puzzles are included?\n\n### 03. How does this course help with technical interviews?"}
{"reference": "https://www.geeksforgeeks.org/courses/ms-word-and-google-docs-skill-up", "content": "# MS Word and Google Docs - Skill Up\n\nSelf-Paced Course\n\nThe Microsoft Word & Google Docs Course is a 9-week structured program that covers everything from the basics of Word to advanced document automation with Google Docs. You'll learn editing, formatting, layouts, references, collaboration, and smart AI-powered features to create professional, academic, and business-ready documents.\n\n**9 Weeks**\n\n**1k+ interested Geeks**\n\n## Course Overview\n\nThis course blends **practical lessons, formatting techniques, and real-world projects** to help you create, design, and manage documents efficiently. You'll Words advanced tools like styles, macros, mail merge, and Copilot while also exploring Google Docs features like collaboration, templates, extensions, and automation. By the end, you'll be able to **produce professional reports, resumes, publications, and interactive documents** with ease.\n\n## Course Highlights\n\n- Learn Microsoft Word basics: creating, saving, and managing documents\n- Master text formatting, page layouts, tables, and SmartArt\n- Explore professional features like mail merge, macros, and developer tools\n- Automate document creation with AI (ChatGPT & Copilot)\n- Work with Google Docs offline and online with smart formatting tools\n- Collaborate in real-time with comments, suggestions, and versioning\n- Create professional outputs: resumes, reports, flyers, forms, and eBooks\n- Integrate Google Docs with Sheets, Forms, and add-ons\n- Boost productivity with shortcuts, smart features, and workflow hacks\n\n## Course Content\n\n### Week 1: Getting Started with Microsoft Word\n\n- Introduction to Word\n- Document Basics\n- Document Management\n- Page Setup\n- Basic Editing\n- Text Operations\n- Basic Formatting\n\n### Week 2: Text and Paragraph Formatting\n\n- Advanced Text Formatting\n- Paragraph Formatting\n- Specialized Text Features\n- Styles in Word\n- Formatting Tools\n- Lists in Word\n- Document Navigation\n\n### Week 3: Document Layout and Design\n\n- Page Layout\n- Page & Section Formatting\n- Document Enhancements\n- Borders & Lines\n- Visual Elements\n- Shapes & SmartArt\n- Text Boxes & WordArt\n\n### Week 4: Tables, Charts, and Advanced Features\n\n- Tables in Word\n- Table & Chart Features\n- Organizational Visuals\n- Hyperlinks & Signatures\n- Notes & References\n- Productivity Tools\n- Developer Tools"}
{"reference": "https://www.geeksforgeeks.org/courses/category/development-testing", "content": "### We couldn't find what you're looking for"}
{"reference": "https://www.facebook.com/geeksforgeeks.org/", "content": "# GeeksforGeeks\n\nGeeksforGeeks, Noida. 204,635 likes · 958 talking about this. Official Facebook page of GeeksforGeeks.org. All the posts, blog news will be updated here."}
{"reference": "https://www.geeksforgeeks.org/nlp/nlp-interview-questions/)", "content": "# Natural Language Processing Interview Questions\n\nNatural Language Processing (NLP) is evolving rapidly, with interviews focusing not just on basics but also on advanced architectures, contextual understanding and real-world applications. Let's prepare for interviews with a few practice questions.\n\n## Q1. What is tokenization and what are its types?\n\n[Tokenization](https://www.geeksforgeeks.org/nlp/nlp-how-tokenizing-text-sentence-words-works/) is the process of splitting text into smaller units called tokens, which can be words, subwords or characters. It is a fundamental step in NLP because most downstream tasks—like embeddings, parsing and classification—require input in a structured, tokenized form.\n\n**Types of Tokenization:**\n\n- **Word-level Tokenization**: Splits text into individual words and it is used for most classic NLP tasks like text classification or POS tagging.  \n  **Example**: \"NLP is fun\" → [\"NLP\", \"is\", \"fun\"]\n\n- **Subword Tokenization**: Splits words into meaningful subword units using methods like WordPiece or Byte-Pair Encoding (BPE) and it can handle rare/unknown words in language models; used in BERT, GPT.  \n  **Example**: \"unhappiness\" → [\"un\", \"happiness\"]\n\n- **Character-level Tokenization**: Splits text into characters and it is useful for languages with large vocabularies, misspellings or morphological analysis.  \n  **Example**: \"NLP\" → [\"N\", \"L\", \"P\"]\n\n- **Sentence-level Tokenization**: Splits text into sentences and it is useful in tasks like summarization or translation.  \n  **Example**: \"NLP is fun. It is evolving.\" → [\"NLP is fun.\", \"It is evolving.\"]\n\n## Q2. What is the difference between stemming and lemmatization?\n\nLet's see the difference between [stemming](https://www.geeksforgeeks.org/machine-learning/introduction-to-stemming/) and [lemmatization](https://www.geeksforgeeks.org/python-lemmatization-with-nltk/),\n\n| Feature | Stemming | Lemmatization |\n| --- | --- | --- |\n| Definition | Reduces a word to its base or root form by removing suffixes/prefixes | Reduces a word to its dictionary or canonical form using linguistic rules and context |\n| Output | Often produces non-words or truncated forms | Produces valid words found in a dictionary |\n| Accuracy | Crude approximation; may remove too much | More precise; considers context and part-of-speech |\n| Computation | Fast, computationally inexpensive | Slower due to use of dictionaries and POS tagging |\n| Example | \"studies\" → \"studi\"; \"running\" → \"run\" | \"better\" → \"good\"; \"running\" → \"run\" |\n| Use-case | Search engines, text indexing where speed matters | NLP tasks requiring semantic understanding, e.g., sentiment analysis, text summarization |\n\n## Q3. What is the Out-of-Vocabulary (OOV) problem in NLP?\n\nThe OOV problem occurs when a model encounters a word not seen during training, leading to poor representation or prediction failure. This is a major challenge for traditional embedding methods like Word2Vec or GloVe, which assign vectors only to words present in the training corpus.\n\n**Example**: Model trained on \"I love NLP\" may fail on \"I enjoy NLU\" because \"NLU\" is OOV.\n\n**Solutions**:\n\n1. **Subword embeddings**: BPE, WordPiece break unknown words into known subwords.\n2. **Character-level embeddings**: Represent words via character sequences to handle rare/misspelled words.\n3. **Contextual embeddings**: Models like BERT or ELMo generate dynamic embeddings for any input, mitigating OOV issues.\n\n## Q4. What is the Bag of Words (BoW) model and what are its limitations?\n\n[Bag of Words (BoW)](https://www.geeksforgeeks.org/nlp/bag-of-words-bow-model-in-nlp/) is a feature extraction technique that represents text as a vector of word counts or frequencies, ignoring grammar and word order. It’s simple and widely used in classic NLP pipelines.\n\n**Example**:\n\n- Sentence 1: \"I love NLP\" → [I:1, love:1, NLP:1]\n- Sentence 2: \"NLP love I\" → [I:1, love:1, NLP:1]\n- Both sentences have identical BoW representations because word order is ignored.\n\n**Limitations**:\n\n- **Ignores word order**: Cannot distinguish sentences with the same words but different meanings.\n- **No semantic understanding**: Words like \"good\" and \"excellent\" are treated as unrelated.\n- **High dimensionality**: For large vocabularies, the feature vectors can become sparse and memory-intensive.\n- **Does not handle OOV words**: Words unseen during training are ignored.\n\n## Q5. What is TF-IDF and how is it used in NLP?\n\n[TF-IDF](https://www.geeksforgeeks.org/machine-learning/understanding-tf-idf-term-frequency-inverse-document-frequency/) (Term Frequency-Inverse Document Frequency) is a statistical measure used in NLP to evaluate the importance of a word in a document relative to a collection of documents (corpus).\n\n- **Term Frequency (TF)**: Measures how often a word appears in a document, normalized by the total number of words in that document.\n- **Inverse Document Frequency (IDF)**: Measures how rare or informative a word is across all documents, reducing the weight of common words like \"the\" and increasing the weight of rare, meaningful words.\n\nTF-IDF score is the product of TF and IDF, highlighting words that are important in a specific document but not common across the corpus.\n\n**Formula**:\n\n> TF-IDF(t,d) = TF(t,d) × IDF(t)\n\n**Applications**:\n\n- Feature extraction for classification tasks.\n- Keyword extraction.\n- Search engines and information retrieval.\n\n## Q6. What are word embeddings and why are they important?\n\n[Word embeddings](https://www.geeksforgeeks.org/nlp/word-embeddings-in-nlp/) are dense vector representations of words in a continuous space, capturing semantic and syntactic relationships. Unlike one-hot vectors, embeddings encode similarity and contextual relationships between words.\n\n**Example**: \"king\" and \"queen\" have vectors close together, reflecting their semantic similarity, whereas \"king\" and \"apple\" are distant.\n\n**Word Embedding Techniques**:\n\n- **Word2Vec**: Predicts words from context (CBOW) or context from word (Skip-gram).\n- **GloVe**: Factorizes co-occurrence matrices to learn global statistical relationships.\n- **FastText**: Embeds subwords to handle rare or misspelled words.\n\n**Importance**:\n\n- Captures semantic similarity beyond simple counts.\n- Improves performance in NLP tasks like sentiment analysis, translation, text classification and semantic search.\n- Reduces dimensionality while preserving meaning.\n\n## Q7. What is the difference between word embeddings and contextual embeddings?\n\nLet's see the difference between word embeddings and contextual embeddings,\n\n| Feature | Word Embeddings | Contextual Embeddings |\n| --- | --- | --- |\n| Definition | Fixed vector representation for each word | Dynamic vectors that vary depending on context |\n| Example | \"bank\" → same vector regardless of \"river bank\" or \"financial bank\" | \"bank\" → different vectors for \"river bank\" and \"financial bank\" |\n| Techniques | Word2Vec, GloVe, FastText | BERT, ELMo, GPT |\n| Context Awareness | None | Captures surrounding words and semantic meaning |\n| Use-case | Basic NLP tasks, semantic similarity | Tasks requiring context understanding (QA, NER, disambiguation) |\n\n## Q8. What are the different types of embeddings in NLP?\n\nLet's see the various types of embeddings,\n\n**1. Word-level embeddings:**\n\n- Represent each word as a fixed vector.\n- **Examples**: Word2Vec, GloVe.\n- **Use-case**: Classic NLP tasks like similarity or classification.\n\n**2. Subword embeddings:**\n\n- Split words into meaningful sub-units to handle rare or unknown words.\n- **Examples**: FastText, BPE, WordPiece.\n- **Use-case**: Mitigates OOV problems, improves morphological understanding.\n\n**3. Character-level embeddings**:\n\n- Represent text at character granularity.\n- **Example**: \"running\" → sequence of character vectors.\n- **Use-case**: Morphologically rich languages, misspellings or rare words.\n\n**4. Contextual embeddings**:\n\n- Generate dynamic vectors for words based on surrounding text.\n- **Examples**: BERT, ELMo, GPT.\n- **Use-case**: Tasks like QA, NER and semantic disambiguation.\n\n**5. Sentence/document embeddings:**\n\n- Represent sentences or documents as single vectors.\n- **Examples**: Universal Sentence Encoder, Sentence-BERT.\n- **Use-case**: Semantic similarity, clustering, retrieval.\n\nDifferent embeddings capture meaning at different granularities—word, subword, character, sentence—depending on the task.\n\n## Q9. Dense vs. Sparse Embeddings\n\nLet's see the difference between sparse and dense embeddings,\n\n| Feature | Dense Embeddings | Sparse Embeddings |\n| --- | --- | --- |\n| Vector Characteristics | Low-dimensional, mostly non-zero | High-dimensional, mostly zero |\n| Representation | Learned via neural networks capturing semantic meaning | Based on explicit features like TF-IDF or one-hot encoding |\n| Dimensionality | Typically 100–1000 dimensions | Thousands to millions of dimensions |\n| Interpretability | Less interpretable; dimensions do not correspond directly to features | Highly interpretable; each dimension maps to a specific feature or term |\n| Use-case | Semantic search, recommendations, NLP tasks needing contextual understanding | Keyword matching, traditional information retrieval, sparse data scenarios |\n| Storage & Efficiency | Compact but computationally intensive | Larger storage, efficiently indexed for exact match retrieval |\n| Strength | Captures subtle contextual and semantic relationships | Efficient for exact match retrieval and scalable |\n| Limitation | Requires large datasets and training overhead | Cannot capture semantic similarity or context well |\n\n## Q10. What is the difference between pretrained embeddings and fine-tuning?\n\nLet's see the difference between [pretrained embeddings](https://www.geeksforgeeks.org/nlp/pre-trained-word-embedding-in-nlp/) and [fine-tuning](https://www.geeksforgeeks.org/deep-learning/what-is-fine-tuning/),\n\n| Feature | Pretrained Embeddings | Fine-tuning |\n| --- | --- | --- |\n| Definition | Embeddings trained on large general corpora and used as-is | Pretrained embeddings further trained on task-specific data to improve performance |\n| Flexibility | General-purpose | Task-specific adaptation |\n| Computation | Low (no additional training required) | Higher (requires gradient updates on embeddings) |\n| Example | Word2Vec trained on Wikipedia | BERT embeddings fine-tuned for sentiment analysis |\n| Use-case | Quickly incorporate semantic knowledge into models | Improve accuracy for specific downstream tasks |\n\n## Q11. What are Recurrent Neural Networks (RNNs)?\n\n[Recurrent Neural Networks](https://www.geeksforgeeks.org/machine-learning/introduction-to-recurrent-neural-network/) (RNNs) are a class of neural networks designed to handle sequential data, where the order of inputs is important. Unlike feedforward networks, RNNs maintain a hidden state that acts as memory, capturing information from previous time steps to influence current predictions.\n\n**Mathematical Representation**:\n\n> h_t = f(W_xh x_t + W_hh h_{t-1} + b_h)\n\n- x_t = input at time step t\n- h_t = hidden state at time step t\n- f = activation function (e.g., tanh, ReLU)\n\n**Applications**:\n\n- Language modeling and text generation\n- Machine translation\n- Speech recognition\n- Time-series forecasting\n\n## Q13. What is the vanishing gradient problem in RNNs?\n\nThe vanishing gradient problem occurs when gradients shrink exponentially as they are backpropagated through time steps in an RNN. This prevents the network from learning long-range dependencies effectively.\n\n**Example**: If an RNN is trying to predict a word based on a sequence of 50 previous words, gradients may become extremely small by the time they reach the first word, leading to ineffective weight updates.\n\n**Solutions**:\n\n1. **LSTM (Long Short-Term Memory)** networks with memory cells\n2. **GRU (Gated Recurrent Units)** with simplified gating\n3. **Gradient clipping** to prevent extremely small or large gradients\n\nThe vanishing gradient problem is why RNNs struggle with long sequences, motivating LSTM and GRU architectures.\n\n## Q14. What is the difference between RNN, LSTM and GRU networks?\n\nLet's see the difference between RNN, [LSTM](https://www.geeksforgeeks.org/deep-learning/deep-learning-introduction-to-long-short-term-memory/), [GRU](https://www.geeksforgeeks.org/machine-learning/gated-recurrent-unit-networks/),\n\n| Feature | RNN | LSTM | GRU |\n| --- | --- | --- | --- |\n| Memory Mechanism | Simple hidden state | Separate memory cell and hidden state | Single hidden state combining memory |\n| Gates | None | Input, Forget, Output | Update, Reset |\n| Ability to handle long sequences | Poor due to vanishing gradients | Excellent due to gating mechanisms | Good, slightly less complex than LSTM |\n| Complexity | Low | High | Moderate |\n| Computation Cost | Lower | Higher | Lower than LSTM |\n| Use-case | Short sequences or simple tasks | Long sequences, language modeling, translation | Medium-length sequences, lightweight tasks |\n| Advantage | Simple and fast | Captures long-range dependencies | Efficient and less computationally heavy |\n| Limitation | Cannot handle long-term dependencies | Computationally intensive | Slightly less powerful for very long sequences |\n\n## Q15. Explain sequence-to-sequence (Seq2Seq) models and their components\n\n[Sequence-to-sequence (Seq2Seq)](https://www.geeksforgeeks.org/machine-learning/seq2seq-model-in-machine-learning/) models are neural network architectures designed to transform an input sequence into an output sequence. They are widely used in NLP tasks where the lengths of input and output sequences can vary, such as machine translation, text summarization and speech recognition.\n\n**Components**:\n\n**1. Encoder:**\n\n- Processes the input sequence and compresses it into a context vector, capturing the information of the entire sequence.\n- An LSTM or GRU reads \"I love NLP\" and encodes it into a fixed-size vector representation.\n\n**2. Decoder:**\n\n- Generates the output sequence from the context vector.\n- Predicts one token at a time, using the previously generated token as input.\n\n**3. Attention Mechanism**:\n\n- Allows the decoder to focus on specific parts of the input at each step, improving performance on longer sequences.\n\n**Example**:\n\n- **Input**: \"I love NLP\"\n- **Output** (French): \"J'aime le NLP\"\n\nSeq2Seq allows mapping variable-length input sequences to variable-length outputs, a crucial aspect in NLP tasks like translation.\n\n## Q16. What is an Encoder-Decoder model in NLP?\n\nThe [Encoder-Decoder](https://www.geeksforgeeks.org/nlp/encoder-decoder-models/) architecture is a foundational framework for sequence-to-sequence (Seq2Seq) tasks in NLP. It separates input comprehension and output generation, enabling flexible transformation of variable-length sequences.\n\n**Components**:\n\n**Encoder**:\n\n- Processes the input sequence and compresses it into a context vector (dense representation).\n- Often implemented using RNNs, LSTMs, GRUs or Transformer encoders.\n\n**Decoder**:\n\n- Generates the output sequence from the context vector, predicting one token at a time.\n- Can use attention mechanisms to dynamically focus on relevant parts of the input.\n\n**Attention Layer**:\n\n- Enhances the decoder by weighting encoder outputs based on relevance to current decoding step.\n\n**Use-cases**:\n\n- Machine translation (English → French)\n- Text summarization\n- Chatbots and dialogue systems\n\nEncoder-Decoder models provide a structured way to handle variable-length sequences, bridging input understanding with output generation.\n\n## Q17. Explain the Transformer architecture and its impact on NLP\n\n[Transformers](https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/) process sequences in parallel using self-attention, instead of sequentially like RNNs. Self-attention weighs the importance of every word with respect to others, capturing long-range dependencies effectively.\n\n**Key Components:**\n\n- **Self-Attention**: Computes relationships between all words in a sequence simultaneously.\n- **Multi-Head Attention**: Allows the model to focus on multiple aspects of context concurrently.\n- **Positional Encoding**: Adds information about word order since attention itself is order-agnostic.\n- **Feed-Forward Layers**: Non-linear transformations applied after attention for feature refinement.\n- **Layer Normalization & Residual Connections**: Stabilizes training and improves gradient flow.\n\n**Impact on NLP:**\n\n- Enables parallelization, overcoming the sequential bottleneck of RNNs.\n- Captures long-range dependencies efficiently.\n- Forms the backbone of state-of-the-art models like BERT, GPT, T5, excelling in translation, summarization, text classification and QA.\n\nTransformers outperform RNN-based architectures by modeling context more effectively and training faster on large corpora.\n\n## Q18. Give the difference between BERT and GPT architectures.\n\nLet's see the difference between [BERT](https://www.geeksforgeeks.org/nlp/explanation-of-bert-model-nlp/) and [GPT](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-generative-pre-trained-transformer-gpt/) architectures,\n\n| Feature | BERT | GPT |\n| --- | --- | --- |\n| Architecture | Encoder-only | Decoder-only |\n| Training Objective | Masked Language Modeling (MLM) | Autoregressive Language Modeling |\n| Context | Bidirectional (considers left and right context) | Unidirectional (left-to-right context) |\n| Use-case | Understanding tasks: NER, QA, classification | Text generation, completion, dialogue systems |\n| Fine-tuning | Requires task-specific fine-tuning | Can generate text with minimal adaptation |\n| Strength | Captures full context for comprehension | Generates coherent, sequential text |\n| Limitation | Not naturally suited for text generation | Limited bidirectional understanding |\n\n## Q19. Autoregressive vs Autoencoder models.\n\nLet's see the differences between [Autoregressive](https://www.geeksforgeeks.org/nlp/autoregressive-models-in-natural-language-processing/) and [Autoencoders](https://www.geeksforgeeks.org/machine-learning/auto-encoders/),\n\n| Feature | Autoregressive Models | Autoencoder Models |\n| --- | --- | --- |\n| Purpose | Predict next token based on previous tokens in sequence | Reconstruct input from compressed latent representation |\n| Context Usage | Left (previous) context only (unidirectional) | Both left and right context (bidirectional) |\n| Training Objective | Maximize likelihood of next token | Minimize reconstruction loss between input and output |\n| Typical Architecture | Decoder-only Transformer (e.g., GPT series) | Encoder-decoder or encoder-only (e.g., BERT) |\n| Applications | Text generation, speech synthesis, time-series forecasting | Text classification, question answering, representation learning |\n| Inference | Sequential token generation; slower | Parallel processing possible; faster |\n| Strength | Excellent at coherent sequential generation | Strong at contextual understanding and embeddings |\n| Limitation | Limited bidirectional context | Not naturally suited for free-form text generation |\n\n## Q20. What are the differences between Masked Language Modeling (MLM) and Causal Language Modeling (CLM)?\n\nLet's see the difference between [MLM](https://www.geeksforgeeks.org/nlp/masked-language-models/) and [CLM](https://www.geeksforgeeks.org/nlp/causal-language-models-in-nlp/),\n\n| Feature | Masked Language Modeling (MLM) | Causal Language Modeling (CLM) |\n| --- | --- | --- |\n| Objective | Predict masked tokens anywhere in the input | Predict the next token based on previous tokens only |\n| Context | Bidirectional (uses both left and right context) | Unidirectional (left-to-right context) |\n| Example | Input: \"The [MASK] is bright\" → predict \"sun\" | Input: \"The sun is\" → predict \"bright\" |\n| Model Examples | BERT, RoBERTa | GPT series |\n| Use-case | Language understanding tasks: NER, QA, classification | Language generation tasks: text completion, dialogue |\n| Strength | Captures full context for better comprehension | Generates coherent sequential text |\n| Limitation | Not naturally suited for free text generation | Limited to past context; cannot see future tokens |\n\n## Q21. How does dependency parsing differ from constituency parsing?\n\n| Feature | Dependency Parsing | Constituency Parsing |\n| --- | --- | --- |\n| Focus | Grammatical relationships between words (head-dependent relations) | Hierarchical structure of phrases (sub-phrases like NP, VP) |\n| Output | Dependency tree: edges represent direct relationships | Constituency tree: nested tree structure of constituents |\n| Example | Sentence: \"She enjoys reading books\" → \"enjoys\" is root; \"She\" → subject; \"reading books\" → object | Same sentence → NP: \"She\"; VP: \"enjoys reading books\" |\n| Advantages | Highlights syntactic dependencies useful for relation extraction | Captures hierarchical grammatical structure |\n| Use-cases | Information extraction, syntax-based sentiment analysis, NER | Grammar analysis, parsing for machine translation, text generation |\n| Representation | Graph-based (nodes = words, edges = dependencies) | Tree-based (nested phrase structure) |\n\n## Q22. What are positional encodings in Transformers and why are they needed?\n\nTransformers process sequences in parallel and do not inherently capture the order of tokens. [Positional encodings](https://www.geeksforgeeks.org/nlp/positional-encoding-in-transformers/) add information about the position of each token in the sequence, enabling the model to recognize the relative or absolute position of words.\n\n**Types of Positional Encodings:**\n\n1. **Sinusoidal (fixed) encoding**: Uses sine and cosine functions of different frequencies.\n2. **Learned encoding**: Position embeddings are learned during training.\n\nWhy Needed:\n\n- Without positional encodings, a Transformer cannot distinguish \"I love NLP\" from \"NLP love I\".\n- Enables modeling of sequential patterns and relationships between words.\n\nPositional encodings provide order information, essential for accurate context modeling in Transformers.\n\n## Q23. Explain the concept of embeddings for subwords and character-level models\n\nSubword and character-level embeddings are designed to address the Out-of-Vocabulary (OOV) problem and handle rare, morphologically complex or unseen words in NLP tasks. They allow models to generate meaningful representations even for words not seen during training.\n\n**1. Subword Embeddings:**\n\nWords are split into subword units such as prefixes, suffixes or frequent subword patterns. Common methods: Byte-Pair Encoding (BPE), WordPiece, FastText.\n\n**Benefits:**\n\n- Handles rare and unseen words by combining known subwords.\n- Reduces overall vocabulary size.\n- Captures morphological structure of words.\n\n**Example**:\n\n- Word: \"unhappiness\"\n- Subwords: \"un\" + \"happi\" + \"ness\"\n- Embedding: Combine embeddings of subwords to represent the word.\n\n**2. Character-Level Embeddings:**\n\nEach character in a word is represented as an embedding. A sequence of character embeddings is processed (e.g., via CNNs or RNNs) to form a word-level representation.\n\n**Benefits**:\n\n- Handles typos, misspellings and very rare words.\n- Captures fine-grained morphological and orthographic patterns.\n\n**Example**:\n\n- Word: \"running\"\n- Characters: r, u, n, n, i, n, g\n- Processed via RNN/CNN → Combined embedding represents \"running\".\n\n## Q24. Explain Named Entity Recognition (NER) and its importance\n\n[Named Entity Recognition (NER)](https://www.geeksforgeeks.org/nlp/named-entity-recognition/) is a subtask of information extraction that identifies and classifies entities in text into predefined categories such as persons organizations, locations, dates, monetary values, percentages and more.\n\n- **Entity Recognition**: Detecting the presence of an entity in the text.\n- **Entity Classification**: Assigning the detected entity to a predefined category.\n\n**Example**:\n\n**Sentence**: \"Apple Inc. was founded by Steve Jobs in Cupertino.\"\n\n**NER Output**:\n\n- \"Apple Inc.\" → Organization\n- \"Steve Jobs\" → Person\n- \"Cupertino\" → Location\n\n**Importance of NER**:\n\n- **Information Retrieval**: Improves search accuracy by identifying key entities.\n- **Question Answering Systems**: Helps extract relevant facts from documents.\n- **Content Recommendation**: Enhances understanding of text content for personalization.\n- **Knowledge Graph Construction**: Extracts structured information from unstructured text.\n\nNER is foundational for structured understanding of unstructured text, enabling downstream NLP tasks to operate more effectively.\n\n## Q26. What is Word Sense Disambiguation (WSD)? Differentiate between WSD and NER.\n\n[Word Sense Disambiguation](https://www.geeksforgeeks.org/machine-learning/word-sense-disambiguation-in-natural-language-processing/) (WSD) is the process of determining the correct meaning of a word in context when the word has multiple possible senses. WSD is crucial for accurate understanding and downstream NLP tasks.\n\n**Techniques:**\n\n1. **Knowledge-based approaches**: Use lexical databases like WordNet to match context with word senses.\n2. **Supervised learning**: Train classifiers on labeled datasets where words are annotated with their correct senses.\n3. **Contextual embeddings**: Modern models like BERT produce dynamic embeddings that inherently disambiguate word senses based on surrounding context.\n\n| Feature | WSD (Word Sense Disambiguation) | NER (Named Entity Recognition) |\n| --- | --- | --- |\n| Definition | Identifies the correct meaning (sense) of a word based on context. | Identifies and classifies proper nouns or entities (like names, locations, organizations). |\n| Focus | Resolving lexical ambiguity for common words. | Detecting specific entities in text. |\n| Example | “Bank” → financial institution vs river bank depending on sentence. | “Apple” → company vs “Steve Jobs” → person. |\n| Context Use | Requires surrounding words or sentence-level context to choose correct sense. | Uses surrounding words and sometimes grammar to classify entity type. |\n| Applications | Machine translation, semantic search, word-level sense analysis. | Information extraction, question answering, knowledge graph construction. |\n\n## Q27. What is topic modeling and which algorithms are commonly used?\n\n[Topic modeling](https://www.geeksforgeeks.org/nlp/what-is-topic-modeling/) is an unsupervised learning technique that identifies hidden topics in large collections of text documents by analyzing word patterns and co-occurrences.\n\n**Common Algorithms**:\n\n- **Latent Dirichlet Allocation (LDA)**: Probabilistic model that represents documents as mixtures of topics and topics as distributions of words.\n- **Non-negative Matrix Factorization (NMF)**: Factorizes document-term matrices into topic-word and document-topic matrices.\n- **BERTopic**: Transformer-based approach that leverages contextual embeddings for richer topic representations.\n\n**Applications**:\n\n- Trend analysis and market research\n- Document clustering and organization\n- Summarization and content recommendation\n\n## Q28. What is information extraction (IE)?\n\n[Information Extraction (IE)](https://www.geeksforgeeks.org/nlp/information-extraction-in-nlp/) is the process of automatically converting unstructured text into structured data that can be easily analyzed and used in downstream applications. IE allows systems to extract meaningful facts, entities, relationships and events from raw text.\n\n**Key Components:**\n\n1. **Named Entity Recognition (NER)**: Identify and classify entities (persons organizations, locations, etc.)\n2. **Relation Extraction**: Detect relationships between entities (e.g., “Steve Jobs → founder → Apple Inc.”)\n3. **Event Extraction**: Identify events and participants, along with temporal and spatial details\n\n**Applications**:\n\n- **Knowledge Graph Construction**: Populating structured graphs for reasoning and search.\n- **Question Answering Systems**: Extracting precise answers from large text corpora.\n- **Content Summarization**: Automatically summarizing key information from articles.\n- **Data Analytics**: Structuring unstructured textual data for insights.\n\n## Q29. What are the challenges faced in sentiment analysis and how can they be addressed?\n\nSentiment analysis determines the emotional tone of text (positive, negative, neutral), but it faces several challenges:\n\n**1. Sarcasm and Irony:**\n\n- Sentences may convey the opposite sentiment of literal words.\n- Example: \"Great job!\" could be sarcastic and actually negative.\n- Solution: Use contextual embeddings like BERT or specific sarcasm detection models that can capture nuanced meaning.\n\n**2. Contextual Ambiguity:**\n\n- Words can have different sentiment depending on context.\n- **Example**: \"The movie was good, but the ending was disappointing.\"\n- **Solution**: Fine-tune context-aware architectures like Transformers to understand subtle shifts in sentiment.\n\n**3. Domain-Specific Language:**\n\n- Words can carry different sentiment in specialized domains.\n- **Example**: \"Positive\" in a medical report vs. a movie review.\n- **Solution**: Use domain-specific datasets for training or fine-tuning.\n\n**4. Negation Handling:**\n\n- Negations can flip sentiment.\n- **Example**: \"I don’t like this movie.\"\n- **Solution**: Incorporate syntactic parsing or negation-aware embeddings.\n\n**5. Imbalanced Data:**\n\n- Some sentiment classes may dominate the dataset, biasing predictions.\n- **Solution**: Apply data augmentation, class weighting or resampling techniques\n\n## Q30. What are common challenges in text classification and how can they be solved?\n\n[Text classification](https://www.geeksforgeeks.org/nlp/text-classification-using-scikit-learn-in-nlp/) assigns predefined categories to text documents, but it faces multiple challenges:\n\n**High Dimensionality:**\n\n- Text represented with large vocabularies leads to sparse feature spaces.\n- **Solution**: Use dimensionality reduction methods like TF-IDF with PCA or dense embeddings such as Word2Vec or BERT.\n\n**Class Imbalance:**\n\n- Some categories have significantly fewer examples, causing biased models.\n- **Solution**: Use oversampling, undersampling or weighted loss functions to balance training.\n\n**Noise and Irrelevant Information:**\n\n- Text may contain typos, stopwords or unrelated content.\n- **Solution**: Perform preprocessing steps like tokenization, stopword removal and normalization.\n\n**Ambiguity:**\n\n- Words with multiple meanings can confuse the classifier.\n- **Solution**: Employ contextual embeddings (e.g., BERT, ELMo) to capture word meaning in context.\n\n**Domain Adaptation:**\n\n- Models trained on one domain may not generalize to another.\n- **Solution**: Apply transfer learning and fine-tune models on target domain data.\n\n## Q31. How do attention mechanisms work in NLP?\n\n[Attention mechanisms](https://www.geeksforgeeks.org/artificial-intelligence/ml-attention-mechanism/) in NLP allow models to focus on relevant parts of the input sequence when processing or generating text. Each word is assigned a weight based on its importance to other words in the sequence, enabling the model to capture context and long-range dependencies effectively.\n\n- **Self-Attention**: Computes relevance of each word with every other word in the sequence.\n- **Scaled Dot-Product Attention**: Uses the dot product of queries and keys, scaled and applied to values to determine attention weights.\n- **Multi-Head Attention**: Uses multiple attention heads to capture different aspects of relationships simultaneously.\n\n## Q32. What is the role of Layer Normalization in Transformer models?\n\n[Layer Normalization](https://www.geeksforgeeks.org/deep-learning/what-is-layer-normalization/) is a technique that normalizes the inputs of each layer to have zero mean and unit variance, stabilizing and accelerating training in deep neural networks, particularly Transformers.\n\n- Prevents vanishing/exploding gradients.\n- Applied to self-attention and feed-forward layers.\n- Variants: Pre-LayerNorm (before operations) and Post-LayerNorm (after operations).\n\nLayer Normalization ensures stable and efficient training, improving convergence and model performance.\n\n## Q33. What is the role of context windows in NLP?\n\nA context window is the set of words surrounding a target word that a model considers when interpreting its meaning. It defines the scope of context used to capture semantic and syntactic relationships.\n\n**Types:**\n\n- **Narrow Window**: Focuses on immediate neighbors; captures local syntactic relationships.\n- **Wide Window**: Includes distant words; captures long-range semantic dependencies.\n- **Dynamic/Adaptive Window**: Context is learned dynamically, as in Transformers, via attention.\n\n## Q34. What is zero-shot and few-shot learning in NLP?\n\n[Zero-shot learning](https://www.geeksforgeeks.org/deep-learning/zero-shot-learning-in-deep-learning/) in NLP refers to the ability of a model to perform a task without having seen any labeled examples of that task during training, relying solely on its pre-trained knowledge. **For Example**: A sentiment analysis model trained on English being used to classify sentiments in Hindi without explicit Hindi training data.\n\n[Few-shot learning](https://www.geeksforgeeks.org/machine-learning/few-shot-learning-in-machine-learning/) refers to the ability of a model to adapt to a task with only a small number of labeled examples, leveraging prior knowledge for generalization. **For example**: Fine-tuning a pre-trained model for intent classification with just a handful of labeled sentences.\n\n## Q35. Explain Cross-lingual Transfer Learning and its challenges.\n\nCross-lingual Transfer Learning is the process of using knowledge learned from a high-resource source language (e.g., English) to improve model performance in a low-resource target language (e.g., Swahili), enabling multilingual applications with limited labeled data.\n\n- Utilizes multilingual embeddings and pre-trained models like mBERT or XLM-R.\n- Enables tasks like machine translation, sentiment analysis and question answering across languages.\n\n**Challenges:**\n\n- **Language diversity**: Structural and syntactic differences hinder transfer.\n- **Data scarcity**: Limited parallel corpora for many languages.\n- **Domain mismatch**: Source and target may differ in usage contexts.\n- **Cultural nuances**: Idioms and semantics vary across languages.\n- **High computation costs**: Multilingual models are large and resource-intensive.\n\n## Q36. What is retrieval-augmented generation (RAG) in NLP?\n\n[Retrieval-Augmented Generation (RAG)](https://www.geeksforgeeks.org/nlp/what-is-retrieval-augmented-generation-rag/) is a hybrid NLP approach that combines retrieval-based methods with generative models to improve accuracy, factuality and knowledge coverage in text generation tasks.\n\n- The retriever component fetches relevant documents or passages from an external knowledge source (e.g., Wikipedia, a vector database).\n- The generator (usually a Transformer-based model like BART or GPT) uses both the retrieved context and its own learned knowledge to produce the final output.\n- This helps reduce hallucinations and improves performance on tasks requiring factual grounding.\n\n**Applications**:\n\n- Open-domain question answering\n- Chatbots with external knowledge integration\n- Summarization with verified context\n- Legal, financial and medical document assistance\n\nRAG enhances generative models by anchoring responses in real-world data, making them more reliable and trustworthy.\n\n## Q37. How can knowledge graphs be integrated into NLP applications?\n\nA knowledge graph (KG) is a structured representation of entities and their relationships. Integrating KGs into NLP allows models to use explicit symbolic knowledge alongside statistical learning for better reasoning and interpretability.\n\n- **Entity Linking**: Mapping text mentions to KG entities (e.g., “Apple” → company vs fruit).\n- **Relation Extraction**: Using KGs to validate or discover relationships between entities.\n- **KG-Enhanced Embeddings**: Incorporating KG structure into word or sentence embeddings for semantic enrichment.\n- **Hybrid Models**: Combining KGs with neural architectures (e.g., Graph Neural Networks + Transformers).\n\n**Applications**:\n\n- **Question Answering**: Providing factual, graph-based answers.\n- **Recommendation Systems**: Leveraging entity relationships for personalized recommendations.\n- **Semantic Search**: Improving retrieval accuracy with KG-based reasoning.\n- **Dialogue Systems**: Maintaining consistency and factual grounding in conversations.\n\n## Q38. Describe how you would implement a chatbot using NLP techniques.\n\nA chatbot is an AI system that simulates human conversation, often using Natural Language Processing (NLP) to understand user input and generate appropriate responses.\n\n**Implementation Steps:**\n\n**1. Text Preprocessing**\n\n- Clean input (tokenization, stopword removal, stemming/lemmatization).\n- Handle spelling correction and entity recognition for better interpretation.\n\n**2. Intent Recognition**\n\n- Use text classification models (e.g., logistic regression, SVM or deep learning models like BERT) to identify user intent (e.g., \"book flight,\" \"check weather\").\n\n**3. Entity Extraction**\n\n- Apply Named Entity Recognition (NER) to capture required entities (e.g., dates, names, locations).\n\n**4. Dialogue Management**\n\n- Rule-based (dialogue flow charts, if-else rules).\n- Machine learning-based (Reinforcement Learning or Transformer-based dialogue policies).\n\n**5. Response Generation**\n\n- **Retrieval-based**: Predefined responses based on matching.\n- **Generative-based**: Neural models (e.g., Seq2Seq, Transformer, GPT) generate responses dynamically.\n- **Hybrid approach** (retrieval + generative).\n\n**6. Knowledge Integration**\n\n- Incorporate knowledge graphs or retrieval-augmented generation (RAG) to improve factual accuracy.\n\n**Application**:\n\n- Banking chatbot (checking balances, transaction history).\n- Customer support (handling FAQs).\n- Healthcare chatbot (symptom checker with disclaimers).\n\n## Q39. What are machine translation approaches?\n\n[Machine Translation (MT)](https://www.geeksforgeeks.org/nlp/machine-translation-of-languages-in-artificial-intelligence/) refers to the process of automatically converting text or speech from one natural language into another using computational methods. Over time, MT has evolved through three main paradigms: Rule-Based (RBMT), Statistical (SMT) and Neural Machine Translation (NMT). Each approach differs in how it models language, handles grammar and learns translation patterns.\n\n**1. Rule-Based Machine Translation (RBMT):**\n\nRBMT is the earliest approach to MT, which relies on explicit linguistic rules and bilingual dictionaries crafted by experts. It uses knowledge of grammar, syntax and semantics of both the source and target languages to perform translation.\n\n- **Pros**: Grammatically precise for structured sentences.\n- **Cons**: Requires extensive manual effort, struggles with ambiguity and idioms.\n\n**2. Statistical Machine Translation (SMT):**\n\nSMT relies on probability and statistics derived from large bilingual corpora to generate translations. Instead of rules, it learns how words and phrases in one language map to another based on frequency and alignment.\n\n- **Example**: Phrase-Based SMT learns phrase mappings from aligned sentences.\n- **Pros**: More flexible than RBMT, learns from data.\n- **Cons**: Still limited in fluency and long-range dependencies.\n\n**3. Neural Machine Translation (NMT):**\n\nNMT uses deep learning models, particularly sequence-to-sequence architectures with attention (and later Transformers), to perform translation. It represents words and sentences in continuous vector spaces (embeddings), enabling context-aware and fluent translations.\n\n- **Pros**: Produces fluent, context-aware translations.\n- **Cons**: Requires large data and compute resources, may hallucinate translations.\n\n## Q40. How can NLP be applied in recommendation systems, search engines and QA systems?\n\n**1. NLP in Recommendation System**\n\nA recommendation system is an AI-based system that predicts and suggests items (such as products, movies or news articles) to users by analyzing their past interactions, preferences and available content. When NLP is applied, the system can also interpret textual content (e.g., item descriptions, user reviews) to make smarter and more personalized recommendations.\n\n**How NLP is applied:**\n\n- Analyzing product/movie descriptions using embeddings.\n- Understanding user feedback via sentiment analysis.\n- Extracting key themes through topic modeling.\n- Capturing user intent from natural language queries (e.g., “affordable phones for photography”).\n\n**2. NLP in Search Engines**\n\nA search engine is a system that retrieves and ranks relevant documents, web pages or content based on a user’s query. NLP improves search engines by enabling them to understand the meaning behind queries instead of just matching keywords.\n\n**How NLP is applied:**\n\n- **Query processing**: Tokenization, stemming and lemmatization make queries more precise.\n- **Semantic search**: Embedding-based retrieval (e.g., BERT, SBERT) allows searches by meaning, not exact words.\n- **Entity recognition**: Identifying names, places or dates in queries.\n- **Re-ranking models**: NLP-powered ranking ensures that the most relevant documents appear at the top.\n- **Conversational search**: Handles follow-up and context-aware queries.\n\n**3. NLP in Question Answering (QA) Systems**\n\nA QA system is an NLP-powered application that provides direct answers to user queries expressed in natural language, instead of returning just a list of documents. Unlike search engines, QA systems aim to extract or generate exact responses from available knowledge.\n\n**How NLP is applied:**\n\n- **Extractive QA**: Models like BERT highlight the exact span of text containing the answer.\n- **Generative QA**: GPT-like models generate natural language answers.\n- **Knowledge graph QA**: Uses structured graphs to answer factual queries.\n- **Conversational QA**: Context-aware systems that manage follow-up questions.\n- **Domain-specific QA**: Trained on specialized datasets for medicine, law or finance.\n\n## Q41. What are the evaluations metrics in NLP?\n\nEvaluation metrics in NLP vary by task and generally include:\n\n**Classification Tasks:**\n\n- **Accuracy**: Overall correctness of predictions\n- **Precision**: Proportion of correctly predicted positive instances\n- **Recall**: Proportion of actual positives correctly identified\n- **F1-Score**: [F1-Score](https://www.geeksforgeeks.org/machine-learning/f1-score-in-machine-learning/) is harmonic mean of precision and recall, balancing both\n\n**Machine Translation**:\n\n- [****BLEU****](https://www.geeksforgeeks.org/nlp/understanding-bleu-and-rouge-score-for-nlp-evaluation/) ****(Bilingual Evaluation Understudy)**: Measures n-gram overlap between generated and reference text\n- [****ROUGE****](https://www.geeksforgeeks.org/nlp/understanding-bleu-and-rouge-score-for-nlp-evaluation/) ****(Recall-Oriented Understudy for Gisting Evaluation)**: Emphasizes recall of overlapping units, used also for summarization\n\n**Summarization**:\n\n- **ROUGE**: Commonly used metric for overlap with reference summaries\n- **BERTScore**: Uses contextual embeddings to evaluate semantic similarity beyond exact word matches\n\n**Semantic Similarity**:\n\n- [****Cosine Similarity****](https://www.geeksforgeeks.org/dbms/cosine-similarity/)**: Measures angle-based similarity between vector embeddings of sentences or words\n- [****Word Mover’s Distance****](https://www.geeksforgeeks.org/nlp/word-movers-distance-wmd-in-nlp/) ****(WMD)**: Quantifies semantic distance based on optimal transport between word embeddings\n\n## Q42. What is cosine similarity and Word Mover’s Distance (WMD) in semantic similarity?\n\nSemantic similarity refers to measuring how closely two texts (words, sentences or documents) are related in meaning. Two popular approaches for this are cosine similarity and Word Mover’s Distance (WMD).\n\n**Cosine Similarity:**\n\n[Cosine similarity](https://www.geeksforgeeks.org/dbms/cosine-similarity/) is a vector-based metric that measures the cosine of the angle between two vectors in high-dimensional space. It captures how similar the direction of two vectors is, regardless of their magnitude.\n\n- Represents words, sentences or documents as embeddings (numerical vectors).\n- Computes similarity based on vector orientation.\n\n**Formula**:\n\n> Cosine Similarity = (A.B) / (||A|| × ||B||)\n\nwhere A and B are embedding vectors.\n\n**Use cases:**\n\n- Semantic search (matching queries with documents).\n- Document clustering.\n- Recommender systems based on text similarity.\n\n**Word Mover’s Distance (WMD):**\n\n[Word Mover’s Distance](https://www.geeksforgeeks.org/nlp/word-movers-distance-wmd-in-nlp/) is a document-level distance metric that measures the minimum cumulative distance required to move words from one text to another, using their embeddings. It is based on the Earth Mover’s Distance (optimal transport theory).\n\n- Represents each word in both documents as embeddings.\n- Calculates how much \"effort\" is needed to transform one document into the other by optimally matching and moving words.\n- Accounts for semantic similarity between words (e.g., “Obama” and “President” are close in embedding space).\n\n**Advantages over cosine similarity:**\n\n- Captures fine-grained word-to-word relationships instead of just comparing overall vectors.\n- Better at handling paraphrases or semantically equivalent but differently worded sentences.\n\n**Example**:\n\n- **Sentence 1**: “Obama speaks to the press.”\n- **Sentence 2**: “The President gives a speech.”\n\nCosine similarity may not capture the relation fully, but WMD shows high similarity because word embeddings align semantically.\n\n## Q43. What is pragmatic ambiguity?\n\n[Pragmatic ambiguity](https://www.geeksforgeeks.org/nlp/ambiguity-in-nlp-and-how-to-address-them/) occurs when the meaning of an utterance depends on the context, situation or speaker intent, rather than the literal interpretation of the words themselves. It arises from how language is used in communication, not from grammatical or lexical ambiguity.\n\n- Unlike lexical ambiguity (where a word has multiple meanings, e.g., “bank”), pragmatic ambiguity involves interpretation based on context.\n- It can lead to multiple valid readings of the same sentence depending on the speaker, listener or situation.\n\n**Examples:**\n\n1. “Can you pass the salt?”\n\n   - Literal interpretation: Asking if the listener is able to pass the salt.\n   - Pragmatic interpretation: Polite request for the salt.\n\n2. “I’ll meet you at the bank.”\n\n   - Without context, it could refer to a financial institution or the side of a river.\n   - The context (river vs city) resolves the ambiguity.\n\n## Q44. What are Hugging Face Transformers and how are they used in NLP?\n\n[Hugging Face Transformers](https://www.geeksforgeeks.org/artificial-intelligence/Introduction-to-hugging-face-transformers/) is an open-source library that provides pretrained Transformer-based models for a wide range of NLP tasks. It enables easy access to models like BERT, GPT, RoBERTa, T5, and DistilBERT, along with tools for training, fine-tuning, and deploying them efficiently.\n\n**Key Features:**\n\n- **Pretrained Models**: Hundreds of models trained on large corpora, ready for downstream tasks.\n- **Task Support**: Includes text classification, token classification, question answering, summarization, translation, and text generation.\n- **Easy Integration**: Works with PyTorch, TensorFlow, and JAX.\n- **Tokenizers**: Supports subword tokenization like WordPiece, BPE, and SentencePiece.\n- **Fine-Tuning**: Allows adapting pretrained models to domain-specific tasks with minimal code.\n\n**Applications in NLP:**\n\n- **Text Classification**: Sentiment analysis, spam detection, topic classification.\n- **Named Entity Recognition (NER)**: Identifying entities like names, dates, locations.\n- **Question Answering (QA)**: Extractive and generative QA systems.\n- **Text Generation**: Chatbots, story generation, summarization.\n- **Translation and Summarization**: Multilingual and abstractive text processing.\n\n## Q.45. Apply a full text preprocessing pipeline.\n\n[Text preprocessing](https://www.geeksforgeeks.org/nlp/text-preprocessing-for-nlp-tasks/) is the process of cleaning and transforming raw text into a structured format suitable for NLP tasks. It helps remove noise, standardize the input and prepare features for downstream models. Using NLTK (Natural Language Toolkit), we can implement a complete preprocessing pipeline.\n\n**1. Import Necessary Libraries**\n\nWe will be importing[nltk](https://www.geeksforgeeks.org/python/NLTK-NLP/),[regex](https://www.geeksforgeeks.org/python/python-regex/),[string](https://www.geeksforgeeks.org/python/python-string/)and inflect.\n\n```python\nimport nltk\nimport string\nimport re\nimport inflect\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.porter import PorterStemmer\n```\n\n**2. Convert to Lowercase**\n\nWe convert the text lowercase to reduce the size of the vocabulary of our text data.\n\n```python\ndef text_lowercase(text):\n    return text.lower()\n\ninput_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\"\nprint(text_lowercase(input_str))\n```\n\n**Output**:\n\n> hey, did you know that the summer break is coming? amazing right !! it's only 5 more days !!\n\n**3. Removing Numbers**\n\nWe can either remove numbers or convert the numbers into their textual representations. To remove the numbers we can use regular expressions.\n\n```python\ndef remove_numbers(text):\n    return re.sub(r'\\d+', '', text)\n\ninput_str = \"There are 3 balls in this bag, and 12 in the other one.\"\nprint(remove_numbers(input_str))\n```\n\n**Output**:\n\n> There are balls in this bag and in the other one.\n\n**4. Converting Numerical Values**\n\nWe can also convert the numbers into words. This can be done by using the inflect library.\n\n```python\np = inflect.engine()\n\ndef convert_number(text):\n    temp_str = text.split()\n    new_string = []\n    for word in temp_str:\n        if word.isdigit():\n            new_string.append(p.number_to_words(word))\n        else:\n            new_string.append(word)\n    return ' '.join(new_string)\n\ninput_str = \"There are 3 balls in this bag, and 12 in the other one.\"\nprint(convert_number(input_str))\n```\n\n**Output**:\n\n> There are three balls in this bag and twelve in the other one.\n\n**5. Removing Punctuation**\n\nWe remove punctuations so that we don't have different forms of the same word. For example if we don't remove the punctuation then been. been, been! will be treated separately.\n\n```python\ndef remove_punctuation(text):\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\ninput_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\"\nprint(remove_punctuation(input_str))\n```\n\n**Output**:\n\n> Hey did you know that the summer break is coming Amazing right Its only 5 more days\n\n**6. Removing Whitespace**\n\nWe can use the join and split functions to remove all the white spaces in a string.\n\n```python\ndef remove_whitespace(text):\n    return \" \".join(text.split())\n\ninput_str = \"we    don't   need   the given      questions\"\nprint(remove_whitespace(input_str))\n```\n\n**Output**:\n\n> we don't need the given questions\n\n**7. Removing Stopwords**\n\n[Stopwords](https://www.geeksforgeeks.org/nlp/removing-stop-words-nltk-python/)are words that do not contribute much to the meaning of a sentence hence they can be removed.\n\n```python\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('punkt_tab')\n\ndef remove_stopwords(text):\n    stop_words = set(stopwords.words(\"english\"))\n    word_tokens = word_tokenize(text)\n    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n    return filtered_text\n\nexample_text = \"This is a sample sentence and we are going to remove the stopwords from this.\"\nprint(remove_stopwords(example_text))\n```\n\n**Output**:\n\n> ['sample', 'sentence', 'going', 'remove', 'stopwords', '.']\n\n**8. Applying Stemming**\n\n[Stemming](https://www.geeksforgeeks.org/machine-learning/introduction-to-stemming/)is the process of getting the root form of a word. Stem or root is the part to which affixes like -ed, -ize, -de, -s, etc are added. The stem of a word is created by removing the prefix or suffix of a word.\n\n```python\nstemmer = PorterStemmer()\ndef stem_words(text):\n    word_tokens = word_tokenize(text)\n    stems = [stemmer.stem(word) for word in word_tokens]\n    return stems\n\ntext = \"data science uses scientific methods algorithms and many types of processes\"\nprint(stem_words(text))\n```\n\n**Output**:\n\n> ['data', 'scienc', 'use', 'scientif', 'method', 'algorithm', 'and', 'mani', 'type', 'of', 'process']\n\n**9. Applying Lemmatization**\n\n[Lemmatization](https://www.geeksforgeeks.org/python/python-lemmatization-with-nltk/)is an NLP technique that reduces a word to its root form. This can be helpful for tasks such as text analysis and search as it allows us to compare words that are related but have different forms\n\n```python\nnltk.download('wordnet')\nlemmatizer = WordNetLemmatizer()\ndef lemma_words(text):\n    word_tokens = word_tokenize(text)\n    lemmas = [lemmatizer.lemmatize(word) for word in word_tokens]\n    return lemmas\n\ninput_str = \"data science uses scientific methods algorithms and many types of processes\"\nprint(lemma_words(input_str))\n```\n\n**Output**:\n\n> ['data', 'science', 'us', 'scientific', 'method', 'algorithm', 'and', 'many', 'type', 'of', 'process']\n\n**10. POS Tagging**\n\nPOS tagging is the process of assigning each word in a sentence its grammatical category, such as noun, verb, adjective or adverb.\n\n```python\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nimport os\nimport sys\n\nnltk_data_dir = '/usr/local/share/nltk_data'\nif nltk_data_dir not in nltk.data.path:\n    nltk.data.path.append(nltk_data_dir)\n\nnltk.download('averaged_perceptron_tagger_eng')\ndef pos_tagging(text):\n    word_tokens = word_tokenize(text)\n    return pos_tag(word_tokens)\n\ninput_str = \"Data science combines statistics, programming, and machine learning.\"\nprint(pos_tagging(input_str))\n```\n\n**Output**:\n\n> [('Data', 'NNP'), ('science', 'NN'), ('combines', 'NNS'), ('statistics', 'NNS'), (',', ','), ('programming', 'NN'), (',', ','), ('and', 'CC'), ('machine', 'NN'), ('learning', 'NN'), ('.', '.')]\n\n**Where,**\n\n- **NNP**: Proper noun\n- **NN**: Noun (singular)\n- **VBZ**: Verb (3rd person singular)\n- **CC**: Conjunction"}
{"reference": "https://www.geeksforgeeks.org/courses/devops-skill-up", "content": "# DevOps - Skill up\n\nSelf-Paced Course\n\nThe Advanced DevOps Engineering Program is an intensive, hands-on course designed to help learners master the tools, practices, and principles of modern DevOps. Covering everything from Linux fundamentals to CI/CD pipelines, container orchestration, cloud deployments, and Infrastructure as Code (IaC), this 12-week course offers a complete journey into DevOps engineering.\n\n**Duration:** 12 Weeks\n\n## Course Overview\n\nThis 12-week immersive program combines theory, practical labs, and projects to equip learners with in-demand DevOps skills. Participants will learn automation, configuration management, version control, containerization, orchestration, and cloud-native deployments using tools like Docker, Kubernetes, Jenkins, Terraform, Ansible, and AWS.\n\nBy the end of the course, you will be confident in building robust, scalable, and secure DevOps pipelines and practices to support modern software delivery.\n\n### DevOps Course Highlights\n\n- Build strong foundations in Linux and shell scripting\n- Master Git and GitHub for version control and collaboration\n- Understand cloud computing fundamentals with AWS\n- Learn Infrastructure as Code (IaC) using Ansible and Terraform\n- Automate application build and deployment with Jenkins\n- Deep dive into containerization with Docker\n- Orchestrate containerized applications with Docker Swarm and Kubernetes\n- Work on real-world DevOps projects and deployment pipelines\n- Follow best practices for security in DevOps environments\n- Learn CI/CD automation and smart deployment using AI\n\n## Course Content\n\n### Week 1: Basics and Fundamentals of DevOps\n\n- What is DevOps? Roles, salaries, and career paths\n- SDLC methodologies\n- DevOps lifecycle\n- Linux for DevOps\n- Scripting for DevOps\n- Scripting Projects\n\n### Week 2: Introduction to Version Control System\n\n- Introduction to Version Control Systems\n- Git installation and configuration\n- Essential Git commands\n- Git branching and branching strategies\n- Handling Git rebase, merge, and conflicts\n- Deploying and contributing projects on GitHub\n\n### Week 3: Cloud Computing and AWS Services\n\n- Introduction to cloud computing and its DevOps impact\n- AWS fundamentals and account setup\n- Key AWS services for DevOps\n- AWS Identity and Access Management (IAM)\n- Deployment strategies and Blue/Green deployment using AWS Lambda\n- Deploying a Node-Express server on AWS EC2 (mini project)\n\n### Week 4: Build Tools, IaC & Ansible\n\n- Introduction to build tools and Apache Maven\n- Maven build phases, automation, and a basic project\n- Introduction to Apache Tomcat, setup and deployment\n- Deploying a Spring Boot project\n- Infrastructure as Code (IaC) concepts and introduction to Ansible\n- Installing and configuring Ansible on AWS EC2\n- Writing Ansible playbooks with YAML"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/data-preprocessing-machine-learning-python/", "content": "# Data Preprocessing in Python\n\nData preprocessing is the first step in any data analysis or machine learning pipeline. It involves cleaning, transforming and organizing raw data to ensure it is accurate, consistent and ready for modeling. It has a big impact on model building such as:\n\n- Clean and well-structured data allows models to learn meaningful patterns rather than noise.\n- Properly processed data prevents misleading inputs, leading to more reliable predictions.\n- Organized data makes it simpler to create useful inputs for the model, enhancing model performance.\n- Organized data supports better Exploratory Data Analysis (EDA), making patterns and trends more interpretable.\n\n![Data Preprocessing](https://media.geeksforgeeks.org/wp-content/uploads/20250829154818842988/data_preprocessing.webp)\n\n## Steps-by-Step Implementation\n\nLet's implement various preprocessing features.\n\n### Step 1: Import Libraries and Load Dataset\n\nWe prepare the environment with libraries like [pandas](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/), [numpy](https://www.geeksforgeeks.org/numpy/python-numpy/), [scikit learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/), [matplotlib](https://www.geeksforgeeks.org/python/python-introduction-matplotlib/) and [seaborn](https://www.geeksforgeeks.org/python/introduction-to-seaborn-python/) for data manipulation, numerical operations, visualization and scaling. Load the dataset for preprocessing.\n\n> The sample dataset can be downloaded from [here](https://media.geeksforgeeks.org/wp-content/uploads/20250115110111213229/diabetes.csv).\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('Geeksforgeeks/Data/diabetes.csv')\ndf.head()\n```\n\n**Output:**\n\n![Dataset](https://media.geeksforgeeks.org/wp-content/uploads/20250829133434412896/Screenshot-2025-08-29-132400.webp)\n\n### Step 2: Inspect Data Structure and Check Missing Values\n\nWe understand dataset size, data types and identify any incomplete (missing) data that needs handling.\n\n- **df.info():** Prints concise summary including count of non-null entries and data type of each column.\n- **df.isnull().sum():** Returns the number of missing values per column.\n\n```python\ndf.info()\nprint(df.isnull().sum())\n```\n\n**Output:**\n\n### Step 3: Statistical Summary and Visualizing Outliers\n\nGet numeric summaries like mean, median, min/max and detect unusual points (outliers). Outliers can skew models if not handled.\n\n- **df.describe():** Computes count, mean, std deviation, min/max and quartiles for numerical columns.\n- **Boxplots:** Visualize spread and detect outliers using matplotlib’s boxplot().\n\n```python\ndf.describe()\n\nfig, axs = plt.subplots(len(df.columns), 1, figsize=(7, 18), dpi=95)\nfor i, col in enumerate(df.columns):\n    axs[i].boxplot(df[col], vert=False)\n    axs[i].set_ylabel(col)\nplt.tight_layout()\nplt.show()\n```\n\n**Output:**\n\n![Boxplot](https://media.geeksforgeeks.org/wp-content/uploads/20250829133635752868/boxplot-data-preprocessing.webp)\n\n### Step 4: Remove Outliers Using the Interquartile Range (IQR) Method\n\nRemove extreme values beyond a reasonable range to improve model robustness.\n\n- IQR = Q3 (75th percentile) – Q1 (25th percentile).\n- Values below Q1 - 1.5IQR or above Q3 + 1.5IQR are outliers.\n- Calculate lower and upper bounds for each column separately.\n- Filter data points to keep only those within bounds.\n\n```python\nq1, q3 = np.percentile(df['Insulin'], [25, 75])\niqr = q3 - q1\nlower = q1 - 1.5 * iqr\nupper = q3 + 1.5 * iqr\nclean_df = df[(df['Insulin'] >= lower) & (df['Insulin'] <= upper)]\n```\n\n### Step 5: Correlation Analysis\n\nUnderstand relationships between features and the target variable (Outcome). Correlation helps gauge feature importance.\n\n- **df.corr():** Computes pairwise correlation coefficients between columns.\n- Heatmap via seaborn visualizes correlation matrix clearly.\n- Sorting correlations with corr['Outcome'].sort_values() highlights features most correlated with the target.\n\n```python\ncorr = df.corr()\nplt.figure(dpi=130)\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\nplt.show()\n\nprint(corr['Outcome'].sort_values(ascending=False))\n```\n\n**Output:**\n\n### Step 6: Visualize Target Variable Distribution\n\nCheck if target classes (Diabetes vs Not Diabetes) are balanced, affecting model training and evaluation.\n\n- **plt.pie():** Pie chart to display proportion of each class in the target variable 'Outcome'.\n\n```python\nplt.pie(df['Outcome'].value_counts(), labels=[\n    'Diabetes', 'Not Diabetes'], autopct='%.f%%', shadow=True)\nplt.title('Outcome Proportionality')\nplt.show()\n```\n\n**Output:**\n\n![Result](https://media.geeksforgeeks.org/wp-content/uploads/20250829133842061194/pie.webp)\n\n### Step 7: Separate Features and Target Variable\n\nPrepare independent variables (features) and dependent variable (target) separately for modeling.\n\n- **df.drop(columns=[...]):** Drops the target column from features.\n- Direct column selection df['Outcome'] selects target column.\n\n```python\nX = df.drop(columns=['Outcome'])\ny = df['Outcome']\n```\n\n### Step 8: Feature Scaling: Normalization and Standardization\n\nScale features to a common range or distribution, important for many ML algorithms sensitive to feature magnitudes.\n\n#### 1. Normalization (Min-Max Scaling):\nRescales features between 0 and 1. Good for algorithms like k-NN and neural networks.\n\n- **Class:** MinMaxScaler from sklearn.\n- **.fit_transform():** Learns min/max from data and applies scaling.\n\n```python\nscaler = MinMaxScaler()\nX_normalized = scaler.fit_transform(X)\nprint(X_normalized[:5])\n```\n\n**Output:**\n\n![Normalization](https://media.geeksforgeeks.org/wp-content/uploads/20250829133922543007/Screenshot-2025-08-29-132258.webp)\n\n#### 2. Standardization:\nTransforms features to have mean = 0 and standard deviation = 1, useful for normally distributed features.\n\n- **Class:** StandardScaler from sklearn.\n\n```python\nscaler = StandardScaler()\nX_standardized = scaler.fit_transform(X)\nprint(X_standardized[:5])\n```\n\n**Output:**\n\n![Standardization](https://media.geeksforgeeks.org/wp-content/uploads/20250829134002498787/Screenshot-2025-08-29-132251.webp)\n\n## Advantages\n\nLet's see the advantages of data preprocessing,\n\n- **Improves Data Quality:** Cleans and organizes raw data for better analysis.\n- **Enhances Model Accuracy:** Removes noise and irrelevant data, leading to more precise predictions.\n- **Reduces Overfitting:** Handles outliers and redundant features, improving model generalization.\n- **Speeds Up Training:** Efficiently scaled data reduces computation time.\n- **Ensures Algorithm Compatibility:** Converts data into formats suitable for machine learning models."}
{"reference": "https://www.youtube.com/geeksforgeeksvideos", "content": "# GeeksforGeeks\n\nWelcome to the Official Channel of GeekforGeeks, your one-stop destination for diverse tech education!\n\n🚀 **Tech Variety:**  \nExplore Data Structures, Algorithms, Machine Learning(ML), Artificial Intelligence(AI), Software Testing, Python, Data Science, Web and App Development (Flutter, React JS, JavaScript, etc), and more.\n\n📚 **Complete DSA Concepts and More:**  \nMaster not only Data Structures and Algorithms but all essential Computer Science topics. Perfect for both beginners and those looking to polish their skills.\n\n🤝 **Interview Insights:**  \nAce tech interviews with insights from real interview experiences, building confidence for your next opportunity.\n\n🌐 **Tech Trends Updates:**  \nStay ahead with our updates on the latest tech trends and industry insights.\n\n🎓 **For All Tech Enthusiasts:**  \nWhether you're a student, a seasoned professional, or simply passionate about tech, our content is tailored for enthusiasts of all backgrounds!\n\n✨ Join us on this tech journey! Subscribe Now! ✨"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/support-vector-machine-algorithm/", "content": "# Support Vector Machine (SVM) Algorithm\n\nSupport Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. It tries to find the best boundary known as hyperplane that separates different classes in the data. It is useful when you want to do binary classification like spam vs. not spam or cat vs. dog.\n\nThe main goal of SVM is to maximize the margin between the two classes. The larger the margin the better the model performs on new and unseen data.\n\n## Key Concepts of Support Vector Machine\n\n- **Hyperplane**: A decision boundary separating different classes in feature space and is represented by the equation \\( wx + b = 0 \\) in linear classification.\n- **Support Vectors**: The closest data points to the hyperplane, crucial for determining the hyperplane and margin in SVM.\n- **Margin**: The distance between the hyperplane and the support vectors. SVM aims to maximize this margin for better classification performance.\n- **Kernel**: A function that maps data to a higher-dimensional space enabling SVM to handle non-linearly separable data.\n- **Hard Margin**: A maximum-margin hyperplane that perfectly separates the data without misclassifications.\n- **Soft Margin**: Allows some misclassifications by introducing slack variables, balancing margin maximization and misclassification penalties when data is not perfectly separable.\n- **C**: A regularization term balancing margin maximization and misclassification penalties. A higher C value forces stricter penalty for misclassifications.\n- **Hinge Loss**: A loss function penalizing misclassified points or margin violations and is combined with regularization in SVM.\n- **Dual Problem**: Involves solving for Lagrange multipliers associated with support vectors, facilitating the kernel trick and efficient computation.\n\n## How does Support Vector Machine Algorithm Work?\n\nThe key idea behind the SVM algorithm is to find the hyperplane that best separates two classes by maximizing the margin between them. This margin is the distance from the hyperplane to the nearest data points (support vectors) on each side.\n\n![SVM](https://media.geeksforgeeks.org/wp-content/uploads/20250805115844223142/SVM.webp)\n\n*Multiple hyperplanes separate the data from two classes*\n\nThe best hyperplane also known as the **\"hard margin\"** is the one that maximizes the distance between the hyperplane and the nearest data points from both classes. This ensures a clear separation between the classes. So from the above figure, we choose L2 as hard margin. Let's consider a scenario like shown below:\n\n![2](https://media.geeksforgeeks.org/wp-content/uploads/20250805115918786327/2.webp)\n\n*Selecting hyperplane for data with outlier*\n\nHere, we have one blue ball in the boundary of the red ball.\n\n### How does SVM classify the data?\n\nThe blue ball in the boundary of red ones is an outlier of blue balls. The SVM algorithm has the characteristics to ignore the outlier and finds the best hyperplane that maximizes the margin. SVM is robust to outliers.\n\n![3](https://media.geeksforgeeks.org/wp-content/uploads/20250805115955302230/3.webp)\n\n*Hyperplane which is the most optimized one*\n\nA soft margin allows for some misclassifications or violations of the margin to improve generalization. The SVM optimizes the following equation to balance margin maximization and penalty minimization:\n\n\\[\n\\text{Objective Function} = \\left(\\frac{1}{\\text{margin}}\\right) + \\lambda \\sum \\text{penalty }\n\\]\n\nThe penalty used for violations is often [hinge loss](https://www.geeksforgeeks.org/machine-learning/hinge-loss-relationship-with-support-vector-machines/) which has the following behavior:\n\n- If a data point is correctly classified and within the margin there is no penalty (loss = 0).\n- If a point is incorrectly classified or violates the margin the hinge loss increases proportionally to the distance of the violation.\n\nTill now we were talking about linearly separable data that separates group of blue balls and red balls by a straight line/linear line.\n\n## What if data is not linearly separable?\n\nWhen data is not linearly separable i.e it can't be divided by a straight line, SVM uses a technique called [kernels](https://www.geeksforgeeks.org/machine-learning/major-kernel-functions-in-support-vector-machine-svm/) to map the data into a higher-dimensional space where it becomes separable. This transformation helps SVM find a decision boundary even for non-linear data.\n\n![4](https://media.geeksforgeeks.org/wp-content/uploads/20250805120032248972/4.webp)\n\n*Original 1D dataset for classification*\n\nA kernel is a function that maps data points into a higher-dimensional space without explicitly computing the coordinates in that space. This allows SVM to work efficiently with non-linear data by implicitly performing the mapping. For example consider data points that are not linearly separable. By applying a kernel function SVM transforms the data points into a higher-dimensional space where they become linearly separable.\n\n- **Linear Kernel**: For linear separability.\n- **Polynomial Kernel**: Maps data into a polynomial space.\n- **Radial Basis Function (RBF) Kernel**: Transforms data into a space based on distances between data points.\n\n![5](https://media.geeksforgeeks.org/wp-content/uploads/20250805120110091246/5.webp)\n\n*Mapping 1D data to 2D to become able to separate the two classes*\n\nIn this case the new variable y is created as a function of distance from the origin.\n\n## Mathematical Computation of SVM\n\nConsider a binary classification problem with two classes, labeled as +1 and -1. We have a training dataset consisting of input feature vectors X and their corresponding class labels Y. The equation for the linear hyperplane can be written as:\n\n\\[\nw^T x + b = 0\n\\]\n\nWhere:\n\n- \\( w \\) is the normal vector to the hyperplane (the direction perpendicular to it).\n- \\( b \\) is the offset or bias term representing the distance of the hyperplane from the origin along the normal vector \\( w \\).\n\n### Distance from a Data Point to the Hyperplane\n\nThe distance between a data point \\( x_i \\) and the decision boundary can be calculated as:\n\n\\[\nd_i = \\frac{w^T x_i + b}{\\|w\\|}\n\\]\n\nwhere \\( \\|w\\| \\) represents the Euclidean norm of the weight vector \\( w \\).\n\n### Linear SVM Classifier\n\nDistance from a Data Point to the Hyperplane:\n\n\\[\n\\hat{y} = \\left\\{ \\begin{array}{cl} 1 & : w^T x + b \\geq 0 \\\\ 0 & : w^T x + b < 0 \\end{array} \\right.\n\\]\n\nWhere \\( \\hat{y} \\) is the predicted label of a data point.\n\n### Optimization Problem for SVM\n\nFor a linearly separable dataset the goal is to find the hyperplane that maximizes the margin between the two classes while ensuring that all data points are correctly classified. This leads to the following optimization problem:\n\n\\[\n\\underset{w,b}{\\text{minimize}} \\frac{1}{2} \\| w \\|^2\n\\]\n\nSubject to the constraint:\n\n\\[\ny_i (w^T x_i + b) \\geq 1 \\quad \\text{for} \\quad i = 1, 2,3, \\cdots, m\n\\]\n\nWhere:\n\n- \\( y_i \\) is the class label (+1 or -1) for each training instance.\n- \\( x_i \\) is the feature vector for the i-th training instance.\n- \\( m \\) is the total number of training instances.\n\nThe condition \\( y_i (w^T x_i + b) \\geq 1 \\) ensures that each data point is correctly classified and lies outside the margin.\n\n### Soft Margin in Linear SVM Classifier\n\nIn the presence of outliers or non-separable data the SVM allows some misclassification by introducing slack variables \\( \\zeta_i \\). The optimization problem is modified as:\n\n\\[\n\\underset{w, b}{\\text{minimize }} \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^{m} \\zeta_i\n\\]\n\nSubject to the constraints:\n\n\\[\ny_i (w^T x_i + b) \\geq 1 - \\zeta_i \\quad \\text{and} \\quad \\zeta_i \\geq 0 \\quad \\text{for } i = 1, 2, \\dots, m\n\\]\n\nWhere:\n\n- \\( C \\) is a regularization parameter that controls the trade-off between margin maximization and penalty for misclassifications.\n- \\( \\zeta_i \\) are slack variables that represent the degree of violation of the margin by each data point.\n\n### Dual Problem for SVM\n\nThe dual problem involves maximizing the Lagrange multipliers associated with the support vectors. This transformation allows solving the SVM optimization using kernel functions for non-linear classification.\n\nThe dual objective function is given by:\n\n\\[\n\\underset{\\alpha}{\\text{maximize }} \\frac{1}{2} \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\alpha_i \\alpha_j t_i t_j K(x_i, x_j) - \\sum_{i=1}^{m} \\alpha_i\n\\]\n\nWhere:\n\n- \\( \\alpha_i \\) are the Lagrange multipliers associated with the i-th training sample.\n- \\( t_i \\) is the class label for the i-th training sample.\n- \\( K(x_i, x_j) \\) is the kernel function that computes the similarity between data points \\( x_i \\) and \\( x_j \\). The kernel allows SVM to handle non-linear classification problems by mapping data into a higher-dimensional space.\n\nThe dual formulation optimizes the Lagrange multipliers \\( \\alpha_i \\) and the support vectors are those training samples where \\( \\alpha_i > 0 \\).\n\n### SVM Decision Boundary\n\nOnce the dual problem is solved, the decision boundary is given by:\n\n\\[\nw = \\sum_{i=1}^{m} \\alpha_i t_i K(x_i, x) + b\n\\]\n\nWhere \\( w \\) is the weight vector, \\( x \\) is the test data point and \\( b \\) is the bias term. Finally the bias term \\( b \\) is determined by the support vectors, which satisfy:\n\n\\[\nt_i (w^T x_i - b) = 1 \\quad \\Rightarrow \\quad b = w^T x_i - t_i\n\\]\n\nWhere \\( x_i \\) is any support vector.\n\nThis completes the mathematical framework of the Support Vector Machine algorithm which allows for both linear and non-linear classification using the dual problem and kernel trick.\n\n## Types of Support Vector Machine\n\nBased on the nature of the decision boundary, Support Vector Machines (SVM) can be divided into two main parts:\n\n- **Linear SVM:** Linear SVMs use a linear decision boundary to separate the data points of different classes. When the data can be precisely linearly separated, linear SVMs are very suitable. This means that a single straight line (in 2D) or a hyperplane (in higher dimensions) can entirely divide the data points into their respective classes. A hyperplane that maximizes the margin between the classes is the decision boundary.\n\n- **Non-Linear SVM:** [Non-Linear SVM](https://www.geeksforgeeks.org/machine-learning/ml-non-linear-svm/) can be used to classify data when it cannot be separated into two classes by a straight line (in the case of 2D). By using kernel functions, nonlinear SVMs can handle nonlinearly separable data. The original input data is transformed by these kernel functions into a higher-dimensional feature space where the data points can be linearly separated. A linear SVM is used to locate a nonlinear decision boundary in this modified space.\n\n## Implementing SVM Algorithm Using Scikit-Learn\n\nWe will predict whether cancer is Benign or Malignant using historical data about patients diagnosed with cancer. This data includes independent attributes such as tumor size, texture, and others. To perform this classification, we will use an SVM (Support Vector Machine) classifier to differentiate between benign and malignant cases effectively.\n\n- **load_breast_cancer():** Loads the breast cancer dataset (features and target labels).\n- **SVC(kernel=\"linear\", C=1):** Creates a Support Vector Classifier with a linear kernel and regularization parameter C=1.\n- **svm.fit(X, y):** Trains the SVM model on the feature matrix X and target labels y.\n- **DecisionBoundaryDisplay.from_estimator():** Visualizes the decision boundary of the trained model with a specified color map.\n- **plt.scatter():** Creates a scatter plot of the data points, colored by their labels.\n- **plt.show():** Displays the plot to the screen.\n\n```python\nfrom sklearn.datasets import load_breast_cancer\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.svm import SVC\n\ncancer = load_breast_cancer()\nX = cancer.data[:, :2]\ny = cancer.target\n\nsvm = SVC(kernel=\"linear\", C=1)\nsvm.fit(X, y)\n\nDecisionBoundaryDisplay.from_estimator(\n    svm,\n    X,\n    response_method=\"predict\",\n    alpha=0.8,\n    cmap=\"Pastel1\",\n    xlabel=cancer.feature_names[0],\n    ylabel=cancer.feature_names[1],\n)\n\nplt.scatter(X[:, 0], X[:, 1], \n            c=y, \n            s=20, edgecolors=\"k\")\nplt.show()\n```\n\n**Output**:\n\n![svm](https://media.geeksforgeeks.org/wp-content/uploads/20250804164626487517/svm.webp)\n\n*SVM*\n\n## Advantages of Support Vector Machine (SVM)\n\n1. **High-Dimensional Performance**: SVM excels in high-dimensional spaces, making it suitable for image classification and gene expression analysis.\n2. **Nonlinear Capability**: Utilizing kernel functions like RBF and polynomial SVM effectively handles nonlinear relationships.\n3. **Outlier Resilience**: The soft margin feature allows SVM to ignore outliers, enhancing robustness in spam detection and anomaly detection.\n4. **Binary and Multiclass Support**: SVM is effective for both binary classification and multiclass classification suitable for applications in text classification.\n5. **Memory Efficiency**: It focuses on support vectors making it memory efficient compared to other algorithms.\n\n## Disadvantages of Support Vector Machine (SVM)\n\n1. **Slow Training**: SVM can be slow for large datasets, affecting performance in SVM in data mining tasks.\n2. **Parameter Tuning Difficulty**: Selecting the right kernel and adjusting parameters like C requires careful tuning, impacting SVM algorithms.\n3. **Noise Sensitivity**: SVM struggles with noisy datasets and overlapping classes, limiting effectiveness in real-world scenarios.\n4. **Limited Interpretability**: The complexity of the hyperplane in higher dimensions makes SVM less interpretable than other models.\n5. **Feature Scaling Sensitivity**: Proper feature scaling is essential, otherwise SVM models may perform poorly."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/machine-learning-mathematics/", "content": "# Maths for Machine Learning\n\nMathematics is the foundation of machine learning. Math concepts play an important role in understanding how models learn from data and optimizing their performance. They form the base for most machine learning algorithms.\n\n- Builds understanding of data representation and transformation\n- Helps in training and optimizing algorithms\n- Supports decision-making under uncertainty\n\n## Why Learn Mathematics for Machine Learning?\n\n- Math provides the theoretical foundation for understanding how machine learning algorithms work.\n- Concepts like calculus and linear algebra enable fine-tuning of models for better performance.\n- Knowing the math helps troubleshoot issues in models and algorithms.\n- Topics like deep learning, NLP and reinforcement learning require strong mathematical foundations.\n\n## How Much Math is Required for Machine Learning?\n\nThe amount of math required for machine learning depends on your goals. Let's see the breakdown based on different level:\n\n### Basic Understanding (Entry-Level)\n\n- **Linear Algebra:** [Basics of vectors](https://www.geeksforgeeks.org/maths/vectors-in-maths/), [matrices and matrix operations](https://www.geeksforgeeks.org/maths/introduction-to-matrices/), [vector norms](https://www.geeksforgeeks.org/maths/vector-norms/), [Euclidean distance](https://www.geeksforgeeks.org/maths/euclidean-distance/), [Manhattan distance](https://www.geeksforgeeks.org/data-science/manhattan-distance/).\n- **Statistics:** Descriptive statistics ([mean, variance, standard deviation](https://www.geeksforgeeks.org/maths/mathematics-mean-variance-and-standard-deviation/)), [correlation and covariance](https://www.geeksforgeeks.org/engineering-mathematics/mathematics-covariance-and-correlation/), [methods of measurement of correlation](https://www.geeksforgeeks.org/data-science/methods-of-measurements-of-correlation/).\n- **Probability:** [Basics of probability theory](https://www.geeksforgeeks.org/maths/probability-theory/), [joint/conditional/marginal probability](https://www.geeksforgeeks.org/maths/probability-joint-vs-marginal-vs-conditional/), [Bayes' theorem](https://www.geeksforgeeks.org/maths/bayes-theorem/).\n- **Calculus:** [Fundamental Calculus Concepts](https://www.geeksforgeeks.org/maths/fundamental-of-differential-calculus/) , [gradient](https://www.geeksforgeeks.org/python/gradient/), [Partial Derivatives](https://www.geeksforgeeks.org/maths/partial-derivative/), [Higher-Order Derivatives](https://www.geeksforgeeks.org/maths/higher-order-derivatives/).\n\n### Intermediate Understanding (Practical Implementation)\n\n- **Linear Algebra**: [Eigenvalues and Eigenvectors](https://www.geeksforgeeks.org/engineering-mathematics/eigen-values/), [LU Decomposition](https://www.geeksforgeeks.org/engineering-mathematics/l-u-decomposition-system-linear-equations/), [Singular Value Decomposition (SVD)](https://www.geeksforgeeks.org/machine-learning/singular-value-decomposition-svd/)\n- **Probability and Statistics**: [Central Limit Theorem](https://www.geeksforgeeks.org/maths/central-limit-theorem/), [Discrete Probability Distributions](https://www.geeksforgeeks.org/maths/discrete-probability-distribution/), [Continuous Probability Distributions](https://www.geeksforgeeks.org/machine-learning/continuous-probability-distributions-for-machine-learning/), [hypothesis testing](https://www.geeksforgeeks.org/software-testing/understanding-hypothesis-testing/) and [confidence intervals](https://www.geeksforgeeks.org/dsa/confidence-interval/).\n- **Calculus**: [Partial Derivatives](https://www.geeksforgeeks.org/maths/partial-derivative/) and [chain rule](https://www.geeksforgeeks.org/machine-learning/chain-rule-derivative-in-machine-learning/) for backpropagation in neural networks.\n- **Optimization**: [Understanding gradient descent](https://www.geeksforgeeks.org/data-science/what-is-gradient-descent/) and its variations (e.g., [stochastic gradient descent](https://www.geeksforgeeks.org/machine-learning/ml-stochastic-gradient-descent-sgd/)).\n\n### Advanced Understanding (Research and Custom Algorithms)\n\n- **Vector Calculus**: [Jacobian, Hessian Matrices](https://www.geeksforgeeks.org/engineering-mathematics/jacobian-and-hessian-matrices/).\n- **Probability Distributions and Statistics**: [Sampling Distributions](https://www.geeksforgeeks.org/maths/sampling-distribution/), [Chi-Square Distribution](https://www.geeksforgeeks.org/engineering-mathematics/chi-squared-distributions/), [t-Distribution](https://www.geeksforgeeks.org/engineering-mathematics/students-t-distribution-in-statistics/), [Parametric Methods](https://www.geeksforgeeks.org/maths/parametric-methods-in-statistics/), [Non-Parametric Test](https://www.geeksforgeeks.org/artificial-intelligence/non-parametric-tests/), [Bias Vs Variance](https://www.geeksforgeeks.org/machine-learning/bias-vs-variance-in-machine-learning/) and [Bootstrap method](https://www.geeksforgeeks.org/maths/bootstrap-method/).\n- **Geometry:**[Cosine Similarity](https://www.geeksforgeeks.org/python/how-to-calculate-cosine-similarity-in-python/), [Jaccard Similarity](https://www.geeksforgeeks.org/python/jaccard-similarity/) and [Orthogonality and Projections](https://www.geeksforgeeks.org/machine-learning/orthogonal-projections/).\n- **Regression Analysis:** [Maximum Likelihood Estimation (MLE)](https://www.geeksforgeeks.org/machine-learning/probability-density-estimation-maximum-likelihood-estimation/#maximum-likelihood-estimation), [Mean Squared Error](https://www.geeksforgeeks.org/maths/mean-squared-error/).\n\n## Some Related Articles\n\n- [Machine learning Tutorial](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\n- [Top 50 Machine Learning Interview Questions (2023)](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)"}
{"reference": "https://www.geeksforgeeks.org/learn-data-structures-and-algorithms-dsa-tutorial/", "content": "# DSA Tutorial - Learn Data Structures and Algorithms\n\nDSA stands for **Data Structures and Algorithms**. Data structures manage how data is stored and accessed. Algorithms focus on processing this data. Examples of data structures are Array, Linked List, Tree and Heap, and examples of algorithms are Binary Search, Quick Sort and Merge Sort.\n\n## Why to Learn DSA?\n\n- Foundation for almost every software like GPS, Search Engines, AI ChatBots, Gaming Apps, Databases, Web Applications, etc\n- Top Companies like Google, Microsoft, Amazon, Apple, Meta and many other heavily focus on DSA **i**n interviews.\n- Learning DSA boosts your problem-solving abilities and make you a stronger programmer.\n\n## How to learn DSA?\n\n1. Learn at-least one programming language ([C++](https://www.geeksforgeeks.org/cpp/c-plus-plus/), [Java](https://www.geeksforgeeks.org/java/java/), [Python](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/) or [JavaScript](https://www.geeksforgeeks.org/javascript/javascript-tutorial/)) and build your basic logic.\n2. Learn about Time and Space complexities\n3. Learn Data Structures (Arrays, Linked List, etc) and Algorithms (Searching, Sorting, etc).\n4. Once you learn main topics, it is important to [solve coding problems](https://www.geeksforgeeks.org/explore?page=1&sortBy=submissions&itm_source=geeksforgeeks&itm_medium=main_header&itm_campaign=practice_header) against some predefined test cases,\n5. Solve problems daily using [GfG Problem of the Day](https://www.geeksforgeeks.org/problem-of-the-day)\n\n> Try our free courses [GfG 160](https://www.geeksforgeeks.org/courses/gfg-160-series) and [DSA Skillup](https://www.geeksforgeeks.org/courses/dsa-skill-up) with daily topic coverage, notes, quizzes and most asked coding problems.\n\n### 1. Logic Building\n\nOnce you have learned basics of a programming language, it is recommended that you learn basic logic building\n\n- [Logic Building Guide](https://www.geeksforgeeks.org/dsa/logic-building-problems/)\n- [Quiz on Logic Building](https://www.geeksforgeeks.org/quizzes/dsa-tutorial-logic-building/)\n\n### 2. Learn about Complexities\n\nTo analyze algorithms, we mainly measure order of growth of time or space taken in terms of input size. We do this in the worst case scenario in most of the cases. Please refer the below links for a clear understanding of these concepts.\n\n- [Complexity Analysis Guide](https://www.geeksforgeeks.org/dsa/analysis-of-algorithms/)\n- [Quiz on Complexity Analysis](https://www.geeksforgeeks.org/quizzes/quiz-on-complexity-analysis-for-dsa/)\n\n### 3. Array\n\n**Array** is a linear data structure where elements are allocated **contiguous memory**, allowing for **constant-time access**.\n\n- [Array Guide](https://www.geeksforgeeks.org/dsa/array-data-structure-guide/)\n- [Quiz on Arrays](https://www.geeksforgeeks.org/quizzes/dsa-tutorial-array/)\n\n### 4. Searching Algorithms\n\n**Searching algorithms** are used to locate specific data within a large set of data. It helps **find a target value** within the data. There are various types of searching algorithms, each with its own approach and efficiency.\n\n- [Searching Guide](https://www.geeksforgeeks.org/dsa/searching-algorithms/)\n- [Quiz on Searching](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-searching-algorithm-with-answers/)\n\n### 5. Sorting Algorithm\n\n**Sorting algorithms** are used to **arrange** the elements of a list in a **specific order**, such as numerical or alphabetical. It organizes the items in a systematic way, making it easier to search for and access specific elements.\n\n- [Sorting Guide](https://www.geeksforgeeks.org/dsa/sorting-algorithms/)\n- [Quiz on Sorting](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-sorting-algorithms-with-answers/)\n\n### 6. Hashing\n\nHashing is a technique that generates a fixed-size output (hash value) from an input of variable size using mathematical formulas called hash functions. Hashing is commonly used in data structures for efficient searching, insertion and deletion.\n\n- [Hashing Guide](https://www.geeksforgeeks.org/dsa/hashing-data-structure/)\n- [Quiz on Hashing](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-hash-data-strcuture-with-answers/)\n\n### 7. Two Pointer Technique\n\n**I**n Two Pointer Technique, we typically use two index variables from two corners of an array. We use the two pointer technique for searching a required point or value in an array.\n\n- [Two Pointer Technique](https://www.geeksforgeeks.org/dsa/two-pointers-technique/)\n- [Quiz on Two Pointer Technique](https://www.geeksforgeeks.org/quizzes/quiz-on-two-pointer-technique-for-dsa/)\n\n### 8. Window Sliding Technique\n\n**I**n Window Sliding Technique, we use the result of previous subarray to quickly compute the result of current.\n\n- [Window Sliding Technique](https://www.geeksforgeeks.org/dsa/window-sliding-technique/)\n- [Quiz on Sliding Window](https://www.geeksforgeeks.org/quizzes/quiz-on-sliding-window-technique-for-dsa/)\n\n### 9. Prefix Sum Technique\n\n**I**n Prefix Sum Technique, we compute prefix sums of an array to quickly find results for a subarray.\n\n- [Prefix Sum Technique](https://www.geeksforgeeks.org/dsa/prefix-sum-array-implementation-applications-competitive-programming/)\n- [Quiz on Prefix Sum](https://www.geeksforgeeks.org/quizzes/quiz-on-prefix-sum-for-dsa/)\n\n### 10. String\n\nA sequence of characters, typically immutable and have limited set of elements (lower case or all English alphabets).\n\n- [Strings Guide](https://www.geeksforgeeks.org/dsa/string-data-structure/)\n- [Quiz on Strings](https://www.geeksforgeeks.org/quizzes/quiz-on-string-for-dsa/)\n\n### 11. Recursion\n\nA programming technique where a function **calls itself** within its own definition. It is usually used to solve problems that can be broken down into smaller instances of the same problem.\n\n- [Recursion Guide](https://www.geeksforgeeks.org/dsa/recursion-algorithms/)\n- [Quiz on Recursion](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-recursion-algorithm-with-answers/)\n\n### 12. Matrix/Grid\n\nA two-dimensional array of elements, arranged in **rows** and **columns**. It is represented as a rectangular grid, with each element at the intersection of a row and column.\n\n- [Matrix Guide](https://www.geeksforgeeks.org/dsa/matrix/)\n- [Quiz on Matrix/Grid.](https://www.geeksforgeeks.org/quizzes/quiz-on-matrixgrid-for-dsa/)\n\n### 13. Linked List\n\nA linear data structure that stores data in nodes, which are connected by pointers. Unlike arrays, nodes of linked lists are not stored in contiguous memory locations and can only be **accessed sequentially**, starting from the head of list.\n\n- [Linked List Guide](https://www.geeksforgeeks.org/dsa/linked-list-data-structure/)\n- [Quiz on Linked List](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-linked-list-data-structure-with-answers/)\n\n### 14. Stack\n\n**A** linear data structure that follows the **Last In, First Out (LIFO)** principle. Stacks play an important role in managing function calls, memory, and are widely used in algorithms like stock span problem, next greater element and largest area in a histogram.\n\n- [Stack Guide](https://www.geeksforgeeks.org/dsa/stack-data-structure/)\n- [Quiz on Stack](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-stack-data-strcuture-with-answers/)\n\n### 15. Queue\n\n**Queue** is a linear data structure that follows the **First In, First Out (FIFO)** principle. Queues play an important role in managing tasks or data in order, scheduling and message handling systems.\n\n- [Queue Guide](https://www.geeksforgeeks.org/dsa/queue-data-structure/)\n- [Quiz on Queue](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-queue-data-structure-with-answers/)\n\n### 16. Deque\n\nA Deque or double-ended queue is a data structure that allows elements to be added or removed from both ends efficiently.\n\n- [Deque Guide](https://www.geeksforgeeks.org/dsa/deque-set-1-introduction-applications/)\n- [Quiz on Deque](https://www.geeksforgeeks.org/quizzes/deque-960/)\n\n### 17. Tree\n\nA **non-linear, hierarchical** data structure consisting of nodes connected by edges, with a top node called the **root** and nodes having child nodes. It is widely used in **file systems**, **databases**, **decision-making algorithms**, etc.\n\n- [Tree Guide](https://www.geeksforgeeks.org/dsa/tree-data-structure/)\n- [Quiz on Tree](https://www.geeksforgeeks.org/quizzes/tree-22648/)\n\n### 18. Heap\n\nA **complete binary tree** that satisfies the **heap property**. Heaps are usually used to implement [priority queues](https://www.geeksforgeeks.org/dsa/priority-queue-set-1-introduction/), where the **smallest** or **largest** element is always at the root of the tree.\n\n- [Heap Guide](https://www.geeksforgeeks.org/dsa/heap-data-structure/)\n- [Quiz on Heap](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-heap-data-strcuture-with-answers/)\n\n### 19. Graph\n\nA **non-linear** data structure consisting of a finite set of **vertices**(or nodes) and a set of **edges**(or links)that connect a pair of nodes. Graphs are widely used to represent relationships between entities.\n\n- [Graph Guide](https://www.geeksforgeeks.org/dsa/graph-data-structure-and-algorithms/)\n- [Quiz on Graph](https://www.geeksforgeeks.org/quizzes/graph-12715/)\n\n### 20. Greedy Algorithm\n\nGreedy Algorithm builds up the solution one piece at a time and chooses the next piece which gives the most obvious and immediate benefit i.e., which is the most optimal choice at that moment. So the problems where choosing **locally optimal** also leads to the global solutions are best fit for Greedy.\n\n- [Greedy Algorithms Guide](https://www.geeksforgeeks.org/dsa/greedy-algorithms/)\n- [Quiz on Greedy](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-greedy-algorithms-with-answers/?page=3)\n\n### 21. Dynamic Programming\n\nDynamic Programming is a method used to solve complex problems by breaking them down into simpler **subproblems**. By solving each subproblem only once and storing the results, it avoids redundant computations, leading to more efficient solutions for a wide range of problems.\n\n- [Dynamic Programming Guide](https://www.geeksforgeeks.org/competitive-programming/dynamic-programming/)\n- [Quiz on DP](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-dynamic-programming-with-answers/)\n\n### 22. Advanced Data Structure and Algorithms\n\nAdvanced Data Structures like **Trie**, **Segment Tree**, **Red-Black Tree** and **Binary Indexed Tree** offer significant performance improvements for specific problem domains. They provide efficient solutions for tasks like fast prefix searches, range queries, dynamic updates, and maintaining balanced data structures, which are crucial for handling large datasets and real-time processing.\n\n- [Trie](https://www.geeksforgeeks.org/dsa/trie-insert-and-search/)\n- [Segment Tree](https://www.geeksforgeeks.org/dsa/segment-tree-data-structure/)\n- [Red-Black Tree](https://www.geeksforgeeks.org/dsa/introduction-to-red-black-tree/)\n- [Binary Indexed Tree](https://www.geeksforgeeks.org/dsa/binary-indexed-tree-or-fenwick-tree-2/)\n- [Practice Advanced Data Structures](https://www.geeksforgeeks.org/dsa/advance-data-structure/)\n\n### 23. Other Algorithms\n\n**Bitwise Algorithms:** Operate on individual bits of numbers.\n\n- [Bitwise Algorithms Guide](https://www.geeksforgeeks.org/dsa/bitwise-algorithms/)\n- [Quiz on Bit Magic](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-bitwise-algorithms-and-bit-manipulations-with-answers/)\n\n**Backtracking Algorithm :** Follow Recursion with the option to **revert and traces back** if the solution from current point is not feasible.\n\n- [Backtracking Guide](https://www.geeksforgeeks.org/dsa/backtracking-algorithms/)\n- [Quiz on Backtracking](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-backtracking-algorithm-with-answers/)\n\n**Divide and conquer:** A strategy to solve problems by dividing them into **smaller subproblems**, solving those subproblems, and combining the solutions to obtain the final solution.\n\n- [Divide and Conquer Guide](https://www.geeksforgeeks.org/dsa/divide-and-conquer/)\n- [Quiz on Divide and Conquer](https://www.geeksforgeeks.org/quizzes/top-mcqs-on-divide-and-conquer-algrithm-with-answers/)\n\n**Branch and Bound :** Used in combinatorial optimization problems to systematically search for the best solution. It works by dividing the problem into smaller subproblems, or branches, and then eliminating certain branches based on bounds on the optimal solution. This process continues until the best solution is found or all branches have been explored.\n\n- [Branch and Bound Algorithm](https://www.geeksforgeeks.org/dsa/branch-and-bound-algorithm/)\n\n**Geometric algorithms** are a set of algorithms that solve problems related to shapes, points, lines and polygons.\n\n- [Geometric Algorithms](https://www.geeksforgeeks.org/dsa/geometric-algorithms/)\n- [Practice Geometric Algorithms](https://www.geeksforgeeks.org/explore?page=1&category=Geometric&sortBy=submissions)\n\n**Randomized algorithms** are algorithms that use randomness to solve problems. They make use of random input to achieve their goals, often leading to simpler and more efficient solutions. These algorithms may not product same result but are particularly useful in situations when a probabilistic approach is acceptable.\n\n- [Randomized Algorithms](https://www.geeksforgeeks.org/dsa/randomized-algorithms/)"}
{"reference": "https://www.geeksforgeeks.org/courses/java-skill-up", "content": "# Java Skill Up\n\nSelf-Paced Course\n\n33k+ interested Geeks\n\nThe Java Complete Course is designed to take learners from absolute beginners to proficient Java developers. Covering foundational programming concepts, object-oriented principles, memory management, exception handling, multithreading, file I/O, and JDBC connectivity, the course also dives into modern features like Lambda expressions and design patterns. This hands-on curriculum is perfect for aspiring software developers, backend engineers, or anyone wanting to learn Java in-depth.\n\n**Duration:** 11 Weeks\n\n## Course Overview\n\nThis 11-week course offers a structured path to mastering Java programming through practical projects, detailed theory, and real-world coding exercises. Each week focuses on essential Java topics with consistent quizzes and mini-projects to reinforce concepts.\n\n### Course Highlights\n\n- Learn Java syntax, variables, operators, and control flow\n- Build reusable code with methods and arrays\n- Explore object-oriented principles in Java\n- Master memory handling, garbage collection, and packages\n- Understand exception handling and Java generics\n- Work with Java Collections, Streams, and Lambda expressions\n- Implement file I/O and serialization techniques\n- Use JDBC for database connectivity\n- Understand multithreading and concurrency\n- Learn and implement core design patterns\n- Build real-world projects for hands-on learning\n\n## Course Content\n\n### Week 1: Java Programming Basics\n\n- Java Basics, Features, JDK, JRE, JVM\n- Setting up Environment and Hello World Program\n- Java Program Structure and Execution Flow\n- Syntax, Identifiers, Data Types\n- Variables, Literals, Type Casting\n- Operators, Input/Output in Java\n- Conditional and Looping Constructs\n- Project: Tic-Tac-Toe Game\n\n### Week 2: Methods, Arrays, and Strings\n\n- Java Methods and Calling Techniques\n- Static vs Instance Methods\n- Command Line Arguments, Varargs\n- Arrays and Multi-Dimensional Arrays\n- Jagged Arrays, Arrays Class\n- Introduction to Strings, String Concatenation\n- String Class & Methods\n- StringBuffer & StringBuilder, Regular Expressions\n- Project: Memory Game\n\n### Week 3: Object-Oriented Programming (OOP)\n\n- OOP Concepts and Class/Object Creation\n- Constructors and Inheritance\n- Polymorphism, Abstraction, and Encapsulation\n- Inner Classes, Access Modifiers\n- Final Keyword, Object Class\n- Interfaces, Nested, Marker & Comparator Interfaces\n- Project: Library Management System\n\n### Week 4: Memory Management and Packages\n\n- Java Memory Management Fundamentals\n- Stack vs Heap, JVM Memory Areas\n- Garbage Collection and finalize() Method\n- Memory Leaks and Reference Types\n- Java Packages: Built-in and User-defined\n- Importing Packages and Naming Conventions\n- Project: Online Quiz System\n\n## Frequently Asked Questions\n\n### Who is this Java Course for?\n\n### Is any prior programming knowledge required for Java Course?\n\n### What projects will I complete in this course?\n\n### What roles can I pursue after this course?"}
{"reference": "https://www.geeksforgeeks.org/courses/software-testing-skill-up", "content": "# Software Testing - Skill Up\n\nSelf-Paced Course\n\n![course-thumbnail](https://media.geeksforgeeks.org/wp-content/uploads/20250711172508648844/Software-Testing.png)\n\n9k+ interested Geeks\n\nThis advanced Software Testing program is a hands-on, career-focused course designed to help you master the complete testing lifecycle. Covering everything from manual and automation testing to framework development, API testing, and CI/CD integration, this 9-week program prepares you to work on real-world projects using industry-standard tools like Selenium, TestNG, Maven, Jenkins, Postman, and REST Assured.\n\n10 Weeks\n\n## Course Overview\n\nThis structured Software Testing Program takes you from foundational concepts to advanced test automation. You'll start by learning manual testing, test types, SDLC/STLC models, and test case design. As you progress, you'll build expertise in automation testing using Selenium WebDriver, TestNG, and Maven, followed by behavior-driven development (BDD) with Cucumber.  \nLater weeks focus on API testing with Postman and REST Assured, continuous integration with Jenkins, and building a complete test automation framework using Java and open-source tools. Each week includes practical tasks, real-world projects, and quizzes to reinforce learning.  \nWhether you're preparing for a QA analyst role or planning to become a test automation engineer, this course equips you with job-ready skills and hands-on experience to stand out in interviews and real projects.\n\n**Software Testing Course Highlights:**\n\n* Understand software testing fundamentals, STLC, and SDLC models\n* Learn manual testing techniques, types, and test case design\n* Master Selenium WebDriver for UI automation\n* Use Maven and TestNG to build scalable test suites\n* Build feature-driven test cases with Cucumber and BDD\n* Perform automated API testing with Postman and REST Assured\n* Create CI/CD pipelines with Jenkins and GitHub integrations\n* Implement data-driven testing, assertions, and reports\n* Build and structure a complete test automation framework\n* Work on real-world testing projects with reusable code\n* Generate HTML reports and share test automation results\n* Align your skills with QA Engineer and SDET roles\n\n## Course Content\n\n### Week 1: Introduction to Software Testing\n\n* Software Testing Basics\n* Software Testing Types\n* Manual Testing Types\n* Functional Testing Types\n* Non-functional Testing Types\n* White Box Testing Types\n\n### Week 2: Testing Types and Selenium Introduction\n\n* Gray Box Testing Types\n* Manual Testing Test Cases\n* Continuation of Manual Testing Test Cases\n* Automation Testing\n* Automation Testing Types\n* Selenium Introduction and Setup\n* Selenium Locating Strategies\n\n### Week 3: Selenium in Advance\n\n* Selenium Locating Strategies (Continued)\n* Selenium Wait & Handling Web Elements\n* Selenium WebDriver Architecture\n* Handling Selenium Dynamic Elements\n* Selenium WebDriver (Advanced)\n* Selenium Advanced Handling\n* Selenium Advanced Handling (Continued)\n\n### Week 4: Maven Introduction\n\n* Selenium Cross Browser Testing\n* Selenium Parallel Testing\n* Selenium Data Driven Testing\n* Maven Introduction and Setting up\n* Maven First project, Pom.XML file\n* Maven Basic"}
{"reference": "https://www.geeksforgeeks.org/computer-science-fundamentals/programming-language-tutorials/", "content": "# Programming Languages Tutorials\n\nLast Updated: 11 Sep, 2025\n\nProgramming languages are how we tell computers what to do. The following are quick links to tutorials of the most common programming languages.\n\n- [C Language](https://www.geeksforgeeks.org/c/c-programming-language/)\n- [C++](https://www.geeksforgeeks.org/cpp/c-plus-plus/)\n- [Java](https://www.geeksforgeeks.org/java/java/)\n- [Python](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/)\n- [JavaScript](https://www.geeksforgeeks.org/javascript/javascript-tutorial/)\n- [TypeScript](https://www.geeksforgeeks.org/typescript/typescript-tutorial/)\n- [PHP](https://www.geeksforgeeks.org/php/php-tutorial/)\n- [R](https://www.geeksforgeeks.org/r-language/r-programming-language-introduction/)\n- [Ruby](https://www.geeksforgeeks.org/ruby/ruby-programming-language/)\n\n## How to Learn a Programming Language?\n\n- Pick a language based on your goals (e.g., Python for data science, JavaScript for web development).\n- Understand syntax, variables, data types, control flow, functions, and data structures.\n- Write Code and [Solve Problems](https://www.geeksforgeeks.org/blogs/geeksforgeeks-practice-best-online-coding-platform/).\n- Build Projects.\n- Review code examples on GitHub and learn to use official documentation to understand libraries and functions.\n- Join a Community.\n- Stay updated with trends in the language.\n- Progress takes time. Keep practicing and stay persistent even when faced with challenges.\n\n## Applications of Different Programming Languages\n\n- **C Language**: Used for designing software that work close to hardware and that work in low resource environment (less memory and CPU power) like embedded systems. C is also considered as mother of all languages and used as a first language to be taught in engineering so that students learn fundamentals.\n\n- **C++**: C++ is considered as a superset of C as it supports almost all syntax of C with additional features like Object Oriented Programming, Generic Programming and Exception Handling. C++ also has richer library and has wider applications compared to C. Both C and C++ are considered as faster languages compared to other popular programming languages like Java, Python and JavaScript.\n\n- **Java**: Java is a high-level, object-oriented programming language known for its platform independence, thanks to the Java Virtual Machine (JVM). It is widely used in enterprise-level applications, mobile development (especially Android apps) and large systems. Java is popular for its robustness, security features and scalability, making it a go-to choice for building reliable and high-performance systems.\n\n- **Python**: Python is a high-level, interpreted language known for its simplicity and readability. It's widely used for rapid application development, scripting, data analysis, artificial intelligence and web development. Python has an extensive collection of libraries and frameworks, making it versatile for various applications.\n\n- **JavaScript**: JavaScript is a dynamic, interpreted language that is primarily used for building interactive and dynamic websites. Initially designed for web development, JavaScript now has wide applications through frameworks and libraries such as Node.js, React and Angular. It runs in browsers, making it essential for client-side scripting.\n\n- **R**: R is a programming language and environment specifically designed for statistical computing and data analysis. It is widely used by statisticians, data scientists and researchers for analyzing and visualizing large datasets. R has a rich set of libraries and tools for data manipulation, statistical modeling and visualization, making it ideal for tasks such as machine learning, data analysis and data visualization.\n\n- **PHP**: PHP is a server-side, scripting language mainly used for web development. It is widely used to create dynamic web pages and web applications. Known for its deep integration with HTML and database management systems like MySQL, PHP powers a significant portion of the web, including popular content management systems like WordPress.\n\n- **Swift**: Swift is a powerful, high-level language developed by Apple for creating applications for iOS, macOS, watchOS and tvOS. It is known for its clean syntax, safety features and high performance. Swift is intended to be an easier and safer alternative to Objective-C for iOS and macOS development.\n\n- **[Kotlin](https://www.geeksforgeeks.org/kotlin/kotlin-programming-language/)**: Kotlin is a modern, statically typed language that runs on the Java Virtual Machine (JVM). It is fully interoperable with Java but provides more concise syntax and additional features, such as null safety, which helps avoid common programming errors. Kotlin is officially supported for Android development and is becoming increasingly popular due to its enhanced developer productivity and safety features.\n\n- **[Rust](https://www.geeksforgeeks.org/rust/introduction-to-rust-programming-language/)**: Rust is a systems programming language focused on safety, speed and concurrency. It’s designed to prevent memory safety issues like null pointer dereferencing and buffer overflows, which are common in languages like C and C++. Rust is particularly popular for developing high-performance, memory-efficient applications, such as operating systems, game engines and blockchain systems.\n\n- **TypeScript**: TypeScript is a superset of JavaScript that adds static typing, making it easier to catch errors during development. It compiles down to plain JavaScript, ensuring compatibility with existing JavaScript libraries and frameworks. TypeScript is widely used in large-scale web applications, as its type system helps with maintainability and scalability.\n\n- **Ruby**: Ruby is a high-level, interpreted language known for its elegant and readable syntax. It is primarily used for web development, with Ruby on Rails being its most well-known framework for building scalable, dynamic websites. Ruby emphasizes simplicity and productivity, allowing developers to build web applications quickly. Its dynamic typing and flexible syntax make it a popular choice for startups and rapid application development."}
{"reference": "https://www.geeksforgeeks.org/devops/devops-tutorial/", "content": "# DevOps Tutorial\n\n**DevOps** is a combination of two words: **\"Development\"** and **\"Operations.\"** It's a modern approach where software developers and software operations teams work together throughout the entire software life cycle.\n\nThe goals of DevOps are:\n\n- Faster and continuous software releases.\n- Reduces manual errors through automation.\n- Built-in Monitoring, detect failures or issues during delivery or in production.\n- Automate testing throughout the software delivery process.\n\nBefore DevOps, software delivery was slow and manual. Separate teams handled coding, server setup, testing, and deployment, leading to delays and frequent errors due to lack of automation.\n\nWith DevOps, the process is fast, automated, and collaborative. Using tools like Git, Jenkins, Docker, and Kubernetes, teams can build, test, and deploy code continuously, enabling deployment in hours instead of days.\n\n## 1. Understanding DevOps Fundamentals\n\nIn this section, we will cover the basic DevOps fundamentals and terminologies that are essential for a DevOps engineer.\n\n- [DevOps Introduction](https://www.geeksforgeeks.org/devops/introduction-to-devops/)\n- [DevOps Prerequisites](https://www.geeksforgeeks.org/devops/devops-prerequisites/)\n- [Lifecycle of DevOps](https://www.geeksforgeeks.org/devops/devops-lifecycle/)\n\n## 2. Linux for DevOps\n\nLinux is one of the most widely used operating systems for servers and cloud environment. This section introduces the core Linux concepts, commands, and networking essentials every DevOps engineer should know.\n\n- [What is Linux Operating System?](https://www.geeksforgeeks.org/linux-unix/introduction-to-linux-operating-system/)\n- [Linux Commands for DevOps](https://www.geeksforgeeks.org/linux-unix/linux-command-in-devops/)\n- [Network configuration and troubleshooting commands in Linux](https://www.geeksforgeeks.org/linux-unix/network-configuration-trouble-shooting-commands-linux/)\n- [SSH Server (sshd) Configuration and Security Options With Examples](https://www.geeksforgeeks.org/linux-unix/linux-ssh-server-sshd-configuration-and-security-options-with-examples/)\n\n> Learn Linux in Advance with our: [Linux Tutorial](https://www.geeksforgeeks.org/linux-unix/linux-tutorial/)\n\n## 3. Source Code Management\n\nSource Code Management is one of the key aspects of DevOps. Git is considered to be one of the best tools for version control of source codes. In this section on Source Code Management, we'll explore the fundamentals of version control using tools like Git, GitHub, GitLab, and Bitbucket.\n\n- [Introduction and Installation of Git](https://www.geeksforgeeks.org/git/git-introduction/)\n- [How Git Version Control Works?](https://www.geeksforgeeks.org/blogs/how-git-version-control-works/)\n- [Useful Git Commands and Basic Concepts](https://www.geeksforgeeks.org/git/useful-git-commands-and-basic-concepts/)\n- [Introduction to GitHub](https://www.geeksforgeeks.org/git/introduction-to-github/)\n- [List of useful GitHub Commands](https://www.geeksforgeeks.org/git/useful-github-commands/)\n- [Difference Between GitLab and GitHub](https://www.geeksforgeeks.org/git/difference-between-gitlab-and-github/)\n- [How to setup GitLab Repo in Windows 10](https://www.geeksforgeeks.org/techtips/setup-gitlab-repository-windows-10/)\n- [Bitbucket vs GitHub Vs GitLab](https://www.geeksforgeeks.org/git/bitbucket-vs-github-vs-gitlab/)\n\n> To learn Git in advance, refer: [Git Tutorial](https://www.geeksforgeeks.org/git/git-tutorial/)\n\n### CI/CD in DevOps\n\nCI/CD stands for Continuous Integration and Continuous Deployment/Delivery. It is a core DevOps practice that automates the process of building, testing, and deploying code changes to production faster and more reliably.\n\n- [What is CI/CD?](https://www.geeksforgeeks.org/devops/what-is-ci-cd/)\n- [What is Jenkins?](https://www.geeksforgeeks.org/devops/what-is-jenkins/)\n- [Understanding Jenkins CI/CD Pipeline And Its Stages](https://www.geeksforgeeks.org/devops/understanding-jenkins-ci-cd-pipeline-and-its-stages/)\n- [How to Make a CI-CD Pipeline in Jenkins?](https://www.geeksforgeeks.org/devops/how-to-make-a-ci-cd-pipeline-in-jenkins/)\n\n> To learn Jenkins in advance, refer: [Jenkins Tutorial](https://www.geeksforgeeks.org/devops/jenkins-tutorial/)\n\n## 4. Scripting Language for DevOps\n\nScripting language is essential in DevOps as it helps automate repetitive tasks, reduces errors, and saves time. Languages like Bash, YAML, and Python are widely used.\n\n- [What is YAML?](https://www.geeksforgeeks.org/linux-unix/what-type-of-language-is-yaml/)\n- [YAML Comments](https://www.geeksforgeeks.org/html/yaml-comments/)\n- [How to block comments in YAML](https://www.geeksforgeeks.org/techtips/how-to-block-comments-in-yaml/)\n- [Difference between YAML and JSON](https://www.geeksforgeeks.org/html/what-is-the-difference-between-yaml-and-json/)\n- [Python For DevOps: A Complete Guide For Beginners](https://www.geeksforgeeks.org/devops/python-for-devops/)\n- [How to run python script](https://www.geeksforgeeks.org/python/how-to-run-a-python-script/)\n- [Introduction to Linux Shell Scripting](https://www.geeksforgeeks.org/linux-unix/introduction-linux-shell-shell-scripting/)\n- [How to create a Shell Script](https://www.geeksforgeeks.org/linux-unix/how-to-create-a-shell-script-in-linux/)\n- [Introduction to Bash and Bash Scripting](https://www.geeksforgeeks.org/linux-unix/bash-scripting-introduction-to-bash-and-bash-scripting/)\n\n## 5. Starting With A Cloud Platform\n\nCloud computing is essential as it powers most modern applications through platforms like AWS, Azure, and Google Cloud.\n\n- [AWS Tutorial](https://www.geeksforgeeks.org/devops/aws-tutorial/)\n- [Microsoft Azure Tutorial](https://www.geeksforgeeks.org/devops/microsoft-azure/)\n- [Google Cloud Platform Tutorial](https://www.geeksforgeeks.org/devops/google-cloud-platform-tutorial/)\n\n## 6. Docker\n\nDocker is a popular containerization tool that is used to deliver software quickly by using the concept of containerized code which helps for easy management and maintenance of applications.\n\n- [Introduction to Docker](https://www.geeksforgeeks.org/devops/introduction-to-docker/)\n- [Docker Architecture](https://www.geeksforgeeks.org/devops/architecture-of-docker/)\n- [Docker Commands](https://www.geeksforgeeks.org/devops/docker-instruction-commands/)\n- [Dockerfile](https://www.geeksforgeeks.org/cloud-computing/what-is-dockerfile/)\n- [Docker Images](https://www.geeksforgeeks.org/devops/what-is-docker-image/)\n- [Introduction to Docker Compose](https://www.geeksforgeeks.org/devops/docker-compose/)\n- [Docker Storage](https://www.geeksforgeeks.org/cloud-computing/data-storage-in-docker/)\n- [Docker Networking](https://www.geeksforgeeks.org/devops/basics-of-docker-networking/)\n- [Docker Ports](https://www.geeksforgeeks.org/devops/docker-managing-ports/)\n- [Docker Registry](https://www.geeksforgeeks.org/devops/what-is-docker-registry/)\n\n> To learn Docker in advance, refer: [Docker Tutorial](https://www.geeksforgeeks.org/devops/docker-tutorial/)\n\n## 7. Kubernetes\n\nKubernetes is used to orchestrate and manage Docker containers at scale.\n\n- [Introduction to Kubernetes](https://www.geeksforgeeks.org/devops/introduction-to-kubernetes-k8s/)\n- [Kubernetes Deployments](https://www.geeksforgeeks.org/devops/kubernetes-deployment/)\n- [Kubernetes Volumes](https://www.geeksforgeeks.org/devops/kubernetes-volumes/)\n- [Kubernetes Secrets](https://www.geeksforgeeks.org/devops/kubernetes-secrets/)\n- [Kubernetes Kubectl](https://www.geeksforgeeks.org/devops/kubernetes-kubectl/)\n- [Kubernetes ConfigMap](https://www.geeksforgeeks.org/devops/kubernetes-configmap/)\n\n> To learn Kubernetes in advance, refer: [Kubernetes Tutorial](https://www.geeksforgeeks.org/devops/kubernetes-tutorial/)\n\n## 8. Infrastructure as a Code\n\nIaC enables automating and configuring the infrastructure resources using various tools such as Terraform, CloudFormation, ARM Templates, etc.\n\n- [Introduction to Terraform](https://www.geeksforgeeks.org/devops/what-is-terraform/)\n- [Terraform Syntax With Examples](https://www.geeksforgeeks.org/devops/terraform-syntax-with-examples/)\n- [Introduction to AWS Cloudformation](https://www.geeksforgeeks.org/cloud-computing/aws-cloudformation/)\n- [AWS CloudFormation Templates](https://www.geeksforgeeks.org/devops/aws-cloudformation-templates/)\n- [Automation using Chef](https://www.geeksforgeeks.org/software-engineering/automation-using-chef/)\n- [Using Ansible to Manage Remote Machines](https://www.geeksforgeeks.org/devops/using-ansible-to-manage-remote-machines/)\n\n> To learn more, you can refer to [Complete DevOps Roadmap – Beginner to Advanced](https://www.geeksforgeeks.org/devops/devops-roadmap/)\n\n## DevOps Course by GeeksforGeeks\n\nLearn DevOps step by step with GeeksforGeeks DevOps courses. These self-paced programs cover everything from Linux, Git, Docker, and Kubernetes to CI/CD, Jenkins, Terraform, Ansible, and cloud platforms like AWS and Azure—helping you build and deploy real-world projects\n\n- **[DevOps Bootcamp - Self-Paced Course](https://www.geeksforgeeks.org/courses/devops-bootcamp)**\n- **[DevOps Engineering - Planning to Production](https://www.geeksforgeeks.org/courses/devops-live?source=google&medium=cpc&device=c&keyword=devops%20course&matchtype=b&campaignid=19646466219&adgroup=146286121336&gclid=Cj0KCQiApKagBhC1ARIsAFc7Mc6sSr1tHAdZyU_UK1bBAb5EhQFB6Wlk28WE5GX0TWix92sW1uDNdm4aAn6ZEALw_wcB)**\n\n## DevOps Interview Questions\n\nHere are the top 70 most commonly asked DevOps interview questions, covering essential topics like CI/CD, configuration management, containerization, cloud services, infrastructure as code, and monitoring tools.\n\n- [DevOps Interview Questions and Answers](https://www.geeksforgeeks.org/devops/devops-interview-questions/)\n\n### Important Links\n\n- [DevOps Engineer - Salary, Skills & Career Guide](https://www.geeksforgeeks.org/devops/devops-engineer-salary-and-skills-required/)\n- [Companies That Use DevOps](https://www.geeksforgeeks.org/devops/companies-that-use-devops/)\n- [Careers and Jobs in DevOps](https://www.geeksforgeeks.org/devops/careers-and-jobs-in-devops/)\n\n## Is DevOps for Freshers?\n\nDevOps is a hot topic in the IT industry and lots of companies now need a DevOps Engineer to manage their servers, code deployment process, and maintenance of their applications. If you also want to join any organization as a DevOps Engineer without any prior work experience, then it is very important for you to follow these certain tips to get into the world of DevOps.\n\n1. **Learn the Fundamentals listed above**\n2. **Gain Hands-on knowledge by practicing and building projects**\n3. **Try to learn and master automation**\n4. **Develop soft skills**\n5. **Network with professionals**\n6. **Always be in the loop of learning and implementing.**"}
{"reference": "https://www.geeksforgeeks.org/courses/ai-tools-skill-up", "content": "# AI Tools Skill Up\n\nSelf-Paced Course\n\n28k+ interested Geeks\n\nThe AI Tools and Prompt Engineering Course is a 5-week program teaching practical skills in AI applications like prompt engineering, code generation, voice synthesis, image/video creation, and research. Learners master tools like **ChatGPT**, **Gemini**, **ElevenLabs**, **DALL-E**, and **Perplexity AI** through theory and hands-on projects, enabling them to build and automate intelligent workflows with expertise.\n\n**Duration:** 5 Weeks\n\n## Course Overview\n\nExplore the exciting world of AI with our AI Tools and Prompt Engineering Course! This dynamic 5-week journey blends engaging lectures, hands-on labs, and real-world projects to transform you into an AI powerhouse. Master prompt engineering, turbocharge your coding with AI-powered IDEs, create stunning voice and media content, and unlock cutting-edge research tools. By the end, you'll confidently build and deploy AI-driven solutions, all while championing ethical and practical best practices. Get ready to shape the future with AI!\n\n## AI Tools Course Highlights\n\n- Learn to write clear AI prompts\n- Code faster with tools like GitHub Copilot and Cursor AI\n- Make voice audio with ElevenLabs and Speechify\n- Create images and videos with DALL-E and Sora\n- Research better with Notebook LM and Perplexity AI\n- Use AI safely and responsibly\n- Work with Google Colab for AI coding\n- Automate tasks with n8n\n- Learn simple ways to use AI tools\n\n## Course Content\n\n### Week 1: Introduction to AI & Prompt Engineering\n\n- What is AI?\n- AI Ethics: Challenges, Importance, and Future\n- How to Run LLMs Model Locally\n- AI Prompts Basics\n- Zero-Shot and One-Shot Prompts\n- Chain of Thought Prompts\n- Role and Context Prompts\n- Advanced Reasoning Prompts\n- Prompt Optimization\n- AI Guardrails\n\n### Week 2: AI-Tools for Coding\n\n- Code Generation Tools like DeepSeek ChatGPT and more\n- Google Colab\n- Learn AI-Powered IDEs like Cursor AI, Windsurf, WARP\n- Explore Replit, Firebase Studio, Bolt, and Lovable\n- Learn Code Rabbit and Cursor BugBot\n- AI Automation and Project with n8n\n\n### Week 3: AI Tools for Voice Generation\n\n- Learn about text-to-speech and voice cloning\n- Learn Text-to-Speech with ElevenLabs\n- Voice Cloning with ElevenLabs\n- Use Speechify to turn text into speech\n- Advanced use case of Speechify\n- Learn about Resemble.ai\n\n### Week 4: AI Tools for Image and Video Generation\n\n- Use Adobe Firefly to make images\n- Learn about Sora\n- Explore Veo 2 for video generation.\n- Create images with DALL-E\n- Make images with Leonardo AI\n- Use Picsart AI for pro images"}
{"reference": "https://www.geeksforgeeks.org/data-analysis/data-analysis-tutorial/", "content": "# Data Analysis (Analytics) Tutorial\n\n****Data Analytics**** is a process of examining, cleaning, transforming and interpreting data to discover useful information, draw conclusions and support decision-making. It helps businesses and organizations understand their data better, identify patterns, solve problems and improve overall performance.\n\n> ****Do you wish to learn Data Analytics in scheduled manner?**** **Try our ongoing free course** [Data Analytics Skillup](https://www.geeksforgeeks.org/courses/data-analytics-skill-up) **with weekly topic coverage, notes, daily quizzes and coding problems.**\n\n## Tools & Skills for Data Analytics\n\nTo strong skill for Data Analysis we needs to learn this resources to have a best practice in this domains.\n\n* [Python For Data Analytics](https://www.geeksforgeeks.org/data-analysis/data-analysis-with-python/)\n* [SQL For Data Analytics](https://www.geeksforgeeks.org/sql/sql-data-analysis/)\n* [Excel for Data Analytics](https://www.geeksforgeeks.org/excel/data-analysis-in-excel/)\n* [Power BI](https://www.geeksforgeeks.org/power-bi/power-bi-tutorial/) / [Tableau](https://www.geeksforgeeks.org/tableau/tableau-tutorial/)\n* [Mathematics](https://www.geeksforgeeks.org/blogs/maths-for-data-science/) & [Statistics for Data Analysis](https://www.geeksforgeeks.org/data-science/statistics-for-data-science/)\n\n## Data Analysis Libraries\n\nGain hands-on experience with the most powerful Python libraries:\n\n* [****Pandas****:](https://www.geeksforgeeks.org/pandas/pandas-tutorial/) Data manipulation and analysis\n* [****NumPy****:](https://www.geeksforgeeks.org/python/numpy-tutorial/) Numerical operations and matrix handling\n* [****Matplotlib****](https://www.geeksforgeeks.org/python/matplotlib-tutorial/)**/**[****Seaborn****](https://www.geeksforgeeks.org/python/python-seaborn-tutorial/): Data visualization\n* [****Scikit-learn****](https://www.geeksforgeeks.org/machine-learning/what-is-python-scikit-library/): Data preprocessing and statistical modeling\n\n## Understanding the Data\n\nBefore starting any analysis it’s important to understand the type and structure of your data. This helps you choose the right methods for cleaning, exploring and analyzing it.\n\n* [What is Data?](https://www.geeksforgeeks.org/data-science/what-is-data/)\n* [Sample vs Population](https://www.geeksforgeeks.org/machine-learning/population-and-sample-statistics/)\n* [Qualitative vs Quantitative Data](https://www.geeksforgeeks.org/maths/difference-between-qualitative-and-quantitative-data/)\n* [Univariate vs Multivariate Data](https://www.geeksforgeeks.org/data-analysis/univariate-bivariate-and-multivariate-data-and-its-analysis/)\n* [Nominal, Ordinal, Interval and Ratio Scales](https://www.geeksforgeeks.org/engineering-mathematics/scales-of-measurement/)\n\n## Reading and Loading Datasets\n\n****Reading and Loading Datasets**** is the first step in data analysis where you import data from files like CSV, Excel or databases into your working environment such as Python or Excel so you can explore, clean and analyze it.\n\n* [Reading CSV](https://www.geeksforgeeks.org/pandas/python-read-csv-using-pandas-read_csv/), [Excel](https://www.geeksforgeeks.org/python/working-with-excel-files-using-pandas/) and [JSON files](https://www.geeksforgeeks.org/python/working-with-json-data-in-python/)\n* [Exporting dataframes to CSV](https://www.geeksforgeeks.org/python/export-pandas-dataframe-to-a-csv-file/)/[JSON](https://www.geeksforgeeks.org/python/exporting-pandas-dataframe-to-json-file/)\n* [Slicing, Indexing, Manipulating and Cleaning DataFrames](https://www.geeksforgeeks.org/data-science/slicing-indexing-manipulating-and-cleaning-pandas-dataframe/)\n\n## Data Preprocessing\n\nData preprocessing involves cleaning and transforming raw data into a usable format. It includes handling missing values, removing duplicates, converting data types and making sure the data is in the right format for accurate results.\n\n* [Data Preprocessing](https://www.geeksforgeeks.org/dbms/data-preprocessing-in-data-mining/)\n* [What is Data Cleaning?](https://www.geeksforgeeks.org/data-analysis/data-cleansing-introduction/)\n* [Handling Missing Data](https://www.geeksforgeeks.org/machine-learning/ml-handling-missing-values/)\n* [Handling outliers](https://www.geeksforgeeks.org/data-science/detect-and-remove-the-outliers-using-python/)\n* [Data Transformation](https://www.geeksforgeeks.org/data-analysis/what-is-data-transformation/)\n* [Feature Engineering](https://www.geeksforgeeks.org/machine-learning/ml-feature-scaling-part-2/)\n* [Data Sampling](https://www.geeksforgeeks.org/data-analysis/what-is-data-sampling-types-importance-best-practices/)\n\n## Exploratory Data Analysis (EDA)\n\n****Exploratory Data Analysis (EDA)**** in data analytics is the initial step of analyzing data through statistical summaries and visualizations to understand its structure, find patterns and prepare it for further analysis or decision-making.\n\n* [Exploratory Data Analysis in Python](https://www.geeksforgeeks.org/data-analysis/exploratory-data-analysis-in-python/)\n\n### Univariate Analysis\n\n* [Measures of Central Tendency](https://www.geeksforgeeks.org/maths/measures-of-central-tendency/)\n* [Measures of spread](https://www.geeksforgeeks.org/maths/measures-of-spread-range-variance-and-standard-deviation/), [IQR](https://www.geeksforgeeks.org/numpy/interquartile-range-and-quartile-deviation-using-numpy-and-scipy/)\n* [Skewness & Kurtosis](https://www.geeksforgeeks.org/python/how-to-calculate-skewness-and-kurtosis-in-python/)\n* Visualization: [Histograms](https://www.geeksforgeeks.org/data-science/histogram-meaning-example-types-and-steps-to-draw/), [Boxplots](https://www.geeksforgeeks.org/machine-learning/box-plot/), [Q-Q plots](https://www.geeksforgeeks.org/machine-learning/quantile-quantile-plots/)\n\n### Multivariate Analysis\n\n* [Correlation and Covariance](https://www.geeksforgeeks.org/engineering-mathematics/mathematics-covariance-and-correlation/)\n* [Cross-tabulation](https://www.geeksforgeeks.org/data-analysis/what-is-cross-tabulation-and-how-does-it-organize-data-in-a-table/)\n* [Cluster Analysis](https://www.geeksforgeeks.org/data-analysis/data-mining-cluster-analysis/), [MANOVA(Multivariate Analysis of Variance)](https://www.geeksforgeeks.org/r-language/manova-test-in-r-programming/), [Factor](https://www.geeksforgeeks.org/machine-learning/introduction-to-factor-analytics/) and [Canonical Correlation Analysis](https://www.geeksforgeeks.org/data-analysis/what-is-canonical-correlation-analysis/)\n\n## Data Visualization\n\nData visualization uses graphical representations such as charts and graphs to understand and interpret complex data.\n\n* [What is Data Visualization and Why is It Important?](https://www.geeksforgeeks.org/data-visualization/data-visualization-and-its-importance/)\n* [Visualization with Matplotlib](https://www.geeksforgeeks.org/data-visualization/data-visualization-using-matplotlib/)\n* [Visualization using Seaborn](https://www.geeksforgeeks.org/data-visualization/data-visualization-with-python-seaborn/)\n* [Visualization using Plotly](https://www.geeksforgeeks.org/data-visualization/using-plotly-for-interactive-data-visualization-in-python/)\n* [PowerBI](https://www.geeksforgeeks.org/power-bi/power-bi-tutorial/) and [Tableau](https://www.geeksforgeeks.org/tableau/tableau-tutorial/)\n\n## Probability & Statistics in Data Analytics\n\nIt help you understand data, find patterns and make smart decisions. Probability deals with chances and likelihoods, while statistics helps you collect, organize and interpret data to see what it tells you.\n\n* [Probability Distributions](https://www.geeksforgeeks.org/maths/probability-distribution/)\n* [Central Limit Theorem](https://www.geeksforgeeks.org/python/python-central-limit-theorem/)\n* [PDF vs CDF](https://www.geeksforgeeks.org/maths/cdf-vs-pdf-what-is-the-difference/)\n* [Confidence Intervals](https://www.geeksforgeeks.org/dsa/confidence-interval/)\n* [Z-score](https://www.geeksforgeeks.org/data-science/z-score-in-statistics/), [T-distribution](https://www.geeksforgeeks.org/engineering-mathematics/students-t-distribution-in-statistics/)\n* [P-Values](https://www.geeksforgeeks.org/machine-learning/p-value/) & [Hypothesis Testing](https://www.geeksforgeeks.org/software-testing/understanding-hypothesis-testing/)\n* [One-Tailed vs Two-Tailed Tests](https://www.geeksforgeeks.org/data-science/difference-between-one-tailed-and-two-tailed-tests/)\n* [Chi-Squared Tests](https://www.geeksforgeeks.org/machine-learning/chi-square-test-in-Data-Science-and-Data-Analytics/)\n* [Point Estimation](https://www.geeksforgeeks.org/maths/point-estimation/)\n\n## Time Series Data Analysis\n\n****Time Series Data Analysis**** is the process of studying data points collected or recorded over time like daily sales, monthly temperatures or yearly profits to find patterns, trends and seasonal changes that help in forecasting and decision-making.\n\n* [Define Time Series Data](https://www.geeksforgeeks.org/data-science/data-mining-time-series-symbolic-and-biological-sequences-data/)\n* [Data and Time function in Python](https://www.geeksforgeeks.org/python/basic-datetime-operations-in-python/)\n* [Time Series Data Plotting](https://www.geeksforgeeks.org/data-analysis/time-series-data-visualization-in-python/)\n* [Deal with missing values in a Time series](https://www.geeksforgeeks.org/python/how-to-deal-with-missing-values-in-a-timeseries-in-python/)\n* [Moving Averages](https://www.geeksforgeeks.org/pandas/how-to-calculate-moving-average-in-a-pandas-dataframe/) : [Stationarity](https://www.geeksforgeeks.org/python/how-to-check-if-time-series-data-is-stationary-with-python-2/), [Seasonality](https://www.geeksforgeeks.org/machine-learning/seasonality-detection-in-time-series-data/), [Trend](https://www.geeksforgeeks.org/python/what-is-a-trend-in-time-series/)\n* [Augmented Dickey-Fuller Test](https://www.geeksforgeeks.org/r-language/how-to-perform-an-augmented-dickey-fuller-test-in-r/)\n* [Autocorrelation](https://www.geeksforgeeks.org/machine-learning/autocorrelation/)\n\n*****You are now ready to explore real-world projects. For detailed guidance and project ideas refer to below article:*****\n\n> ### [Data Analytics Projects [With Source code]](https://www.geeksforgeeks.org/data-analysis/data-analyst-projects/)"}
{"reference": "https://www.geeksforgeeks.org/legal/privacy-policy/", "content": "# Privacy Policy\n\n## Privacy Statement\n\nWelcome to **GeeksforGeeks**.  \nSanchhaya Education Pvt. Ltd., registered and headquartered at 143A, Sovereign Corporate Towers, 9th Floor, Sector-136, NOIDA, Gautam Buddha Nagar, Uttar Pradesh, 201305, hereinafter referred to as [GeeksforGeeks](https://www.geeksforgeeks.org/) (“us”, “we”, or “our”) operates https://www.geeksforgeeks.org/ (hereinafter referred to as **“Service”**).  \n\nOur Privacy Policy governs your visit to https://www.geeksforgeeks.org/, and explains how we collect, safeguard and disclose information that results from your use of our Service.  \nBy using our services, you agree to the collection and use of information in accordance with this policy. Unless otherwise defined in this Privacy Policy, the terms used in this Privacy Policy have the same meanings as in our Terms and Conditions.  \nOur Terms and Conditions (**“Terms”**) govern all use of our Service and together with the Privacy Policy constitutes your agreement with us (**“agreement”**).\n\n## Definitions\n\n**Service** means the https://www.geeksforgeeks.org/ website & app operated by GeeksforGeeks.  \n**Personal Data** means data about a living individual who can be identified from that data (or from that and other information either in our possession or likely to come into our possession).  \n**Usage Data** is data collected automatically either generated by the use of Service or from Service infrastructure itself (for example, the duration of a page visit).  \n**Cookies** are small files stored on your device (computer or mobile device).  \n**Data Controller** means a natural or legal person who (either alone or jointly or in common with other persons) determines the purposes for which and the manner in which any personal data are, or are to be, processed. For the purpose of this Privacy Policy, we are a Data Controller of your data.  \n**Data Processors (or service providers)** means any natural or legal person who processes the data on behalf of the Data Controller. We may use the services of various Service Providers in order to process your data more effectively.  \n**Data subject** is any living individual who is the subject of Personal Data.  \n**The user** is the individual using our Service. The User corresponds to the Data Subject, who is the subject of Personal Data.\n\n## Information Collection and Use\n\nWe collect several different types of information for various purposes to provide and improve our Service to you.\n\n### Types of Data Collected\n\n#### Personal Data\n\nWhile using our Service, we may ask you to provide us with certain personally identifiable information that can be used to contact or identify you (**“Personal Data”**). Personally identifiable information may include, but is not limited to your name, email address, phone number, the contents of the message and/or attachments you may send us, and any other information you may choose to provide.  \nWe may use your Personal Data to contact you with newsletters, marketing or promotional materials and other information that may be of interest to you. You may opt out of receiving any, or all, of these communications from us by following the unsubscribe link.\n\n#### Usage Data\n\nWe may also collect information that your browser/app sends whenever you visit our Service or when you access Service by or through any device (**“Usage Data”**).  \nThis Usage Data may include information such as your computer’s Internet Protocol address (e.g. IP address), browser/app type, browser version, the pages of our Service that you visit, the time and date of your visit, the time spent on those pages, unique device identifiers and other diagnostic data.  \nWhen you access Service with a device, this Usage Data may include information such as the type of device you use, your device unique ID, the IP address of your device, your device operating system, the type of Internet browser you use, unique device identifiers and other diagnostic data.\n\n#### Location Data\n\nWe may use and store information about your location if you give us permission to do so (**“Location Data”**). We use this data to provide features of our Service, to improve and customize our Service.  \nYou can enable or disable location services when you use our Service at any time by way of your device settings.\n\n#### Tracking Cookies Data\n\nWe use cookies and similar tracking technologies to track the activity on our Service and we hold certain information.  \nCookies are files with a small amount of data which may include an anonymous unique identifier. Cookies are sent to your browser or application from a website and stored on your device. Other tracking technologies are also used such as beacons, tags and scripts to collect and track information and to improve and analyse our Service.  \nYou can instruct your browser/app to refuse all cookies or to indicate when a cookie is being sent. However, if you do not accept cookies, you may not be able to use some portions of our Service.  \nExamples of Cookies we use:  \nI. **Session Cookies:** We use Session Cookies to operate our Service.  \nII. **Preference Cookies:** We use Preference Cookies to remember your preferences and various settings.  \nIII. **Security Cookies:** We use Security Cookies for security purposes.  \nIV. **Advertising Cookies:** Advertising Cookies are used to serve you with advertisements that may be relevant to you and your interests.\n\n#### Social Media Data\n\nWe may provide you with the option to register with us using your existing social media account details like your Facebook, Twitter or other social media account. If you choose to do this, we may receive certain profile information about you from your social media provider. The profile information we receive may vary based on the social media provider concerned, but will often include your name, email address, friends list, and profile picture, as well as anything else you choose to make public on such a social media platform. We shall only use this information as given in this privacy policy. For more information on personal information usage Third Party Social Media provider, please refer to the **‘Links to Other Sites’** section.\n\n#### Other Data\n\nWhile using our Service, we may also collect the following information: sex, age, date of birth, place of birth, passport details, citizenship, registration at place of residence and actual address, telephone number (work, mobile), details of documents on education, qualification, professional training, employment agreements, NDA agreements, information on bonuses and compensation, information on marital status, family members, social security (or other taxpayer identification) number, office location and other data.\n\n### Use of Data\n\nWe use the information we collect in various ways, including to:\n\n- Provide, operate, and maintain our website & app\n- Improve, personalize, and expand our website & app\n- Understand and analyse how you use our website & app\n- Develop new products, services, features, and functionality\n- Communicate with you, either directly or through one of our partners, including for customer service, to provide you with updates and other information relating to the website & app, and for marketing and promotional purposes\n- Send you emails\n- Find and prevent fraud\n- Personalize Advertisements as per your interests and send you marketing and promotional content via Phone Calls, WhatsApp and Email.\n\n#### I. Log Files\n\nGeeksforGeeks follows a standard procedure of using log files. These files log visitors when they visit websites & app. All hosting companies do this as part of hosting services’ analytics. The information collected by log files include internet protocol (IP) addresses, browser type, Internet Service Provider (ISP), date and time stamp, referring/exit pages, and possibly the number of clicks. These are not linked to any information that is personally identifiable. The purpose of the information is for analyzing trends, administering the site, tracking users’ movement on the website & app, and gathering demographic information.\n\n#### II. Cookies and Web Beacons\n\nLike any other website & app, GeeksforGeeks uses ‘cookies’. These cookies are used to store information including visitors’ preferences, and the pages on the website & app that the visitor accessed or visited. The information is used to optimize the users’ experience by customizing our web page content based on visitors’ browser type and/or other information.\n\n#### III. DoubleClick DART Cookie\n\n→ Google, as a third party vendor, uses cookies to serve ads on GeeksforGeeks.  \n→ Google’s use of the DART cookie enables it to serve ads to our site’s visitors based upon their visit to GeeksforGeeks and other sites on the Internet.  \n→ Users may opt out of the use of the DART cookie by visiting the Google ad and content network privacy policy at the following URL – http://www.google.com/privacy_ads.html\n\n## Retention of Data\n\nWe retain all Personal Data in accordance with our data retention policy which abides by applicable Data Protection Laws. The retention period depends on the type of data and existence of the user’s account. We retain data for as long as the account stays active and delete it within 15 days after the account is deleted. If the user does not deactivate his/her account, we retain the data indefinitely.  \nUnless the user deletes their account, we will retain the user’s data for 15 days. If the user deletes their account, we will delete their data within 15 days, we do not have any feature for deactivation of the user account, therefore if the user wants to remove their data then they will have to delete their account.  \nWe will retain and use your Personal Data to the extent necessary to comply with our legal obligations (for example, if we are required to retain your data to comply with applicable laws), resolve disputes, and enforce our legal agreements and policies.  \nWe will also retain Usage Data for internal analysis purposes. Usage Data is generally retained for a shorter period, except when this data is used to strengthen the security or to improve the functionality of our Service, or we are legally obligated to retain this data for longer time periods.\n\n## Transfer of Data\n\nYour information, including Personal Data, may be transferred to – and maintained on – computers located outside of your state, province, country or other governmental jurisdiction where the data protection laws may differ from those of your jurisdiction.  \nIf you are located outside India and choose to provide information to us, please note that we transfer the data, including Personal Data, to India and process it there.  \nYour consent to this Privacy Policy followed by your submission of such information represents your agreement to that transfer.  \nGeeksforGeeks will take all the steps reasonably necessary to ensure that your data is treated securely and in accordance with this Privacy Policy and no transfer of your Personal Data will take place to an organisation or a country unless there are adequate controls in place including the security of your data and other personal information.\n\n## Disclosure of Data\n\nWe may release personal information when we believe in good faith that release is necessary to comply with the law; enforce or apply our conditions of use and other agreements; or protect the rights, property, or safety of GeeksforGeeks, our employees, our users, or others. This includes exchanging information with other companies and organizations for fraud protection and credit risk reduction.\n\n#### I. With Your Consent\n\nExcept as set forth above, you will be notified when your personal information may be shared with third parties, and will be able to prevent the sharing of this information.\n\n### Sharing of User Activity with Recruiters\n\nWe value your achievements and progress on our platform, and we believe that your accomplishments reflect your skills and dedication. By using our services, you agree that GeeksforGeeks may share certain activity information with potential recruiters to enhance your visibility and career opportunities.\n\nActivities that may be shared include, but are not limited to:\n\n- Participation and performance in coding challenges and contests\n- Progress and completion of courses\n- Problem-solving achievements and milestones\n\nThis information will be shared with the intention of showcasing your skills to potential employers who are seeking coding talent. Rest assured, we will never disclose sensitive information without your explicit consent.\n\n## Security of Data\n\nThe security of your data is important to us but remember that no method of transmission over the Internet or method of electronic storage is 100% secure. While we strive to use commercially acceptable means to protect your Personal Data, we cannot guarantee its absolute security.\n\n## Service Providers\n\nWe may employ third party companies and individuals to facilitate our Service (**“Service Providers”**), provide Service on our behalf, perform Service-related services or assist us in analysing how our Service is used.  \nThese third parties have access to your Personal Data only to perform these tasks on our behalf and are obligated not to disclose or use it for any other purpose.\n\n## Profile Visibility\n\nWhile employing our website & app, your profile shall be visible to other users and vice versa. Further, some activities that you engage in on our platform shall be broadcasted to other users. Your continued use of the GeeksforGeeks website & app shall constitute acceptance of this feature.\n\n## Analytics\n\nWe use Google Analytics on our website & app to\n\n- Monitor site traffic and behavior flows of users\n- Measure the effectiveness of on-site products\n- Measure the effectiveness of off-site marketing campaigns and tactics.\n\nGoogle has developed the Google Analytics opt-out browser add-on; if you want to opt out of Google Analytics, you can download and install the add-on for your web browser [here](https://tools.google.com/dlpage/gaoptout). We also use Fabric for our reporting of Application crashes and Analytics. For more information on their Terms of Use and Privacy Policy, click [here](https://fabric.io/terms).\n\n## CI/CD tools\n\nWe may use third-party Service Providers to automate the development process of our Service.\n\n## Advertising\n\nSome of the advertisers on our site may use cookies and web beacons. We may display personalized ads to our users. Each of our advertising partners has their own Privacy Policy for their policies on user data.\n\n## Payments\n\nWe may provide paid products and/or services within Service. In that case, we use third-party services for payment processing (e.g. payment processors).  \nWe will not store or collect your payment card details. That information is provided directly to our third-party payment processors whose use of your personal information is governed by their Privacy Policy. These payment processors adhere to the standards set by PCI-DSS as managed by the PCI Security Standards Council, which is a joint effort of brands like Visa, Mastercard, American Express and Discover. PCI-DSS requirements help ensure the secure handling of payment information.\n\n## Non-Transferability\n\nThe rights to a user account and paid courses may not be transferred or assigned to another account/person/entity, whether by sharing, requesting, operation of law, or otherwise. Any effort to share account rights, purchased courses, or any other privileges granted to the user is void and will not be considered. As a result, transferring account rights is not permitted.\n\n## Links to Other Sites\n\nOur Service may contain links to other sites that are not operated by us. If you click a third party link, you will be directed to that third party’s site. We strongly advise you to review the Privacy Policy of every site you visit.  \nWe have no control over and assume no responsibility for the content, privacy policies or practices of any third party sites or services. You can choose to disable cookies through your individual browser options. To know more detailed information about cookie management with specific web browsers, it can be found at the browsers’ respective websites & app.\n\n## Report Vulnerabilities\n\nYou can send a report regarding vulnerabilities to support@geeksforgeeks.org including the following:  \n- Vulnerability Description  \n- Affected URL(s)  \n- Steps to reproduce  \n- POC(Screenshot/Video)  \n- Resolution(Optional)  \nWe only accept vulnerability reports for the following domains:  \n[www.geeksforgeeks.org](http://www.geeksforgeeks.org) Auth.geeksforgeeks.org  \nWrite.geeksforgeeks.org  \nPractice.geeksforgeeks.org  \nScript.geeksforgeeks.org  \nIde.geeksforgeeks.org  \nApi.geeksforgeeks.org  \nUpon confirmation of the aforementioned vulnerabilities, we provide certificates and goodies to the individuals who reported the issue. Please note that we will only be able to provide the certificates and goodies if you are a resident of India. Furthermore, we do not provide monetary rewards.\n\n## Commercial Communication\n\nWe may still send you commercial communication even if you have chosen DND for your telecommunications service provider. If you want to enable DND, please email us at [support@geeksforgeeks.org](mailto:support@geeksforgeeks.org), and we won't send you any commercial communications.\n\n## Children’s Privacy\n\nOur Services are not intended for use by children under the age of 18 (**“Child”** or **“Children”**).  \nWe do not knowingly collect personally identifiable information from Children under 18. If you become aware that a Child has provided us with Personal Data, please contact us at support@geeksforgeeks.org. If we become aware that we have collected Personal Data from Children without verification of parental consent, we take steps to remove that information from our servers.\n\n## Update\n\nThis Privacy Policy was last updated on : **13 June 2023**  \nIf you require any more information or have any questions about our privacy policy, please feel free to contact us by email at GeeksforGeeks.  \n**Should we update, amend or make any changes to our privacy policy, those changes will be posted here.**\n\n## GDPR\n\n### DO EU/UK RESIDENTS HAVE SPECIFIC PRIVACY RIGHTS?\n\nThis information has been produced to help you understand everything you need to know about the way Sanchhaya Education collects, uses, and shares personal data, what your legal rights are and how to exercise them.\n\nWe hope you’ll take some time to read this document; we’ve tried to keep it all as simple as possible and to avoid jargon, and we’ll make our best efforts to keep you informed if there are any changes to the way we process your personal data in the future.\n\nSanchhaya Education takes its responsibility for protecting your data very seriously and we do advise you to get to know our practices. If there’s anything here you don’t understand, or if you want to ask any questions, please feel free to contact us.\n\n#### Who is the Data Controller?\n\nWe are Sanchhaya Education.\n\nRegistered address: A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)  \nor  \n8th FLOOR TOWER-B, B-808, ADVANT NAVIS BUSINESS PARK, SECTOR-142, NOIDA, Gautam Buddha Nagar, Uttar Pradesh,201305\n\nIn this document Sanchhaya Education may be referred to as “we”, “us”, or “our''.\n\n#### What kinds of Personal Data do we Process?\n\nSanchhaya Education collects personal data for various purposes; with that in mind we have created a list of the types of personal data that we may collect, either directly from yourself or from other sources, in order to achieve those purposes.\n\nThe kinds of personal data we may collect include:\n\n| Customer / Client | Name, email address, Phone numbers, the contents of the message and/or attachments you may send us, and any other information you may choose to provide. Sex, Age, DOB, Place of birth, Citizenship, registration at place of residence and actual address, education, qualification and professional training details, family members, social security (or other taxpayer identification) number. |\n| Applicant / Temp / Volunteer / Intern | CV, contact details. |\n| Candidate | CV, contact details, social security details, bank details, gender, parental information, Unified ID number. |\n| Pupil / Student | Contact details, payment details, educational details. |\n| Supplier / Trade | Contact details, bank details, taxation details, unified ID number, social security number. |\n| Content creators | Contact details, social security details, payment details, CV, bank details, gender, parental information, Unified ID number. |\n\n#### What are the reasons we collect Personal Data?\n\n##### Legal Obligations\n\nSanchhaya Education uses personal data firstly to fulfil any contractual obligations that exist between us and yourself. Where we request personal data be provided to enter into, or meet the terms of any such contract, you will be required to provide the relevant personal data or we will not be able to deliver the goods or services you want. In such cases the lawful basis of us processing the personal data is that it is necessary for the performance of a contract.\n\nWe are required by law to process personal data for purposes relating to our legal obligations, these include:\n\n| To provide for our financial commitments, or to relevant financial authorities. |\n| To comply with regulatory requirements and any self-regulatory schemes. |\n| To carry out required business operations and due diligence. |\n| To cooperate with relevant authorities for reporting criminal activity, or to detect and prevent fraud. |\n| To investigate any insurance claims, claims of any kind of harassment or of discrimination, or any other claim whereby the organisation may have to defend itself. |\n\n##### Consent\n\nWe may process Personal Data for the following purposes where we have received consent to do so:  \n| To inform you of goods and services provided by third-party organisations. |  \n| To provide personal data to third-party organisations for their own future marketing purposes. You can find the list of Third Parties we may share your information with above. |  \n| To offer goods, services, or activities to children. |  \n| To monitor people’s activities, either through online means or otherwise, to identify trends and/or behavioural patterns, or for profiling. |  \n| newsletters, marketing or promotional materials and other information that may be of interest to you |  \n| You may withdraw your consent for us to process your personal data for these purposes at any time; after a withdrawal of consent request is received, we may have to contact you to verify the request. Withdrawing your consent for us to process your personal data will not affect the lawfulness of the processing beforehand. |  \n| If you are under the age of 13, you must have permission from your parents or guardians to use our online services. This is called ‘parental consent’. If we find out that any person under the age of 13 is using our services without the proper parental consent, we may have to stop that service; this might include deleting your accounts and any data that you have added to them. |\n\n##### Legitimate Interests\n\nWe may process Personal Data for any of the following purposes, which are considered to be within our legitimate business interests:\n\n| To provide goods and services where it has been requested, |  \n| To inform people of goods and services we provide or offers that may interest them, |  \n| To send notification on subjects to individuals who have asked to be kept informed, |  \n| To improve the quality of the services we offer, and to better understand customers’ needs by requesting feedback, or reviews of the services provided, or sending survey forms, |  \n| To send notifications of any changes to the goods and/or services provided that may affect people, |  \n| To understand the scale of the customer base; for statistical analysis and market research, |  \n| To recognise when people re-engage with our organisation, |  \n| To allow the organisation to support and maintain our products in active service, |  \n| To provide reference information to third party organisations when necessary, |  \n| To improve the organisations website & app so content is delivered more efficiently, |  \n| To enhance the security measures in place that protect data we are responsible for, |  \n| To protect the organisation's assets |\n\n#### Where do we obtain Personal Data from?\n\nWe will collect personal data directly from you in various ways. This could include when you complete an online form, or if you provide the data directly to a representative of Sanchhaya Education.\n\n| We collect some personal data from publicly accessible sources such as: Recruitment platforms. |  \n| We may also gather personal data by any of the following methods: |  \n| From technical functionality that gathers data automatically from computer equipment when people visit our online platforms. |  \n| From platforms that make use of device settings that allow geographical location tracking, such as IP Address mapping, WiFi, GPS signals and cell tower positioning. |\n\n#### Who will we share your Personal Data with?\n\nTo achieve the above stated purposes for which we process your personal data, we may have to share your personal data with certain third parties.\n\nWe shall make all reasonable efforts to ensure that any third-party we share your personal data with is also compliant with data protection law.\n\n| The kinds of third parties we may share your personal data with include: |  \n| Organisation where it is necessary to provide goods or services. |  \n| Organisations where it is necessary to set up various resources. |  \n| Organisations that are acting as our marketing agents. |  \n| Regional and/or local government authorities. |\n\n#### Where will we store your Personal Data?\n\n| As a part of our standard business practices, we may transfer your personal data to organisations based in countries that have not been granted an adequacy decision under the General Data Protection Regulation. |  \n| Where data is transferred to such countries, we shall ensure that specific safeguards or derogations have been established. These might include where the data transfer is necessary in order to fulfil a contract between us and yourself, where we have received your specific consent after having made you aware of any risks involved, or where contracts are in place between us and the third-parties involved that ensure the recipient organisation has a suitable standard of data protection in place. |\n\n#### How long will we keep your Personal Data?\n\nWe will keep your personal data only for as long as required to achieve the purposes for which it was collected, in line with this privacy notice.\n\nThe following criteria are what determine the period for which we will keep your personal data:\n\n| Until we are no longer required to do so to comply with regulatory requirements or financial obligations. |  \n| Until we are no longer required to do so by any law we are subject to. |  \n| Until all purposes for which the data was originally gathered have become irrelevant or obsolete. |  \n| Until it has been requested that we no longer process the data and that it is erased; in some cases, where there is a remaining relevant or legal reason why we are required to keep this data, we may opt to restrict the amount of processing being conducted to what is absolutely necessary rather than erase it. |  \n| Data is retained for as long as an account stays active and it is then deleted within 15 days after the account is deleted. |\n\n#### Your Rights, Our Responsibility\n\nThere are several rights granted to you immediately upon providing us with your personal information; some of these are mentioned above. We’d like you to know that at Sanchhaya Education we take your rights seriously and will always conduct ourselves in a way that is considerate of our responsibility to serve your legal rights.\n\n##### The Right of Access\n\nThis grants you the right to confirm whether or not your personal data is being processed, and to be provided with relevant details of what those processing operations are and what personal data of yours is being processed.\n\nIf you would like access to the personal data we have about you, we ask that you contact us using the details below.\n\n##### The Right to Rectification\n\nThis one is fairly straightforward; if you notice that the data we have about you is inaccurate or incomplete, you may request we rectify the mistake. We will make every effort to respond to requests of this type immediately.\n\n##### The Right to Erasure\n\nOtherwise known as the ‘right to be forgotten’, this gives you the right to request your personal data be deleted.\n\nThis is not an absolute right; if you were to request that we erase your personal data, we would erase as much of that data as we could but may have to retain some information if it is necessary.\n\nWhere we have received a request for personal data to be erased, if it is necessary for us to retain some of that information we shall ensure that the remaining data is used only when and where it is absolutely necessary.\n\n##### The Right to Objection\n\nThe right to object is a basic freedom all democracies enjoy. If you wish to object to the way we use, or have used, your personal data you may do so freely.\n\n| The Right to Portability This is a legal right afforded to you that states we must pass on all of the details you have provided to us in a machine-readable format, either to your or to another provider of your choosing. |\n\n##### The Right to Complain\n\nWe will always try to maintain the highest standards and encourage the confidence our customers have in us as an organisation. To achieve this, we request that any complaints be first brought to our attention so we can properly investigate matters. If you would like to complain about Sanchhaya Education to a regulatory body, you may do so by contacting your local data protection supervisory authority.\n\nYou can access the Data Processing Agreement here - [Link](https://www.geeksforgeeks.org/legal/data-processing-agreement/)\n\n#### Sanchhaya Education Contact Details\n\nSanchhaya Education (GeeksForGeeks)\n\n8th FLOOR TOWER-B, B-808, ADVANT NAVIS BUSINESS PARK, SECTOR-142, NOIDA, Gautam Buddha Nagar, Uttar Pradesh,201305  \nor  \nA-143, 9th Floor, Sovereign Corporate Tower,  \nSector- 136, Noida, Uttar Pradesh (201305)\n\nLegal@geeksforgeeks.org\n\n| Who is the Sanchhaya Education Data Protection Officer? Ametros Group Ltd Lakeside Offices, Thorn Business Park Rotherwas Industrial Estate Hereford Herefordshire England HR2 6JT 0330 223 2246 dpo@ametrosgroup.com [www.ametrosgroup.com](http://www.ametrosgroup.com) |\n\n| Who is the Sanchhaya Education EU Representative? Ametros Ltd Unit 3D North Point House North Point Business Park New Mallow Road Cork Ireland gdpr@ametrosgroup.com [www.ametrosgroup.com](http://www.ametrosgroup.com) |\n\n| Who is the Sanchhaya Education UK Representative? Ametros Group Ltd Lakeside Offices, Thorn Business Park Rotherwas Industrial Estate Hereford Herefordshire England HR2 6JT gdpr@ametrosgroup.com [www.ametrosgroup.com](http://www.ametrosgroup.com) |\n\n## CCPA\n\n### DO CALIFORNIA RESIDENTS HAVE SPECIFIC PRIVACY RIGHTS?\n\nIf you are under 18 years of age, reside in California, and have a registered account with Services, you have the right to request removal of unwanted data that you publicly post on the Services. To request removal of such data, please contact us using the contact information provided below and include the email address associated with your account and a statement that you reside in California. We will make sure the data is not publicly displayed on the Services, but please be aware that the data may not be completely or comprehensively removed from all our systems if your data is required to provide services to you.\n\n### What categories of personal information do we collect?\n\nWe have collected the following categories of personal information in the past twelve (12) months:\n\n| Category | Examples | Collected | Disclosed | Sold |\n|----------|----------|-----------|-----------|------|\n| A. Identifiers | Contact details, such as real name, alias, postal address, telephone or mobile contact number, unique personal identifier, online identifier, Internet Protocol address, email address, and account name | YES | YES | NO |\n| B. Personal information categories listed in the California Customer Records statute | Name, contact information, education, employment, employment history, and financial information | YES | YES | NO |\n| C. Protected classification characteristics under California or federal law | Gender and date of birth | YES | YES | NO |\n| D. Commercial information | Transaction information, purchase history, financial details, and payment information | YES | YES | NO |\n| E. Biometric information | Fingerprints and voiceprints | NO | NO | NO |\n| F. Internet or other similar network activity | Browsing history, search history, online behavior, interest data, and interactions with our and other websites, applications, systems, and advertisements | YES | YES | NO |\n| G. Geolocation data | Device location | YES | YES | NO |\n| H. Audio, electronic, visual, thermal, olfactory, or similar information | Images and audio, video or call recordings created in connection with our business activities | YES | NO | NO |\n| I. Professional or employment-related information | Business contact details in order to provide you our Services at a business level or job title, work history, and professional qualifications if you apply for a job with us | YES | YES | NO |\n| J. Education Information | Student records and directory information | YES | YES | NO |\n| K. Inferences drawn from other personal information | Inferences drawn from any of the collected personal information listed above to create a profile or summary about, for example, an individual’s preferences and characteristics | YES | YES | NO |\n| L. Sensitive Personal Information | Account login information and precise geolocation | YES | YES | NO |\n\nWe will use and retain the aforementioned collected personal information as needed to provide the Services or until a user raises a deletion request. The details will be removed 15 days after the deletion request is received.\n\nCategory L information may be used, or disclosed to a service provider or contractor, for additional, specified purposes. You have the right to limit the use or disclosure of your sensitive personal information.\n\nWe may also collect other personal information outside of these categories through instances where you interact with us in person, online, or by phone or mail in the context of:\n\n- Receiving help through our customer support channels;\n- Participation in customer surveys or contests; and\n- Facilitation in the delivery of our Services and to respond to your inquiries.\n\n### How do we use and share your personal information?\n\nGeeksforGeeks collects and shares your personal information through:\n\n- Targeting cookies/Marketing cookies\n- Social media cookies\n- Beacons/Pixels/Tags\n- Click redirects: Ads.\n- Social media plugins: Google, Github, Linkedin, Apple, Facebook.. Such features may process your Internet Protocol (IP) address and track which page you are visiting on our website & app. We may place a cookie to enable the feature to work correctly. We have no control over how a Third Party app is storing or using your information, please go through their policy for the same.\n\nYou may contact us by email at **support@geeksforgeeks.org**, or by referring to the contact details at the bottom of this document. If you are using an authorized agent to exercise your right to opt out we may deny a request if the authorized agent does not submit proof that they have been validly authorized to act on your behalf.\n\n### Will your information be shared with anyone else?\n\nWe may disclose your personal information with our service providers pursuant to a written contract between us and each service provider. Each service provider is a for-profit entity that processes the information on our behalf, following the same strict privacy protection obligations mandated by the CCPA.\n\nWe may use your personal information for our own business purposes, such as for undertaking internal research for technological development and demonstration. This is not considered to be \"selling\" your personal information.\n\n### Your rights with respect to your personal data\n\n**Right to request deletion of the data — Request to delete**\n\nYou can ask for the deletion of your personal information. If you ask us to delete your personal information, we will respect your request and delete your personal information, subject to certain exceptions provided by law, such as (but not limited to) the exercise by another consumer of his or her right to free speech, our compliance requirements resulting from a legal obligation, or any processing that may be required to protect against illegal activities.\n\n**Right to be informed — Request to know**\n\nDepending on the circumstances, you have a right to know:\n\n- whether we collect and use your personal information;\n- the categories of personal information that we collect;\n- the purposes for which the collected personal information is used;\n- whether we sell or share personal information to third parties;\n- the categories of personal information that we sold, shared, or disclosed for a business purpose;\n- the categories of third parties to whom the personal information was sold, shared, or disclosed for a business purpose;\n- the business or commercial purpose for collecting, selling, or sharing personal information; and\n- the specific pieces of personal information we collected about you.\n\nIn accordance with applicable law, we are not obligated to provide or delete consumer information that is de-identified in response to a consumer request or to re-identify individual data to verify a consumer request.\n\n**Right to Non-Discrimination for the Exercise of a Consumer’s Privacy Rights**\n\nWe will not discriminate against you if you exercise your privacy rights.\n\n**Right to Limit Use and Disclosure of Sensitive Personal Information**\n\nYou have the right to direct us to limit its use of your sensitive personal information to that use which is necessary to perform the Services.\n\nPlease note that sensitive personal information that is collected or processed without the purpose of inferring characteristics about a consumer is not covered by this right, as well as the publicly available information.\n\nTo exercise your right to limit use, deletion and disclosure of sensitive personal information, please submit a request form by clicking [here](https://www.geeksforgeeks.org/about/contact-us/?ref=footer)\n\nUpon receiving your request, we will need to verify your identity to determine you are the same person about whom we have the information in our system. These verification efforts require us to ask you to provide information so that we can match it with information you have previously provided us.\n\nHowever, if we cannot verify your identity from the information already maintained by us, we may request that you provide additional information for the purposes of verifying your identity and for security or fraud-prevention purposes.\n\n**Other privacy rights**\n\n- You may object to the processing of your personal information.\n- You may request correction of your personal data if it is incorrect or no longer relevant, or ask to restrict the processing of the information.\n- You can designate an authorized agent to make a request under the CCPA on your behalf. We may deny a request from an authorized agent that does not submit proof that they have been validly authorized to act on your behalf in accordance with the CCPA.\n- You may request to opt out from future selling or sharing of your personal information to third parties. Upon receiving an opt-out request, we will act upon the request as soon as feasibly possible, but no later than fifteen (15) days from the date of the request submission.\n\nTo exercise these rights, you can contact us by email at support@geeksforgeeks.org, or by referring to the contact details at the bottom of this document. If you have a complaint about how we handle your data, we would like to hear from you.\n\n### CONTROLS FOR DO-NOT-TRACK FEATURES\n\nMost web browsers and some mobile operating systems and mobile applications include a Do-Not-Track (\"DNT\") feature or setting you can activate to signal your privacy preference not to have data about your online browsing activities monitored and collected. At this stage no uniform technology standard for recognizing and implementing DNT signals has been finalized. As such, we do not currently respond to DNT browser signals or any other mechanism that automatically communicates your choice not to be tracked online. If a standard for online tracking is adopted that we must follow in the future, we will inform you about that practice in a revised version of this privacy notice.\n\n## Copyright Infringement and DMCA\n\nThis site is an Internet “service provider” under the Digital Millennium Copyright Act, 17 U.S.C. Section 512 (“DMCA”). For concerns related to copyright infringement and DMCA Notice, you may visit this [page](https://www.geeksforgeeks.org/about/contact-us/?ref=footer) and submit a query for the same. If the posted material is believed in good faith by us to violate any applicable law, we will remove or disable access to any such material, and we will notify the posting party that the material has been blocked or removed.  \nIn notifying us of alleged copyright infringement, the DMCA requires that you include the following information:  \n1. Name of publisher of the website & app Maths-Formulas app/blog or the claimant.  \n2. Link to the infringed content.  \n3. Link to the content on your website & app or blog.  \n4. Date on which the content was published on your website & app or blog.  \n5. A statement by you that you have a good faith belief that the material in the manner complained of is not authorized by the copyright owner, or its agent, or by the operation of any law;  \n6. A statement by you, signed under penalty of perjury, that the information in the notification is accurate and that you have the authority to enforce the copyrights that are claimed to be infringed; and  \n7. Claimant’s contact details.  \nRest assured that if it is determined that any copyright rights have been violated, we will take the appropriate measures.\n\n## COOKIE POLICY\n\nA cookie is a small piece of data that a website & app asks your browser to store on your computer or mobile device. The cookie allows the website & app to “remember” your actions or preferences over time.\n\nMost browsers support cookies, but users can set their browsers to decline them and can delete them whenever they like.\n\nIf you use GeeksforGeeks, both GeeksforGeeks and third parties will use cookies to track and monitor some of your activities on and off GeeksforGeeks, and store and access some data about you, your browsing history, and your usage of GeeksforGeeks.\n\nThis policy describes how both GeeksforGeeks and other third parties use cookies both within and without GeeksforGeeks and how you can exercise a better control over cookies. Please keep in mind that this may alter your experience with our platform, and may limit certain features (including being logged in as a user).\n\n**General Browsing:** We use cookies that are important for certain technical features of our website & app, like logging into user accounts and implementing fixes and improvements to our platform.\n\nThese cookies help us:\n\n- Remember users’ custom preferences and help create more useful products\n- Allow users to opt out of certain types of modeling, tailoring, or personalization in our products\n- Collect information on our users’ preferences in order to create more useful products\n- Cookies can also be used for online behavioral target advertising and to show adverts relevant to something that the user searched for in the past\n\n**Advertising:** We use cookies to enable advertising with our third-party Partners, which in turn allows us to provide many of our services free of charge.\n\nThese cookies:\n\n- Customize the ad experience for our users, including tailoring job and display ads to the technologies a person has previously looked at, the communities a person has visited, and the job ads a person has already seen\n- Allow direct communication between a 3rd party partner who hosts a promotional event with us, and users who have opted into the promotion\n- Allow us to track when a GeeksforGeeks user sees or clicks on an ad or later visits a third-party website & app or purchases a product on a third-party website & app\n- Collect impressions and click data for internal reporting and product optimization\n\n**Analytics:** We use cookies to compile usage activity in order to better cater our Products and Services offerings to you, and to third parties. We DO NOT share identifiable “raw” data with our clients or any third parties, however we do make high-level decisions based on aggregated data about your usage of our Products and Services.\n\nThese cookies:\n\n- Monitor site traffic and behavior flows of users\n- Measure the effectiveness of on-site products\n- Measure the effectiveness of off-site marketing campaigns and tactics\n\n### WHAT INFORMATION IS COLLECTED ON ME VIA COOKIES?\n\nIn general, we collect most data from you via form submission. However, there are cases when visiting our site and/or using our platforms in which we may receive certain information through the use of cookies. This data will generally not include personally identifying information about you.\n\n- Unique identification tokens\n- User preferences\n\n**Third Party Cookies**\n\nThe use of cookies, the names of cookies, and other cookies related to cookie technology may change over time and GeeksforGeeks will make all reasonable efforts to notify you. Please also note that companies and other organizations that sponsor pages on GeeksforGeeks may use cookies or other technologies to learn more about your interest in their products and services and in some cases to tailor such products and services to you.\n\n### HOW DO I RESTRICT COOKIES?\n\nPlease note that GeeksforGeeks may not work properly and you may have diminished functionality if you wish to opt-out of certain cookies.\n\nIf you decide that you do not want cookies to be set on your device by our third-party Partners, you can adjust the settings on your internet browser and choose from the available Cookies setting to best meet your preferences. While setting options may vary from browser to browser, you can generally choose to reject some or all cookies, or instead to receive a notification when a cookie is being placed on your device. For more information, please refer to the user help information for your browser of choice. Please keep in mind that cookies may be required for certain functionalities, and by blocking these cookies, you may limit your access to certain parts or features of our sites and platforms.\n\nFinally, while cookies are set for varying durations on your device, you can manually delete them at any time. However, deleting cookies will not prevent the site from setting further cookies on your device unless you adjust the settings discussed above.\n\nFor any query, you can reach out to our [help center](https://www.geeksforgeeks.org/about/contact-us/?ref=footer)"}
{"reference": "https://www.geeksforgeeks.org/interview-corner/", "content": "# Interview Corner\n\n**Last Updated: 20 Sep, 2025**\n\nThis article serves as your **one-stop guide to interview preparation**, designed to help you succeed across different experience levels and company expectations. Here is what you should expect in a Tech Interview, please remember the following points:\n\n- Tech Interview Preparation does not have any fixed syllabus. Different companies, roles, and hiring managers have their own approaches. However, a few patterns have become standard over the years.\n- One thing is, most of the companies take an online round first where they check your problem-solving skills using coding problems. Once you qualify the online coding round, you go to the next face-to-face technical rounds, that includes live coding and domain specific discussions.\n- **For students**, the most important topics are Data Structures and Algorithms (DSA), Object Oriented Programming (OOP), DBMS, OS, SQL, Web Development basics, AI, ML, and Data Science basics. Some companies ask Aptitude, Puzzle, and Design (Low Level and High Level) as well for internship.\n- **For early working professionals**, the process and topics are almost same as freshers, with addition of questions related to previous work experience and technologies they've previously used.\n- For more **experienced working professionals**, the process varies a lot. Some top product-based companies like Google ask DSA for all levels. However, there is going to be a lot more focus on System Design and technologies used in the previous companies.\n\nLet us now explore different interview resources.\n\n## DSA\n\n- [GFG 160](https://www.geeksforgeeks.org/courses/gfg-160-series) - A complete list of top 160 questions + 90 bonus questions with editorials and video explanations.\n- [DSA 360](https://www.geeksforgeeks.org/courses/dsa-skill-up) - Try our ongoing free course with weekly topic coverage with mock contests, short notes, daily problems and quizzes.\n\n## LLD and HLD\n\n- [System Design Tutorial](https://www.geeksforgeeks.org/system-design/system-design-tutorial/)\n- [Design Patterns Interview Questions](https://www.geeksforgeeks.org/system-design/top-design-patterns-interview-questions/)\n- [System Design SkillUp](https://www.geeksforgeeks.org/courses/system-design-skill-up) - Try our ongoing free course with weekly topic coverage with mock contests, short notes, daily problems and quizzes.\n\n## DevOps\n\nHere are top resources to prepare for DevOps interviews, including cloud computing and AWS-specific roles\n\n- [DevOps Interview Questions](https://www.geeksforgeeks.org/devops/devops-interview-questions/)\n- [AWS Interview Questions](https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/)\n- [Google Cloud Platform (GCP) Interview Questions](https://www.geeksforgeeks.org/devops/google-cloud-platform-interview-questions/)\n- [DevOps SkillUp](https://www.geeksforgeeks.org/courses/devops-skill-up) - Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Interview Experiences\n\n- [Interview Experiences for all roles](https://www.geeksforgeeks.org/category/experiences/interview-experiences/)\n\n## Web Development\n\n- [Full Stack Interview Questions](https://www.geeksforgeeks.org/html/full-stack-developer-interview-questions-and-answers/)\n- [MERN Skillup](https://www.geeksforgeeks.org/courses/full-stack-web-dev-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Aptitude & Puzzles\n\n- [Aptitude Questions and Answers](https://www.geeksforgeeks.org/aptitude/aptitude-questions-and-answers/)\n- [Puzzles for Interviews](https://www.geeksforgeeks.org/aptitude/puzzles/)\n- [Aptitude & Reasoning Skillup](https://www.geeksforgeeks.org/courses/aptitude-and-reasoning-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n- [100 Days of Interview Puzzles SkillUp](https://www.geeksforgeeks.org/courses/100-days-of-interview-puzzles-skill-up) - Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Computer Subjects\n\n- [Commonly asked Computer Subject Interview Questions](https://www.geeksforgeeks.org/courses/cs-core-subjects-skill-up)\n- [CS Core SkillUp](https://www.geeksforgeeks.org/courses/cs-core-subjects-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Python\n\n- [Python Interview Questions](https://www.geeksforgeeks.org/python/python-interview-questions/)\n- [Python SkillUp](https://www.geeksforgeeks.org/courses/python-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Data Science and Machine Learning\n\n- [Data Science Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-interview-questions-and-answers/)\n- [Data Science Coding Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-coding-interview-questions/)\n- [Machine Learning Interview Questions](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n- [Data Science SkillUp](https://www.geeksforgeeks.org/courses/ds-16): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Data Analytics\n\n- [Data Analyst Interview Questions](https://www.geeksforgeeks.org/data-science/data-analyst-interview-questions-and-answers/)\n- [Data Analytics SkillUp](https://www.geeksforgeeks.org/courses/data-analytics-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Software Testing\n\n- [Software Testing Interview Questions](https://www.geeksforgeeks.org/software-testing/software-testing-interview-questions/)\n- [Software Testing SkillUp](https://www.geeksforgeeks.org/courses/software-testing-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Mobile App Development (Android Development)\n\n- [Application Developer Interview Questions](https://www.geeksforgeeks.org/interview-experiences/application-developer-interview-questions/)\n- [Android Interview Questions for SDE I to SDE III](https://www.geeksforgeeks.org/android/top-50-android-interview-questions-answers-sde-i-to-sde-iii/)\n\n## Article Tags\n\n- [Experiences](https://www.geeksforgeeks.org/category/experiences/)\n- [Interview Preparation](https://www.geeksforgeeks.org/category/interview-preparation/)\n- [Interview Prep](https://www.geeksforgeeks.org/category/interview-prep/)\n\n## Explore\n\n- [DSA Tutorial - Learn Data Structures and Algorithms](https://www.geeksforgeeks.org/dsa/dsa-tutorial-learn-data-structures-and-algorithms/)\n- [System Design Tutorial](https://www.geeksforgeeks.org/system-design/system-design-tutorial/)\n- [Aptitude Questions and Answers](https://www.geeksforgeeks.org/aptitude/aptitude-questions-and-answers/)\n- [Web Development Technologies](https://www.geeksforgeeks.org/web-technology/)\n- [AI, ML and Data Science Tutorial](https://www.geeksforgeeks.org/machine-learning/ai-ml-and-data-science-tutorial-learn-ai-ml-and-data-science/)\n- [DevOps Tutorial](https://www.geeksforgeeks.org/devops/devops-tutorial/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/", "content": "# Regularization in Machine Learning\n\nRegularization is a technique used in machine learning to prevent overfitting and performs poorly on unseen data. By adding a penalty for complexity, regularization encourages simpler, more generalizable models.\n\n- **Prevents overfitting**: Adds constraints to the model to reduce the risk of memorizing noise in the training data.\n- **Improves generalization**: Encourages simpler models that perform better on new, unseen data.\n\n## Types of Regularization\n\nThere are mainly 3 types of regularization techniques, each applying penalties in different ways to control model complexity and improve generalization.\n\n### 1. Lasso Regression\n\nA regression model which uses the **L1 Regularization** technique is called **[LASSO (Least Absolute Shrinkage and Selection Operator)](https://www.geeksforgeeks.org/machine-learning/what-is-lasso-regression/)** regression. It adds the **absolute value of magnitude** of the coefficient as a penalty term to the loss function(L). This penalty can shrink some coefficients to zero which helps in selecting only the important features and ignoring the less important ones.\n\n> $\\rm{Cost} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y_i})^2 +\\lambda \\sum_{i=1}^{m}{\\|w_i\\|}$\n\nWhere\n\n- m - Number of Features\n- n - Number of Examples\n- $y_i$ - Actual Target Value\n- $\\hat{y}_i$ - Predicted Target Value\n\nLet's see how to implement this using python:\n\n- **X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)** : Generates a regression dataset with 100 samples, 5 features and some noise.\n- **X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)** : Splits the data into 80% training and 20% testing sets.\n- **lasso = Lasso(alpha=0.1)** : Creates a Lasso regression model with regularization strength alpha set to 0.1.\n\n```python\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_regression\nfrom sklearn.metrics import mean_squared_error\n\nX, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nlasso = Lasso(alpha=0.1)\nlasso.fit(X_train, y_train)\n\ny_pred = lasso.predict(X_test)\n\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")\n\nprint(\"Coefficients:\", lasso.coef_)\n```\n\n**Output:**\n\n![regularization1](https://media.geeksforgeeks.org/wp-content/uploads/20250521170718703437/regularization1.PNG)\n\n*Lasso Regression*\n\nThe output shows the model's prediction error and the importance of features with some coefficients reduced to zero due to L1 regularization.\n\n### 2. Ridge Regression\n\nA regression model that uses the **L2 regularization** technique is called **[Ridge regression](https://www.geeksforgeeks.org/machine-learning/what-is-ridge-regression/)**. It adds the **squared magnitude** of the coefficient as a penalty term to the loss function(L). It handles multicollinearity by shrinking the coefficients of correlated features instead of eliminating them.\n\n> $\\rm{Cost} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y_i})^2 + \\lambda \\sum_{i=1}^{m}{w_i^2}$\n\nWhere,\n\n- n = Number of examples or data points\n- m = Number of features i.e predictor variables\n- $y_i$ = Actual target value for the ith example\n- $\\hat{y}_i$ = Predicted target value for the ith example\n- $w_i$ = Coefficients of the features\n- $\\lambda$= Regularization parameter that controls the strength of regularization\n\nLet's see how to implement this using python:\n\n- **ridge = Ridge(alpha=1.0)** : Creates a Ridge regression model with regularization strength alpha set to 1.0.\n\n```python\nfrom sklearn.linear_model import Ridge\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nridge = Ridge(alpha=1.0)\nridge.fit(X_train, y_train)\ny_pred = ridge.predict(X_test)\n\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error:\", mse)\nprint(\"Coefficients:\", ridge.coef_)\n```\n\n**Output**:\n\n![regualrization2](https://media.geeksforgeeks.org/wp-content/uploads/20250521170802215020/regualrization2.PNG)\n\n*Ridge Regression*\n\nThe output shows the MSE showing model performance. Lower MSE means better accuracy. The **coefficients** reflect the regularized feature weights.\n\n### 3. Elastic Net Regression\n\n**[Elastic Net Regression](https://www.geeksforgeeks.org/machine-learning/implementation-of-elastic-net-regression-from-scratch/)** is a combination of both **L1 as well as L2 regularization.** That shows that we add the **absolute norm of the weights** as well as the **squared measure of the weights**. With the help of an extra hyperparameter that controls the ratio of the L1 and L2 regularization.\n\n> $\\rm{Cost} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y_i})^2 + \\lambda\\left((1-\\alpha)\\sum_{i=1}^{m}{\\|w_i\\|} + \\alpha \\sum_{i=1}^{m}{w_i^2}\\right)$\n\nWhere\n\n- n = Number of examples (data points)\n- m = Number of features (predictor variables)\n- $\\hat{y}_i$ = Actual target value for the i^{th} example\n- $\\hat{y}_i$ = Predicted target value for the ith example\n- $w_i$ = Coefficients of the features\n- $\\lambda$= Regularization parameter that controls the strength of regularization\n- $\\alpha$= Mixing parameter where $0 \\leq \\alpha \\leq 1$ and $\\alpha= 1$ corresponds to Lasso (L_1) regularization, $\\alpha= 0$ corresponds to Ridge (L_2) regularization and Values between 0 and 1 provide a balance of both L1 and L2 regularization\n\nLet's see how to implement this using python:\n\n- **model = ElasticNet(alpha=1.0, l1_ratio=0.5)** : Creates an Elastic Net model with regularization strength alpha=1.0 and L1/L2 mixing ratio 0.5.\n\n```python\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = ElasticNet(alpha=1.0, l1_ratio=0.5)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"Coefficients:\", model.coef_)\n```\n\n**Output**:\n\n![regularization3](https://media.geeksforgeeks.org/wp-content/uploads/20250521170834658723/regularization3.PNG)\n\n*Elastic Net Regression*\n\nThe output shows **MSE** which measures how far off predictions are from actual values (lower is better)and **coefficients** show feature importance.\n\n## Benefits of Regularization\n\nNow, let's see various benefits of regularization which are as follows:\n\n1. **Prevents Overfitting:** Regularization helps models focus on underlying patterns instead of memorizing noise in the training data.\n2. **Improves Interpretability:** L1 (Lasso) regularization simplifies models by reducing less important feature coefficients to zero.\n3. **Enhances Performance:** Prevents excessive weighting of outliers or irrelevant features helps in improving overall model accuracy.\n4. **Stabilizes Models:** Reduces sensitivity to minor data changes which ensures consistency across different data subsets.\n5. **Prevents Complexity:** Keeps model from becoming too complex which is important for limited or noisy data.\n6. **Handles Multicollinearity:** Reduces the magnitudes of correlated coefficients helps in improving model stability.\n7. **Allows Fine-Tuning:** Hyperparameters like alpha and lambda control regularization strength helps in balancing bias and variance.\n8. **Promotes Consistency:** Ensures reliable performance across different datasets which reduces the risk of large performance shifts.\n\n> Learn more about the difference between the regularization techniques here: **[Lasso vs Ridge vs Elastic Net](https://www.geeksforgeeks.org/machine-learning/lasso-vs-ridge-vs-elastic-net-ml/)**"}
{"reference": "https://www.geeksforgeeks.org/courses/full-stack-web-dev-skill-up", "content": "# Full Stack Web Development - Skill Up\n\nSelf-Paced Course\n\n![course-thumbnail](https://media.geeksforgeeks.org/wp-content/uploads/20250711102428241571/Full-Stack--Web-Development-Course-PNG.png)\n\n49k+ interested Geeks\n\nThe Full Stack Web Development Program is a structured, hands-on course designed to help learners build responsive, dynamic, and scalable web applications from scratch. Covering everything from HTML5 and modular CSS architectures to asynchronous JavaScript, ES6+ standards, and modern frontend frameworks like React and TypeScript. On the backend, you'll architect RESTful APIs using Node.js and Express, integrate NoSQL databases with Mongoose and MongoDB.\n\n**Duration:** 16 Weeks\n\n## Course Overview\n\nThis 16-week Full Stack Web Development Program is designed to take you from beginner to job-ready developer. You'll start with HTML, CSS, and JavaScript, mastering the foundations of modern websites structure, styling, and interactivity. Learn essential concepts like responsive design, accessibility, DOM manipulation, and asynchronous JavaScript. Strengthen your skills with real-time collaboration using Git and GitHub. Advance into frontend development with React and TypeScript, then build dynamic backend services using Node.js, Express, and MongoDB. Apply version control, deploy full-stack apps, and work on real-world projects that mirror professional environments. You'll also gain essential skills in version control, API development, deployment, and database management (SQL + NoSQL)\n\n**Course Highlights:**\n\n* Understand how the internet works and how websites are served\n* Build visually appealing interfaces using HTML, CSS, Bootstrap, and Tailwind\n* Develop interactive web pages using modern JavaScript (ES6+)\n* Master React fundamentals: components, hooks, routing, and state management\n* Work with TypeScript for type-safe, scalable frontend code\n* Build robust RESTful APIs using Node.js and Express\n* Integrate MongoDB with Mongoose for efficient data storage and modeling\n* Learn SQL fundamentals for relational database operations\n* Handle authentication, sessions, cookies, and security best practices\n* Use Git and GitHub for collaboration and version control\n* Deploy real-world projects using modern cloud-based hosting platforms\n\n## Course Content\n\n### WEEK-1 LEARN HTML\n\n* Web Development Prerequisites\n* Web Hosting: What Is It?\n* How to Install Visual Studio Code on Windows?\n* What Is a GIT Repository?\n* HTML5 | Introduction\n* First Web Page Printing Hello World\n* HTML Intermediate Level\n* HTML Advanced Level\n* Project & Practice\n\n### WEEK-2 LEARN CSS\n\n* CSS Fundamentals\n* CSS Advanced\n* Bootstrap\n* Tailwind\n* Project & Practice\n\n### WEEK-3 LEARN JAVASCRIPT (PART 1)\n\n* Introduction to JavaScript\n* Datatypes and Operators\n* Control Flow\n* Functions\n* Arrays\n* Objects\n* DOM and BOM\n\n### WEEK-4 LEARN JAVASCRIPT (PART 2)\n\n* Events\n* OOP'S\n* ES6+ Features\n* Asynchronous JavaScript\n* Strict Mode and Error Handling\n* Modules and Advanced Topics\n* Build and Deploy Projects"}
{"reference": "https://www.geeksforgeeks.org/videos/category/cs-subjects/", "content": "# CS Subjects Videos\n\n## SQL in Action\n**Duration:** 24:39  \n**Views:** 2.1K | **Date:** 08/01/2025  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/sql-in-action/)  \n**Tags:** GATE, SQL, CS-subjects\n\n## Update data from a table\n**Duration:** 13:19  \n**Views:** 1.4K | **Date:** 08/01/2025  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/update-data-from-a-table/)  \n**Tags:** GATE, SQL, CS-subjects\n\n## Insert Data in a table\n**Duration:** 20:16  \n**Views:** 2.1K | **Date:** 08/01/2025  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/insert-data-in-a-table/)  \n**Tags:** GATE, SQL, CS-subjects\n\n## Introduction to Keys\n**Duration:** 21:56  \n**Views:** 4.8K | **Date:** 08/01/2025  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/introduction-to-keys/)  \n**Tags:** GATE, SQL, CS-subjects\n\n## Data Retrieval with SQL\n**Duration:** 29:21  \n**Views:** 11.4K | **Date:** 08/01/2025  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/data-retrieval-with-sql/)  \n**Tags:** GATE, SQL, CS-subjects\n\n## Introduction to SQL\n**Duration:** 23:45  \n**Views:** 86.3K | **Date:** 08/01/2025  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/introduction-to-sql/)  \n**Tags:** GATE, SQL, CS-subjects\n\n## Shortest Job First (SJF) Scheduling Algorithm | Operating Systems\n**Duration:** 04:35  \n**Views:** 3.2K | **Date:** 07/01/2025  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/shortest-job-first-sjf-scheduling-algorithm-operating-systems/)  \n**Tags:** OS, CS-subjects, scheduling-algorithm, cpu-scheduling\n\n## Boundary Fill Algorithm in Computer Graphics\n**Duration:** 07:25  \n**Views:** 28.1K | **Date:** 31/07/2024  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/boundary-fill-algorithm/)  \n**Tags:** Computer-Graphics, CS-subjects\n\n## Flood Fill Algorithm | Computer Graphics\n**Duration:** 14:16  \n**Views:** 38.3K | **Date:** 18/07/2024  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/flood-fill-algorithm-computer-graphics/)  \n**Tags:** Computer-Graphics, CS-subjects\n\n## Resource Allocation Graph in Operating System\n**Duration:** 29:09  \n**Views:** 24.2K | **Date:** 24/11/2022  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/resource-allocation-graph-in-operating-system/)  \n**Tags:** OS, CS-subjects\n\n## Six-State Process Model in Operating System\n**Duration:** 22:39  \n**Views:** 6.7K | **Date:** 23/11/2022  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/six-state-process-model-in-operating-system/)  \n**Tags:** OS, CS-subjects\n\n## Producer Consumer Problem in Operating System\n**Duration:** 24:13  \n**Views:** 28.1K | **Date:** 18/11/2022  \n\n[Watch Video](https://www.geeksforgeeks.org/videos/producer-consumer-problem-in-operating-system/)  \n**Tags:** OS, CS-subjects\n\n*Showing 1-11 of 11 videos*"}
{"reference": "https://www.geeksforgeeks.org/nlp/natural-language-processing-nlp-tutorial/", "content": "# Natural Language Processing (NLP) Tutorial\n\nNatural Language Processing (NLP) is a branch of Artificial Intelligence (AI) that helps machines to understand and process human languages either in text or audio form. It is used across a variety of applications from speech recognition to language translation and text summarization.\n\nNatural Language Processing can be categorized into two components:\n\n1. **Natural Language Understanding**: It involves interpreting the meaning of the text.  \n   [Natural Language Understanding](https://www.geeksforgeeks.org/nlp/natural-language-understanding/)\n\n2. **Natural Language Generation**: It involves generating human-like text based on processed data.  \n   [Natural Language Generation](https://www.geeksforgeeks.org/nlp/artificial-intelligence-natural-language-generation/)\n\n## Phases of Natural Language Processing\n\nIt involves a series of phases that work together to process and interpret language with each phase contributing to understanding its structure and meaning.\n\n![Phases-of-Natural-Language-Processing](https://media.geeksforgeeks.org/wp-content/uploads/20230301155815/Phases-of-Natural-Language-Processing.png)\n\n*Phases of NLP*\n\nFor more details you can refer to: [Phases of NLP](https://www.geeksforgeeks.org/machine-learning/phases-of-natural-language-processing-nlp/)\n\n## Libraries for NLP\n\nSome of natural language processing libraries include:\n\n- [NLTK (Natural Language Toolkit)](https://www.geeksforgeeks.org/python/NLTK-NLP/)\n- [spaCy](https://www.geeksforgeeks.org/nlp/tokenization-using-spacy-library/)\n- [TextBlob](https://www.geeksforgeeks.org/python/python-textblob-sentiment-method/)\n- [Transformers (by Hugging Face)](https://www.geeksforgeeks.org/artificial-intelligence/Introduction-to-hugging-face-transformers/)\n- [Gensim](https://www.geeksforgeeks.org/nlp/nlp-gensim-tutorial-complete-guide-for-beginners/)\n- [NLP Libraries in Python](https://www.geeksforgeeks.org/nlp/nlp-libraries-in-python/)\n\n## Normalizing Textual Data in NLP\n\nText Normalization transforms text into a consistent format improves the quality and makes it easier to process in NLP tasks.\n\nKey steps in text normalization includes:\n\n**1. Regular Expressions (RE)** are sequences of characters that define search patterns.\n\n- [Text Normalization](https://www.geeksforgeeks.org/python/normalizing-textual-data-with-python/)\n- [Regular Expressions (RE)](https://www.geeksforgeeks.org/python/regular-expression-python-examples/)\n- [How to write Regular Expressions?](https://www.geeksforgeeks.org/dsa/write-regular-expressions/)\n- [Properties of Regular Expressions](https://www.geeksforgeeks.org/theory-of-computation/properties-of-regular-expressions/)\n- [Email Extraction using RE](https://www.geeksforgeeks.org/python/extracting-email-addresses-using-regular-expressions-python/)\n\n**2. Tokenization** is a process of splitting text into smaller units called tokens.\n\n- [Tokenization](https://www.geeksforgeeks.org/nlp/what-is-tokenization/)\n- [Word Tokenization](https://www.geeksforgeeks.org/python/python-nltk-nltk-tokenizer-word_tokenize/)\n- [Rule-based Tokenization](https://www.geeksforgeeks.org/nlp/rule-based-tokenization-in-nlp/)\n- [Subword Tokenization](https://www.geeksforgeeks.org/nlp/subword-tokenization-in-nlp/)\n- [Dictionary-Based Tokenization](https://www.geeksforgeeks.org/nlp/dictionary-based-tokenization-in-nlp/)\n- [Whitespace Tokenization](https://www.geeksforgeeks.org/python/python-nltk-nltk-whitespacetokenizer/)\n- [WordPiece Tokenization](https://www.geeksforgeeks.org/nlp/how-wordpiece-tokenization-addresses-the-rare-words-problem-in-nlp/)\n\n**3. Lemmatization** reduces words to their base or root form.\n\n- [Lemmatization](https://www.geeksforgeeks.org/python/python-lemmatization-with-nltk/)\n\n**4. Stemming** reduces works to their root by removing suffixes. Types of stemmers include:\n\n- [Stemming](https://www.geeksforgeeks.org/machine-learning/introduction-to-stemming/)\n- [Porter Stemmer](https://www.geeksforgeeks.org/nlp/porter-stemmer-technique-in-natural-language-processing/)\n- [Lancaster Stemmer](https://www.geeksforgeeks.org/nlp/lancaster-stemming-technique-in-natural-language-processing/)\n- [Snowball Stemmer](https://www.geeksforgeeks.org/nlp/snowball-stemmer-nlp/)\n- [Rule-based Stemming](https://www.geeksforgeeks.org/nlp/rule-based-stemming-in-natural-language-processing/)\n\n**5. Stopword removal** is a process to remove common words from the document.\n\n- [Stopword removal](https://www.geeksforgeeks.org/nlp/removing-stop-words-nltk-python/)\n\n**6. Parts of Speech (POS) Tagging** assigns a part of speech to each word in sentence based on definition and context.\n\n- [Parts of Speech (POS) Tagging](https://www.geeksforgeeks.org/nlp/nlp-part-of-speech-default-tagging/)\n\n## Text Representation and Embedding Techniques in NLP\n\nLets see how these techniques works in NLP.\n\n### Text representation Techniques\n\nIt converts textual data into numerical vectors that are processed by the following methods:\n\n- [One-Hot Encoding](https://www.geeksforgeeks.org/machine-learning/ml-one-hot-encoding/)\n- [Bag of Words (BOW)](https://www.geeksforgeeks.org/nlp/bag-of-words-bow-model-in-nlp/)\n- [Term Frequency-Inverse Document Frequency (TF-IDF)](https://www.geeksforgeeks.org/machine-learning/understanding-tf-idf-term-frequency-inverse-document-frequency/)\n- [N-Gram Language Modeling with NLTK](https://www.geeksforgeeks.org/nlp/n-gram-language-modelling-with-nltk/)\n- [Latent Semantic Analysis (LSA)](https://www.geeksforgeeks.org/machine-learning/latent-semantic-analysis/)\n- [Latent Dirichlet Allocation (LDA)](https://www.geeksforgeeks.org/machine-learning/latent-dirichlet-allocation/)\n\n### Text Embedding Techniques\n\nIt refers to methods that create dense vector representations of text, capturing semantic meaning including advanced approaches like:\n\n**1. Word Embedding**\n\n- [Word2Vec](https://www.geeksforgeeks.org/python/python-word-embedding-using-word2vec/) ([SkipGram](https://www.geeksforgeeks.org/python/implement-your-own-word2vecskip-gram-model-in-python/), [Continuous Bag of Words - CBOW](https://www.geeksforgeeks.org/nlp/continuous-bag-of-words-cbow-in-nlp/))\n- [GloVe (Global Vectors for Word Representation)](https://www.geeksforgeeks.org/nlp/pre-trained-word-embedding-using-glove-in-nlp-models/)\n- [fastText](https://www.geeksforgeeks.org/nlp/word-embeddings-using-fasttext/)\n\n**2. Pre-Trained Embedding**\n\n- [ELMo (Embeddings from Language Models)](https://www.geeksforgeeks.org/python/overview-of-word-embedding-using-embeddings-from-language-models-elmo/)\n- [BERT (Bidirectional Encoder Representations from Transformers)](https://www.geeksforgeeks.org/nlp/explanation-of-bert-model-nlp/)\n\n**3. Document Embedding**\n\n- [Doc2Vec](https://www.geeksforgeeks.org/nlp/doc2vec-in-nlp/)\n\n**4. Advanced Embeddings**\n\n- [RoBERTa](https://www.geeksforgeeks.org/machine-learning/overview-of-roberta-model/)\n- [DistilBERT](https://www.geeksforgeeks.org/nlp/distilbert-in-natural-language-processing/)\n\n## Deep Learning Techniques for NLP\n\nDeep learning has revolutionized Natural Language Processing by helping models to automatically learn complex patterns from raw text.\n\nKey deep learning techniques in NLP include:\n\n- [Deep learning](https://www.geeksforgeeks.org/deep-learning/introduction-deep-learning/)\n- [Artificial Neural Networks (ANNs)](https://www.geeksforgeeks.org/artificial-intelligence/artificial-neural-networks-and-its-applications/)\n- [Recurrent Neural Networks (RNNs)](https://www.geeksforgeeks.org/machine-learning/introduction-to-recurrent-neural-network/)\n- [Long Short-Term Memory (LSTM)](https://www.geeksforgeeks.org/deep-learning/deep-learning-introduction-to-long-short-term-memory/)\n- [Gated Recurrent Unit (GRU)](https://www.geeksforgeeks.org/machine-learning/gated-recurrent-unit-networks/)\n- [Seq2Seq Models](https://www.geeksforgeeks.org/machine-learning/seq2seq-model-in-machine-learning/)\n- [Transformer Models](https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/)\n\n### Pre-Trained Language Models\n\nPre-trained models can be fine-tuned for specific tasks:\n\n- [Pre-trained models](https://www.geeksforgeeks.org/nlp/top-5-pre-trained-models-in-natural-language-processing-nlp/)\n- [GPT (Generative Pre-trained Transformer)](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-generative-pre-trained-transformer-gpt/)\n- [Transformers XL](https://www.geeksforgeeks.org/nlp/trasformer-xl-beyond-a-fixed-length-context/)\n- [T5 (Text-to-Text Transfer Transformer)](https://www.geeksforgeeks.org/nlp/t5-text-to-text-transfer-transformer/)\n- [Transfer Learning with Fine-tuning](https://www.geeksforgeeks.org/nlp/transfer-learning-and-fine-tuning-in-nlp/)\n\n## Natural Language Processing Tasks\n\nCore NLP tasks that help machines understand, interpret and generate human language.\n\n### 1. Text Classification\n\n- [Dataset for Text Classification](https://www.geeksforgeeks.org/nlp/dataset-for-text-classification/)\n- [Text Classification using Naive Bayes](https://www.geeksforgeeks.org/machine-learning/classification-of-text-documents-using-the-approach-of-naive-bayes/)\n- [Text Classification using Logistic Regression](https://www.geeksforgeeks.org/machine-learning/text-classification-using-logistic-regression/)\n- [Text Classification using RNNs](https://www.geeksforgeeks.org/nlp/rnn-for-text-classifications-in-nlp/)\n- [Text Classification using CNNs](https://www.geeksforgeeks.org/nlp/text-classification-using-cnn/)\n\n### 2. Information Extraction\n\n- [Named Entity Recognition (NER) using SpaCy](https://www.geeksforgeeks.org/python/python-named-entity-recognition-ner-using-spacy/)\n- [Named Entity Recognition (NER) using NLTK](https://www.geeksforgeeks.org/nlp/named-entity-recognition/)\n- [Relationship Extraction](https://www.geeksforgeeks.org/nlp/relationship-extraction-in-nlp/)\n\n### 3. Sentiment Analysis\n\n- [What is Sentiment Analysis?](https://www.geeksforgeeks.org/machine-learning/what-is-sentiment-analysis/)\n- [Sentiment Analysis using VADER](https://www.geeksforgeeks.org/python/python-sentiment-analysis-using-vader/)\n- [Sentiment Analysis using Recurrent Neural Networks (RNN)](https://www.geeksforgeeks.org/python/sentiment-analysis-with-an-recurrent-neural-networks-rnn/)\n\n### 4. Machine Translation\n\n- [Statistical Machine Translation of Language](https://www.geeksforgeeks.org/artificial-intelligence/statistical-machine-translation-of-languages-in-artificial-intelligence/)\n- [Machine Translation with Transformer](https://www.geeksforgeeks.org/nlp/machine-translation-with-transformer-in-python/)\n\n### 5. Text Summarization\n\n- [What is Text Summarization?](https://www.geeksforgeeks.org/nlp/text-summarization-in-nlp/)\n- [Text Summarizations using Hugging Face Model](https://www.geeksforgeeks.org/nlp/text-summarizations-using-huggingface-model/)\n- [Text Summarization using Sumy](https://www.geeksforgeeks.org/nlp/mastering-text-summarization-with-sumy-a-python-library-overview/)\n\n### 6. Text Generation\n\n- [Text Generation using Fnet](https://www.geeksforgeeks.org/nlp/text-generation-using-fnet/)\n- [Text Generation using Recurrent Long Short Term Memory Network](https://www.geeksforgeeks.org/machine-learning/text-generation-using-recurrent-long-short-term-memory-network/)\n- [Text2Text Generations using HuggingFace Model](https://www.geeksforgeeks.org/nlp/text2text-generations-using-huggingface-model/)\n\n## Natural Language Processing Chatbots\n\nNLP chatbots are computer programs designed to interact with users in natural language helps in seamless communication between humans and machines. By using NLP techniques, these chatbots understand, interpret and generate human language.\n\n- [What is Natural Language Processing (NLP) Chatbots?](https://www.geeksforgeeks.org/nlp/what-is-natural-language-processing-nlp-chatbots/)\n\n## Applications of NLP\n\n1. **Voice Assistants:** Alexa, Siri and Google Assistant use NLP for voice recognition and interaction.  \n2. **Grammar and Text Analysis:** Tools like Grammarly, Microsoft Word and Google Docs apply NLP for grammar checking.  \n3. **Information Extraction:** Search engines like Google and DuckDuckGo use NLP to extract relevant information.  \n4. **Chatbots:** Website bots and customer support chatbots leverage NLP for automated conversations.\n\nFor more details you can refer to: [Applications of NLP](https://www.geeksforgeeks.org/nlp/top-7-applications-of-natural-language-processing/)\n\n## Importance of NLP\n\nNatural Language Processing (NLP) plays an important role in transforming how we interact with technology and understand data. Below are reasons why it’s so important:\n\n1. **Information Extraction:** Extracts useful data from unstructured content.  \n2. **Sentiment Analysis:** Analyzes customer opinions for businesses.  \n3. **Automation:** Streamlines tasks like customer service and document processing.  \n4. **Language Translation:** Breaks down language barriers with tools like Google Translate.  \n5. **Healthcare:** Assists in analyzing medical records and research.\n\nFor more details you can refer to: [Why is NLP important?](https://www.geeksforgeeks.org/nlp/why-is-nlp-important/)"}
{"reference": "https://www.geeksforgeeks.org/tag/ai-ml-ds-python/", "content": "# AI-ML-DS With Python\n\n**2.1K+ posts**\n\n## Recent Articles\n\n### [Keras Tuner for Hyperparameter Optimization](https://www.geeksforgeeks.org/deep-learning/keras-tuner-for-hyperparameter-optimization/)\n*Last Updated: 20 August 2025*\n\nKeras Tuner is a scalable and user-friendly framework designed to automate the hyperparameter optimization process for deep learning models built using Keras and TensorFlow.\n\n**Categories:** [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Visualizing Classifier Decision Boundaries](https://www.geeksforgeeks.org/machine-learning/visualizing-classifier-decision-boundaries/)\n*Last Updated: 06 August 2025*\n\nVisualizing classifier decision boundaries is a way to gain intuitive insight into how machine learning models separate different classes in a feature space. These visualizations...\n\n**Categories:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Kuberflow vs. MLflow](https://www.geeksforgeeks.org/machine-learning/kuberflow-vs-mlflow/)\n*Last Updated: 06 August 2025*\n\nKubeflow and MLflow are both tools for managing the machine learning lifecycle but they serve different purposes. Kubeflow is designed for building, deploying and managing...\n\n**Categories:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Episodic Memory in AI Agents](https://www.geeksforgeeks.org/artificial-intelligence/episodic-memory-in-ai-agents/)\n*Last Updated: 20 August 2025*\n\nEpisodic memory in AI agents is an advanced capability that enables an artificial agent to store, recall and reason about its own past experiences or events it has personally...\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Huber Loss Function in Machine Learning](https://www.geeksforgeeks.org/machine-learning/huber-loss-function-in-machine-learning/)\n*Last Updated: 01 August 2025*\n\nThe Huber Loss Function is a popular loss function used primarily in regression tasks. It is designed to be robust to outliers combining the best properties of two common...\n\n**Categories:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [PyGraphistry](https://www.geeksforgeeks.org/artificial-intelligence/pygraphistry/)\n*Last Updated: 22 August 2025*\n\nPyGraphistry is an open source Python library that enables visual graph analytics at scale. It acts as a Python interface to the Graphistry platform which turns raw data into...\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [What is Mistral AI](https://www.geeksforgeeks.org/artificial-intelligence/what-is-mistral-ai/)\n*Last Updated: 20 August 2025*\n\nMistral AI is a French artificial intelligence startup established in April 2023 by three leading AI researchers: Arthur Mensch, Guillaume Lample and Timothée Lacroix, all...\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [What is Semantic Segmentation](https://www.geeksforgeeks.org/computer-vision/what-is-semantic-segmentation/)\n*Last Updated: 22 August 2025*\n\nSemantic segmentation is a process in computer vision that focuses on assigning a class label to every pixel in an image. This process transforms simple images into meaningful...\n\n**Categories:** [Computer Vision](https://www.geeksforgeeks.org/category/ai-ml-ds/computer-vision/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Life2Vec AI - Predicting Death Using AI](https://www.geeksforgeeks.org/artificial-intelligence/life2vec-ai-predicting-death-using-ai/)\n*Last Updated: 01 August 2025*\n\nLife2Vec is an AI model developed by researchers in Denmark and the U.S. that predicts human life outcomes such as the risk of death by analyzing detailed life event data.\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Implementing Custom Layers and Activation Functions in TensorFlow](https://www.geeksforgeeks.org/deep-learning/implementing-custom-layers-and-activation-functions-in-tensorflow/)\n*Last Updated: 06 August 2025*\n\nTensorFlow is a flexible deep learning framework that supports both predefined and user defined components. While standard layers and activation functions work well for many...\n\n**Categories:** [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [cuML : RAPIDS Machine Learning Library](https://www.geeksforgeeks.org/machine-learning/cuml-rapids-machine-learning-library/)\n*Last Updated: 06 August 2025*\n\ncuML is a GPU accelerated machine learning library developed by NVIDIA as part of the RAPIDS AI ecosystem. It is designed to enable fast and scalable execution of traditional...\n\n**Categories:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Incremental Learning with Scikit-learn](https://www.geeksforgeeks.org/machine-learning/incremental-learning-with-scikit-learn/)\n*Last Updated: 31 July 2025*\n\nIncremental Learning is a technique where a machine learning model learns from data in small chunks or batches rather than all at once. This is useful when working with very...\n\n**Categories:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Collaborative AI agents for learning](https://www.geeksforgeeks.org/artificial-intelligence/collaborative-ai-agents-for-learning/)\n*Last Updated: 31 July 2025*\n\nCollaborative AI agents also known as multi-agent or crew AI systems represent an advanced paradigm in artificial intelligence where autonomous entities cooperate to solve...\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [GeoPandas Tutorial](https://www.geeksforgeeks.org/python/geopandas-tutorial/)\n*Last Updated: 29 August 2025*\n\nGeoPandas is an open-source Python library that makes working with geospatial data easy. It extends pandas to support geometric data types and operations, enabling spatial...\n\n**Categories:** [Python](https://www.geeksforgeeks.org/category/programming-language/python/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### [Agno: Building Multimodal AI Agents](https://www.geeksforgeeks.org/artificial-intelligence/agno-building-multimodal-ai-agents/)\n*Last Updated: 22 August 2025*\n\nAgno is a framework designed to help developers create multimodal AI agents smart systems that can understand and process many types of input not just text. While most AI...\n\n**Categories:** [Artificial Intelligence](https://www.geeksforgeeks.org/category/ai-ml-ds/artificial-intelligence/), [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n*[View more pages: 1](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/page/1/?type=recent) [2](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/page/2/?type=recent) [3](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/page/3/?type=recent) [4](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/page/4/?type=recent) ... [137](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/page/137/?type=recent)*"}
{"reference": "https://www.geeksforgeeks.org/courses/category/programming-languages", "content": "### We couldn't find what you're looking for"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/what-is-feature-engineering/", "content": "# What is Feature Engineering?\n\nFeature engineering is the process of turning raw data into useful features that help improve the performance of machine learning models. It includes choosing, creating and adjusting data attributes to make the model's predictions more accurate. The goal is to make the model better by providing relevant and easy-to-understand information.\n\nA feature or attribute is a measurable property of data that is used as input for machine learning algorithms. Features can be numerical, categorical or text-based representing essential data aspects which are relevant to the problem. For example in housing price prediction, features might include the number of bedrooms, location and property age.\n\n![Feature Engineering Architecture](https://media.geeksforgeeks.org/wp-content/uploads/20250701114435618562/feature-engineering.webp)\n\n## Importance of Feature Engineering\n\nFeature engineering can significantly influence model performance. By refining features, we can:\n\n- **Improve accuracy**: Choosing the right features helps the model learn better, leading to more accurate predictions.\n- **Reduce overfitting**: Using fewer, more important features helps the model avoid memorizing the data and perform better on new data.\n- **Boost interpretability**: Well-chosen features make it easier to understand how the model makes its predictions.\n- **Enhance efficiency**: Focusing on key features speeds up the model's training and prediction process, saving time and resources.\n\n## Processes Involved in Feature Engineering\n\nLet's see various features involved in feature engineering:\n\n![Processes involved in Feature Engineering](https://media.geeksforgeeks.org/wp-content/uploads/20250701123223591115/processes.webp)\n\n### 1. Feature Creation\nFeature creation involves generating new features from domain knowledge or by observing patterns in the data. It can be:\n\n1. **Domain-specific**: Created based on industry knowledge like business rules.\n2. **Data-driven**: Derived by recognizing patterns in data.\n3. **Synthetic**: Formed by combining existing features.\n\n### 2. Feature Transformation\nTransformation adjusts features to improve model learning:\n\n1. **Normalization & Scaling**: Adjust the range of features for consistency.\n2. **Encoding**: Converts categorical data to numerical form i.e one-hot encoding.\n3. **Mathematical transformations**: Like logarithmic transformations for skewed data.\n\n### 3. Feature Extraction\nExtracting meaningful features can reduce dimensionality and improve model accuracy:\n\n- **Dimensionality reduction**: Techniques like PCA reduce features while preserving important information.\n- **Aggregation & Combination**: Summing or averaging features to simplify the model.\n\n### 4. Feature Selection\nFeature selection involves choosing a subset of relevant features to use:\n\n- **Filter methods**: Based on statistical measures like correlation.\n- **Wrapper methods**: Select based on model performance.\n- **Embedded methods**: Feature selection integrated within model training.\n\n### 5. Feature Scaling\nScaling ensures that all features contribute equally to the model:\n\n- **Min-Max scaling**: Rescales values to a fixed range like 0 to 1.\n- **Standard scaling**: Normalizes to have a mean of 0 and variance of 1.\n\n## Steps in Feature Engineering\n\nFeature engineering can vary depending on the specific problem but the general steps are:\n\n1. **Data Cleaning:** Identify and correct errors or inconsistencies in the dataset to ensure data quality and reliability.\n2. **Data Transformation:** Transform raw data into a format suitable for modeling including scaling, normalization and encoding.\n3. **Feature Extraction:** Create new features by combining or deriving information from existing ones to provide more meaningful input to the model.\n4. **Feature Selection:** Choose the most relevant features for the model using techniques like correlation analysis, mutual information and stepwise regression.\n5. **Feature Iteration:** Continuously refine features based on model performance by adding, removing or modifying features for improvement.\n\n## Common Techniques in Feature Engineering\n\n### 1. One-Hot Encoding\n[One-Hot Encoding](https://www.geeksforgeeks.org/machine-learning/ml-one-hot-encoding/) converts categorical variables into binary indicators, allowing them to be used by machine learning models.\n\n```python\nimport pandas as pd\n\ndata = {'Color': ['Red', 'Blue', 'Green', 'Blue']}\ndf = pd.DataFrame(data)\n\ndf_encoded = pd.get_dummies(df, columns=['Color'], prefix='Color')\n\nprint(df_encoded)\n```\n\n**Output**\n\n```\n   Color_Blue  Color_Green  Color_Red\n0       False        False       True\n1        True        False      False\n2       False         True      False\n3        True        False      False\n```\n\n### 2. Binning\n[Binning](https://www.geeksforgeeks.org/machine-learning/binning-in-data-mining/) transforms continuous variables into discrete bins, making them categorical for easier analysis.\n\n```python\nimport pandas as pd\n\ndata = {'Age': [23, 45, 18, 34, 67, 50, 21]}\ndf = pd.DataFrame(data)\n\nbins = [0, 20, 40, 60, 100]\nlabels = ['0-20', '21-40', '41-60', '61+']\n\ndf['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n\nprint(df)\n```\n\n**Output**\n\n```\n   Age Age_Group\n0   23     21-40\n1   45     41-60\n2   18      0-20\n3   34     21-40\n4   67       61+\n5   50     41-60\n6   21     21-40\n```\n\n### 3. Text Data Preprocessing\nInvolves removing [stop-words](https://www.geeksforgeeks.org/nlp/removing-stop-words-nltk-python/), [stemming](https://www.geeksforgeeks.org/machine-learning/introduction-to-stemming/) and [vectorizing](https://www.geeksforgeeks.org/nlp/vectorization-techniques-in-nlp/) text data to prepare it for machine learning models.\n\n```python\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ntexts = [\"This is a sample sentence.\", \"Text data preprocessing is important.\"]\n\nstop_words = set(stopwords.words('english'))\nstemmer = PorterStemmer()\nvectorizer = CountVectorizer()\n\ndef preprocess_text(text):\n    words = text.split()\n    words = [stemmer.stem(word)\n             for word in words if word.lower() not in stop_words]\n    return \" \".join(words)\n\ncleaned_texts = [preprocess_text(text) for text in texts]\n\nX = vectorizer.fit_transform(cleaned_texts)\n\nprint(\"Cleaned Texts:\", cleaned_texts)\nprint(\"Vectorized Text:\", X.toarray())\n```\n\n**Output:**\n\n![output](https://media.geeksforgeeks.org/wp-content/uploads/20250701113324922110/output.webp)\n\n### 4. Feature Splitting\nDivides a single feature into multiple sub-features, uncovering valuable insights and improving model performance.\n\n```python\nimport pandas as pd\n\ndata = {'Full_Address': [\n    '123 Elm St, Springfield, 12345', '456 Oak Rd, Shelbyville, 67890']}\ndf = pd.DataFrame(data)\n\ndf[['Street', 'City', 'Zipcode']] = df['Full_Address'].str.extract(\n    r'(\\d+\\s[\\w\\s]+),\\s([\\w\\s]+),\\s(\\d+)')\n\nprint(df)\n```\n\n**Output**\n\n```\n                                         Full_Address      Street         City Zipcode\n0  123 Elm St, Springfield, 12345  123 Elm St  Springfield   12345\n1  456 Oak Rd, Shelbyville, 67890  456 Oak Rd  Shelbyville   67890\n```\n\n## Tools for Feature Engineering\n\nThere are several tools available for feature engineering. Here are some popular ones:\n\n- **Featuretools**: Automates feature engineering by extracting and transforming features from structured data. It integrates well with libraries like pandas and scikit-learn making it easy to create complex features without extensive coding.\n- **TPOT**: Uses genetic algorithms to optimize machine learning pipelines, automating feature selection and model optimization. It visualizes the entire process, helping you identify the best combination of features and algorithms.\n- **DataRobot**: Automates machine learning workflows including feature engineering, model selection and optimization. It supports time-dependent and text data and offers collaborative tools for teams to efficiently work on projects.\n- **Alteryx**: Offers a visual interface for building data workflows, simplifying feature extraction, transformation and cleaning. It integrates with popular data sources and its drag-and-drop interface makes it accessible for non-programmers.\n- **H2O.ai**: Provides both automated and manual feature engineering tools for a variety of data types. It includes features for scaling, imputation and encoding and offers interactive visualizations to better understand model results."}
{"reference": "https://www.geeksforgeeks.org/courses/advanced-java-skill-up", "content": "# Advanced Java Skill Up\n\nSelf-Paced Course\n\n**19k+ interested Geeks**\n\nThe Advanced Java Course is built for learners who already understand Java basics and want to level up to professional backend development. This course takes a deep dive into web development with Servlets and JSP, enterprise backend development with Spring Framework, and real-world application design with microservices, databases, security, and testing. Whether you're aiming to work with large-scale systems or transition into cloud-based Java applications, this course has you covered.\n\n**12 Weeks**\n\n## Course Overview\n\nThis 12-week journey explores advanced concepts like Spring Boot, Hibernate, RESTful APIs, Spring Security, Microservices, and Docker. Through hands-on projects, you'll build real applications and gain the skills needed for backend engineering roles. Each week comes with practical lessons, tools, and assignments to apply what you've learned.\n\n### Course Highlights\n\n- Dive into Servlets, JSP, and JDBC for full-stack web development\n- Build and manage Java applications with Maven and Gradle\n- Master Spring Framework: DI, AOP, MVC, and Bean Lifecycle\n- Create REST APIs using Spring Boot and secure them with Spring Security\n- Understand and implement Microservices with Spring Cloud & Eureka\n- Work with ORM using Hibernate and Spring Data JPA\n- Integrate Docker and deploy Java applications to the cloud\n- Write unit tests using JUnit and Mockito for better code reliability\n- Apply design patterns to structure scalable applications\n- Complete real-world Java projects in each module\n\n## Course Content\n\n### Week 1: Core Java Fundamentals\n\n- Java Basics, JDK/JRE/JVM Setup\n- Variables, Data Types, Type Casting\n- Control Flow: if-else, loops, switch\n- Input/Output and Operators\n- Mini Project: Tic-Tac-Toe Game\n\n### Week 2: Object-Oriented Programming Concepts\n\n- Classes, Objects, Methods, Overloading\n- Constructors, this Keyword, Encapsulation\n- Inheritance, Polymorphism, Overriding\n- Arrays and Strings\n- Wrapper Classes, Static Members\n- Mini Project: Library Management System\n\n### Week 3: Advanced Java Concepts & Build Tools\n\n- Collections & Exception Handling\n- Multithreading in Java\n- Java 8 Features: Lambdas, Streams, Optionals\n- Introduction to Maven and Gradle\n- Mini Project: Employee Data Analyzer\n\n### Week 4: Java Web Development (Servlets + JSP + JDBC)\n\n- HTTP Basics, Client-Server Model\n- Servlet Lifecycle, doGet/doPost, Sessions\n- JDBC CRUD Operations with Servlets\n- JSP Basics, EL, JSTL, Login/Logout Example\n- Mini Project: Online Banking App\n\n## Frequently Asked Questions\n\n### Who should take Advance Java course?\n\n### Is Java beginner knowledge enough?\n\n### What kind of projects are included?\n\n### What roles can this course prepare me for?"}
{"reference": "https://www.geeksforgeeks.org/aptitude/puzzles/", "content": "# Puzzles\n\nPuzzles are commonly asked in exams and interviews to test logical and analytical thinking. Here is a list of most asked Puzzles divided into four categories as per examination pattern.\n\n## 1. Analytical / Mathematical Puzzles\n\n| Puzzle Title | Asked in Company |\n| --- | --- |\n| [Find ages of daughters](https://www.geeksforgeeks.org/aptitude/puzzle-2-find-ages-of-daughters/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Calculate total distance traveled by bee](https://www.geeksforgeeks.org/aptitude/puzzle-3-calculate-total-distance-travelled-by-bee/) | [Yahoo](https://www.geeksforgeeks.org/companies/yahoo/) |\n| [6×6 Grid - Ways to Reach Bottom Right](https://www.geeksforgeeks.org/aptitude/puzzle-6x6-grid-how-many-ways/) | [Amazon](https://www.geeksforgeeks.org/companies/amazon-inc/), [Zoho](https://www.geeksforgeeks.org/companies/zoho-corporation/) |\n| [Monty Hall problem](https://www.geeksforgeeks.org/aptitude/puzzle-6-monty-hall-problem/) | [VMWare](https://www.geeksforgeeks.org/companies/vmware/) |\n| [Torch and Bridge](https://www.geeksforgeeks.org/aptitude/puzzle-18-torch-and-bridge/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [2 Eggs and 100 Floors](https://www.geeksforgeeks.org/aptitude/puzzle-set-35-2-eggs-and-100-floors/) | [VMWare](https://www.geeksforgeeks.org/companies/vmware/) |\n| [Maximize the probability of White Ball](https://www.geeksforgeeks.org/aptitude/puzzle-12-maximize-probability-of-white-ball/) | [Amazon](https://www.geeksforgeeks.org/companies/amazon-inc/) |\n| [Poison and Rat](https://www.geeksforgeeks.org/aptitude/puzzle-19-poison-and-rat/) | [Amazon](https://www.geeksforgeeks.org/companies/amazon-inc/) |\n| [Hourglasses Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-27-hourglasses-puzzle/) | Bank of America, [Yahoo](https://www.geeksforgeeks.org/companies/yahoo/) |\n| [The ratio of Boys and Girls in a Country where people want only boys](https://www.geeksforgeeks.org/aptitude/puzzle-17-ratio-of-boys-and-girls-in-a-country-where-people-want-only-boys/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Goldman Sachs](https://www.geeksforgeeks.org/companies/goldman-sachs/) |\n| [Car Wheel Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-29-car-wheel-puzzle/) | [MakeMytrip](https://www.geeksforgeeks.org/companies/makemytrip/) |\n| [Maximum Chocolates](https://www.geeksforgeeks.org/aptitude/puzzle-22-maximum-chocolates/) | [Infosys](https://www.geeksforgeeks.org/companies/infosys/), [MakeMytrip](https://www.geeksforgeeks.org/companies/makemytrip/) |\n| [Puzzle \\| Splitting a Cake with a Missing Piece in two equal portion](https://www.geeksforgeeks.org/aptitude/puzzle-splitting-a-cake-with-a-missing-piece-in-two-equal-portion/) | Alcatel-Lucent, [Cognizant](https://www.geeksforgeeks.org/companies/cognizant/) |\n| [Rs 500 Note Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-33-rs-500-note-puzzle/) | CAT, [UPSC](https://www.geeksforgeeks.org/category/upsc/) |\n| [Girl or Boy](https://www.geeksforgeeks.org/aptitude/puzzle-44-girl-or-boy/) | [Amazon](https://www.geeksforgeeks.org/companies/amazon-inc/) |\n| [Know Average Salary without Disclosing Individual Salaries](https://www.geeksforgeeks.org/maths/puzzle-26-know-average-salary-without-disclosing-individual-salaries/) | [Infosys](https://www.geeksforgeeks.org/companies/infosys/), Bloomberg. |\n| [Maximum run in cricket](https://www.geeksforgeeks.org/aptitude/puzzle-37-maximum-run-in-cricket/) | FAANG |\n| [Completion of Task](https://www.geeksforgeeks.org/aptitude/puzzle-32-completion-of-task/) | Reflexis Systems |\n| [Find missing Row in Excel](https://www.geeksforgeeks.org/aptitude/puzzle-40-find-missing-row-in-excel/) | [philips](https://www.geeksforgeeks.org/companies/philips/) |\n| [Four People on a Rickety Bridge](https://www.geeksforgeeks.org/aptitude/four-people-rickety-bridge/) | Jumbotail, [SAP](https://www.geeksforgeeks.org/companies/sap/) |\n| [Man fell in well Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-man-fell-in-well-puzzle/) | [American Express](https://www.geeksforgeeks.org/companies/american-express/) |\n| [50 red marbles and 50 blue marbles](https://www.geeksforgeeks.org/aptitude/puzzle-50-red-marbles-and-50-blue-marbles/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/), J[P morgan chase](https://www.geeksforgeeks.org/companies/jpmorgan-chase--co/) |\n| [Puzzle \\| Form Three Equilateral Triangles](https://www.geeksforgeeks.org/aptitude/puzzle-form-three-equilateral-triangles/) | [Google](https://www.geeksforgeeks.org/companies/google/) |\n| [10 identical bottles of pills](https://www.geeksforgeeks.org/aptitude/puzzle-10-identical-bottles-pills/) | ZS Associate |\n| [Puzzle \\| Maximum pieces that can be cut from a Circle using 6 straight lines](https://www.geeksforgeeks.org/aptitude/puzzle-maximum-pieces-that-can-be-cut-from-a-circle-using-6-straight-lines/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [Chain Link Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-85-chain-link-puzzle/) | [cognizant](https://www.geeksforgeeks.org/companies/cognizant/) |\n| [The shopkeeper and the lady who made a purchase of Rs 200 with fake note](https://www.geeksforgeeks.org/gfg-academy/interview-puzzle-the-shopkeeper-and-the-lady-who-made-a-purchase-of-rs-200-with-fake-note/) | [Persistent Systems](https://www.geeksforgeeks.org/companies/persistent-systems/) |\n| [Egg Dropping Puzzle with 2 Eggs and K Floors](https://www.geeksforgeeks.org/dsa/egg-dropping-puzzle-with-2-eggs-and-k-floors/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Minimum number of Apples to be collected from trees to guarantee M red apples](https://www.geeksforgeeks.org/dsa/minimum-number-of-apples-to-be-collected-from-trees-to-guarantee-m-red-apples/) | Leetcode |\n| [Snail and Wall](https://www.geeksforgeeks.org/aptitude/puzzle-snail-and-wall/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [1000 light bulbs switched on/off by 1000 people passing by](https://www.geeksforgeeks.org/dsa/puzzle-1000-light-bulbs-switched-on-off-by-1000-persons-passing-by/) | UK university interview |\n| [Puzzle \\| Four Alternating Knights](https://www.geeksforgeeks.org/aptitude/puzzle-four-alternating-knights/) | Amazon, [Google](https://www.geeksforgeeks.org/companies/google/) |\n| [TCS DIGITAL PUZZLE \\| Lateral Thinking 2](https://www.geeksforgeeks.org/interview-experiences/tcs-digital-puzzle-lateral-thinking-2/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [Puzzle \\| 100 Cows And Milk](https://www.geeksforgeeks.org/aptitude/puzzle-100-cows-and-milk/) | ZS |\n| [Puzzle \\| One Mile on the Globe](https://www.geeksforgeeks.org/aptitude/puzzle-one-mile-on-the-globe-mcq/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [TCS DIGITAL PUZZLE \\| Lateral Thinking](https://www.geeksforgeeks.org/aptitude/tcs-digital-puzzle-lateral-thinking/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [Puzzle \\| The Counters and Board](https://www.geeksforgeeks.org/aptitude/puzzle-the-counters-and-board/) | [JP-morgan](https://www.geeksforgeeks.org/companies/jpmorgan-chase--co/) |\n| [Camel and Banana Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-15-camel-and-banana-puzzle/) | Amazon, [Yahoo](https://www.geeksforgeeks.org/companies/yahoo/) |\n| [Puzzle \\| (Six Matches , Right Foot Forward)](https://www.geeksforgeeks.org/aptitude/puzzle-six-matches-right-foot-forward/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [How much he had initially?](https://www.geeksforgeeks.org/aptitude/puzzle-how-much-he-had-initially/) | [IAS interview question](https://www.geeksforgeeks.org/tag/ias/) |\n| [Puzzle \\| 3 cuts to cut round cake into 8 equal pieces](https://www.geeksforgeeks.org/aptitude/puzzle-3-cuts-cut-round-cake-8-equal-pieces/) | [Adobe](https://www.geeksforgeeks.org/companies/adobe-systems/), [Citius Tech](https://www.geeksforgeeks.org/companies/citiustech-healthcare-technology-private-ltd/), [Cognizant](https://www.geeksforgeeks.org/companies/cognizant/), [blackrock](https://www.geeksforgeeks.org/companies/blackrock/) |\n| [Two Creepers Climbing a Tree](https://www.geeksforgeeks.org/aptitude/puzzle-two-creepers-climbing-a-tree/) | [Adobe](https://www.geeksforgeeks.org/companies/adobe-systems/), [Google](https://www.geeksforgeeks.org/companies/google/), [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n\n**Read More:** [Articles on Analytical/mathematical puzzles](https://www.geeksforgeeks.org/tag/analytical-mathematical-puzzles/)\n\n## 2. Logical Puzzles\n\n| **Puzzle Title** | **Asked in Company** |\n| --- | --- |\n| [Pay an employee using a gold rod of 7 units ?](https://www.geeksforgeeks.org/aptitude/puzzle-4-pay-an-employee-using-a-gold-rod-of-7-units/) | FAANG, Ola cabs |\n| [Find the fastest 3 horses](https://www.geeksforgeeks.org/aptitude/puzzle-9-find-the-fastest-3-horses/) | Accolite, [Goldman Sachs](https://www.geeksforgeeks.org/companies/goldman-sachs/), [MakeMyTrip](https://www.geeksforgeeks.org/companies/makemytrip/) |\n| [Finding the injection for Anesthesia](https://www.geeksforgeeks.org/aptitude/puzzle-5-finding-the-injection-for-anesthesia/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Yahoo](https://www.geeksforgeeks.org/companies/yahoo/) |\n| [3 Bulbs and 3 Switches](https://www.geeksforgeeks.org/aptitude/puzzle-7-3-bulbs-and-3-switches/) | [MakeMyTrip](https://www.geeksforgeeks.org/companies/makemytrip/), [Qualcomm](https://www.geeksforgeeks.org/companies/qualcomm/) |\n| [Camel and Banana Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-15-camel-and-banana-puzzle/) | Amazon, [Yahoo](https://www.geeksforgeeks.org/companies/yahoo/) |\n| [Find the Jar with contaminated pills](https://www.geeksforgeeks.org/aptitude/puzzle-7-find-the-jar-with-contaminated-pills/) | [MakeMyTrip](https://www.geeksforgeeks.org/companies/makemytrip/) |\n| [100 Prisoners with Red/Black Hats](https://www.geeksforgeeks.org/aptitude/puzzle-13-100-prisoners-with-redblack-hats/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [10 Coins Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-24-10-coins-puzzle/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Yahoo](https://www.geeksforgeeks.org/companies/yahoo/) |\n| [Strategy for a 2-Player Coin Game](https://www.geeksforgeeks.org/aptitude/puzzle-14-strategy-for-a-2-player-coin-game/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [5 Pirates and 100 Gold Coins](https://www.geeksforgeeks.org/aptitude/puzzle-20-5-pirates-and-100-gold-coins/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Minimum cut Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-31-minimum-cut-puzzle/) | Amazon |\n| [Prisoner and Policeman Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-34-prisoner-and-policeman-puzzle/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Puzzle - Cheating Husband](https://www.geeksforgeeks.org/gfg-academy/guess-the-victim/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/), [Google](https://www.geeksforgeeks.org/companies/google/) |\n| [Puzzle – Blind Games](https://www.geeksforgeeks.org/aptitude/puzzle-blind-games/) | Bloomberg L.P. |\n| [Puzzle – Chameleons go on a date](https://www.geeksforgeeks.org/aptitude/puzzle-chameleons-go-on-a-date/) | Amazon |\n| [Heaven and Hell](https://www.geeksforgeeks.org/aptitude/puzzle-heaven-hell/) | Amazon, [Infosys](https://www.geeksforgeeks.org/companies/infosys/) |\n| [Mislabeled Jars](https://www.geeksforgeeks.org/aptitude/puzzle-mislabeled-jars/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [8 balls problem](https://www.geeksforgeeks.org/aptitude/puzzle-8-balls-problem/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/), Simence |\n| [Cheryl's Birthday Puzzle and Solution](https://www.geeksforgeeks.org/aptitude/cheryls-birthday-puzzle-and-solution/) | [Facebook](https://www.geeksforgeeks.org/companies/facebook/), Whatsapp, Singapore math Olympic |\n| [Puzzle – The Lion and the Unicorn](https://www.geeksforgeeks.org/aptitude/puzzle-the-lion-and-the-unicorn/) | The Access Group (UK), [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [Farmer, Goat, Wolf, and Cabbage](https://www.geeksforgeeks.org/aptitude/puzzle-farmer-goat-wolf-cabbage/) | [Infosys](https://www.geeksforgeeks.org/companies/infosys/) |\n| [Water Jug Problem](https://www.geeksforgeeks.org/aptitude/puzzle-water-jug-problem/) | Wells Fargo |\n| [Blind man and Pills](https://www.geeksforgeeks.org/aptitude/puzzle-blind-man-and-pills/) | Mentor Graphics |\n| [The Burning Candles](https://www.geeksforgeeks.org/gfg-academy/puzzle-the-burning-candles/) | [Wipro](https://www.geeksforgeeks.org/companies/wipro/) |\n| [Puzzle \\| The Burning Candles](https://www.geeksforgeeks.org/gfg-academy/puzzle-the-burning-candles/) | [Wipro](https://www.geeksforgeeks.org/companies/wipro/), [IBM](https://www.geeksforgeeks.org/companies/ibm/), [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [Rat and Poisonous Milk Bottles](https://www.geeksforgeeks.org/aptitude/puzzle-rat-and-poisonous-milk-bottles/) | [Google](https://www.geeksforgeeks.org/companies/google/) |\n| [Measuring 6L water from 4L and 9L buckets](https://www.geeksforgeeks.org/aptitude/measuring-6l-water-4l-9l-buckets/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Six Houses P, Q, R, S, T, and U](https://www.geeksforgeeks.org/aptitude/puzzle-six-houses-p-q-r-s-t-and-u/) | [CAT Quiz](https://www.geeksforgeeks.org/category/quizzes-gq/cat-quiz/) |\n| [Melting Candles](https://www.geeksforgeeks.org/gfg-academy/melting-candles-puzzle/) | Faang |\n| [Red Hat vs Blue Hat](https://www.geeksforgeeks.org/aptitude/puzzle-47-red-hat-vs-blue-hat/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Puzzle \\| Joint family of seven persons (L, M, N, O, P, Q, and R)](https://www.geeksforgeeks.org/aptitude/puzzle-joint-family-of-seven-persons-l-m-n-o-p-q-and-r/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [Puzzle \\| The Circle of Lights](https://www.geeksforgeeks.org/aptitude/puzzle-the-circle-of-lights/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/), Bloomberg |\n| [Puzzle \\| 9 Students and Red Black Hats](https://www.geeksforgeeks.org/aptitude/puzzle-9-students-and-red-black-hats/) | [Google](https://www.geeksforgeeks.org/companies/google/) |\n| [Light all the bulbs](https://www.geeksforgeeks.org/competitive-programming/puzzle-light-all-the-bulbs/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/), Bloomberg |\n| [Distribute the Water](https://www.geeksforgeeks.org/aptitude/puzzle-distribute-the-water/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Puzzle \\| Can 2 persons be with same number of hairs on their heads?](https://www.geeksforgeeks.org/aptitude/puzzle-can-2-persons-be-with-same-number-of-hairs-on-their-heads/) | [oppo](https://www.geeksforgeeks.org/companies/oppo/), inflame |\n| [Weight of Heavy Ball](https://www.geeksforgeeks.org/dsa/weight-heavy-ball/) | [IBM](https://www.geeksforgeeks.org/companies/ibm/) |\n\n**Read More:** [Articles on Logical Puzzles](https://www.geeksforgeeks.org/tag/logical-puzzles/)\n\n## 3. Arrangement Puzzles\n\n| **Puzzle Title** | **Asked in Company** |\n| --- | --- |\n| [10 Coins Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-24-10-coins-puzzle/) | [Google](https://www.geeksforgeeks.org/companies/google/), [Yahoo](https://www.geeksforgeeks.org/companies/yahoo/) |\n| [Days of the month using 2 dice](https://www.geeksforgeeks.org/aptitude/puzzle-23-days-of-month-using-2-dice/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/) |\n| [Tic Tac Toe Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-38-tic-tac-toe-puzzle/) | Amazon |\n| [Matchstick Puzzle](https://www.geeksforgeeks.org/aptitude/puzzle-36-matchstick-puzzle/) | Kirloskar Brothers, SLB |\n| [Last Palindrome Date Before 10/02/2001](https://www.geeksforgeeks.org/aptitude/puzzle-30-last-palindrome-data/) | Amazon |\n| [10 identical bottles of pills](https://www.geeksforgeeks.org/aptitude/puzzle-10-identical-bottles-pills/) | ZS Associate |\n| [10 Balls in 5 Lines](https://www.geeksforgeeks.org/aptitude/puzzle-10-balls-in-5-lines/) | [Publicis Sapient](https://www.geeksforgeeks.org/companies/publicis-sapient/) |\n| [Round table coin game](https://www.geeksforgeeks.org/aptitude/puzzle-round-table-coin-game/) | ElectrifAi |\n| [Puzzle \\| The Circle of Lights](https://www.geeksforgeeks.org/aptitude/puzzle-the-circle-of-lights/) | [Microsoft](https://www.geeksforgeeks.org/companies/microsoft/), Bloomberg |\n\n**Read More:** [Articles on Arrangement Puzzles](https://www.geeksforgeeks.org/tag/arrangement-puzzles/)\n\n## 4. Shape based Puzzles\n\n| Puzzle Title | Asked in Company |\n| --- | --- |\n| [3 cuts to cut the round cake into 8 equal pieces](https://www.geeksforgeeks.org/aptitude/puzzle-3-cuts-cut-round-cake-8-equal-pieces/) | [Adobe](https://www.geeksforgeeks.org/companies/adobe-systems/), [Citius Tech](https://www.geeksforgeeks.org/companies/citiustech-healthcare-technology-private-ltd/), [Cognizant](https://www.geeksforgeeks.org/companies/cognizant-technology-solutions/) |\n| [Chessboard and dominos](https://www.geeksforgeeks.org/aptitude/puzzle-25chessboard-and-dominos/) | [Google](https://www.geeksforgeeks.org/companies/google/) |\n| [Puzzle 36 \\| (Matchstick Puzzle)](https://www.geeksforgeeks.org/aptitude/puzzle-36-matchstick-puzzle/) | SLB |\n| [Maximum pieces that can be cut from a Circle using 6 straight lines](https://www.geeksforgeeks.org/aptitude/puzzle-maximum-pieces-that-can-be-cut-from-a-circle-using-6-straight-lines/) | [TCS](https://www.geeksforgeeks.org/companies/tata-consultancy-service-tcs/) |\n| [Splitting a Cake with a Missing Piece in two equal portion](https://www.geeksforgeeks.org/aptitude/puzzle-splitting-a-cake-with-a-missing-piece-in-two-equal-portion/) | [SAP](https://www.geeksforgeeks.org/companies/sap/) |\n| [3 Ants and Triangle](https://www.geeksforgeeks.org/aptitude/puzzle-21-3-ants-and-triangle/) | [Intuit](https://www.geeksforgeeks.org/companies/intuit/), ZS Associate, [EXL](https://www.geeksforgeeks.org/companies/exl/) |\n\n**Read More:** [Articles on Shape based puzzles](https://www.geeksforgeeks.org/tag/shape-puzzles/)\n\n## 5. Mechanical Puzzles\n\n1. [Algorithm to solve Rubik's Cube](https://www.geeksforgeeks.org/blogs/algorithm-to-solve-rubiks-cube/)\n2. [Crossword Puzzle Of The Week #1 (for DSA)](https://www.geeksforgeeks.org/dsa/crossword-puzzle-of-the-week-1-for-dsa/)\n3. [Crossword Puzzle Of The Week #2 (for Computer Science and Applications)](https://www.geeksforgeeks.org/aptitude/crossword-puzzle-of-the-week-2-for-computer-science-and-applications/)\n4. [Crossword Puzzle Of The Week #3 (for Database and Queries)](https://www.geeksforgeeks.org/aptitude/crossword-puzzle-of-the-week-3-for-database-and-queries/)\n5. [Crossword Puzzle Of The Week #4 (for Object Oriented Programming)](https://www.geeksforgeeks.org/aptitude/crossword-puzzle-of-the-week-4-for-object-oriented-programming/)\n\n## Quick Links:\n\n- [Logic Building Coding Problems](https://www.geeksforgeeks.org/dsa/logic-building-problems/)\n- ['Practice Problems' on Puzzles](https://www.geeksforgeeks.org/explore?page=1&category=Puzzle&sortBy=submissions)\n- [Recent Puzzles!](https://www.geeksforgeeks.org/category/puzzles/)"}
{"reference": "https://www.geeksforgeeks.org/courses/cyber-security-skill-up", "content": "# Cyber Security - Skill Up\n\nSelf-Paced Course\n\n**7k+ interested Geeks**\n\nThis Cybersecurity Course takes you from a complete beginner to an advanced level, covering computer basics, ethical hacking, web security, malware, cloud, and incident response. With hands-on labs using free tools like Wireshark, Nmap, Burp Suite, Packet Tracer, and TryHackMe, you'll learn both hacking and defense skills to become job-ready for roles such as Ethical Hacker, Security Analyst, or SOC Engineer. This 12-week program provides a complete journey into cybersecurity.\n\n**Duration:** 10 Weeks\n\n## Course Overview\n\nThis Cybersecurity Program is designed to take you from beginner to job-ready security professional. You'll start with the foundations of computer systems, building a strong base for understanding how digital environments work. Learn core security principles like the CIA triad, access control, and cryptography. Progress into **Red Team skills** such as reconnaissance, scanning, exploitation, web application security, and penetration testing with tools like Nmap, Metasploit, and Burp Suite. At the same time, strengthen your **Blue Team skills** by practicing SOC monitoring, SIEM, log analysis, malware detection, incident response, and digital forensics using free and open-source labs. You'll also cover cloud security, compliance standards, and secure coding practices to round out your expertise. The entire program is structured to be completed in **12 weeks**.\n\n### Course Highlights\n\n- Understand core cybersecurity concepts, threats, and defense strategies\n- Learn and practice Red Team techniques: ethical hacking, web attacks, wireless security, and exploitation\n- Develop Blue Team expertise: SOC monitoring, SIEM tools, log analysis, and digital forensics\n- Work with essential tools like Wireshark, Nmap, Metasploit, Burp Suite, and Autopsy\n- Analyze and respond to real-world threats such as malware, phishing, and misconfigurations\n- Gain exposure to cloud security, compliance (GDPR, ISO 27001, PCI-DSS), and risk management\n- Practice with free platforms like TryHackMe, Hack The Box (free tier), and OWASP Juice Shop\n- Complete Red vs Blue team simulations and Capture-the-Flag (CTF) challenges\n- Build job-ready skills for roles like Ethical Hacker, SOC Analyst, or Security Engineer\n\n## Course Content\n\n### Week 1: Cybersecurity Fundamentals & Lab Setup\n\n- Cybersecurity Basics\n- Cybersecurity Trends & Salaries\n- Cyber Attacks and Principles\n- Basic Access Controls\n- Network Security Fundamentals\n- Setting Up Your First Lab\n\n### Week 2: Foundations of Network Defense and Encryption\n\n- Firewall Fundamentals\n- Network Traffic Analysis\n- Threat Modeling and Vulnerabilities\n- Applied Cryptography\n- Network Protocol & Services\n\n### Week 3: OSINT & Network Security\n\n- Introduction to Ethical Hacking & OSINT\n- Network Scanning\n- Enumeration & Service Discovery\n- Vulnerability Scanning & Analysis\n- Exploitation Techniques (Metasploit & Public Exploits)\n\n### Week 4\n\nStay tuned! The upcoming weeks' syllabus will be available soon."}
{"reference": "https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/", "content": "# Principal Component Analysis (PCA)\n\n**PCA (Principal Component Analysis)** is a [dimensionality reduction](https://www.geeksforgeeks.org/machine-learning/dimensionality-reduction/) technique used in data analysis and machine learning. It helps you to reduce the number of features in a dataset while keeping the most important information. It changes your original features into new features these new features don't overlap with each other and the first few keep most of the important differences found in the original data.\n\nPCA is commonly used for data preprocessing for use with machine learning algorithms. It helps to remove redundancy, improve computational efficiency and make data easier to visualize and analyze especially when dealing with high-dimensional data.\n\n## How Principal Component Analysis Works\n\nPCA uses linear algebra to transform data into new features called principal components. It finds these by calculating eigenvectors (directions) and eigenvalues (importance) from the covariance matrix. PCA selects the top components with the highest eigenvalues and projects the data onto them simplify the dataset.\n\n> **Note:** It prioritizes the directions where the data varies the most because more variation = more useful information.\n\nImagine you're looking at a messy cloud of data points like stars in the sky and want to simplify it. PCA helps you find the \"most important angles\" to view this cloud so you don't miss the big patterns. Here's how it works step by step:\n\n### Step 1: Standardize the Data\n\nDifferent features may have different units and scales like salary vs. age. To compare them fairly PCA first [standardizes](https://www.geeksforgeeks.org/machine-learning/normalization-vs-standardization/) the data by making each feature have:\n\n- A mean of 0\n- A standard deviation of 1\n\n\\[ Z = \\frac{X - \\mu}{\\sigma} \\]\n\nwhere:\n\n- \\(\\mu\\) is the mean of independent features \\(\\mu = \\{ \\mu_1, \\mu_2, \\cdots, \\mu_m \\}\\)\n- \\(\\sigma\\) is the standard deviation of independent features \\(\\sigma = \\{ \\sigma_1, \\sigma_2, \\cdots, \\sigma_m \\}\\)\n\n### Step 2: Calculate Covariance Matrix\n\nNext PCA calculates the [covariance matrix](https://www.geeksforgeeks.org/maths/covariance-matrix/) to see how features relate to each other whether they increase or decrease together. The covariance between two features \\(x_1\\) and \\(x_2\\) is:\n\n\\[ \\text{cov}(x_1, x_2) = \\frac{\\sum_{i=1}^{n} (x1_i - \\bar{x1})(x2_i - \\bar{x2})}{n-1} \\]\n\nWhere:\n\n- \\(\\bar{x}_1\\) and \\(\\bar{x}_2\\) are the mean values of features \\(x_1\\) and \\(x_2\\)\n- \\(n\\) is the number of data points\n\nThe value of covariance can be positive, negative or zeros.\n\n### Step 3: Find the Principal Components\n\nPCA identifies **new axes** where the data spreads out the most:\n\n- **1st Principal Component (PC1):** The direction of maximum variance (most spread).\n- **2nd Principal Component (PC2):** The next best direction, **perpendicular to PC1** and so on.\n\nThese directions come from the **eigenvectors** of the covariance matrix and their importance is measured by **eigenvalues**. For a square matrix \\(A\\) an **eigenvector** \\(X\\) (a non-zero vector) and its corresponding **eigenvalue** \\(\\lambda\\) satisfy:\n\n\\[ AX = \\lambda X \\]\n\nThis means:\n\n- When **A** acts on \\(X\\) it only stretches or shrinks \\(X\\) by the scalar \\(\\lambda\\).\n- The direction of \\(X\\) remains unchanged hence eigenvectors define \"stable directions\" of \\(A\\).\n\nEigenvalues help rank these directions by importance.\n\n### Step 4: Pick the Top Directions & Transform Data\n\nAfter calculating the eigenvalues and eigenvectors PCA ranks them by the amount of information they capture. We then:\n\n1. **Select the top k components** that capture most of the variance like 95%.\n2. **Transform the original dataset** by projecting it onto these top components.\n\nThis means we reduce the number of features (dimensions) while keeping the important patterns in the data.\n\n![Principal Component Analysis - Geeksforgeeks](https://media.geeksforgeeks.org/wp-content/uploads/20230420165431/Principal-Componenent-Analysisi.webp)\n\n*Transform this 2D dataset into a 1D representation while preserving as much variance as possible.*\n\nIn the above image the original dataset has two features \"Radius\" and \"Area\" represented by the black axes. PCA identifies two new directions: **PC₁** and **PC₂** which are the **principal components**.\n\n- These new axes are rotated versions of the original ones. **PC₁** captures the maximum variance in the data meaning it holds the most information while **PC₂** captures the remaining variance and is perpendicular to PC₁.\n- The spread of data is much wider along PC₁ than along PC₂. This is why PC₁ is chosen for dimensionality reduction. By projecting the data points (blue crosses) onto PC₁ we effectively **transform the 2D data into 1D and** retain most of the important structure and patterns.\n\n## Implementation of Principal Component Analysis in Python\n\nHence PCA uses a linear transformation that is based on preserving the most variance in the data using the least number of dimensions. It involves the following steps:\n\n### Step 1: Importing Required Libraries\n\nWe import the necessary library like [pandas](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/), [numpy](https://www.geeksforgeeks.org/python/introduction-to-numpy/), [scikit learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/), [seaborn](https://www.geeksforgeeks.org/python/introduction-to-seaborn-python/) and [matplotlib](https://www.geeksforgeeks.org/python/python-introduction-matplotlib/) to visualize results.\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n\n### Step 2: Creating Sample Dataset\n\nWe make a small dataset with three features Height, Weight, Age and Gender.\n\n```python\ndata = {\n    'Height': [170, 165, 180, 175, 160, 172, 168, 177, 162, 158],\n    'Weight': [65, 59, 75, 68, 55, 70, 62, 74, 58, 54],\n    'Age': [30, 25, 35, 28, 22, 32, 27, 33, 24, 21],\n    'Gender': [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]  # 1 = Male, 0 = Female\n}\ndf = pd.DataFrame(data)\nprint(df)\n```\n\n**Output:**\n\n![dataset](https://media.geeksforgeeks.org/wp-content/uploads/20250516130656047418/dataset.png)\n\n*Dataset*\n\n### Step 3: Standardizing the Data\n\nSince the features have different scales Height vs Age we standardize the data. This makes all features have mean = 0 and standard deviation = 1 so that no feature dominates just because of its units.\n\n```python\nX = df.drop('Gender', axis=1)\ny = df['Gender']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df)\n```\n\n### Step 4: Applying PCA algorithm\n\n- We reduce the data from 3 features to 2 new features called principal components. These components capture most of the original information but in fewer dimensions.\n- We split the data into 70% training and 30% testing sets.\n- We train a [logistic regression](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/) model on the reduced training data and predict gender labels on the test set.\n\n```python\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n```\n\n### Step 5: Evaluating with Confusion Matrix\n\nThe [confusion matrix](https://www.geeksforgeeks.org/machine-learning/confusion-matrix-machine-learning/) compares actual vs predicted labels. This makes it easy to see where predictions were correct or wrong.\n\n```python\ncm = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Female', 'Male'], yticklabels=['Female', 'Male'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n```\n\n**Output:**\n\n![Confusion-matrix](https://media.geeksforgeeks.org/wp-content/uploads/20250516130833359837/Confusion-matrix.png)\n\n*Confusion matrix*\n\n### Step 6: Visualizing PCA Result\n\n```python\ny_numeric = pd.factorize(y)[0]\n\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_numeric, cmap='coolwarm', edgecolor='k', s=80)\nplt.xlabel('Original Feature 1')\nplt.ylabel('Original Feature 2')\nplt.title('Before PCA: Using First 2 Standardized Features')\nplt.colorbar(label='Target classes')\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_numeric, cmap='coolwarm', edgecolor='k', s=80)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('After PCA: Projected onto 2 Principal Components')\nplt.colorbar(label='Target classes')\n\nplt.tight_layout()\nplt.show()\n```\n\n**Output:**\n\n![PCA](https://media.geeksforgeeks.org/wp-content/uploads/20250516131136375690/PCA.webp)\n\n*PCA Algorithm*\n\n- **Left Plot Before PCA**: This shows the **original standardized data** plotted using the first two features. There is **no guarantee of clear separation** between classes as these are raw input dimensions.\n- **Right Plot After PCA**: This displays the **transformed data** using the **top 2 principal components**. These new components capture the **maximum variance** often showing better **class separation and structure** making it easier to analyze or model.\n\n## Advantages of Principal Component Analysis\n\n1. **Multicollinearity Handling:** Creates new, uncorrelated variables to address issues when original features are highly correlated.\n2. **Noise Reduction:** Eliminates components with low variance enhance data clarity.\n3. **Data Compression:** Represents data with fewer components reduce storage needs and speeding up processing.\n4. **Outlier Detection:** Identifies unusual data points by showing which ones deviate significantly in the reduced space.\n\n## Disadvantages of Principal Component Analysis\n\n1. **Interpretation Challenges:** The new components are combinations of original variables which can be hard to explain.\n2. **Data Scaling Sensitivity:** Requires proper scaling of data before application or results may be misleading.\n3. **Information Loss:** Reducing dimensions may lose some important information if too few components are kept.\n4. **Assumption of Linearity:** Works best when relationships between variables are linear and may struggle with non-linear data.\n5. **Computational Complexity:** Can be slow and resource-intensive on very large datasets.\n6. **Risk of Overfitting:** Using too many components or working with a small dataset might lead to models that don't generalize well."}
{"reference": "https://www.geeksforgeeks.org/courses/category/gate", "content": "# GATE CSE & DA Classroom & Live Online Courses [2026, 2027, 2028]\n\n## Explore GATE Foundation Programs\n\n### Crash Course - CSE GATE 2026\n\n**Batch Start Date:** 06 Oct 2025  \n**Schedule:** Mon to Fri  \n**Course Duration:** 360+ hours  \n**Language:** English  \n**Batch Timing:** (Morning) & (Evening)  \n\n### Crash Course + Question Practice Batch (3000+ Questions)\n\n**Batch Start Date:** 06 Oct 2025  \n**Schedule:** Mon to Sun  \n**Course Duration:** 504+ hours  \n**Language:** English  \n**Batch Timing:** (Morning) & (Evening)  \n\n### Agni Pariksha - GATE CSE\n\n**Batch Start Date:** 01 Sep 2025  \n**Schedule:** Mon to Sun  \n**USP:** 3100+ Practice Questions  \n**Language:** English  \n**Batch Timing:** (Morning) & (Evening)  \n\n### GATE CSE Rank Booster with Expert-Curated Questions\n\n**Batch Start Date:** 28 Jul 2025  \n**Schedule:** Mon to Fri  \n**Course Duration:** 780+ hours  \n**Language:** English  \n**Batch Timing:** (Morning) & (Evening)  \n\n### GATE CS & IT Weekdays (Live + Recorded)\n\n**Batch Start Date:** 08 Sep 2025  \n**Schedule:** Mon to Fri  \n**Course Duration:** 810+ hours  \n**Language:** English/Hinglish  \n**Batch Timing:** (Morning) & (Evening)  \n\n## DA Crash Course\n\n### Interested in Bulk Purchase?\n\nContact us for special pricing!  \n[+91-8130600851](tel:+91-8130600851)\n\n## GATE Courses - What Sets Us Apart\n\n### Complete Syllabus\n\nComprehensive GATE prep with 900+ live hours for CS/IT, 600+ for DA, including 300+ hours of recorded sessions.\n\n### Teaching Approach\n\nEngaging classes with instant resources, real-time Q&A, and personalized 1:1 mentorship.\n\n### Study Material\n\nStudy materials with curated workbooks, PYQs, theory booklets, daily practice problems, and a formula book for quick reference.\n\n### Online Test Series\n\n200+ mock tests with varied formats and detailed performance tracking to monitor progress.\n\n### Doubt Resolution\n\nRound-the-clock support with instant AI assistance, 24-hour mentor responses, and doubt-solving sessions.\n\n### Interview Guidance Program\n\nPost-exam guidance with personalized counseling and interview prep for IITs and PSUs selection.\n\n### Placement Preparation\n\nComprehensive learning with recorded DSA & core subject lectures, industry insights, mock tests, and soft skills courses.\n\n### Semester Preparation\n\nCore subjects including Cyber Security, OOP, Machine Learning, and more, with future content additions to meet university needs.\n\n## Learn from the Best\n\n### Vijay Kumar Agarwal\nNIT M.Tech, 13 years’ experience, mentors GATE in CS & IT.\n\n### Sakshi Singhal\nIIT Roorkee M.Sc., AIR 56 CSIR-NET, mentors in Maths, ML & AI.\n\n### Shailendra Singh\nM.Tech, GATE 99.24 percentile, mentors in CS, PSUs, and tech skills.\n\n### Devasane Mallesham\nIIT Bombay M.Tech, 13 years’ experience, mentors GATE in CS.\n\n### Satish Kumar Yadav\nBE IT, Mumbai Univ, 200K+ trained, expert in Discrete & Engg Maths, DBMS etc.\n\n### Avinash Kumar\nWith 10+ years’ experience, trained 20K+ in GATE Maths, Reasoning & Aptitude.\n\n### Gaurav Raj\nIIT Jodhpur M.Tech, 12+ years' experience, expert in GATE CS, MERN Stack, and DSA.\n\n### Dr. Khaleel\nPh.D. in CS, 29 years’ experience, mentors GATE in Principles of Operating Systems and Design and Analysis of Algorithms.\n\n### Chandan Jha\nEx-ISRO, AIR 23 GATE, mentors GATE in Digital Logic Design (DLD).\n\n## What Students Say\n\n**Daram Vishnu Vardhan**  \nGATE AIR 2340  \nGFG notes were instrumental in my success. Their concise yet comprehensive content made studying efficient and effective. I found clarity on complex topics, boosting my understanding and confidence. Grateful for such invaluable resources.\n\n**KILAPARTHI VISHNU VARDHAN**  \nGATE AIR 288  \nI am writing to express my heartfelt gratitude for the invaluable role Geeks for Geeks (GFG) Mentors played in helping me crack the GATE DATA SCI 2024 exam and secure an All India Rank (AIR) of 288. A Big Thank You to GFG Mentors: A special thanks goes out to the GFG Mentors for their exceptional teaching. Their clear and in-depth explanations for Discrete Mathematics and Engineering Mathematics provided a rock-solid foundation that I couldn't have achieved anywhere else. The mentors' teaching truly stands out compared to other platforms I explored. The Importance of Maths, Bhai! As someone who scored a whopping 800 in CS, I firmly believe that mastering Maths is absolutely crucial for GATE success. Many platforms tend to overlook this important section, which carries a weight of nearly 13 marks! Geeks for Geeks: A One-Stop Shop Beyond Maths, Geeks for Geeks became my one-stop shop for GATE preparation. The user-friendly interface and the treasure trove of high-quality materials on Data Structures & Algorithms (the highest scoring subject in CS) were immensely helpful. In fact, I even used the platform to clarify doubts I had during my past college projects. The detailed explanations for subjects like Operating Systems and Computer Networks further strengthened my grasp of the concepts. Test Series that Packed a Punch I also want to give a big shout out to the Geeks for Geeks test series. The focus on truly understanding the concepts, along with the inclusion of technical numerical problems, made them exceptional tools for exam preparation. A Recommendation from the Heart Having explored a variety of platforms during my GATE journey, I can confidently say that Geeks for Geeks stands out as the most valuable resource. I highly recommend Geeks for Geeks to all future GATE aspirants out there. It will definitely give your preparation a big boost.\n\n**Anant Om**  \nGATE AIR 951  \nI am thrilled to share my success with GeeksforGeeks (GFG), which played a pivotal role in my GATE DA 2024 achievement. I have secured AIR 951 despite not having a strong CS background. GFG's Doubt Classes were invaluable, offering personalized assistance whenever needed. Their in-depth syllabus coverage ensured a strong conceptual understanding, while the abundance of practice problems sharpened my problem-solving skills effectively. Despite offering top-notch resources and high quality, GFG charges very less fees so that it does not become a burden for any of the students. I, Anant Om, highly recommend GFG to anyone aiming for GATE DA.\n\n**Soumyadev Saha**  \nGATE AIR 441  \nI am incredibly grateful for GFG's Data Analytics (DA) course, especially since the DA paper was introduced for the first time this year. Finding proper course materials was a challenge, but GFG's DA course came to my rescue. Upon purchasing the course, I immediately realized that I had made the right choice. The course offered doubt clearing sessions, well-structured topics covering nearly everything, recorded lectures, and mock tests. These resources were invaluable in helping me understand the basics and gain practical experience with the types of questions likely to appear on the DA paper. One of the standout features of the course was the immediate provision of correct explanations for any wrong answers. This saved me a significant amount of time that would have otherwise been spent searching for explanations online. In summary, I am immensely thankful to GFG for creating such an exceptional course. I consider myself fortunate to have found it at the right time and believe that it played a crucial role in my success.\n\n**Koyya Saketh Venkata Sai**  \nGATE AIR 2290  \nGFG helped me in understanding the most important concepts while I was preparing for my gate DA paper.\n\n**Koustubh**  \nGATE AIR 3397  \nFinding excellent articles elucidating fundamental Gate exam concepts was pivotal for my success. Staying composed throughout the preparation journey was essential. These resources provided clarity, instilled confidence, and ultimately contributed to my achievement in the exam. Highly recommended for aspirants seeking effective study materials.\n\n**Prayas Chaudhary**  \nGATE AIR 1823  \nGFG helped me a lot in my journey. Every time I found difficulty in my preparation, the name that came to my mind was GFG. On this platform, there is a lot of study material in a well-formatted manner. There are so many questions with multiple solutions, and a lot more...\n\n**SUYASH**  \nGATE AIR 447  \nIn the GFG test series, I was able to find the new patterns of questions and the questions were very relevant. The test series assisted me in thinking about the questions in a new way. It helped me a lot.\n\n**MAYUKH MAJUMDAR**  \nGATE AIR 1856  \ngeeksforGeeks has been instrumental in my success in GATE (CS) 2024. Their comprehensive lecture videos, insightful web articles, and challenging yet exam-oriented test series were the pillars of my preparation. Thanks to their meticulous guidance, I secured AIR 1856(GATE Score:632), a testament to the effectiveness of their resources. I highly recommend Geeks For Geeks to any aspiring GATE candidate seeking top-notch support and guidance.\n\n**Sai Rahul N**  \nGATE AIR 3864  \nI recently utilized geeksforgeeks to prepare for the GATE exam, and I must say, it was a valuable resource throughout my preparation journey. It significantly contributed to my success. The vast array of study materials, practice questions, and mock tests provided me with ample opportunities to strengthen my understanding of key concepts. I particularly appreciated the clarity and depth of explanations provided, which enabled me to grasp even the most challenging topics with ease. Particularly I found GATE LMN last minute notes to be useful to me. So do give them a try.\n\n**Soumyadev Saha**  \nGATE AIR 3874  \nThe GFG's CS/IT gate course was awesome, it was the only place from where I studied for GATE, my only regret is that If I could have bought the course earlier and might not be that busy with final year projects, seminars, and semesters, I surely could have secured even better rank. The course was completely comprehensive, properly structured, and had even mock test and practice sections. All in one, it was a complete package.\n\n**Ojas Hegde**  \nGATE AIR 565  \nI was very undisciplined, so I needed some kind of framework, but I also study best at my own pace. The chapter wise recorded lectures helped me break down the portions into manageable chunks that motivated me to study instead of getting overwhelmed. I only studied theory from these lectures.it was well explained. Had I been more disciplined I could have taken advantage of the contest system and gotten a even better rank, but I am satisfied with this course even without getting the full value out of it.\n\n**Abhijeet Kumar**  \nGATE AIR 1316  \nI am thrilled to share my experience with the GFG GATE CS Course, as it played an instrumental role in helping me to achieve an impressive All India Rank of 1316 in the GATE CS 2024 exam with a gate score of 668. I started my preparation in September; I had only 5 months to prepare for GATE. At the time, I had no hope of getting such good marks. I have attended GFG's CIP course, so I knew that their courses are structured, and thus I decided to take the GATE CS self-paced course for my preparations. Before discovering this course, I was overwhelmed by the vast syllabus and intricate concepts of the GATE exam. However, the structured approach and comprehensive content provided by GeeksforGeeks helped me navigate through the complexities with confidence. One aspect that truly stood out was the depth of coverage across all topics. From fundamental concepts to advanced problem-solving techniques, every aspect of the syllabus was meticulously explained, leaving no room for doubt or confusion. The well-organized modules and practice exercises allowed me to reinforce my understanding and hone my skills effectively. There are also articles for every subject, which allowed me to make my notes short, and for deeper understanding while revising, I referred to articles. The PYQs for all the topics and chapters helped a lot while giving mock tests. I have given mock tests on various platforms to get diversity. These simulated exams not only helped me assess my progress but also equipped me with the strategies needed to tackle the actual exam confidently. I am immensely grateful to geeksforgeeks, for their unwavering support and commitment to helping students excel in their GATE endeavors. Thanks to their exceptional course, I was able to surpass my own expectations and secure a commendable rank in the GATE CS 2024 exam. I wholeheartedly recommend the geeksforgeeks GATE Course to any aspiring GATE candidate looking to achieve similar success.\n\n**Saptarshi Dutta**  \nGATE AIR 2041  \nFor my DSA knowledge, GHG POTD helped me a lot. I practiced problems daily on the GFG Platform which helped me to build a logical and competitive mindset. Even on the day before the exam I did solve the POTD. Also, the plethora of libraries for Machine learning and Data Science helped me a lot.\n\n**Bala Sai Vamsi Madhupada**  \nGATE AIR 19022  \nMy first attempt was a mediocre one and I just prepared around 3-4 subjects from geeks for geeks and was able to score way above qualifying marks, thanks to the quality content for geeks for geeks! This year, I have even more time to prepare for gate 2025 and this time, I’m sure of scoring below 500 rank and top score by finishing all the subjects!\n\n## Frequently Asked Questions\n\n### What does the CS + DA GATE course cover?\n\n### What does the CS + DA + Placement course include?\n\n### What does the GATE CS + DA + Placement + Semester course include?\n\n### Will Engineering Mathematics and Aptitude be part of the course?\n\n### What subjects will be covered in the Semester Plan?"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/decision-tree-introduction-example/", "content": "# Decision Tree in Machine Learning\n\nA decision tree is a supervised learning algorithm used for both classification and regression tasks. It has a hierarchical tree structure which consists of a root node, branches, internal nodes and leaf nodes. It works like a flowchart help to make decisions step by step where:\n\n- Internal nodes represent attribute tests\n- Branches represent attribute values\n- Leaf nodes represent final decisions or predictions.\n\nDecision trees are widely used due to their interpretability, flexibility and low preprocessing needs.\n\n## How Does a Decision Tree Work?\n\nA decision tree splits the dataset based on feature values to create pure subsets ideally all items in a group belong to the same class. Each leaf node of the tree corresponds to a class label and the internal nodes are feature-based decision points. Let's understand this with an example.\n\n![predicting whether a customer will buy a product](https://media.geeksforgeeks.org/wp-content/uploads/20250408153824016146/predicting_whether_a_customer_will_buy_a_product.webp)\n\n*Decision Tree*\n\nLet's consider a decision tree for predicting whether a customer will buy a product based on age, income and previous purchases: Here's how the decision tree works:\n\n**1. Root Node (Income)**\n\n**First Question**: **\"Is the person's income greater than $50,000?\"**\n\n- If Yes, proceed to the next question.\n- If No, predict \"No Purchase\" (leaf node).\n\n**2. Internal Node (Age)**:\n\n**If the person's income is greater than $50,000**, ask: **\"Is the person's age above 30?\"**\n\n- If Yes, proceed to the next question.\n- If No, predict \"No Purchase\" (leaf node).\n\n**3. Internal Node (Previous Purchases)**:\n\n- If the person is above 30 and has made previous purchases, predict \"Purchase\" (leaf node).\n- If the person is above 30 and has not made previous purchases, predict \"No Purchase\" (leaf node).\n\n![Decision making with 2 Decision Tree](https://media.geeksforgeeks.org/wp-content/uploads/20250408153952530850/tree_1_customer_demographics.webp)\n\n*Decision making with 2 Decision Tree*\n\n**Example:** Predicting Whether a Customer Will Buy a Product Using Two Decision Trees\n\n### **Tree 1:** Customer Demographics\n\nFirst tree asks two questions:\n\n1. \"Income > $50,000?\"\n\n   - If Yes, Proceed to the next question.\n   - If No, \"No Purchase\"\n\n2. \"Age > 30?\"\n\n   - Yes: \"Purchase\"\n   - No: \"No Purchase\"\n\n### Tree 2: Previous Purchases\n\n\"Previous Purchases > 0?\"\n\n- Yes: \"Purchase\"\n- No: \"No Purchase\"\n\nOnce we have predictions from both trees, we can combine the results to make a final prediction. If Tree 1 predicts \"Purchase\" and Tree 2 predicts \"No Purchase\", the final prediction might be \"Purchase\" or \"No Purchase\" depending on the weight or confidence assigned to each tree. This can be decided based on the problem context.\n\n## Information Gain and Gini Index in Decision Tree\n\nTill now we have discovered the basic intuition and approach of how decision tree works, so lets just move to the attribute selection measure of decision tree. We have two popular attribute selection measures used:\n\n**1. Information Gain**\n\n### Information Gain\n\nInformation Gain tells us how useful a question (or feature) is for splitting data into groups. It measures how much the uncertainty decreases after the split. A good question will create clearer groups and the feature with the highest Information Gain is chosen to make the decision.\n\nFor example if we split a dataset of people into \"Young\" and \"Old\" based on age and all young people bought the product while all old people did not, the Information Gain would be high because the split perfectly separates the two groups with no uncertainty left\n\n- Suppose $S$ is a set of instances $A$ is an attribute, $S_v$ is the subset of $S$, $v$ represents an individual value that the attribute $A$ can take and Values ($A$) is the set of all possible values of $A$ then\n\n> Gain(S, A) = Entropy(S) - $\\sum_{v}^{A}\\frac{|S_{v}|}{|S|}$. Entropy($S_{v}$)\n\n- **Entropy:** is the measure of uncertainty of a random variable it characterizes the impurity of an arbitrary collection of examples. The higher the entropy more the information content.\n\nFor example if a dataset has an equal number of \"Yes\" and \"No\" outcomes (like 3 people who bought a product and 3 who didn't), the entropy is high because it's uncertain which outcome to predict. But if all the outcomes are the same (all \"Yes\" or all \"No\") the entropy is 0 meaning there is no uncertainty left in predicting the outcome\n\nSuppose $S$ is a set of instances, $A$ is an attribute, $S_v$ is the subset of $S$ with $A = v$ and Values ($A$) is the set of all possible values of $A$, then\n\n> Gain(S, A) = Entropy(S) - $\\sum_{v \\epsilon Values(A)}\\frac{|S_{v}|}{|S|}$. Entropy($S_{v}$)\n\n**Example:**\n\n> For the set X = {a,a,a,b,b,b,b,b}  \n> Total instances: 8  \n> Instances of b: 5  \n> Instances of a: 3\n\n> $\\begin{aligned}\\text{Entropy } H(X) & = \\left[ \\left( \\frac{3}{8} \\right)\\log_{2}\\frac{3}{8} + \\left( \\frac{5}{8} \\right)\\log_{2}\\frac{5}{8} \\right]\\\\\\\\& = -[0.375 (-1.415) + 0.625 (-0.678)] \\\\\\\\& = -(-0.53-0.424) \\\\\\\\& = 0.954\\end{aligned}$\n\n### **Building Decision Tree using Information Gain the essentials**\n\n- Start with all training instances associated with the root node\n- Use info gain to choose which attribute to label each node with\n- Recursively construct each subtree on the subset of training instances that would be classified down that path in the tree.\n- If all positive or all negative training instances remain, the label that node \"yes\" or \"no\" accordingly\n- If no attributes remain label with a majority vote of training instances left at that node\n- If no instances remain label with a majority vote of the parent's training instances.\n\n**Example:** Now let us draw a Decision Tree for the following data using Information gain. Training set: 3 features and 2 classes\n\n| X | Y | Z | C |\n|---|---|---|---|\n| 1 | 1 | 1 | I |\n| 1 | 1 | 0 | I |\n| 0 | 0 | 1 | II |\n| 1 | 0 | 0 | II |\n\nHere, we have 3 features and 2 output classes. To build a decision tree using Information gain. We will take each of the features and calculate the information for each feature.\n\n![333](https://media.geeksforgeeks.org/wp-content/uploads/20250804112755899209/333.webp)\n\n*Split on attribute X*\n\n![444](https://media.geeksforgeeks.org/wp-content/uploads/20250804112900346223/444.webp)\n\n*Split on attribute Y*\n\n![555](https://media.geeksforgeeks.org/wp-content/uploads/20250804113010619739/555.webp)\n\n*Split on attribute Z*\n\nFrom the above images we can see that the information gain is **maximum** when we make a split on feature Y. So, for the root node best-suited feature is feature Y. Now we can see that while splitting the dataset by feature Y, the child contains a pure subset of the target variable. So we don't need to further split the dataset. The final tree for the above dataset would look like this:\n\n![information gain on attribute Y](https://media.geeksforgeeks.org/wp-content/uploads/20250804113116461130/777.webp)\n\n*information gain on attribute Y*\n\n**2. Gini Index**\n\n### Gini Index\n\nGini Index is a metric to measure how often a randomly chosen element would be incorrectly identified. It means an attribute with a lower Gini index should be preferred. Sklearn supports \"Gini\" criteria for Gini Index and by default it takes \"gini\" value.\n\nFor example if we have a group of people where all bought the product (100% \"Yes\") the Gini Index is 0 indicate perfect purity. But if the group has an equal mix of \"Yes\" and \"No\" the Gini Index would be 0.5 show high impurity or uncertainty. Formula for Gini Index is given by :\n\n> Gini = 1 - $\\sum_{i=1}^{n} p_i^2$\n\n### **Some additional features of the Gini Index are:**\n\n1. It is calculated by summing the squared probabilities of each outcome in a distribution and subtracting the result from 1.\n2. A lower Gini Index indicates a more homogeneous or pure distribution while a higher Gini Index indicates a more heterogeneous or impure distribution.\n3. In decision trees the Gini Index is used to evaluate the quality of a split by measuring the difference between the impurity of the parent node and the weighted impurity of the child nodes.\n4. Compared to other impurity measures like entropy, the Gini Index is faster to compute and more sensitive to changes in class probabilities.\n5. One disadvantage of the Gini Index is that it tends to favour splits that create equally sized child nodes, even if they are not optimal for classification accuracy.\n6. In practice the choice between using the Gini Index or other impurity measures depends on the specific problem and dataset and requires experimentation and tuning.\n\n## Understanding Decision Tree with Real life use case:\n\nTill now we have understand about the attributes and components of decision tree. Now lets jump to a real life use case in which how decision tree works step by step.\n\n### **Step 1. Start with the Whole Dataset**\n\nWe begin with all the data which is treated as the root node of the decision tree.\n\n### **Step 2. Choose the Best Question (Attribute)**\n\nPick the best question to divide the dataset. For example ask: **\"What is the outlook?\"**\n\n> Possible answers: Sunny, Cloudy or Rainy.\n\n### **Step 3. Split the Data into Subsets**\n\nDivide the dataset into groups based on the question:\n\n- If Sunny go to one subset.\n- If Cloudy go to another subset.\n- If Rainy go to the last subset.\n\n### **Step 4. Split Further if Needed (Recursive Splitting)**\n\nFor each subset ask another question to refine the groups. For example If the Sunny subset is mixed ask: **\"Is the humidity high or normal?\"**\n\n- High humidity → \"Swimming\".\n- Normal humidity → \"Hiking\".\n\n### **Step 5. Assign Final Decisions (Leaf Nodes)**\n\nWhen a subset contains only one activity, stop splitting and assign it a label:\n\n- Cloudy → \"Hiking\".\n- Rainy → \"Stay Inside\".\n- Sunny + High Humidity → \"Swimming\".\n- Sunny + Normal Humidity → \"Hiking\".\n\n### **Step 6. Use the Tree for Predictions**\n\nTo predict an activity follow the branches of the tree. Example: If the outlook is Sunny and the humidity is High follow the tree:\n\n- Start at **Outlook**.\n- Take the branch for Sunny.\n- Then go to **Humidity** and take the branch for High Humidity.\n- Result: \"Swimming\".\n\nA decision tree works by breaking down data step by step asking the best possible questions at each point and stopping once it reaches a clear decision. It's an easy and understandable way to make choices. Because of their simple and clear structure decision trees are very helpful in machine learning for tasks like sorting data into categories or making predictions."}
{"reference": "https://www.geeksforgeeks.org/gate/gate-exam-tutorial/", "content": "# GATE Exam Tutorial\n\nThe Graduate Aptitude Test in Engineering (GATE) is a national-level exam in India, jointly conducted by the Indian Institute of Science (IISc) and seven Indian Institutes of Technology (IITs) on a rotational basis. The exam serves as a gateway for admissions to postgraduate programs and recruitment in public sector undertakings (PSUs).\n\nThis tutorial contains detailed sources for GATE CS & IT and GATE DA preparation.\n\n## Table of Contents\n\n- [GATE CS](#gate-cs)\n- [GATE DA](#gate-da)\n- [General Aptitude for GATE CS and GATE DA](#general-aptitude)\n\n## GATE CS\n\nGATE CSE is a subject-specific examination that evaluates a candidate's understanding of core concepts in Computer Science and Information Technology, including topics such as Data Structures, Algorithms, Operating Systems, Computer Networks etc.\n\n- **[GATE CS Syllabus](https://www.geeksforgeeks.org/blogs/gate-cse-syllabus/)**\n- **[GATE CS Notes](https://www.geeksforgeeks.org/gate/gate-cs-notes-gq/)**\n\n### 1. Digital Logic\n\nDigital Logic in GATE CSE carries an average weightage of 4-6 marks with 3-5 questions, covering topics like number systems, logic gates, combinational & sequential circuits, and K-map simplification.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Digital Electronics and Logic Design Tutorials](https://www.geeksforgeeks.org/digital-logic/digital-electronics-logic-design-tutorials/)\n- [LMN - Digital Electronics](https://www.geeksforgeeks.org/digital-logic/lmn-digital-electronics/)\n- [Digital Logic and Design - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/digital-logic/digital-logic-gate-questions/)\n\n### 2. Discrete Mathematics\n\nDiscrete Mathematics in GATE CSE carries an average weightage of 8-10 marks with around 5-7 questions, covering topics like set theory, relations, functions, propositional and predicate logic, combinatorics, recurrence relations, and graph theory.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Discrete Mathematics Tutorial](https://www.geeksforgeeks.org/engineering-mathematics/discrete-mathematics-tutorial/)\n- [Last Minute Notes – Discrete Mathematics](https://www.geeksforgeeks.org/maths/last-minute-notes-discrete-mathematics/)\n- [Discrete Mathematics - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/engineering-mathematics/discrete-mathematics-gate-questions/)\n\n### 3. Computer Organization & Architecture\n\nComputer Organization & Architecture (COA) in GATE CSE carries an average weightage of 7-9 marks with around 4-6 questions, covering topics like number systems, instruction formats, addressing modes, micro-operations, pipelining, memory hierarchy, and I/O organization.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Computer Organization And Architecture (COA) for GATE](https://www.geeksforgeeks.org/computer-organization-architecture/computer-organization-and-architecture-coa-for-gate/)\n- [Last Minute Notes Computer Organization](https://www.geeksforgeeks.org/computer-organization-architecture/last-minute-notes-computer-organization/)\n- [Computer Organization & Architecture: GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/computer-organization-architecture/computer-organization-architecture-gate-questions/)\n\n### 4. C Programming\n\nC Programming in GATE CSE covers fundamental concepts like data types, operators, control structures, functions, recursion, pointers, arrays, and strings, typically contributing to 2-3 questions worth 3-4 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [C Programming Language Tutorial](https://www.geeksforgeeks.org/c/c-programming-language/)\n- [LMNs-C Programming](https://www.geeksforgeeks.org/cpp/lmns-cc-gq/)\n- [C Programming - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/c/data-structures-programming-gate-questions/)\n\n### 5. Data Structures\n\nData Structures in GATE CSE includes topics such as stacks, queues, linked lists, trees, graphs, hashing, and recursion, generally contributing 3-5 questions worth 7-8 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [DSA Guide for GATE CS Exam](https://www.geeksforgeeks.org/dsa/data-structures-and-algorithms-dsa-guide-for-gate-cs-exam/)\n- [Last Minute Notes - Data Structures using C](https://www.geeksforgeeks.org/dsa/lmns-data-structures/)\n- [Topic wise Quiz on Data Structures](https://www.geeksforgeeks.org/dsa/data-structure-gq/)\n\n### 6. Algorithms\n\nAlgorithms in GATE CSE covers important topics like sorting, searching, greedy algorithms, divide and conquer, dynamic programming, graph algorithms (BFS, DFS, shortest paths), typically contributing 4-6 questions worth 8–10 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Design and Analysis of Algorithm Tutorial](https://www.geeksforgeeks.org/dsa/design-and-analysis-of-algorithm-tutorial/)\n- [LMNs- Algorithms](https://www.geeksforgeeks.org/dsa/lmns-algorithms-gq/)\n- [Algorithms - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/dsa/algorithms-gate-questions/)\n\n### 7. Theory of Computation\n\nTheory of Computation (TOC) in GATE CSE covers topics like regular languages, finite automata, context-free grammars, pushdown automata, Turing machines, decidability, and complexity theory, usually contributing 3-4 questions worth 6-7 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Theory of Computation (TOC) for GATE](https://www.geeksforgeeks.org/theory-of-computation/theory-of-computation-toc-for-gate/)\n- [Last Minute Notes - Theory of Computation](https://www.geeksforgeeks.org/theory-of-computation/lmn-toc/)\n- [Theory of Computation - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/gate/theory-of-computation-gate-questions/)\n\n### 8. Compiler Design\n\nCompiler Design in GATE CSE covers topics like lexical analysis, syntax analysis (parsing), semantic analysis, intermediate code generation, optimization, and code generation, generally contributing 2-3 questions worth 4-6 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Compiler Design (CD) for GATE Exam](https://www.geeksforgeeks.org/compiler-design/compiler-design-for-gate/)\n- [Last Minute Notes - Compiler Design](https://www.geeksforgeeks.org/compiler-design/last-minute-notes-compiler-design-gq/)\n- [Compiler Design - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/compiler-design/compiler-design-gate-questions/)\n\n### 9. Operating System\n\nOperating Systems (OS) in GATE CSE covers topics like process management, threads, synchronization, deadlocks, memory management, paging, segmentation, and file systems, typically contributing 4-6 questions worth 8-10 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Operating System for GATE Exam](https://www.geeksforgeeks.org/operating-systems/operating-system-for-gate/)\n- [Last Minute Notes – Operating Systems](https://www.geeksforgeeks.org/operating-systems/last-minute-notes-operating-systems/)\n- [Operating Systems - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/operating-systems/operating-systems-gate-questions/)\n\n### 10. Databases\n\nDatabases (DBMS) in GATE CSE covers topics like ER modeling, relational algebra, SQL queries, normalization, transactions, indexing, and recovery techniques, typically contributing 3-4 questions worth 5-7 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Databases (DBMS) for GATE Exam](https://www.geeksforgeeks.org/dbms/databases-dbms-for-gate-exam/)\n- [Last Minute Notes - DBMS](https://www.geeksforgeeks.org/dbms/last-minute-notes-dbms/)\n- [Database Management System - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/dbms/database-management-system-gate-questions/)\n\n### 11. Computer Networks\n\nComputer Networks (CN) in GATE CSE covers topics like OSI and TCP/IP models, switching, IP addressing, routing algorithms, transport protocols (TCP/UDP), flow and error control, and network security, generally contributing 3-5 questions worth 6-8 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Computer Networks (CN) for GATE CSE Exam](https://www.geeksforgeeks.org/computer-networks/computer-networks-for-gate/)\n- [Last Minute Notes for Computer Networks](https://www.geeksforgeeks.org/computer-networks/last-minute-notes-computer-network/)\n- [Computer Networks - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/computer-networks/computer-networks-gate-questions/)\n\n### 12. Engineering Mathematics\n\nEngineering Mathematics (excluding Discrete Mathematics) in GATE CSE covers topics like linear algebra, calculus, probability, statistics, and numerical methods, usually contributing 3-5 questions worth 6-8 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Engineering Mathematics Tutorials](https://www.geeksforgeeks.org/engineering-mathematics/engineering-mathematics-tutorials/)\n- [Last Minute Notes - Engineering Mathematics](https://www.geeksforgeeks.org/engineering-mathematics/last-minute-notes-engineering-mathematics/)\n- [Engineering Mathematics - GATE CSE Previous Year Questions](https://www.geeksforgeeks.org/engineering-mathematics/engineering-mathematics-gate-questions/)\n\n## GATE DA\n\nGATE DA is a specialized examination that assesses a candidate's knowledge of core concepts in Data Science, Machine Learning, Artificial Intelligence, and related mathematical foundations, covering topics such as Probability and Statistics, Linear Algebra, Machine Learning Algorithms, Data Engineering, and Artificial Intelligence.\n\n- **[GATE DA (Data Science and Artificial Intelligence) Syllabus](https://www.geeksforgeeks.org/competitive-exam-experiences/gate-data-science-and-artificial-intelligence-syllabus/)**\n- **[GATE DA Notes](https://www.geeksforgeeks.org/gate/gate-da-notes-according-to-gate-2025-syllabus/)**\n\n### 1. Mathematics\n\nMathematics in GATE DA covers fundamental topics including Linear Algebra (matrices, vectors, eigenvalues), Calculus (limits, derivatives, integrals), and Probability & Statistics (distributions, expectation, variance, Bayes theorem), typically contributing 30-35 marks, making it a crucial section for scoring.\n\n- [Math for Data Science](https://www.geeksforgeeks.org/blogs/maths-for-data-science/)\n- [Last Minute Notes (LMNs) - Probability and Statistics](https://www.geeksforgeeks.org/maths/last-minute-notes-lmns-probability-and-statistics/)\n- [LMNs -Linear Algebra](https://www.geeksforgeeks.org/data-science/lmns-linear-algebra/)\n- [Calculus and Optimization](https://www.geeksforgeeks.org/engineering-mathematics/calculus-notes-for-gate-cse-and-da/)\n\n### 2. Programming Data Structures and Algorithm\n\nProgramming, Data Structures, and Algorithms in GATE DA cover fundamental concepts such as basic programming constructs, arrays, linked lists, stacks, queues, trees, graphs, recursion, and algorithm design techniques, typically contributing around 20 marks with questions focused on problem-solving and implementation.\n\n- [Data Structures with Python Tutorial](https://www.geeksforgeeks.org/dsa/data-structures-with-python-tutorial-for-gate-da-2025/)\n- [Algorithms Tutorial](https://www.geeksforgeeks.org/dsa/dsa-tutorial-learn-data-structures-and-algorithms/)\n- [Last Minute Notes (LMNs) - Python Programming](https://www.geeksforgeeks.org/python/lmns-python-programming/)\n- [Last Minute Notes (LMNs) – Data Structures with Python](https://www.geeksforgeeks.org/dsa/last-minute-notes-lmns-data-structures-with-python/)\n- [LMNs- Algorithms](https://www.geeksforgeeks.org/dsa/lmns-algorithms-gq/)\n\n### 3. Machine Learning\n\nMachine Learning in GATE DA covers topics like supervised and unsupervised learning, regression, classification, clustering, decision trees, support vector machines, and evaluation metrics, typically contributing 15–20 marks with questions focused on concepts and applications.\n\n- [Machine Learning Algorithms](https://www.geeksforgeeks.org/machine-learning/machine-learning-algorithms/)\n- [Last Minute Notes (LMNs) - Machine Learning](https://www.geeksforgeeks.org/machine-learning/last-minute-notes-lmns-machine-learning/)\n- [Machine Learning Quiz Questions and Answers](https://www.geeksforgeeks.org/quizzes/machine-learning-quiz-questions-and-answers/)\n\n### 4. Artificial Intelligence\n\nArtificial Intelligence in GATE DA covers topics such as search algorithms, knowledge representation, reasoning, planning, and problem-solving techniques, typically contributing 8–12 marks with questions focusing on core AI concepts and methods.\n\n- [Artificial Intelligence for GATE](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligence-for-gate-2025/)\n- [Last Minute Notes (LMNs) - Artificial Intelligence](https://www.geeksforgeeks.org/artificial-intelligence/lmns-artificial-intelligence/)\n\n### 5. Database Management and Warehousing\n\nDatabase Management and Warehousing in GATE DA covers topics like ER modeling, relational databases, SQL queries, normalization, data warehousing concepts, and ETL processes, typically contributing 6-8 marks with questions on database design and data management techniques.\n\n- [Databases (DBMS) for GATE Exam](https://www.geeksforgeeks.org/dbms/databases-dbms-for-gate-exam/)\n- [Data Warehousing Tutorial](https://www.geeksforgeeks.org/dbms/data-warehousing-tutorial/)\n- [Last Minute Notes - DBMS](https://www.geeksforgeeks.org/dbms/last-minute-notes-dbms/)\n- [Last Minute Notes (LMNs) - Data Warehousing](https://www.geeksforgeeks.org/dbms/lmns-data-warehousing/)\n\n## General Aptitude for GATE CS and GATE DA\n\nGeneral Aptitude in GATE CSE & GATE DA includes topics like verbal ability, numerical ability, reasoning, and data interpretation, usually contributing 10 questions worth 15 marks.\n\nFollow the links below to prepare effectively for the GATE exam, including PYQ quizzes, last-minute notes, and topic-wise tutorials:\n\n- [Aptitude Questions and Answers](https://www.geeksforgeeks.org/aptitude/aptitude-questions-and-answers/)\n- [Quiz About General Aptitude](https://www.geeksforgeeks.org/quizzes/general-aptitude-gq/)\n\n> **Do you want to crack GATE Exam? Explore our** [GATE Courses](https://www.geeksforgeeks.org/courses/category/gate) **curated by experts.**\n\n## Explore\n\n### GATE Syllabus\n\n- [GATE 2025 Syllabus For CSE (Computer Science & Engineering)](https://www.geeksforgeeks.org/blogs/gate-cse-syllabus/)\n- [GATE DA (Data Science and Artificial Intelligence) Syllabus 2025 - PDF Available](https://www.geeksforgeeks.org/competitive-exam-experiences/gate-data-science-and-artificial-intelligence-syllabus/)\n\n### GATE CS Tutorials\n\n- [Digital Electronics and Logic Design Tutorials](https://www.geeksforgeeks.org/digital-logic/digital-electronics-logic-design-tutorials/)\n- [Discrete Mathematics Tutorial](https://www.geeksforgeeks.org/engineering-mathematics/discrete-mathematics-tutorial/)\n- [Engineering Mathematics Tutorials](https://www.geeksforgeeks.org/engineering-mathematics/engineering-mathematics-tutorials/)\n- [Automata Tutorial](https://www.geeksforgeeks.org/theory-of-computation/theory-of-computation-automata-tutorials/)\n- [Compiler Design Tutorial](https://www.geeksforgeeks.org/compiler-design/compiler-design-tutorials/)\n- [Computer Organization and Architecture Tutorial](https://www.geeksforgeeks.org/computer-organization-architecture/computer-organization-and-architecture-tutorials/)\n- [DBMS Tutorial – Learn Database Management System](https://www.geeksforgeeks.org/dbms/dbms/)\n- [Operating System Tutorial](https://www.geeksforgeeks.org/operating-systems/operating-systems/)\n- [Computer Network Tutorial](https://www.geeksforgeeks.org/computer-networks/computer-network-tutorials/)\n- [DSA Tutorial - Learn Data Structures and Algorithms](https://www.geeksforgeeks.org/dsa/dsa-tutorial-learn-data-structures-and-algorithms/)\n\n### GATE DA Tutorials\n\n- [Math for Data Science](https://www.geeksforgeeks.org/blogs/maths-for-data-science/)\n- [Data Structures with Python Tutorial for GATE DA 2025](https://www.geeksforgeeks.org/dsa/data-structures-with-python-tutorial-for-gate-da-2025/)\n- [Machine Learning Algorithms](https://www.geeksforgeeks.org/machine-learning/machine-learning-algorithms/)\n- [Artificial Intelligence for GATE 2025](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligence-for-gate-2025/)\n- [Databases (DBMS) for GATE Exam](https://www.geeksforgeeks.org/dbms/databases-dbms-for-gate-exam/)\n- [Data Warehousing Tutorial](https://www.geeksforgeeks.org/dbms/data-warehousing-tutorial/)\n\n### Aptitude\n\n- [Aptitude Questions and Answers](https://www.geeksforgeeks.org/aptitude/aptitude-questions-and-answers/)\n\n### Practice Content\n\n- [GATE CS Notes](https://www.geeksforgeeks.org/gate/gate-cs-notes-gq/)\n- [GATE DA Notes (According to GATE 2025 Syllabus)](https://www.geeksforgeeks.org/gate/gate-da-notes-according-to-gate-2025-syllabus/)\n- [Last Minute Notes -LMNs](https://www.geeksforgeeks.org/gfg-academy/last-minute-notes-lmns/)\n- [GATE CSE and DA Previous Years Papers PDF Download Link](https://www.geeksforgeeks.org/gate/original-gate-previous-year-question-papers-cse-and-it-gq/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning/", "content": "# Hyperparameter Tuning\n\n****Hyperparameter tuning**** is the process of selecting the optimal values for a machine learning model's hyperparameters. These are typically set before the actual training process begins and control aspects of the learning process itself. They influence the model's performance, its complexity, and how fast it learns.\n\n> For example, the learning rate and number of neurons in a neural network or the kernel size in a support vector machine can significantly impact how well the model trains and generalizes. The goal of hyperparameter tuning is to find the values that lead to the best performance on a given task.\n\nThese settings can affect both the speed and quality of the model's performance.\n\n+ A ****high learning rate**** can cause the model to converge too quickly, possibly skipping over the optimal solution.\n+ A ****low learning rate**** might lead to slower convergence and require more time and computational resources.\n\nDifferent models have different hyperparameters and they need to be tuned accordingly.\n\n## Techniques for Hyperparameter Tuning\n\nModels can have many hyperparameters and finding the best combination of parameters can be treated as a search problem. The two best strategies for Hyperparameter tuning are:\n\n### 1. GridSearchCV\n\n[GridSearchCV](https://www.geeksforgeeks.org/machine-learning/performing-feature-selection-with-gridsearchcv-in-sklearn/) is a brute-force technique for hyperparameter tuning. It trains the model using all possible combinations of specified hyperparameter values to find the best-performing setup. It is slow and uses a lot of computer power which makes it hard to use with big datasets or many settings. It works using below steps:\n\n+ Create a grid of potential values for each hyperparameter.\n+ Train the model for every combination in the grid.\n+ Evaluate each model using cross-validation.\n+ Select the combination that gives the highest score.\n\nFor example, if we want to tune two hyperparameters C and Alpha for a Logistic Regression Classifier model with the following sets of values:  \nC = [0.1, 0.2, 0.3, 0.4, 0.5]  \nAlpha = [0.01, 0.1, 0.5, 1.0]\n\n![GridSearchCV](https://media.geeksforgeeks.org/wp-content/uploads/Hyp_tune.png)\n\nThe grid search technique will construct multiple versions of the model with all possible combinations of C and Alpha, resulting in a total of 5 × 4 = 20 different models. The best-performing combination is then chosen.\n\n#### Example: Tuning Logistic Regression with GridSearchCV\n\nThe following code illustrates how to use GridSearchCV. In this below code:\n\n+ We generate sample data using ****make_classification****.\n+ We define a range of `C` values using logarithmic scale.\n+ GridSearchCV tries all combinations from ****param_grid**** and uses 5-fold cross-validation.\n+ It returns the best hyperparameter (`C`) and its corresponding validation score.\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(\n    n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space}\n\nlogreg = LogisticRegression()\n\nlogreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n\nlogreg_cv.fit(X, y)\n\nprint(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\nprint(\"Best score is {}\".format(logreg_cv.best_score_))\n```\n\n****Output:****\n\n> Tuned Logistic Regression Parameters: {'C': 0.006105402296585327}  \n> Best score is 0.853\n\nThis represents the highest accuracy achieved by the model using the hyperparameter combination ****C = 0.0061****. The best score of ****0.853**** means the model achieved 85.3% accuracy on the validation data during the grid search process.\n\n### 2. RandomizedSearchCV\n\nAs the name suggests [****RandomizedSearchCV****](https://www.geeksforgeeks.org/machine-learning/comparing-randomized-search-and-grid-search-for-hyperparameter-estimation-in-scikit-learn/) picks random combinations of hyperparameters from the given ranges instead of checking every single combination like GridSearchCV.\n\n+ In each iteration it ****tries a new random combination**** of hyperparameter values.\n+ It ****records the model's performance**** for each combination.\n+ After several attempts it ****selects the best-performing set****.\n\n#### Example: Tuning Decision Tree with RandomizedSearchCV\n\nThe following code illustrates how to use RandomizedSearchCV. In this example:\n\n+ We define a range of values for each hyperparameter e.g, ****max_depth,**** ****min_samples_leaf**** etc.\n+ Random combinations are picked and evaluated using 5-fold cross-validation.\n+ The best combination and score are printed.\n\n```python\nimport numpy as np\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n\nfrom scipy.stats import randint\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparam_dist = {\n    \"max_depth\": [3, None],\n    \"max_features\": randint(1, 9),\n    \"min_samples_leaf\": randint(1, 9),\n    \"criterion\": [\"gini\", \"entropy\"]\n}\n\ntree = DecisionTreeClassifier()\ntree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\ntree_cv.fit(X, y)\n\nprint(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\nprint(\"Best score is {}\".format(tree_cv.best_score_))\n```\n\n****Output:****\n\n> Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': 6, 'min_samples_leaf': 6} \n> Best score is 0.8\n\nA score of ****0.842**** means the model performed with an accuracy of 84.2% on the validation set with following hyperparameters.\n\n### 3. Bayesian Optimization\n\nGrid Search and Random Search can be inefficient because they blindly try many hyperparameter combinations, even if some are clearly not useful. [****Bayesian Optimization****](https://www.geeksforgeeks.org/artificial-intelligence/bayesian-optimization-in-machine-learning/) takes a smarter approach. It treats hyperparameter tuning like a mathematical optimization problem and ****learns from past results**** to decide what to try next.\n\n+ Build a probabilistic model (surrogate function) that predicts performance based on hyperparameters.\n+ Update this model after each evaluation.\n+ Use the model to choose the next best set to try.\n+ Repeat until the optimal combination is found. The surrogate function models:\n\n> P(\\text{score}(y) \\mid \\text{hyperparameters}(x))\n\nHere the surrogate function models the relationship between hyperparameters x and the score y. By updating this model iteratively with each new evaluation Bayesian optimization makes more informed decisions. Common surrogate models used in Bayesian optimization include:\n\n+ ****Gaussian Processes****\n+ ****Random Forest Regression****\n+ ****Tree-structured Parzen Estimators (TPE)****\n\n## Advantages of Hyperparameter tuning\n\n+ ****Improved Model Performance****: Finding the optimal combination of hyperparameters can significantly boost model accuracy and robustness.\n+ ****Reduced Overfitting and Underfitting****: Tuning helps to prevent both overfitting and underfitting resulting in a well-balanced model.\n+ ****Enhanced Model Generalizability****: By selecting hyperparameters that optimize performance on validation data the model is more likely to generalize well to unseen data.\n+ ****Optimized Resource Utilization****: With careful tuning resources such as computation time and memory can be used more efficiently avoiding unnecessary work.\n+ ****Improved Model Interpretability****: Properly tuned hyperparameters can make the model simpler and easier to interpret.\n\n## Challenges in Hyperparameter Tuning\n\n+ ****Dealing with High-Dimensional Hyperparameter Spaces:**** The larger the hyperparameter space the more combinations need to be explored. This makes the search process computationally expensive and time-consuming especially for complex models with many hyperparameters.\n+ ****Handling Expensive Function Evaluations:**** Evaluating a model's performance can be computationally expensive, particularly for models that require a lot of data or iterations.\n+ ****Incorporating Domain Knowledge: It**** can help guide the hyperparameter search, narrowing down the search space and making the process more efficient. Using insights from the problem context can improve both the efficiency and effectiveness of tuning.\n+ ****Developing Adaptive Hyperparameter Tuning Methods:**** Dynamic adjustment of hyperparameters during training such as learning rate schedules or early stopping can lead to better model performance."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/ml-semi-supervised-learning/", "content": "# Semi-Supervised Learning in ML\n\nSemi-supervised learning is a hybrid machine learning approach which uses both supervised and unsupervised learning. It uses a small amount of labelled data combined with a large amount of unlabelled data to train models. The goal is to learn a function that accurately predicts outputs based on inputs, similar to supervised learning, but with much less labelled data.\n\n![Semi-supervised-Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250903121305029846/Semi-supervised-Learning.webp)\n\n*Semi-Supervised Learning*\n\nSemi-supervised learning is particularly valuable when acquiring labelled data is expensive or time-consuming, yet unlabelled data is plentiful and easy to collect.\n\n- **Supervised learning**: Similar to a student being taught concepts by a teacher both in class and at home.\n- **Unsupervised learning**: Like a student figuring out concepts independently without instruction like a math problem.\n- **Semi-supervised learning**: A mix where the teacher provides some concepts in class and the student practices with homework assignments based on those concepts.\n\n## Working of Semi-Supervised Learning\n\nSeveral techniques fall under semi-supervised learning including:\n\n- **Self-Training**: The model is first trained on labeled data. It then predicts labels for unlabeled data, adding high-confidence predictions to the labeled set iteratively to refine the model.\n- **Co-Training:** Two models are trained on different feature subsets of the data. Each model labels unlabeled data for the other, enabling them to learn from complementary views.\n- **Multi-View Training**: A variation of co-training where models train on different data representations (e.g., images and text) to predict the same output.\n- **Graph-Based Models**: Data is represented as a graph with nodes (data points) and edges (similarities). Labels are propagated from labeled nodes to unlabeled ones based on graph connectivity.\n\nLet's see an example to understand better,\n\n### Step 1: Importing Libraries and Loading Data\n\nWe will import the necessary libraries such as [numpy](https://www.geeksforgeeks.org/numpy/python-numpy/), [matplotlib](https://www.geeksforgeeks.org/python/matplotlib-tutorial/) and [sklearn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/). We will load IRIS Dataset.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.semi_supervised import LabelPropagation\nfrom sklearn.metrics import accuracy_score\n\niris = datasets.load_iris()\nX = iris.data[:, :2]\ny = iris.target\n```\n\n### Step 2: Semi-Supervised Setup (Mask Labels)\n\nWe will setup the semi-supervised working,\n\n- labels is what we pass to the algorithm (contains -1 for unlabeled).\n- mask is a boolean array indicating which points keep their labels.\n- labels[~mask] = -1 — scikit-learn convention: unlabeled = -1.\n- Print helps readers see how many labels remain (important when describing experiments).\n\n```python\nlabels = np.copy(y)\nrng = np.random.RandomState(42)\nmask = rng.rand(len(y)) < 0.1\nlabels[~mask] = -1\nprint(f\"Labeled: {np.sum(mask)}, Unlabeled: {np.sum(~mask)}\")\n```\n\n### Step 3: Train a Graph-Based Model (Label Propagation)\n\nWe will train a graph-based model,\n\n- LabelPropagation() builds a graph on X (similarities) and propagates labels from labeled nodes to unlabeled ones.\n- fit(X, labels) performs the label diffusion — no separate .predict() needed for transduction.\n\n```python\nmodel = LabelPropagation()\nmodel.fit(X, labels)\n```\n\n### Step 4: Get Transduced Labels and Evaluate\n\nLabels are assigned to all points,\n\n- model.transduction_ gives the inferred labels for every sample (including previously unlabeled).\n- Evaluate both on the small originally-labeled subset (y[mask]) and on the true labels (y) to show how well propagation recovered the full labeling.\n- accuracy_score is a simple, interpretable metric.\n\n```python\ny_pred = model.transduction_\nacc_labeled = accuracy_score(y[mask], y_pred[mask])\nacc_overall = accuracy_score(y, y_pred)\nprint(f\"Acc (on original labeled subset): {acc_labeled:.3f}\")\nprint(f\"Acc (overall after propagation): {acc_overall:.3f}\")\n```\n\n**Output:**\n\n> Labeled samples: 18, Unlabeled samples: 132 \n> Accuracy on labeled data: 1.00 \n> Overall accuracy after label propagation: 0.71\n\n### Step 5: Visualize\n\nWe will visualize results:\n\n- Left plot shows the few labeled examples (colored) against unlabeled (gray).\n- Right plot shows model's assigned labels for every point after propagation.\n- Removing edgecolor avoids common scatter warnings.\n\n```python\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nax[0].scatter(X[:, 0], X[:, 1], c='lightgray', s=30)\nax[0].scatter(X[mask, 0], X[mask, 1], c=y[mask], cmap='viridis', s=60)\nax[0].set_title(\"Before propagation — few labels\")\n\nax[1].scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis', s=60)\nax[1].set_title(\"After propagation — all labeled\")\n\nplt.tight_layout()\nplt.show()\n```\n\n**Output:**\n\n![semi-supervised](https://media.geeksforgeeks.org/wp-content/uploads/20250903120639828902/semi-supervised.webp)\n\n*Result*\n\nAs we can see in the result that the model was able to classify images into the categories or labels after successful operations of semi-supervised learning.\n\n## When to Use Semi-Supervised Learning\n\n- When labeled data is scarce or costly, such as medical imaging requiring expert annotation.\n- When large volumes of unlabeled data exist, like social media or web content.\n- For unstructured data types (text, images, audio) where labeling is difficult.\n- When classes are rare and labeled examples few, improving class recognition.\n- When purely supervised or unsupervised methods are insufficient.\n\n## Applications\n\nLet's see the applications,\n\n- **Face Recognition**: Enhancing accuracy by learning from limited labeled face images plus many unlabeled ones using graph-based methods.\n- **Handwritten Text Recognition**: Adapting models to diverse handwriting styles through generative models.\n- **Speech Recognition**: Improving transcription quality by using unlabeled speech data with CNNs and other techniques.\n- **Security**: Google uses semi-supervised learning for anomaly detection in network traffic and malware detection.\n- **Finance**: PayPal applies it for fraud detection and creditworthiness assessment using transaction data.\n\n## Advantages\n\n- **Better Generalization**: Utilizes both labeled and unlabeled data to capture the whole data structure, improving prediction robustness.\n- **Cost Efficient**: Reduces dependency on costly manual labeling by exploiting unlabeled data.\n- **Flexible and Robust**: Handles different data types and sources, adapting well to changing data distributions.\n- **Improved Clustering**: Refines clusters by leveraging unlabeled data, yielding better class separation.\n- **Handling Rare Classes**: Enhances learning for underrepresented classes where labeled examples are minimal.\n\n## Limitations\n\n- **Model Complexity**: Requires careful choice of architecture and hyperparameters, which may require extensive tuning.\n- **Noisy Data**: Unlabeled data may contain errors or irrelevant information, risking degraded model performance.\n- **Assumption Sensitivity**: Relies on assumptions such as data consistency and clusterability, which may not hold in all cases.\n- **Evaluation Challenge**: Assessing performance is difficult due to limited labeled data and varied quality of unlabeled data."}
{"reference": "https://www.geeksforgeeks.org/web-tech/web-technology/", "content": "# Web Development Technologies\n\nWeb development refers to building, creating, and maintaining websites. It includes aspects such as web design, web publishing, web programming, and database management. It is the creation of an application that works over the internet, i.e., websites.\n\n## Basics of Web Development\n\nTo better understand the foundation of web development, it is recommended to take a look at the concepts used in web development.\n\n- [Why Learn Web Development?](https://www.geeksforgeeks.org/blogs/why-learning-web-development-is-a-great-career-move-in-2025/)\n- [Web Development Prerequisites](https://www.geeksforgeeks.org/websites-apps/web-development-prerequisites/)\n- [Important Terminologies](https://www.geeksforgeeks.org/web-tech/terminologies-of-web-development/)\n\n> ****Do you wish to learn Web Development in a scheduled manner ?**** **Try our ongoing free course** [**Web Development Skillup**](https://www.geeksforgeeks.org/courses/full-stack-web-dev-skill-up) **with weekly topic coverage, notes, quizzes and practical projects.**\n\nThere are two major areas: ****Frontend**** and ****Backend**** which forms the backbone of web development each plays a crucial role in creating seamless, functional web experiences.\n\n### Frontend Development\n\nIn this module, we explore the core technologies that run in the user’s browser—the client side—including how web pages are structured, styled, and made interactive, building everything users see and interact with.\n\n- [****HTML (HyperText Markup Language):****](https://www.geeksforgeeks.org/html/html-tutorial/) HTML is the language used to create the basic structure and content of web pages. It uses elements, tags, and attributes to organize text, images, and links.\n- [****CSS (Cascading Style Sheets):****](https://www.geeksforgeeks.org/css/css-tutorial/) CSS is used to style the HTML content. It controls colors, fonts, layouts, and how the page looks on different devices. More importantly, CSS enables you to do this independent of the HTML that makes up each web page.\n- [****JS (JavaScript):****](https://www.geeksforgeeks.org/javascript/javascript-tutorial/) JavaScript adds life to web pages by making them interactive. It handles things like buttons, animations, and form checks.\n\n### Backend Development\n\nIn this module, we will explore the technologies that work behind the scenes on the server to handle data, run the website, and store information.\n\n#### Server-Side Programming Languages\n\nIn Backend Development, Server-side programming languages are used to write code that runs on the server, not in the user’s browser. This [server-side scripting](https://www.geeksforgeeks.org/html/difference-between-server-side-scripting-and-client-side-scripting/) handles tasks like processing data, managing databases, and controlling how the website works behind the scenes.\n\nBelow are some popular languages used to build the back end of web applications:\n\n- [****JavaScript/Node.js:****](https://www.geeksforgeeks.org/node-js/nodejs/) JavaScript is a popular programming language mainly used to add interactivity on the client side (in browsers). With Node.js, JavaScript can also run on the server side. Node.js is an open-source environment that allows JavaScript to build fast, scalable back-end services like APIs. Many big companies like PayPal, Uber, and Netflix use Node.js for their server-side code.\n- [****PHP:****](https://www.geeksforgeeks.org/php/php-tutorial/) PHP is a server-side scripting language designed specifically for web development. Since PHP code executed on the server-side, so it is called a server-side scripting language.\n- [****Python:****](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/) Python is a programming language that lets you work quickly and integrate systems more efficiently.\n- [****Ruby:****](https://www.geeksforgeeks.org/ruby/ruby-programming-language/) An object-oriented programming language designed to be simple and natural to use. Ruby helps developers write clean and readable code.\n- [****Java:****](https://www.geeksforgeeks.org/java/java/) Java is one of the most popular and widely used programming languages and platforms. It is highly scalable. Java components are easily available.\n- [****Golang(Go):****](https://www.geeksforgeeks.org/go-language/go/) Golang is a procedural and statically typed programming language having the syntax similar to C programming language. Sometimes it is termed as Go Programming Language.\n- [****C#:****](https://www.geeksforgeeks.org/c-sharp/introduction-to-c-sharp/) A modern, object-oriented language often used to build web applications on Microsoft platforms.\n\n#### Databases\n\nA database is where a website’s data like user's data, product's data are stored and organized. It is part of the backend (server side) that manages and keeps this information safe. Websites use databases to save and access information like user details, content, and transactions. Some databases organize data in tables (called relational databases, like MySQL), while others store data in flexible formats (called NoSQL databases, like MongoDB).\n\nThere are basically two types of databases:\n\n##### 1. SQL/Relational Database\n\nA relational database stores data in tables, similar to a spreadsheet, where each table has rows and columns. The rows hold individual records, and the columns define the data attributes. Tables can be linked to each other through special keys, allowing related data to be connected.\n\n- [****MySQL****](https://www.geeksforgeeks.org/sql/sql-tutorial/): MySQL is an open-source relational database management system that uses SQL for managing structured data. It’s known for its reliability, ease of use, and performance, widely used in web applications.\n- [****PostgreSQL****](https://www.geeksforgeeks.org/postgresql/postgresql-tutorial/): PostgreSQL is a powerful, open-source relational database that supports advanced SQL features and complex queries. It handles structured data, ensures ACID compliance, and is known for its reliability and extensibility.\n\n##### 2. NoSQL Databases\n\nA NoSQL database stores data in a flexible, non-tabular format, unlike traditional relational databases. Instead of using tables with rows and columns, NoSQL databases might use documents, key-value pairs, wide-columns, or graphs to store data. This allows them to handle large amounts of unstructured or semi-structured data efficiently. They are designed to scale easily and manage big data applications.\n\n- [****MongoDB****](https://www.geeksforgeeks.org/mongodb/mongodb-tutorial/): MongoDB is a NoSQL database storing data in JSON-like documents. It handles unstructured data, supports powerful queries, and scales easily across servers, making it popular for flexible, scalable applications.\n- [****Cassandra****](https://www.geeksforgeeks.org/dbms/apache-cassandra-nosql-database/): Apache Cassandra is an open-source NoSQL database that is used for handling big data. It has the capability to handle structure, semi-structured, and unstructured data.\n- [****Redis****](https://www.geeksforgeeks.org/system-design/introduction-to-redis-server/): Redis is an in-memory NoSQL database known for its speed. It supports various data structures like strings, hashes, and lists, making it ideal for caching, real-time analytics, and messaging.\n\n****Note:**** We use [Database management systems](https://www.geeksforgeeks.org/dbms/introduction-of-dbms-database-management-system-set-1/) help keep the data safe, organized, and easy to use.\n\n## APIs and Data Exchange Formats\n\nDuring Website development, different software components and web applications constantly need to communicate and share information. For instance, the frontend of your web application (running in the user's browser) needs to get data from the backend (running on a server), or your application might need to fetch information from a third-party service like a weather provider or a payment gateway. This communication is made possible through Application Programming Interfaces (APIs) and standardized Data Formats.\n\n### Data Exchange Formats for API Communication\n\nWhen applications communicate via APIs, they need a common, structured way to represent the data being exchanged. This is where data formats come in.\n\nBelow are two common data formats used extensively in web development for API communication:\n\n- [****JSON:****](https://www.geeksforgeeks.org/javascript/javascript-json/) JSON or JavaScript Object Notation is a format for structuring data.\n- [****XML:****](https://www.geeksforgeeks.org/html/xml-basics/) Extensible Markup Language (XML) is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable.\n\n## Version Control and Deployment\n\nDeveloping a web application involves more than just writing code. Two critical processes that ensure a smooth, organized, and reliable development workflow are [****Version Control****](https://www.geeksforgeeks.org/git/version-control-systems/) and [****Deployment****](https://www.geeksforgeeks.org/websites-apps/deployment-in-web-development/).\n\n****Version control**** helps manage the evolution of your codebase, especially when working in teams, while ****deployment**** is the process of making your web application accessible to the world. Modern development practices tightly integrate these two concepts, often through automation.\n\n## Graphics\n\nGraphical elements are one of the key feature of any webpage. They can be used to convey important points better than text does and beautify the webpage.\n\n- [****Canvas:****](https://www.geeksforgeeks.org/html/html-canvas-basics/) The HTML “canvas” element is used to draw graphics via JavaScript.\n- [****SVG:****](https://www.geeksforgeeks.org/html/html-svg-basics/) SVG stands for Scalable Vector Graphics. It basically defines vector-based graphics in XML format.\n\n## Some Important Links on Web Technology\n\n- [How can I start to learn Web Development?](https://www.geeksforgeeks.org/blogs/can-start-learn-web-development/)\n- [10 Best Web Development Project Ideas For Beginners [2025]](https://www.geeksforgeeks.org/blogs/web-development-project-ideas-for-beginners/)\n- [History And Evolution of Web Development](https://www.geeksforgeeks.org/blogs/history-and-evolution-of-web-development/)\n- [Web 1.0, Web 2.0 and Web 3.0 with their difference](https://www.geeksforgeeks.org/blogs/web-1-0-web-2-0-and-web-3-0-with-their-difference/)\n- [Top Trends in Web Development](https://www.geeksforgeeks.org/blogs/top-web-development-trends/)\n- [Top 9 Technologies Transforming the Future of Web Development](https://www.geeksforgeeks.org/blogs/top-9-technologies-transforming-the-future-of-web-development-comprehensive-guide/)"}
{"reference": "https://www.geeksforgeeks.org/pandas/pandas-tutorial/", "content": "# Pandas Tutorial\n\n**Last Updated**: 11 Aug, 2025\n\nPandas (stands for Python Data Analysis) is an open-source software library designed for **data manipulation** and **analysis**.\n\n- Revolves around two primary Data structures: Series (1D) and DataFrame (2D)\n- Built on top of NumPy, efficiently manages large datasets, offering tools for data cleaning, transformation, and analysis.\n- Tools for working with time series data, including date range generation and frequency conversion. For example, we can convert date or time columns into pandas' datetime type using `pd.to_datetime()`, or specify `parse_dates=True` during CSV loading.\n- Seamlessly integrates with other Python libraries like NumPy, Matplotlib, and scikit-learn.\n- Provides methods like `.dropna()` and `.fillna()` to handle missing values seamlessly\n\n> **Important Facts to Know:**\n>\n> - **DataFrames:** It is a two-dimensional data structure constructed with rows and columns, which is more similar to Excel spreadsheet.\n> - **pandas:** This name is derived for the term \"panel data\" which is [econometrics](https://www.geeksforgeeks.org/school-resources/econometrics-meaning-examples-theory-and-methods/) terms of data sets.\n\n## What is Pandas Used for?\n\nWith pandas, you can perform a wide range of data operations, including\n\n- Reading and writing data from various file formats like CSV, Excel and SQL databases.\n- Cleaning and preparing data by handling missing values and filtering entries.\n- Merging and joining multiple datasets seamlessly.\n- Reshaping data through pivoting and stacking operations.\n- Conducting statistical analysis and generating descriptive statistics.\n- Visualizing data with integrated plotting capabilities.\n\n## Why Learn Pandas\n\nHere’s why it’s worth learning:\n\n- It offers a simple and intuitive way to work with structured data, especially using DataFrames.\n- Makes data exploration easy, so you can quickly understand patterns or spot issues.\n- Saves time by reducing the need for complex code.\n- It's widely used in industries like finance, healthcare, marketing and research.\n- A must-have skill for data science, analytics and machine learning roles.\n\n## Pandas Basics\n\nIn this section, we will explore the fundamentals of Pandas. We will start with an introduction to Pandas, learn how to install it and get familiar with its functionalities. Additionally, we will cover how to use Jupyter Notebook, a popular tool for interactive coding. By the end of this section, we will have a solid understanding of how to set up and start working with Pandas for data analysis.\n\n- [Pandas Introduction](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/)\n- [Pandas Installation](https://www.geeksforgeeks.org/python/how-to-install-python-pandas-on-windows-and-linux/)\n- [Getting started with Pandas](https://www.geeksforgeeks.org/videos/getting-started-with-pandas-1/)\n- [How To Use Jupyter Notebook](https://www.geeksforgeeks.org/machine-learning/how-to-use-jupyter-notebook-an-ultimate-guide/)\n\n## Pandas DataFrame\n\nA [DataFrame](https://www.geeksforgeeks.org/pandas/python-pandas-dataframe/) is a two-dimensional, size-mutable and potentially heterogeneous tabular data structure with labeled axes (rows and columns).\n\n- [Creating a DataFrame](https://www.geeksforgeeks.org/pandas/creating-a-pandas-dataframe/)\n- [Pandas Dataframe Index](https://www.geeksforgeeks.org/pandas/pandas-dataframe-index/)\n- [Pandas Access DataFrame](https://www.geeksforgeeks.org/pandas/pandas-access-dataframe/)\n- [Indexing and Selecting Data with Pandas](https://www.geeksforgeeks.org/pandas/indexing-and-selecting-data-with-pandas/)\n- [Slicing Pandas Dataframe](https://www.geeksforgeeks.org/data-science/slicing-indexing-manipulating-and-cleaning-pandas-dataframe/)\n- [Filter Pandas Dataframe with multiple conditions](https://www.geeksforgeeks.org/python/filter-pandas-dataframe-with-multiple-conditions/)\n- [Merging, Joining and Concatenating Dataframes](https://www.geeksforgeeks.org/python/python-pandas-merging-joining-and-concatenating/)\n- [Sorting Pandas DataFrame](https://www.geeksforgeeks.org/pandas/how-to-sort-pandas-dataframe/)\n- [Pivot Table in Pandas](https://www.geeksforgeeks.org/python/how-to-create-a-pivot-table-in-python-using-pandas/)\n\n## Pandas Series\n\nA [Series](https://www.geeksforgeeks.org/python/python-pandas-series/) is a one-dimensional labeled array capable of holding any data type (integers, strings, floating-point numbers, Python objects, etc.). It’s similar to a column in a spreadsheet or a database table.\n\n- [Creating a Series](https://www.geeksforgeeks.org/python/creating-a-pandas-series/)\n- [Accessing elements of a Pandas Series](https://www.geeksforgeeks.org/python/accessing-elements-of-a-pandas-series/)\n- [Binary Operations on Series](https://www.geeksforgeeks.org/pandas/binary-operations-on-pandas-dataframe-and-series/)\n- [Pandas Series Index() Methods](https://www.geeksforgeeks.org/pandas/python-pandas-series-index/)\n- [Create a Pandas Series from array](https://www.geeksforgeeks.org/python/create-a-pandas-series-from-array/)\n\n## Data Input and Output (I/O)\n\nPandas offers a variety of functions to read data from and write data to different file formats as given below:\n\n- [Read CSV Files with Pandas](https://www.geeksforgeeks.org/pandas/python-read-csv-using-pandas-read_csv/)\n- [Writing data to CSV Files](https://www.geeksforgeeks.org/pandas/saving-a-pandas-dataframe-as-a-csv/)\n- [Export Pandas dataframe to a CSV file](https://www.geeksforgeeks.org/python/export-pandas-dataframe-to-a-csv-file/)\n- [Read JSON Files with Pandas](https://www.geeksforgeeks.org/python/how-to-read-json-files-with-pandas/)\n- [Parsing JSON Dataset](https://www.geeksforgeeks.org/python/pandas-parsing-json-dataset/)\n- [Exporting Pandas DataFrame to JSON File](https://www.geeksforgeeks.org/python/exporting-pandas-dataframe-to-json-file/)\n- [Working with Excel Files in Pandas](https://www.geeksforgeeks.org/python/working-with-excel-files-using-pandas/)\n- [Read Text Files with Pandas](https://www.geeksforgeeks.org/python/how-to-read-text-files-with-pandas/)\n- [Text File to CSV using Python Pandas](https://www.geeksforgeeks.org/python/convert-text-file-to-csv-using-python-pandas/)\n\n## Data Cleaning in Pandas\n\nData cleaning is an essential step in data preprocessing to ensure accuracy and consistency. Here are some articles to know more about it:\n\n- [Handling Missing Data](https://www.geeksforgeeks.org/data-analysis/working-with-missing-data-in-pandas/)\n- [Removing Duplicates](https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-drop_duplicates/)\n- [Pandas Change Datatype](https://www.geeksforgeeks.org/pandas/pandas-change-datatype/)\n- [Drop Empty Columns in Pandas](https://www.geeksforgeeks.org/python/drop-empty-columns-in-pandas/)\n- [String manipulations in Pandas](https://www.geeksforgeeks.org/python/string-manipulations-in-pandas-dataframe/)\n- [String methods in Pandas](https://www.geeksforgeeks.org/python/top-10-string-methods-in-pandas/)\n- [Detect Mixed Data Types and Fix it](https://www.geeksforgeeks.org/python/pandas-detect-mixed-data-types-and-fix-it/)\n\n## Pandas Operations\n\nWe will cover data processing, normalization, manipulation and analysis, along with techniques for grouping and aggregating data. These concepts will help you efficiently clean, transform and analyze datasets. By the end of this section, you’ll learn Pandas operations to handle real-world data effectively.\n\n- [Data Processing with Pandas](https://www.geeksforgeeks.org/python/data-processing-with-pandas/#missing-data-handing).\n- [Data Normalization in Pandas](https://www.geeksforgeeks.org/python/data-normalization-with-pandas/)\n- [Data Manipulation in Pandas](https://www.geeksforgeeks.org/pandas/data-manipulattion-in-python-using-pandas/)\n- [Data Analysis using Pandas](https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-groupby/)\n- [Grouping and Aggregating with Pandas](https://www.geeksforgeeks.org/python/grouping-and-aggregating-with-pandas/)\n- [Different Types of Joins in Pandas](https://www.geeksforgeeks.org/python/different-types-of-joins-in-pandas/)\n\n## Advanced Pandas Operations\n\nIn this section, we will explore advanced Pandas functionalities for deeper data analysis and visualization. We will cover techniques for finding correlations, working with time series data and using Pandas' built-in plotting functions for effective data visualization. By the end of this section, you’ll have a strong grasp of advanced Pandas operations and how to apply them to real-world datasets.\n\n- [Finding Correlation between Data](https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-corr/)\n- [Data Visualization with Pandas](https://www.geeksforgeeks.org/data-visualization/pandas-built-in-data-visualization-ml/)\n- [Pandas Plotting Functions for Data Visualization](https://www.geeksforgeeks.org/data-visualization/pandas-plotting-functions-for-quick-data-visualization/)\n- [Basic of Time Series Manipulation Using Pandas](https://www.geeksforgeeks.org/python/pandas-time-series-manipulation/)\n- [Time Series Analysis & Visualization in Python](https://www.geeksforgeeks.org/data-analysis/time-series-data-visualization-in-python/)\n\n## Pandas Quiz\n\nTest your knowledge of Python's pandas library with this quiz. It's designed to help you check your knowledge of key topics like handling data, working with DataFrames and creating visualizations.\n\n- [Python Pandas Quiz](https://www.geeksforgeeks.org/quizzes/python-pandas-quiz/)\n\n## Projects\n\nIn this section, we will work on real-world data analysis projects using Pandas and other data science tools. These projects will cover various domains, including food delivery, sports, travel, healthcare, real estate and retail. By analyzing datasets like Zomato, IPL, Airbnb, COVID-19 and Titanic, we will apply data processing, visualization and predictive modeling techniques. By the end of this section, you will gain hands-on experience in data analysis and machine learning applications.\n\n- [Zomato Data Analysis Using Python](https://www.geeksforgeeks.org/data-science/zomato-data-analysis-using-python/)\n- [IPL Data Analysis](https://www.geeksforgeeks.org/pandas/ipl-2023-data-analysis-using-pandas-ai/)\n- [Airbnb Data Analysis](https://www.geeksforgeeks.org/tag/airbnb/)\n- [Global Covid-19 Data Analysis and Visualizations](https://www.geeksforgeeks.org/data-visualization/covid-19-analysis-and-visualization-using-plotly-express/)\n- [Housing Price Analysis & Predictions](https://www.geeksforgeeks.org/machine-learning/house-price-prediction-using-machine-learning-in-python/)\n- [Market Basket Analysis](https://www.geeksforgeeks.org/data-science/market-basket-analysis-in-data-mining/)\n- [Titanic Dataset Analysis and Survival Predictions](https://www.geeksforgeeks.org/machine-learning/titanic-survival-prediction-using-ml/)\n- [Iris Flower Dataset Analysis and Predictions](https://www.geeksforgeeks.org/data-analysis/exploratory-data-analysis-on-iris-dataset/)\n- [Customer Churn Analysis](https://www.geeksforgeeks.org/machine-learning/python-customer-churn-analysis-prediction/)\n- [Car Price Prediction Analysis](https://www.geeksforgeeks.org/python/analyzing-selling-price-of-used-cars-using-python/)\n\n> To Explore more Data Analysis Projects refer to article: [30+ Top Data Analytics Projects in 2025 [With Source Codes]](https://www.geeksforgeeks.org/data-analysis/data-analyst-projects/)\n\n## Introduction\n\n- [Pandas Introduction](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/)\n- [How to Install Pandas in Python?](https://www.geeksforgeeks.org/python/how-to-install-python-pandas-on-windows-and-linux/)\n- [How To Use Jupyter Notebook - An Ultimate Guide](https://www.geeksforgeeks.org/machine-learning/how-to-use-jupyter-notebook-an-ultimate-guide/)\n\n## Creating Objects\n\n- [Creating a Pandas DataFrame](https://www.geeksforgeeks.org/pandas/creating-a-pandas-dataframe/)\n- [Python Pandas Series](https://www.geeksforgeeks.org/python/python-pandas-series/)\n- [Creating a Pandas Series](https://www.geeksforgeeks.org/python/creating-a-pandas-series/)\n\n## Viewing Data\n\n- [Pandas Dataframe/Series.head() method - Python](https://www.geeksforgeeks.org/python/python-pandas-dataframe-series-head-method/)\n- [Pandas Dataframe/Series.tail() method - Python](https://www.geeksforgeeks.org/python/python-pandas-dataframe-series-tail-method/)\n- [Pandas DataFrame describe() Method](https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-describe-method/)\n\n## Selection & Slicing\n\n- [Dealing with Rows and Columns in Pandas DataFrame](https://www.geeksforgeeks.org/pandas/dealing-with-rows-and-columns-in-pandas-dataframe/)\n- [Pandas Extracting rows using .loc[] - Python](https://www.geeksforgeeks.org/python/python-pandas-extracting-rows-using-loc/)\n- [Extracting rows using Pandas .iloc[] in Python](https://www.geeksforgeeks.org/python/python-extracting-rows-using-pandas-iloc/)\n- [Indexing and Selecting Data with Pandas](https://www.geeksforgeeks.org/pandas/indexing-and-selecting-data-with-pandas/)\n- [Boolean Indexing in Pandas](https://www.geeksforgeeks.org/pandas/boolean-indexing-in-pandas/)\n- [Python | Pandas DataFrame.ix[ ]](https://www.geeksforgeeks.org/python/python-pandas-dataframe-ix/)\n- [Python | Pandas Series.str.slice()](https://www.geeksforgeeks.org/python/python-pandas-series-str-slice/)\n- [How to take column-slices of DataFrame in Pandas?](https://www.geeksforgeeks.org/python/how-to-take-column-slices-of-dataframe-in-pandas/)\n\n## Operations\n\n- [Python | Pandas.apply()](https://www.geeksforgeeks.org/python/python-pandas-apply/)\n- [Apply function to every row in a Pandas DataFrame](https://www.geeksforgeeks.org/python/apply-function-to-every-row-in-a-pandas-dataframe/)\n- [Python | Pandas Series.apply()](https://www.geeksforgeeks.org/pandas/python-pandas-series-apply/)\n- [Pandas dataframe.aggregate() | Python](https://www.geeksforgeeks.org/python/python-pandas-dataframe-aggregate/)\n- [Pandas DataFrame mean() Method](https://www.geeksforgeeks.org/python/python-pandas-dataframe-mean/)\n- [Python | Pandas Series.mean()](https://www.geeksforgeeks.org/pandas/python-pandas-series-mean/)\n- [Python | Pandas dataframe.mad()](https://www.geeksforgeeks.org/python/python-pandas-dataframe-mad/)\n- [Python | Pandas Series.mad() to calculate Mean Absolute Deviation of a Series](https://www.geeksforgeeks.org/python/python-pandas-series-mad-to-calculate-mean-absolute-deviation-of-a-series/)\n- [Python | Pandas dataframe.sem()](https://www.geeksforgeeks.org/python/python-pandas-dataframe-sem/)\n- [Python | Pandas Series.value_counts()](https://www.geeksforgeeks.org/python/python-pandas-series-value_counts/)\n- [Pandas Index.value_counts()-Python](https://www.geeksforgeeks.org/python/python-pandas-index-value_counts/)\n- [Applying Lambda functions to Pandas Dataframe](https://www.geeksforgeeks.org/python/applying-lambda-functions-to-pandas-dataframe/)\n\n## Manipulating Data\n\n- [Adding New Column to Existing DataFrame in Pandas](https://www.geeksforgeeks.org/pandas/adding-new-column-to-existing-dataframe-in-pandas/)\n- [Python | Delete rows/columns from DataFrame using Pandas.drop()](https://www.geeksforgeeks.org/python/python-delete-rows-columns-from-dataframe-using-pandas-drop/)\n- [Python | Pandas DataFrame.truncate](https://www.geeksforgeeks.org/python/python-pandas-dataframe-truncate/)\n- [Python | Pandas Series.truncate()](https://www.geeksforgeeks.org/pandas/python-pandas-series-truncate/)\n- [Iterating over rows and columns in Pandas DataFrame](https://www.geeksforgeeks.org/data-analysis/iterating-over-rows-and-columns-in-pandas-dataframe/)\n- [Pandas Dataframe.sort_values()](https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-sort_values-set-1/)\n- [Python | Pandas Dataframe.sort_values() | Set-2](https://www.geeksforgeeks.org/python/python-pandas-dataframe-sort_values-set-2/)\n- [How to add one row in existing Pandas DataFrame?](https://www.geeksforgeeks.org/pandas/how-to-add-one-row-in-an-existing-pandas-dataframe/)\n\n## Grouping Data\n\n- [Pandas GroupBy](https://www.geeksforgeeks.org/pandas/pandas-groupby/)\n- [Grouping Rows in pandas](https://www.geeksforgeeks.org/python/grouping-rows-in-pandas/)\n- [Combining Multiple Columns in Pandas groupby with Dictionary](https://www.geeksforgeeks.org/pandas/combining-multiple-columns-in-pandas-groupby-with-dictionary/)\n\n## Merging, Joining, Concatenating and Comparing\n\n- [Python | Pandas Merging, Joining and Concatenating](https://www.geeksforgeeks.org/python/python-pandas-merging-joining-and-concatenating/)\n- [Python | Pandas Series.str.cat() to concatenate string](https://www.geeksforgeeks.org/python/python-pandas-series-str-cat-to-concatenate-string/)\n- [Python - Pandas dataframe.append()](https://www.geeksforgeeks.org/python/python-pandas-dataframe-append/)\n- [Python | Pandas Series.append()](https://www.geeksforgeeks.org/pandas/python-pandas-series-append/)\n- [Pandas Index.append() - Python](https://www.geeksforgeeks.org/python/python-pandas-index-append/)\n- [Python | Pandas Series.combine()](https://www.geeksforgeeks.org/python/python-pandas-series-combine/)\n- [Add a row at top in pandas DataFrame](https://www.geeksforgeeks.org/python/add-a-row-at-top-in-pandas-dataframe/)\n- [Python | Pandas str.join() to join string/list elements with passed delimiter](https://www.geeksforgeeks.org/python/python-pandas-str-join-to-join-string-list-elements-with-passed-delimiter/)\n- [Join two text columns into a single column in Pandas](https://www.geeksforgeeks.org/python/join-two-text-columns-into-a-single-column-in-pandas/)\n- [How To Compare Two Dataframes with Pandas compare?](https://www.geeksforgeeks.org/python/how-to-compare-two-dataframes-with-pandas-compare/)\n- [How to compare the elements of the two Pandas Series?](https://www.geeksforgeeks.org/python/how-to-compare-the-elements-of-the-two-pandas-series/)\n\n## Working with Date and Time\n\n- [Python | Working with date and time using Pandas](https://www.geeksforgeeks.org/python/python-working-with-date-and-time-using-pandas/)\n- [Python | Pandas Timestamp.timestamp](https://www.geeksforgeeks.org/python/python-pandas-timestamp-timestamp/)\n- [Python | Pandas Timestamp.now](https://www.geeksforgeeks.org/python/python-pandas-timestamp-now/)\n- [Python | Pandas Timestamp.isoformat](https://www.geeksforgeeks.org/python/python-pandas-timestamp-isoformat/)\n- [Python | Pandas Timestamp.date](https://www.geeksforgeeks.org/python/python-pandas-timestamp-date/)\n- [Python | Pandas Timestamp.replace](https://www.geeksforgeeks.org/python/python-pandas-timestamp-replace/)\n- [Pandas.to_datetime()-Python](https://www.geeksforgeeks.org/python/python-pandas-to_datetime/)\n- [Python | pandas.date_range() method](https://www.geeksforgeeks.org/python/python-pandas-date_range-method/)"}
{"reference": "https://www.geeksforgeeks.org/courses/ms-excel-and-google-spreadsheets", "content": "# MS Excel and Google Spreadsheets - Skill Up\n\nSelf-Paced Course\n\nThe Excel & Google Sheets Course is an 8-week structured program that teaches you everything from the basics of Excel to advanced data automation in Google Sheets. You'll master data entry, formulas, formatting, analysis tools, visualization, and automation using real-world examples and projects.\n\n**8 Weeks**\n\n**3k+ interested Geeks**\n\n## Course Overview\n\nThis 8-week course combines **theory, hands-on practice, and projects** to help you become confident with Excel and Google Sheets. You'll learn to manage data, use formulas, create dashboards, automate with VBA and Google Apps Script, and collaborate in real-time. By the end, you'll be able to **analyze, visualize, and automate data workflows** for business or personal projects.\n\n## Course Highlights\n\n- Learn Excel basics: navigation, formatting, and formulas\n- Master data manipulation and validation techniques\n- Work with advanced formulas: Lookup, Array, Logical, and Statistical functions\n- Build PivotTables, charts, and interactive dashboards\n- Automate workflows with Macros, VBA, and Google Apps Script\n- Create dynamic reports using Power Query and Power Pivot\n- Explore Google Sheets collaboration tools, AI features, and integrations\n- Apply knowledge through practical projects and case studies\n\n## Course Content\n\n### Week 1: Excel Basics and Formatting\n\n- Excel Introduction and Basics\n- Navigation in Excel\n- Data Manipulation\n- Data Entry Features\n- Grouping and Hiding\n- Basic Formatting\n- Visual and Interactive Elements\n\n### Week 2: Intermediate Formatting and Formulas\n\n- Conditional Formatting\n- Lookup Functions\n- Text and Date Functions\n- Advanced Lookup and Array Functions\n- Statistical and Conditional Functions\n- Data Sorting\n- Choose and Array Functions\n\n### Week 3: Data Analysis and Visualization\n\n- Filtering and Data Entry\n- PivotTables Basics\n- Advanced Pivot Features\n- Data Analysis Tools\n- Basic Charts\n- Advanced Charts\n- Statistical Visualizations\n\n### Week 4: Advanced Excel and Automation\n\n- Power Query Basics\n- Power Pivot Basics\n- Advanced Power Query & Pivot\n- Macros Introduction\n- VBA Basics\n- VBA Advanced\n- Specialized Charts"}
{"reference": "https://www.geeksforgeeks.org/gfg-corporate-solution/", "content": "# GeeksforGeeks Corporate Solution\n\nReach 100 million+ people in tech. Get the word out to the world’s largest audience of developers and technologists. Collaborate with GeeksforGeeks.\n\n**35 Million+**  \nActive monthly users  \n\n**2 Million+**  \nSocial media followers  \n\n**100 Million+**  \nAvg monthly traffic  \n\n**1 Billion+**  \nImpressions served each month  \n\n## We Have Got You Covered In Every Way\n\nWith a deep understanding of the diverse challenges businesses face today, we provide solutions that not only meet, but exceed your expectations.\n\n### GFG Hiring Solution for Recruiters\n\nExperience a transformative approach to recruitment with our cutting-edge solutions. Elevate your brand's presence, connect with top-tier talent, pinpoint the perfect team fit. Simplify your hiring journey and usher in a new era of efficiency and success.\n\n![Corporate Hiring](https://media.geeksforgeeks.org/auth-dashboard-uploads/Corporatehiring-min.png)\n\n### Advertise With Us\n\nAchieve precise targeting, converting leads to conversions effortlessly. Elevate your business with our potent platform, connecting you to a 35+ million-strong audience. Boost brand awareness, conversions, and quality leads for unprecedented growth.\n\n![Advertise](https://media.geeksforgeeks.org/auth-dashboard-uploads/Advertise-min.png)\n\n## Our Clients\n\nWe place a great deal of value on strong relationships and have witnessed the advantages they bring to our business and the value they add. We are thankful to the companies who have partnered with us and are continuing to do so.\n\n- PayU\n- Adobe\n- Nagarro\n- Amazon\n- Oracle\n- Harman\n- Google Cloud\n- Hostinger\n- Microsoft\n\n### Worldwide Traffic Split\n\n- **60%** Domestic Traffic\n- **40%** International Traffic\n\n### Traffic Split Citywide\n\n- **45%** Tier 1 City\n- **35%** Tier 2 City\n- **20%** Tier 3 City\n\n![World Traffic Details](https://media.geeksforgeeks.org/auth-dashboard-uploads/traffic-1.svg)\n\n## Our Social Media Presence\n\n![LinkedIn Icon](https://media.geeksforgeeks.org/auth-dashboard-uploads/Linkedin_image-min.png)  \n**1.4 M** Followers  \n\n![Instagram Icon](https://media.geeksforgeeks.org/auth-dashboard-uploads/insta-min.png)  \n**303 K** Followers  \n\n![Twitter Icon](https://media.geeksforgeeks.org/auth-dashboard-uploads/Twitter-min.png)  \n**56.8 K** Followers  \n\n![YouTube Icon](https://media.geeksforgeeks.org/auth-dashboard-uploads/youtube-min.png)  \n**645 K** Followers  \n\n## About Us\n\n![About Image 1](https://media.geeksforgeeks.org/auth-dashboard-uploads/About-Us-1-min.png) ![About Image 2](https://media.geeksforgeeks.org/auth-dashboard-uploads/About-Us-2-min.png) ![About Image 3](https://media.geeksforgeeks.org/auth-dashboard-uploads/About-Us-3-min.png)\n\n- GeeksforGeeks is one of the leading organizations in the Global ed-tech industry, with over 35+ million active monthly users and 15+ million registered users globally.\n- While establishing its name among millions of engineering students, it has also helped them earn by being a part of the very movement of knowledge-sharing.\n- Started as a blog in 2008, GeeksforGeeks is now a globally recognized topmost computer science & Interview preparation portal in the software industry. Today, tech giants like Google, Facebook, Microsoft, Amazon, and more, recommend GeeksforGeeks as the preparation portal for their technical interview rounds in their interview letters.\n- The platform has been ranked among the top 50 websites in India by Alexa.\n\n## Contact Us\n\nInterested in:  \n- Hiring Solution for Recruiters  \n- Advertise with us  \n\nFull Name:  \nEmail Address:  \nMobile Number:  \nCompany Name:  \n\nSubmit"}
{"reference": "https://www.geeksforgeeks.org/tag/neural-network/", "content": "# Neural Network\n\n183+ posts\n\n## Recent Articles\n\n### Neural Collaborative Filtering\n**Last Updated:** 04 August 2025\n\nNeural Collaborative Filtering (NCF) is an improved version of traditional recommendation systems that uses deep learning to make better suggestions. It is an advanced version...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[Deep Learning](https://www.geeksforgeeks.org/tag/deep-learning-2/)\n\n### Defensive Distillation\n**Last Updated:** 23 July 2025\n\nDefensive distillation is a technique aimed at improving the robustness of deep neural networks against adversarial attacks. It involves training a more robust network by...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)  \n[Deep Learning](https://www.geeksforgeeks.org/tag/deep-learning-2/)\n\n### Why ReLU function is not differentiable at x=0?\n**Last Updated:** 23 July 2025\n\nReLU activation function introduces non-linearity to the neural networks, enabling them to capture complex patterns in the data. It is defined as:  \n\\text{ReLU}(x) = \\max(0, ...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)\n\n### Are Neural Networks Supervised or Unsupervised?\n**Last Updated:** 23 July 2025\n\nNeural networks can be both supervised and unsupervised depending on how they are trained and the task they are designed to perform. In supervised learning, they rely on labeled...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)\n\n### RNN vs LSTM vs GRU vs Transformers\n**Last Updated:** 23 July 2025\n\nWhen working with data that comes in a sequence like sentences, speech or time-based information we need special models that can understand the order and connection between...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)\n\n### Batch Size in Neural Network\n**Last Updated:** 23 July 2025\n\nBatch size is a hyperparameter that determines the number of training records used in one forward and backward pass of the neural network. In this article, we will explore...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)\n\n### Repeated Training on the Same Data: Implications for Model Performance\n**Last Updated:** 23 July 2025\n\nIn machine learning, the process of training a model is crucial for its performance on unseen data. However, a common question arises: What happens if I fit my model on the...\n\n[Picked](https://www.geeksforgeeks.org/tag/picked/)  \n[Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/)  \n[Blogathon](https://www.geeksforgeeks.org/category/blogathon/)  \n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)  \n[AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)  \n[Keras Library](https://www.geeksforgeeks.org/tag/keras-library/)  \n[Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### HyperParameter Tuning: Fixing Overfitting in Neural Networks\n**Last Updated:** 23 July 2025\n\nOverfitting is a pervasive problem in neural networks, where the model becomes too specialized to the training data and fails to generalize well to new, unseen data. This...\n\n[Picked](https://www.geeksforgeeks.org/tag/picked/)  \n[Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/)  \n[Blogathon](https://www.geeksforgeeks.org/category/blogathon/)  \n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)  \n[AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)  \n[Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### Perceptron Convergence Theorem in Neural Networks\n**Last Updated:** 15 July 2024\n\nThe Perceptron Convergence Theorem is a fundamental concept in machine learning, showing how a simple algorithm, the perceptron, can learn to classify items accurately. It...\n\n[Blogathon](https://www.geeksforgeeks.org/category/blogathon/)  \n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)  \n[AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)  \n[Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### Differences Between Bayesian Networks and Neural Networks\n**Last Updated:** 23 July 2025\n\nBayesian networks and neural networks are two distinct types of graphical models used in machine learning and artificial intelligence. While both models are designed to handle...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)\n\n### Feedback Neural Networks: Structure, Training, and Applications\n**Last Updated:** 23 July 2025\n\nNeural networks, a cornerstone of deep learning, are designed to simulate the human brain's behavior in processing data and making decisions. Among the various types of neural...\n\n[Picked](https://www.geeksforgeeks.org/tag/picked/)  \n[Blogathon](https://www.geeksforgeeks.org/category/blogathon/)  \n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)  \n[Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### Unconstrained Optimization Techniques in Neural Networks\n**Last Updated:** 23 July 2025\n\nUnconstrained optimization plays a crucial role in the training of neural networks. Unlike constrained optimization, where the solution must satisfy certain constraints, unconstrained...\n\n[Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/)  \n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[optimization-technique](https://www.geeksforgeeks.org/tag/optimization-technique/)  \n[Machine Learning](https://www.geeksforgeeks.org/tag/machine-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)\n\n### Feedback System in Neural Networks\n**Last Updated:** 23 July 2025\n\nA feedback system in neural networks is a mechanism where the output is fed back into the network to influence subsequent outputs, often used to enhance learning and stability...\n\n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)  \n[AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Linear Regression vs. Neural Networks: Understanding Key Differences\n**Last Updated:** 23 July 2025\n\nLinear Regression and Neural Networks are two fundamental techniques in the machine learning toolkit. Linear Regression is a simple, yet powerful, statistical method for modeling...\n\n[Picked](https://www.geeksforgeeks.org/tag/picked/)  \n[Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/)  \n[Blogathon](https://www.geeksforgeeks.org/category/blogathon/)  \n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)  \n[Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### Least Mean-Squares Algorithm in Neural Networks\n**Last Updated:** 23 July 2025\n\nThe Least Mean-Squares (LMS) algorithm is a widely used adaptive filter technique in neural networks, signal processing, and control systems. Developed by Bernard Widrow and...\n\n[Blogathon](https://www.geeksforgeeks.org/category/blogathon/)  \n[Neural Network](https://www.geeksforgeeks.org/tag/neural-network/)  \n[Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)  \n[AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/)  \n[AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)  \n[Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n[Page 1](https://www.geeksforgeeks.org/tag/neural-network/page/1/?type=recent) | [Page 2](https://www.geeksforgeeks.org/tag/neural-network/page/2/?type=recent) | [Page 3](https://www.geeksforgeeks.org/tag/neural-network/page/3/?type=recent) | [Page 4](https://www.geeksforgeeks.org/tag/neural-network/page/4/?type=recent)  \n...  \n[Page 13](https://www.geeksforgeeks.org/tag/neural-network/page/13/?type=recent)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/", "content": "# K-Nearest Neighbor (KNN) Algorithm\n\nK-Nearest Neighbors (KNN) is a supervised machine learning algorithm generally used for classification but can also be used for regression tasks. It works by finding the \"k\" closest data points (neighbors) to a given input and makes predictions based on the majority class (for classification) or the average value (for regression). Since KNN makes no assumptions about the underlying data distribution, it makes it a non-parametric and instance-based learning method.\n\nK-Nearest Neighbors is also called a lazy learner algorithm because it does not learn from the training set immediately; instead, it stores the entire dataset and performs computations only at the time of classification.\n\nFor example, consider the following table of data points containing two features:\n\n![KNN Algorithm working visualization](https://media.geeksforgeeks.org/wp-content/uploads/20250823095401939200/1223.webp)\n\nThe new point is classified as Category 2 because most of its closest neighbors are blue squares. KNN assigns the category based on the majority of nearby points. The image shows how KNN predicts the category of a new data point based on its closest neighbours.\n\n- The red diamonds represent Category 1 and the blue squares represent Category 2.\n- The new data point checks its closest neighbors (circled points).\n- Since the majority of its closest neighbors are blue squares (Category 2), KNN predicts the new data point belongs to Category 2.\n\nKNN works by using proximity and majority voting to make predictions.\n\n## What is 'K' in K Nearest Neighbour?\n\nIn the k-Nearest Neighbours algorithm, k is just a number that tells the algorithm how many nearby points or neighbors to look at when it makes a decision.\n\n**Example:** Imagine you're deciding which fruit it is based on its shape and size. You compare it to fruits you already know.\n\n- If k = 3, the algorithm looks at the 3 closest fruits to the new one.\n- If 2 of those 3 fruits are apples and 1 is a banana, the algorithm says the new fruit is an apple because most of its neighbors are apples.\n\n### How to choose the value of k for KNN Algorithm?\n\n- The value of k in KNN decides how many neighbors the algorithm looks at when making a prediction.\n- Choosing the right k is important for good results.\n- If the data has lots of noise or outliers, using a larger k can make the predictions more stable.\n- But if k is too large, the model may become too simple and miss important patterns, and this is called underfitting.\n- So k should be picked carefully based on the data.\n\n### Statistical Methods for Selecting k\n\n- **Cross-Validation**: [Cross-Validation](https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/) is a good way to find the best value of k by using k-fold cross-validation. This means dividing the dataset into k parts. The model is trained on some of these parts and tested on the remaining ones. This process is repeated for each part. The k value that gives the highest average accuracy during these tests is usually the best one to use.\n- **Elbow Method**: In [Elbow Method](https://www.geeksforgeeks.org/machine-learning/elbow-method-for-optimal-value-of-k-in-kmeans/), we draw a graph showing the error rate or accuracy for different k values. As k increases, the error usually drops at first. But after a certain point, error stops decreasing quickly. The point where the curve changes direction and looks like an \"elbow\" is usually the best choice for k.\n- **Odd Values for k**: It’s a good idea to use an odd number for k, especially in classification problems. This helps avoid ties when deciding which class is the most common among the neighbors.\n\n## Distance Metrics Used in KNN Algorithm\n\nKNN uses distance metrics to identify nearest neighbors; these neighbors are used for classification and regression tasks. To identify nearest neighbors, we use the below distance metrics:\n\n### 1. Euclidean Distance\n\nEuclidean distance is defined as the straight-line distance between two points in a plane or space. You can think of it like the shortest path you would walk if you were to go directly from one point to another.\n\n$$\n\\text{distance}(x, X_i) = \\sqrt{\\sum_{j=1}^{d} (x_j - X_{i_j})^2}\n$$\n\n### 2. Manhattan Distance\n\nThis is the total distance you would travel if you could only move along horizontal and vertical lines like a grid or city streets. It’s also called \"taxicab distance\" because a taxi can only drive along the grid-like streets of a city.\n\n$$\nd(x,y) = \\sum_{i=1}^{n} \\| x_i - y_i \\|\n$$\n\n### 3. Minkowski Distance\n\nMinkowski distance is like a family of distances, which includes both Euclidean and Manhattan distances as special cases.\n\n$$\nd(x,y) = \\left( \\sum_{i=1}^{n} (x_i - y_i)^p \\right)^{\\frac{1}{p}}\n$$\n\nFrom the formula above, when p=2, it becomes the same as the Euclidean distance formula, and when p=1, it turns into the Manhattan distance formula. Minkowski distance is essentially a flexible formula that can represent either Euclidean or Manhattan distance depending on the value of p.\n\n## Working of KNN Algorithm\n\nThe K-Nearest Neighbors (KNN) algorithm operates on the principle of similarity where it predicts the label or value of a new data point by considering the labels or values of its K nearest neighbors in the training dataset.\n\n![Workings of KNN algorithm](https://media.geeksforgeeks.org/wp-content/uploads/20231207103856/KNN-Algorithm-(1).png)\n\n### Step 1: Selecting the optimal value of K\n\n- K represents the number of nearest neighbors that needs to be considered while making a prediction.\n\n### Step 2: Calculating distance\n\n- To measure the similarity between target and training data points, Euclidean distance is widely used. Distance is calculated between data points in the dataset and the target point.\n\n### Step 3: Finding Nearest Neighbors\n\n- The k data points with the smallest distances to the target point are nearest neighbors.\n\n### Step 4: Voting for Classification or Taking Average for Regression\n\n- When you want to classify a data point into a category like spam or not spam, the KNN algorithm looks at the K closest points in the dataset. These closest points are called neighbors. The algorithm then looks at which category the neighbors belong to and picks the one that appears the most. This is called majority voting.\n- In regression, the algorithm still looks for the K closest points. But instead of voting for a class in classification, it takes the average of the values of those K neighbors. This average is the predicted value for the new point for the algorithm.\n\nIt shows how a test point is classified based on its nearest neighbors. As the test point moves, the algorithm identifies the closest 'k' data points (i.e., 5 in this case) and assigns the test point the majority class label that is grey label class here.\n\n## Implementing KNN from Scratch in Python\n\n### 1. Importing Libraries\n\n[Counter](https://www.geeksforgeeks.org/python/counters-in-python-set-1/) is used to count the occurrences of elements in a list or iterable. In KNN, after finding the k nearest neighbor labels, Counter helps count how many times each label appears.\n\n```python\nimport numpy as np\nfrom collections import Counter\n```\n\n### 2. Defining the Euclidean Distance Function\n\n**euclidean_distance** is to calculate Euclidean distance between points.\n\n```python\ndef euclidean_distance(point1, point2):\n    return np.sqrt(np.sum((np.array(point1) - np.array(point2))**2))\n```\n\n### 3. KNN Prediction Function\n\n- **distances.append** saves how far each training point is from the test point, along with its label.\n- **distances.sort** is used to sort the list so the nearest points come first.\n- **k_nearest_labels** picks the labels of the k closest points.\n- Uses Counter to find which label appears most among those k labels; that becomes the prediction.\n\n```python\ndef knn_predict(training_data, training_labels, test_point, k):\n    distances = []\n    for i in range(len(training_data)):\n        dist = euclidean_distance(test_point, training_data[i])\n        distances.append((dist, training_labels[i]))\n    distances.sort(key=lambda x: x[0])\n    k_nearest_labels = [label for _, label in distances[:k]]\n    return Counter(k_nearest_labels).most_common(1)[0][0]\n```\n\n### 4. Training Data, Labels and Test Point\n\n```python\ntraining_data = [[1, 2], [2, 3], [3, 4], [6, 7], [7, 8]]\ntraining_labels = ['A', 'A', 'A', 'B', 'B']\ntest_point = [4, 5]\nk = 3\n```\n\n### 5. Prediction\n\n```python\nprediction = knn_predict(training_data, training_labels, test_point, k)\nprint(prediction)\n```\n\n**Output:**\n\n> A\n\nThe algorithm calculates the distances of the test point [4, 5] to all training points, selects the 3 closest points as k = 3, and determines their labels. Since the majority of the closest points are labelled **'A'**, the test point is classified as **'A'**.\n\n> In machine learning, we can also use the Scikit Learn Python library, which has built-in functions to perform the KNN machine learning model. For that, you can refer to [Implementation of KNN classifier using Sklearn](https://www.geeksforgeeks.org/machine-learning/ml-implementation-of-knn-classifier-using-sklearn/).\n\n## Applications of KNN\n\n- **Recommendation Systems**: Suggests items like movies or products by finding users with similar preferences.\n- **Spam Detection**: Identifies spam emails by comparing new emails to known spam and non-spam examples.\n- **Customer Segmentation**: Groups customers by comparing their shopping behavior to others.\n- **Speech Recognition**: Matches spoken words to known patterns to convert them into text.\n\n## Advantages of KNN\n\n- **Simple to use**: Easy to understand and implement.\n- **No training step**: No need to train as it just stores the data and uses it during prediction.\n- **Few parameters**: Only needs to set the number of neighbors (k) and a distance method.\n- **Versatile**: Works for both classification and regression problems.\n\n## Disadvantages of KNN\n\n- **Slow with large data**: Needs to compare every point during prediction.\n- **Struggles with many features**: Accuracy drops when data has too many features.\n- **Can Overfit**: It can overfit, especially when the data is high-dimensional or not clean.\n\n## Also Check for more understanding:\n\n- [K Nearest Neighbors with Python | ML](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbor-algorithm-in-python/)\n- [Implementation of K-Nearest Neighbors from Scratch using Python](https://www.geeksforgeeks.org/machine-learning/implementation-of-k-nearest-neighbors-from-scratch-using-python/)\n- [Mathematical explanation of K-Nearest Neighbour](https://www.geeksforgeeks.org/machine-learning/mathematical-explanation-of-k-nearest-neighbour/)\n- [Weighted K-NN](https://www.geeksforgeeks.org/machine-learning/weighted-k-nn/)"}
{"reference": "https://www.geeksforgeeks.org/courses/engineering-mathematics-skill-up", "content": "# Engineering Mathematics - Skill Up\n\n**Self-Paced Course**\n\n**Course Description**\n\nEngineering Mathematics builds a strong foundation in essential topics like Calculus, Differential Equations, Linear Algebra, Matrices, and Complex Analysis. Combining theory with practical applications, the course develops analytical and problem-solving skills through structured lessons, exercises, and real-world engineering examples, enabling learners to model, analyze, and solve complex engineering problems efficiently.\n\n**Duration:** 16 Weeks\n\n**Interested:** 2k+ Geeks\n\n## Course Overview\n\nThis course is designed to provide engineering students with a strong mathematical foundation, covering essential topics such as Calculus, Differential Equations, Linear Algebra, Matrices, Complex Analysis, and more. It equips learners with the analytical tools and problem-solving techniques needed to tackle mathematical challenges in engineering effectively.\n\nEach week focuses on a specific mathematical domain, with daily topics accompanied by practice problems and application-oriented examples.\n\n### Course Highlights\n\n- Develop a solid understanding of limits, continuity, and differentiation for solving real-world engineering problems.\n- Master integration, multivariable calculus, and differential equations for modeling dynamic systems and circuits.\n- Learn vectors, matrices, eigenvalues, and eigenvectors for applications in mechanics, control systems, and signal processing.\n- Explore complex numbers, Laplace transforms, and Fourier series for analyzing engineering systems and vibrations.\n- Access curated examples and problem sets for hands-on practice and conceptual clarity.\n- Build confidence for exams, competitive tests, and engineering projects with a strong focus on applied mathematics.\n\n## Course Content\n\n### 01 Matrices – I\n\n- Introduction to matrices and their applications in engineering.\n- Determinants and their properties, including applications of determinants.\n- Basic Matrices: Row, Column, Square, Identity, Diagonal.\n- Structural Matrices: Scalar, Triangular, Symmetric, and Skew-Symmetric, Orthogonal.\n- Advanced Matrices: Hermitian and Skew-Hermitian, Involutory, Idempotent, Nilpotent, and Complex Matrices.\n- Inverse and rank of a matrix; rank of a matrix using elementary transformations.\n- Rank-Nullity theorem and its implications.\n\n### 02 Matrices – II\n\n- System of linear equations: Solving using Cramer's Rule, and solving using the inverse of matrices.\n- Gauss-Jordan method and LU Decomposition for solving systems of equations.\n- Characteristic equation of a matrix.\n- Cayley-Hamilton theorem and its applications.\n- Eigenvalues and eigenvectors.\n- Diagonalization of a matrix.\n- Practice with Previous Year Questions (PYQs).\n\n### 03 Differential Calculus-I\n\n- Introduction to limits.\n- Rolle's Theorem.\n- Lagrange's Mean Value Theorem.\n- Cauchy's Mean Value Theorem.\n- Successive differentiation (nth order derivatives).\n- Leibniz's theorem and its application.\n- Envelope of the family of one and two parameters.\n- Curve tracing.\n- Cartesian and Polar coordinates.\n\n### 04 Differential Calculus-II\n\n- Partial derivatives\n- Total derivative\n- Euler's Theorem\n- Taylor Theorem\n- Maclaurin's Theorem\n- Maxima and Minima of functions of several variables\n- Lagrange Method of Multipliers\n- Jacobians\n- Approximation of errors\n\n## Frequently Asked Questions\n\n### 01 Who can benefit from this course?\n\n### 02 What topics are covered?\n\n### 03 How will this course help me in engineering?"}
{"reference": "https://www.geeksforgeeks.org/deep-learning/effect-of-bias-in-neural-network/", "content": "# Effect of Bias in Neural Network\n\nNeural Network is conceptually based on actual neuron of brain. Neurons are the basic units of a large neural network. A single neuron passes single forward based on input provided.\n\nIn Neural network, some inputs are provided to an artificial neuron, and with each input a weight is associated. Weight increases the steepness of activation function. This means weight decide how fast the activation function will trigger whereas bias is used to delay the triggering of the activation function.\n\nFor a typical neuron, if the inputs are x1, x2, and x3, then the synaptic weights to be applied to them are denoted as w1, w2, and w3.\n\nOutput is  \n```\ny = f(x) = Σxiwi\n```\nwhere i is 1 to the number of inputs.\n\nThe weight shows the effectiveness of a particular input. More the weight of input, more it will have impact on network.\n\nOn the other hand Bias is like the intercept added in a linear equation. It is an additional parameter in the Neural Network which is used to adjust the output along with the weighted sum of the inputs to the neuron. Therefore Bias is a constant which helps the model in a way that it can fit best for the given data.\n\nThe processing done by a neuron is thus denoted as:  \n```\noutput = sum (weights * inputs) + bias\n```\n\n![Neuron diagram](https://media.geeksforgeeks.org/wp-content/uploads/neuron.png)\n\n## Need of bias\n\nIn above figure  \n```\ny = mx + c\n```\nwhere  \n```\nm = weight\n```\nand  \n```\nc = bias\n```\n\nNow, Suppose if c was absent, then the graph will be formed like this:  \n![Graph without bias](https://media.geeksforgeeks.org/wp-content/uploads/Untitled-drawing-4-2.png)\n\nDue to absence of bias, model will train over point passing through origin only, which is not in accordance with real-world scenario. Also with the introduction of bias, the model will become more flexible. **For Example:** Suppose an activation function act() which get triggered on some input greater than 0.  \nNow,  \n```\ninput1 = 1\n```\n```\nweight1 = 2\n```\n```\ninput2 = 2\n```\n```\nweight2 = 2\n```\nso  \n```\noutput = input1*weight1 + input2*weight2\n```\n```\noutput = 6\n```\nlet  \n```\nsuppose act(output) = 1\n```\n\nNow a bias is introduced in output as  \n```\nbias = -6\n```\nthe output become 0.  \n```\nact(0) = 0\n```\nso activation function will not trigger.\n\n## Change in weight\n\nHere in graph, as it can be seen that when:  \n- weight WI changed from 1.0 to 4.0  \n- weight W2 changed from -0.5 to 1.5  \n\nOn increasing the weight the steepness is increasing.  \n\nTherefore it can be inferred that  \n```\nMore the weight earlier activation function will trigger.\n```\n\n![Weight change graph](https://media.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2018-09-09-19-18-31.png)\n\n## Change in bias\n\nHere in graph below, when  \n```\nBias changed from -1.0 to -5.0\n```\n\nThe change in bias is increasing the value of triggering activation function.  \n\n![Bias change graph](https://media.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2018-09-09-19-40-18.png)\n\nTherefore it can be inferred that from above graph that,  \n```\nbias helps in controlling the value at which activation function will trigger.\n```"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/frequent-pattern-growth-algorithm/", "content": "# Frequent Pattern Growth Algorithm\n\nThe FP-Growth (Frequent Pattern Growth) algorithm efficiently mines frequent itemsets from large transactional datasets. Unlike the [Apriori algorithm](https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/) which suffers from high computational cost due to candidate generation and multiple database scans. FP-Growth avoids these inefficiencies by compressing the data into an FP-Tree (Frequent Pattern Tree) and extracts patterns directly from it.\n\n## How FP-Growth Works\n\nHere's how it works in simple terms:\n\n1. **Data Compression**: First FP-Growth compresses the dataset into a smaller structure called the **Frequent Pattern Tree (FP-Tree)**. This tree stores information about item sets (collections of items) and their frequencies without need to generate candidate sets like Apriori does.\n\n2. **Mining the Tree**: The algorithm then examines this tree to identify patterns that appear frequently based on a minimum support threshold. It does this by breaking the tree down into smaller \"conditional\" trees for each item making the process more efficient.\n\n3. **Generating Patterns**: Once the tree is built and analyzed the algorithm generates the frequent patterns (itemsets) and the rules that describe relationships between items.\n\nImagine you're organizing a party and want to know popular food combinations without asking every guest repeatedly.\n\n1. **List food items** each guest brought transactions.\n\n2. **Count items and remove infrequent ones** filter by support.\n\n3. **Group items in order of popularity** and create a **tree** where paths represent common combinations.\n\n4. Instead of repeatedly asking guests you explore this tree to discover patterns. For example, you might find that pizza and pasta often come together or that cake and pasta are also a common pair.\n\nThis is exactly how FP-Growth finds frequent patterns efficiently.\n\n## Working of FP-Growth Algorithm\n\nLets jump to the usage of FP-Growth Algorithm and how it works with reallife data. Consider the following data:\n\n| Transaction ID | Items          |\n| -------------- | -------------- |\n| T1             | {E,K,M,N,O,Y}  |\n| T2             | {D,E,K,N,O,Y}  |\n| T3             | {A,E,K,M}      |\n| T4             | {K,M,Y}        |\n| T5             | {C,E,I,K,O,O}  |\n\nThe above-given data is a hypothetical dataset of transactions with each letter representing an item. The frequency of each individual item is computed:\n\n| Item | Frequency |\n| ---- | --------- |\n| A    | 1         |\n| C    | 2         |\n| D    | 1         |\n| E    | 4         |\n| I    | 1         |\n| K    | 5         |\n| M    | 3         |\n| N    | 2         |\n| O    | 4         |\n| U    | 1         |\n| Y    | 3         |\n\nLet the minimum support be 3. A **Frequent Pattern set** is built which will contain all the elements whose frequency is greater than or equal to the minimum support. These elements are stored in descending order of their respective frequencies. After insertion of the relevant items, the set L looks like this:\n\n**L = {K : 5, E : 4, M : 3, O : 4, Y : 3}**\n\nNow for each transaction the respective **Ordered-Item set** is built. It is done by iterating the Frequent Pattern set and checking if the current item is contained in the transaction in question. If the current item is contained the item is inserted in the Ordered-Item set for the current transaction. The following table is built for all the transactions:\n\n| Transaction ID | Items          | Ordered-Item-Set |\n| -------------- | -------------- | ---------------- |\n| T1             | {E,K,M,N,O,Y}  | {K,E,M,O,Y}      |\n| T2             | {D,E,K,N,O,Y}  | {K,E,O,Y}        |\n| T3             | {A,E,K,M}      | {K,E,M}          |\n| T4             | {C,K,M,U,Y}    | {K,M,Y}          |\n| T5             | {C,E,I,K,O,O}  | {K,E,O}          |\n\nNow all the Ordered-Item sets are inserted into a Tree Data Structure.\n\n**a) Inserting the set {K, E, M, O, Y}**  \nHere all the items are simply linked one after the other in the order of occurrence in the set and initialise the support count for each item as 1. For inserting {K, E, M, O, Y} we traverse the tree from the root. If a node already exists for an item, we increase its support count. If it doesn't exist, we create a new node for that item and link it to the previous item.\n\n![Inserting the set {K, E, M, O, Y}](https://media.geeksforgeeks.org/wp-content/uploads/20250527122206351780/Frequent-Pattern-Growth-Algorithm.webp)\n\n**b) Inserting the set {K, E, O, Y}**  \nTill the insertion of the elements K and E, simply the support count is increased by 1. On inserting O we can see that there is no direct link between E and O, therefore a new node for the item O is initialized with the support count as 1 and item E is linked to this new node. On inserting Y, we first initialize a new node for the item Y with support count as 1 and link the new node of O with the new node of Y.\n\n![Inserting the set {K, E, O, Y}](https://media.geeksforgeeks.org/wp-content/uploads/20250527123234364694/Frequent-Pattern-Growth-Algorithm-2.webp)\n\n**c) Inserting the set {K, E, M}**  \nHere simply the support count of each element is increased by 1.\n\n![Inserting the set {K, E, M}](https://media.geeksforgeeks.org/wp-content/uploads/20250527123040863785/Frequent-Pattern-Growth-Algorithm-3.webp)\n\n**d) Inserting the set {K, M, Y}**  \nSimilar to step b), first the support count of K is increased, then new nodes for M and Y are initialized and linked accordingly.\n\n![Inserting the set {K, M, Y}](https://media.geeksforgeeks.org/wp-content/uploads/20250527124645654216/Frequent-Pattern-Growth-Algorithm-4.webp)\n\n**e) Inserting the set {K, E, O}**  \nHere simply the support counts of the respective elements are increased. Note that the support count of the new node of item O is increased.\n\n![Inserting the set {K, E, O}](https://media.geeksforgeeks.org/wp-content/uploads/20250527124748171099/Frequent-Pattern-Growth-Algorithm-5.webp)\n\nThe Conditional Pattern Base for each item consists of the set of prefixes of all paths in the FP-tree that lead to that item. Note that the items in the below table are arranged in the ascending order of their frequencies.\n\n![Conditional Pattern Base](https://media.geeksforgeeks.org/wp-content/uploads/20190719131125/condtional-pattern-base.png)\n\nNow for each item, the **Conditional Frequent Pattern Tree is built.** It is done by taking the set of elements that is common in all the paths in the Conditional Pattern Base of that item and calculating its support count by summing the support counts of all the paths in the Conditional Pattern Base.\n\n![Conditional FP-Tree](https://media.geeksforgeeks.org/wp-content/uploads/20190719131644/condtional-fp-tree.png)\n\nFrom the Conditional Frequent Pattern tree the **Frequent Pattern rules** are generated by pairing the items of the Conditional Frequent Pattern Tree set to the corresponding to the item as given in the below table.\n\n![Frequent Pattern Rules](https://www.geeksforgeeks.org/wp-content/cdn-uploads/20220418161601/ek4.jpg)\n\nFor each row two types of association rules can be inferred for example for the first row which contains the element, the rules **K -> Y and Y -> K** can be inferred. To determine the valid rule, the confidence of both the rules is calculated and the one with confidence greater than or equal to the minimum confidence value is retained.\n\nFrequent Pattern Growth (FP-Growth) algorithm improves upon the Apriori algorithm by eliminating the need for multiple database scans and reducing computational overhead. By using a Tree data structure and focusing on ordered-item sets it efficiently mines frequent item sets making it a faster and more scalable solution for large datasets making it useful tool for data mining."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/unsupervised-learning/", "content": "# What is Unsupervised Learning\n\nUnsupervised learning is a type of machine learning that analyzes and models data without labelled responses or predefined categories. Unlike supervised learning, where the algorithm learns from input-output pairs, unsupervised learning algorithms work solely with input data and aim to discover hidden patterns, structures or relationships within the dataset independently, without any human intervention or prior knowledge of the data's meaning.\n\n![Unsupervised Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250903113035199927/Unsupervised-Learning.webp)\n\n*Unsupervised Learning*\n\nThe image shows set of animals like elephants, camels and cows that represents raw data that the unsupervised learning algorithm will process.\n\n- The \"Interpretation\" stage signifies that the algorithm doesn't have predefined labels or categories for the data. It needs to figure out how to group or organize the data based on inherent patterns.\n- An algorithm represents unsupervised learning process which can be clustering, dimensionality reduction or anomaly detection to identify patterns in the data.\n- The processing stage shows the algorithm working on the data.\n\nThe output shows the results of the unsupervised learning process. In this case, the algorithm might have grouped the animals into clusters based on their species (elephants, camels, cows).\n\n## Working of Unsupervised Learning\n\nThe working of unsupervised machine learning can be explained in these steps:\n\n### 1. Collect Unlabeled Data\n\n- Gather a dataset without predefined labels or categories.\n- **Example**: Images of various animals without any tags.\n\n### 2. Select an Algorithm\n\n- Choose a suitable unsupervised algorithm such as clustering like K-Means, association rule learning like Apriori or dimensionality reduction like PCA based on the goal.\n\n### 3. Train the Model on Raw Data\n\n- Feed the entire unlabeled dataset to the algorithm.\n- The algorithm looks for similarities, relationships or hidden structures within the data.\n\n### 4. Group or Transform Data\n\n- The algorithm organizes data into groups (clusters), rules or lower-dimensional forms without human input.\n- Example: It may group similar animals together or extract key patterns from large datasets.\n\n### 5. Interpret and Use Results\n\n- Analyze the discovered groups, rules or features to gain insights or use them for further tasks like visualization, anomaly detection or as input for other models.\n\n## Unsupervised Learning Algorithms\n\nThere are mainly 3 types of Unsupervised Algorithms that are used:\n\n### 1. Clustering Algorithms\n\n[Clustering](https://www.geeksforgeeks.org/machine-learning/clustering-in-machine-learning/) is an unsupervised machine learning technique that groups unlabeled data into clusters based on similarity. Its goal is to discover patterns or relationships within the data without any prior knowledge of categories or labels.\n\n- Groups data points that share similar features or characteristics.\n- Helps find natural groupings in raw, unclassified data.\n- Commonly used for customer segmentation, anomaly detection and data organization.\n- Works purely from the input data without any output labels.\n- Enables understanding of data structure for further analysis or decision-making.\n\n> Some common clustering algorithms:\n>\n> - **[K-means Clustering](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/)**: Groups data into K clusters based on how close the points are to each other.\n> - **[Hierarchical Clustering](https://www.geeksforgeeks.org/machine-learning/hierarchical-clustering/)**: Creates clusters by building a tree step-by-step, either merging or splitting groups.\n> - **[Density-Based Clustering (DBSCAN)](https://www.geeksforgeeks.org/machine-learning/dbscan-clustering-in-ml-density-based-clustering/)**: Finds clusters in dense areas and treats scattered points as noise.\n> - **[Mean-Shift Clustering](https://www.geeksforgeeks.org/machine-learning/ml-mean-shift-clustering/)**: Discovers clusters by moving points toward the most crowded areas.\n> - **[Spectral Clustering](https://www.geeksforgeeks.org/machine-learning/ml-spectral-clustering/)**: Groups data by analyzing connections between points using graphs.\n\n### 2. Association Rule Learning\n\n[Association rule learning](https://www.geeksforgeeks.org/machine-learning/association-rule/) is a rule-based unsupervised learning technique used to discover interesting relationships between variables in large datasets. It identifies patterns in the form of “if-then” rules, showing how the presence of some items in the data implies the presence of others.\n\n- Finds frequent item combinations and the rules connecting them.\n- Commonly used in market basket analysis to understand product purchase relationships.\n- Helps retailers design promotions and cross-selling strategies.\n\n> Some common Association Rule Learning algorithms:\n>\n> - **[Apriori Algorithm](https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/)**: Finds patterns by exploring frequent item combinations step-by-step.\n> - **[FP-Growth Algorithm](https://www.geeksforgeeks.org/machine-learning/frequent-pattern-growth-algorithm/)**: An Efficient Alternative to Apriori. It quickly identifies frequent patterns without generating candidate sets.\n> - **[Eclat Algorithm](https://www.geeksforgeeks.org/machine-learning/ml-eclat-algorithm/)**: Uses intersections of itemsets to efficiently find frequent patterns.\n> - **[Efficient Tree-based Algorithms](https://www.geeksforgeeks.org/dsa/introduction-to-tree-data-structure/)**: Scales to handle large datasets by organizing data in tree structures.\n\n### 3. Dimensionality Reduction\n\n[Dimensionality reduction](https://www.geeksforgeeks.org/machine-learning/dimensionality-reduction/) is the process of decreasing the number of features or variables in a dataset while retaining as much of the original information as possible. This technique helps simplify complex data making it easier to analyze and visualize. It also improves the efficiency and performance of machine learning algorithms by reducing noise and computational cost.\n\n- It reduces the dataset’s feature space from many dimensions to fewer, more meaningful ones.\n- Helps focus on the most important traits or patterns in the data.\n- Commonly used to improve model speed and reduce overfitting.\n\n> Here are some popular Dimensionality Reduction algorithms:\n>\n> - **[Principal Component Analysis (PCA)](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)**: Reduces dimensions by transforming data into uncorrelated principal components.\n> - **[Linear Discriminant Analysis (LDA)](https://www.geeksforgeeks.org/machine-learning/ml-linear-discriminant-analysis/)**: Reduces dimensions while maximizing class separability for classification tasks.\n> - **[Non-negative Matrix Factorization (NMF)](https://www.geeksforgeeks.org/machine-learning/non-negative-matrix-factorization/)**: Breaks data into non-negative parts to simplify representation.\n> - **[Locally Linear Embedding (LLE)](https://www.geeksforgeeks.org/machine-learning/locally-linear-embedding-in-machine-learning/)**: Reduces dimensions while preserving the relationships between nearby points.\n> - **[Isomap](https://www.geeksforgeeks.org/machine-learning/isomap-a-non-linear-dimensionality-reduction-technique/)**: Captures global data structure by preserving distances along a manifold.\n\n## Applications of Unsupervised Learning\n\nUnsupervised learning has diverse applications across industries and domains. Key applications include:\n\n- **Customer Segmentation**: Algorithms cluster customers based on purchasing behavior or demographics, enabling targeted marketing strategies.\n- **Anomaly Detection**: Identifies unusual patterns in data, aiding fraud detection, cybersecurity and equipment failure prevention.\n- **Recommendation Systems**: Suggests products, movies or music by analyzing user behavior and preferences.\n- **Image and Text Clustering**: Groups similar images or documents for tasks like organization, classification or content recommendation.\n- **Social Network Analysis**: Detects communities or trends in user interactions on social media platforms.\n\n## Advantages\n\n- **No need for labeled data**: Works with raw, unlabeled data hence saving time and effort on data annotation.\n- **Discovers hidden patterns**: Finds natural groupings and structures that might be missed by humans.\n- **Handles complex and large datasets**: Effective for high-dimensional or vast amounts of data.\n- **Useful for anomaly detection**: Can identify outliers and unusual data points without prior examples.\n\n## Challenges\n\nHere are the key challenges of unsupervised learning:\n\n- **Noisy Data**: Outliers and noise can distort patterns and reduce the effectiveness of algorithms.\n- **Assumption Dependence**: Algorithms often rely on assumptions (e.g., cluster shapes) which may not match the actual data structure.\n- **Overfitting Risk**: Overfitting can occur when models capture noise instead of meaningful patterns in the data.\n- **Limited Guidance**: The absence of labels restricts the ability to guide the algorithm toward specific outcomes.\n- **Cluster Interpretability**: Results such as clusters may lack clear meaning or alignment with real-world categories.\n- **Sensitivity to Parameters**: Many algorithms require careful tuning of hyperparameters such as the number of clusters in k-means.\n- **Lack of Ground Truth**: Unsupervised learning lacks labeled data making it difficult to evaluate the accuracy of results."}
{"reference": "https://www.geeksforgeeks.org/websites-apps/software-and-tools-a-to-z-list/", "content": "# Software and Tools Directory\n\n**Last Updated:** 05 Sep, 2025\n\nIf you know the right software, then you can easily accomplish a specific task. So, to help you out, we have come up with a list of software and tools that help you boost your productivity and streamline your workflow.\n\n- The right software saves time by automating repetitive tasks.\n- Reduce errors in calculation in data handling and processes.\n- Help you manage a large amount of data.\n\n## AI Tools Directory\n\nAI continues to transform itself and after ChatGPT the race of AI tools or agents are significantly growing. In recent days there are lots of AI tools introduced that help you in writing and content generation, code generation, automation and image generation. Find the right AI tools to streamline your workflow and stay ahead of the curve.\n\n- [ChatGPT](https://www.geeksforgeeks.org/blogs/what-is-chatgpt/)\n- [Google Gemini](https://www.geeksforgeeks.org/blogs/what-is-google-gemini-ai/)\n- [GitHub Copilot](https://www.geeksforgeeks.org/git/github-copilot/)\n- [Google Colab](https://www.geeksforgeeks.org/data-science/getting-started-with-google-colab/)\n- [Google Firebase Studio AI](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-google-firebase-studio-ai/)\n- [WARP](https://www.geeksforgeeks.org/data-science/introduction-to-warp/)\n- [Replit](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-replit/)\n- [Bolt AI](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-bolt-ai/)\n- [ElevenLabs](https://www.geeksforgeeks.org/websites-apps/text-to-speech-with-elevenlabs-a-simple-guide-for-everyone/)\n\n> **Explore:** [AI Tools Directory - Complete Latest List](https://www.geeksforgeeks.org/websites-apps/ai-tools-directory/)\n\n## Microsoft Office Suite\n\nMicrosoft Office Suite is a complete collection of office products that are developed by Microsoft. Under this suite tools come like MS Excel, MS Word, MS PowerPoint, Outlook and more.\n\n- [Microsoft Word Tutorial](https://www.geeksforgeeks.org/websites-apps/ms-word-tutorial/)\n- [Microsoft Excel Tutorial](https://www.geeksforgeeks.org/excel/excel-tutorial/)\n- [Microsoft Powerpoint Tutorial](https://www.geeksforgeeks.org/websites-apps/ms-powerpoint-tutorial-basic-to-advanced/)\n- [Microsoft Outlook Tutorial](https://www.geeksforgeeks.org/websites-apps/microsoft-outlook-tutorial/)\n\n## Operating Systems & Utilities\n\nOperating systems keep computers running smoothly, while utilities are handy tools that boost speed, security, and reliability. From fighting viruses to cleaning up files and managing backups, these software superheroes make everyday tech easy and efficient.\n\n- [Windows 11 Tutorial](https://www.geeksforgeeks.org/techtips/windows-11-tutorial/)\n- [Windows 10 Tutorial](https://www.geeksforgeeks.org/operating-systems/windows-10-tutorial/)\n- [Command Prompt Guide](https://www.geeksforgeeks.org/techtips/windows-command-prompt-tutorial/)\n- [PowerShell Tutorial](https://www.geeksforgeeks.org/techtips/windows-powershell-tutorial/)\n\n## Business Tool Directory\n\nEvery business needs good tools to automate their workflow and increase work productivity. The below business tools directory offers an expertly curated selection of software. From marketing automation to HR and accounting solutions, these tools empower startups, SMEs, and enterprises to drive smarter, data-informed growth.\n\n- [Marketing Tools Directory](https://www.geeksforgeeks.org/websites-apps/marketing-tools-directory-a-to-z-list/)\n- [Accounting Software Directory](https://www.geeksforgeeks.org/websites-apps/accounting-software-directory-a-to-z-list/)\n- [HR Management Tools](https://www.geeksforgeeks.org/websites-apps/best-hr-tools-software-for-workforce-management/)\n\n## Design & Development\n\nTurn ideas into reality with **cutting-edge design and development tools**! Learn Figma for collaborative UI/UX prototyping, Adobe Creative Cloud for graphic design, and coding platforms for web development.\n\n- [Figma Tutorial](https://www.geeksforgeeks.org/websites-apps/figma-tutorial/)\n- [Photoshop](https://www.geeksforgeeks.org/computer-graphics/introduction-to-photoshop/)\n- [Google 2.5 Flash Image](https://www.geeksforgeeks.org/websites-apps/nano-banana/)\n\n### Explore\n\n#### AI for Coding\n\n- [WARP (5 min read)](https://www.geeksforgeeks.org/data-science/introduction-to-warp/)\n- [Google Firebase Studio AI (5 min read)](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-google-firebase-studio-ai/)\n- [Replit (3 min read)](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-replit/)\n- [Bolt AI (5 min read)](https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-bolt-ai/)\n\n#### AI for Image and Video\n\n- [Adobe Firefly: Best Practices, Use Cases, Features (5 min read)](https://www.geeksforgeeks.org/websites-apps/adobe-firefly-best-practices-use-cases-features/)\n- [Sora: Best Practices, Use Cases, Features (5 min read)](https://www.geeksforgeeks.org/websites-apps/sora-best-practices-use-cases-features/)\n- [Google AI Studio (Voe2): Best Practices, Use Cases, Features (5 min read)](https://www.geeksforgeeks.org/websites-apps/google-ai-studio-voe2-best-practices-use-cases-features/)\n- [DeepAI: Use Cases, Features, Best Practices (4 min read)](https://www.geeksforgeeks.org/websites-apps/deepai/)\n- [How to Use DALL.E 3 to Create AI Images With ChatGPT (2 min read)](https://www.geeksforgeeks.org/techtips/how-to-use-dall-e-3-to-create-ai-images-with-chatgpt/)\n\n#### Research Using AI\n\n- [Advanced Use Cases of Notebook LM (6 min read)](https://www.geeksforgeeks.org/websites-apps/advanced-use-cases-of-notebook-lm/)\n- [Deep Research in Perplexity (5 min read)](https://www.geeksforgeeks.org/websites-apps/deep-research-in-perplexity/)\n- [Deep Research in ChatGPT 4.o (5 min read)](https://www.geeksforgeeks.org/websites-apps/what-is-deep-research-in-chatgpt-4-0/)\n- [Deep Research in Gemini 2.5 (7 min read)](https://www.geeksforgeeks.org/websites-apps/deep-research-in-gemini-2-5/)\n\n#### MS Office Suite\n\n- [MS Word Tutorial - Learn How to Use Microsoft Word (7 min read)](https://www.geeksforgeeks.org/websites-apps/ms-word-tutorial/)\n- [MS Excel Tutorial - Learn Excel Online Free (11 min read)](https://www.geeksforgeeks.org/excel/excel-tutorial/)\n- [MS PowerPoint Tutorial: Basic to Advanced (5 min read)](https://www.geeksforgeeks.org/websites-apps/ms-powerpoint-tutorial-basic-to-advanced/)\n\n#### Operating Systems & Tools\n\n- [Interesting Facts about WINDOWS (3 min read)](https://www.geeksforgeeks.org/operating-systems/interesting-facts-about-windows/)\n- [Introduction to Operating System (4 min read)](https://www.geeksforgeeks.org/operating-systems/introduction-of-operating-system-set-1/)\n- [Windows 11 vs. Windows 10 - What's the Difference (8 min read)](https://www.geeksforgeeks.org/operating-systems/windows-11-vs-windows-10-difference/)\n- [How to Optimize Windows PC (7 min read)](https://www.geeksforgeeks.org/techtips/how-to-optimize-windows-pc/)\n- [Windows Keyboard Shortcuts A to Z with PDF (All Windows Versions) (11 min read)](https://www.geeksforgeeks.org/blogs/windows-keyboard-shortcuts-a-to-z-pdf/)\n\n#### Management Tools\n\n- [10 Best Business Software in 2024 (11 min read)](https://www.geeksforgeeks.org/blogs/list-of-10-best-small-business-management-software-2024/)\n- [List of 15 Enterprise Risk Software (15 min read)](https://www.geeksforgeeks.org/blogs/list-of-15-enterprise-risk-software/)\n- [20 Best Employee Evaluation Software Of 2024 (9 min read)](https://www.geeksforgeeks.org/hr/20-best-employee-evaluation-software-of-2024/)\n- [5 Best Human Resource Management System (HRMS) for small and medium-sized Organizations (6 min read)](https://www.geeksforgeeks.org/hr/5-best-human-resource-management-system-hrms-for-small-and-medium-sized-organizations/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/ml-eclat-algorithm/", "content": "# ECLAT Algorithm - ML\n\nECLAT stands for Equivalence Class Clustering and bottom-up Lattice Traversal. It is a data mining algorithm used to find frequent itemsets in a dataset. These frequent itemsets are then used to create association rules which helps to identify patterns in data. It is an improved alternative to the Apriori algorithm by providing better scalability and computational efficiency.\n\n## What Makes ECLAT Different from Apriori?\n\nThe main difference between the two lies in how they store and search through the data:\n\n- [Apriori](https://www.geeksforgeeks.org/machine-learning/apriori-algorithm/) uses a horizontal format where each transaction is a row and it follows a [breadth-first search](https://www.geeksforgeeks.org/dsa/breadth-first-search-or-bfs-for-a-graph/) (BFS) strategy. This means it scans the database multiple times to find frequent item combinations.\n- ECLAT on the other hand uses a vertical format where each item is linked to a list of transaction IDs (TIDs). It uses a [depth-first search](https://www.geeksforgeeks.org/dsa/depth-first-search-or-dfs-for-a-graph/) (DFS) strategy which requires fewer scans and makes it faster and more memory-efficient.\n\nThis vertical approach significantly reduces the number of database scans making ECLAT faster and more memory-efficient especially for large datasets.\n\n| Aspect              | Apriori                          | ECLAT                                      |\n|---------------------|----------------------------------|--------------------------------------------|\n| Data Format         | Horizontal (transactions as rows)| Vertical (items linked to transaction IDs) |\n| Search Strategy     | Breadth-First Search (BFS)       | Depth-First Search (DFS)                   |\n| Database Scans      | Multiple scans required          | Fewer scans needed                         |\n| Memory Efficiency   | Less memory efficient            | More memory-efficient                      |\n| Speed               | Slower, especially with large datasets | Faster due to vertical representation     |\n\n## How ECLAT Algorithm Works\n\nLet’s walk through an example to better understand how ECLAT algorithm works. Consider the following transaction dataset represented in a Boolean matrix:\n\n| Transaction ID | Bread | Butter | Milk | Coke | Jam |\n|----------------|-------|--------|------|------|-----|\n| T1             | 1     | 1      | 0    | 0    | 1   |\n| T2             | 0     | 1      | 0    | 1    | 0   |\n| T3             | 0     | 1      | 1    | 0    | 0   |\n| T4             | 1     | 1      | 0    | 1    | 0   |\n| T5             | 1     | 0      | 1    | 0    | 0   |\n| T6             | 0     | 1      | 1    | 0    | 0   |\n| T7             | 1     | 0      | 1    | 0    | 0   |\n| T8             | 1     | 1      | 1    | 0    | 1   |\n| T9             | 1     | 1      | 1    | 0    | 0   |\n\nThe core idea of the ECLAT algorithm is based on the interaction of datasets to calculate the support of itemsets, avoiding the generation of subsets that are not likely to exist in the dataset. Here’s a breakdown of the steps:\n\n### Step 1: Create the Tidset\n\nThe first step is to generate the tidset for each individual item. A tidset is simply a list of transaction IDs where the item appears. For example: k = 1, minimum support = 2\n\n| Item  | Tidset                  |\n|-------|-------------------------|\n| Bread | {T1, T4, T5, T7, T8, T9} |\n| Butter| {T1, T2, T3, T4, T6, T8, T9} |\n| Milk  | {T3, T5, T6, T7, T8, T9} |\n| Coke  | {T2, T4}                |\n| Jam   | {T1, T8}                |\n\n### Step 2: Calculate the Support of Itemsets by Intersecting Tidsets\n\nECLAT then proceeds by recursively combining the tidsets. The support of an itemset is determined by the intersection of tidsets. For example: k = 2\n\n| Item              | Tidset              |\n|-------------------|---------------------|\n| {Bread, Butter}   | {T1, T4, T8, T9}    |\n| {Bread, Milk}     | {T5, T7, T8, T9}    |\n| {Bread, Coke}     | {T4}                |\n| {Bread, Jam}      | {T1, T8}            |\n| {Butter, Milk}    | {T3, T6, T8, T9}    |\n| {Butter, Coke}    | {T2, T4}            |\n| {Butter, Jam}     | {T1, T8}            |\n| {Milk, Jam}       | {T8}                |\n\n### Step 3: Recursive Call and Generation of Larger Itemsets\n\nThe algorithm continues recursively by combining pairs of itemsets (k-itemsets) checking the support by intersecting the tidsets. The recursion continues until no further frequent itemsets can be generated. Now k = 3\n\n| Item                   | Tidset     |\n|------------------------|------------|\n| {Bread, Butter, Milk}  | {T8, T9}   |\n| {Bread, Butter, Jam}   | {T1, T8}   |\n\n### Step 4: Stop When No More Frequent Itemsets Can Be Found\n\nThe algorithm stops once no more itemset combinations meet the minimum support threshold. k = 4\n\n| Item                        | Tidset |\n|-----------------------------|--------|\n| {Bread, Butter, Milk, Jam}  | {T8}   |\n\nWe stop at k = 4 because there are no more item-tidset pairs to combine. Since minimum support = 2, we conclude the following rules from the given dataset:\n\n| Items Bought     | Recommended Products |\n|------------------|----------------------|\n| Bread            | Butter               |\n| Bread            | Milk                 |\n| Bread            | Jam                  |\n| Butter           | Milk                 |\n| Butter           | Coke                 |\n| Butter           | Jam                  |\n| Bread and Butter | Milk                 |\n| Bread and Butter | Jam                  |\n\n## Implementation\n\nLet's see how ECLAT Algorithm works with the help of an example,\n\n### Step 1: Import Packages and Dataset\n\nWe will import necessary libraires and provide the dataset.\n\n```python\nfrom collections import defaultdict\nfrom itertools import combinations\n\ntransactions = {\n    \"T1\": [\"Bread\", \"Butter\", \"Jam\"],\n    \"T2\": [\"Butter\", \"Coke\"],\n    \"T3\": [\"Butter\", \"Milk\"],\n    \"T4\": [\"Bread\", \"Butter\", \"Coke\"],\n    \"T5\": [\"Bread\", \"Milk\"],\n    \"T6\": [\"Butter\", \"Milk\"],\n    \"T7\": [\"Bread\", \"Milk\"],\n    \"T8\": [\"Bread\", \"Butter\", \"Milk\", \"Jam\"],\n    \"T9\": [\"Bread\", \"Butter\", \"Milk\"]\n}\nmin_support = 2\n```\n\n### Step 2: Generate Tidsets (Vertical representation)\n\n- **Purpose**: create a mapping item -> set_of_tids (the vertical format ECLAT uses).\n- **Benefit**: intersections of these tidsets are quick to compute and give support counts.\n\n```python\ndef generate_tidsets(transactions):\n    item_tidset = defaultdict(set)\n    for tid, items in transactions.items():\n        for item in items:\n            item_tidset[item].add(tid)\n    return item_tidset\n\nitem_tidset = generate_tidsets(transactions)\n\nfor item, tidset in item_tidset.items():\n    print(item, \":\", sorted(tidset))\n```\n\n**Output**:\n\n![generating-Tidsets](https://media.geeksforgeeks.org/wp-content/uploads/20251003120305494152/generating-Tidsets.webp)\n\n*Tidsets*\n\n### Step 3: Prepare a sorted list of items\n\n- **Purpose**: convert the item_tidset dict into a sorted list of (item, tidset) pairs.\n- **Tip**: sorting by tidset size (ascending) often helps pruning and makes intersections cheaper earlier.\n\n```python\nitems = sorted(item_tidset.items(), key=lambda x: len(x[1]))\n```\n\n### Step 4: Implement recursive ECLAT\n\nRecursively build larger itemsets by intersecting tidsets (depth-first). How it works:\n\n- Pop one (item, tidset) from the list.\n- If len(tidset) >= min_support, record the itemset (prefix + item).\n- Build a suffix by intersecting this tidset with each remaining item's tidset; keep intersections that meet min_support.\n- Recurse on the suffix to extend the current itemset.\n\n**Data structure**: we use frequent_itemsets dict with frozenset(itemset) -> support_count.\n\n```python\ndef eclat(prefix, items, min_support, frequent_itemsets):\n    \"\"\"\n    prefix: list of items forming the current prefix\n    items: list of tuples (item, tidset) to consider for extension\n    min_support: absolute minimum support (count)\n    frequent_itemsets: dict to collect results {frozenset(itemset): support_count}\n    \"\"\"\n    while items:\n        item, tidset = items.pop()\n        support = len(tidset)\n        if support >= min_support:\n            new_itemset = prefix + [item]\n            frequent_itemsets[frozenset(new_itemset)] = support\n            suffix = []\n            for other_item, other_tidset in items:\n                intersection = tidset & other_tidset\n                if len(intersection) >= min_support:\n                    suffix.append((other_item, intersection))\n            suffix = sorted(suffix, key=lambda x: len(x[1]))\n            eclat(new_itemset, suffix, min_support, frequent_itemsets)\n```\n\n### Step 5: Run ECLAT and collect frequent itemsets\n\nCall the recursive function, then inspect the found frequent itemsets (with support counts).\n\n```python\nitem_tidset = generate_tidsets(transactions)\nitems = sorted(item_tidset.items(), key=lambda x: len(x[1]))\nfrequent_itemsets = {}\neclat([], items, min_support, frequent_itemsets)\n\nprint(\"Frequent itemsets (as list) -> support count\")\nfor itemset, support in sorted(frequent_itemsets.items(), key=lambda x: (-len(x[0]), -x[1], sorted(list(x[0])))):\n    print(list(itemset), \"=>\", support)\n```\n\n**Output**:\n\n![eclat_result](https://media.geeksforgeeks.org/wp-content/uploads/20251003120056438060/eclat_result.webp)\n\n*Result*\n\n## Applications\n\n- **Market Basket Analysis**: Identifying frequently purchased items together.\n- **Recommendation Systems**: Suggesting products based on past purchase patterns.\n- **Medical Diagnosis**: Finding co-occurring symptoms in medical records.\n- **Web Usage Mining**: Analyzing web logs to understand user behavior.\n- **Fraud Detection**: Discovering frequent patterns in fraudulent activities.\n\n## Advantages\n\n- **Efficient in Dense Datasets**: Performs better than Apriori in datasets with frequent co-occurrences.\n- **Memory Efficient**: Uses vertical representation, reducing redundant scans.\n- **Fast Itemset Intersection**: Computing itemset support via TID-set intersections is faster than scanning transactions repeatedly.\n- **Better Scalability**: Can handle larger datasets due to its depth-first search mechanism.\n\n## Disadvantages\n\n- **High Memory Requirement**: Large TID sets can consume significant memory.\n- **Not Suitable for Sparse Data**: Works better in dense datasets, but performance drops for sparse datasets where intersections result in small itemsets.\n- **Sensitive to Large Transactions**: If a transaction has too many items its corresponding TID-set intersections can be expensive."}
{"reference": "https://www.geeksforgeeks.org/advertise-with-us/", "content": "# Advertise with Us\n\nWe are GeeksforGeeks, the largest and most popular tech community among developers.\n\nTap into the monthly traffic of 200 Million+ niche audience of tech students and working professionals.\n\nAchieve higher conversions with better targeting.\n\nDiscover audience globally.\n\nCreate impactful brand partnerships with us, through ads, content integration, hackathons, bootcamps, coding contests, newsletters, social media campaigns and more.\n\n## Get in Touch\n\nExplore Solutions\n\n![Desktop](https://media.geeksforgeeks.org/auth-dashboard-uploads/GroupAds_desk.png)\n\n## Why Us\n\nGet the results that matter.\n\n### Build brand awareness\nwith 35 Million+ registered users\n\n### Higher Conversion\nAchieve higher conversion with 90% Ads Viewability\n\n### Long term results\nAchieve long term results with 90% Organic Traffic\n\n### Generate Leads\nGenerate lead with 20 million+ Logged in users\n\n## About Us\n\nWe spark action with our audience.\n\nExpertise that everybody counts on.\n\nGeeksforGeeks has made a difference in the lives of many students by providing free knowledge on how to obtain a dream career and by assisting authors all over the world to earn by generating and sharing content, which is why the Geeks community of users are so engaged and devoted.\n\n## Stay Ahead with Our Recurring Events\n\nDiscover Ongoing Opportunities to Elevate Your Business Growth\n\n- **POTD**: Recurring brand exposure to 60,000+ daily unique users\n- **Job-A-Thon**: 1,00,000+ registrations\n- **Courses/Bootcamp**: 47,000+ registrations\n- **Hackathon**: 54,000+ registrations\n- **Content Integration**: Millions of organic views\n\n## Successful Campaigns\n\nGeeksforGeeks has run successful campaigns for: Google, AMD, Amazon, Hostinger, Hirist, Kamatera, Times Education Group, Titan, Surfshark, Updf, Airdroid & other 135+ tech and non-tech brands.\n\n## View Our Presence\n\n- 216k followers\n- 355k followers\n- 1.9M followers\n- 66k followers\n- 700k followers\n\n## User Statistics\n\n- Tier 1 Cities: 45\n- Tier 2 Cities: 35\n- Tier 3 Cities: 20\n- Male Population: 70\n- Female Population: 30\n- 18-35 years Geeks: 70\n\n## Wide array of advertisements\n\nSupport for Multiple desktop banner & operating system based on your choice\n\n- 300X600\n- 728X90\n- 300X250\n- 160X600\n- 336X280\n- 728X250\n\nSupport for Multiple mobile banner & operating system based on your choice\n\n- 320X50\n- 336X280\n\n## Solutions to offer\n\n- Employer Branding\n- Product/ Tech Learning\n- Content Integration\n- Tech Events\n- Social Media Campaigns\n- Podcast\n- Campus Connect\n- Hiring Challenge\n- Hackathon\n- Courses/ Bootcamp\n- Email Marketing\n- Youtube Webinars & Workshops\n\n## Diverse Audience Profiles\n\n- Technology/Gadget enthusiastic\n- Media & Entertainment\n- Frequently Dining Out\n- Business Travelers\n- Shoppers\n- Movie Lovers\n\n## Who we serve\n\nSuccessfully served 2000+ tech and non-tech brands, including:\n\n- Google\n- Amazon\n- Microsoft\n- AMD\n- Oracle\n- Adobe\n- Indeed\n- Wix\n- RazorPay\n- Hostinger\n- Chroma\n- Zoho\n\n## Contact us\n\nWe provide customizable solutions to accommodate your advertising and employer branding preferences.\n\nGet a call back.\n\n**Corporate & Communications Address:**  \nA-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)\n\n**Registered Address:**  \nK 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305"}
{"reference": "https://www.geeksforgeeks.org/courses/category/machine-learning-data-science", "content": "### We couldn't find what you're looking for"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/self-supervised-learning-ssl/", "content": "# Self-Supervised Learning (SSL)\n\nSelf-Supervised Learning (SSL) is a type of machine learning where a model is trained using data that does not have any labels or answers provided. Instead of needing people to label the data, the model finds patterns and creates its own labels from the data automatically.\n\n![Self-Supervised Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250902154828906031/SSL-.webp)\n\nThis allows the model to learn useful information by teaching itself from the data. SSL is especially useful when there is a lot of data but only a small part of it is labelled or labelling the data would take a lot of time and effort.\n\nLet's see some key characteristics of SSL:\n\n- **Uses Unlabeled Data**: The model learns directly from raw data without needing humans to label it.\n- **Dynamic Label Generation**: The model generates training labels by understanding the data structure itself.\n- **Mix of Learning Methods**: SSL is a middle ground between supervised learning (with labels) and unsupervised learning (without labels).\n- **Learns Useful Features**: By learning from the data itself, the model can understand important patterns and details which helps it perform better on new data.\n- **Wide Applications**: It is widely used in areas like image recognition, natural language processing and speech recognition, where labeled data can be expensive or limited.\n- **Helps Transfer Learning**: SSL makes it easier to adapt models to new tasks by using the knowledge gained from pre-training on unlabeled data.\n\n## Training a Self-Supervised Learning Model in ML\n\nLet's see how the training a Self-Supervised Learning Model is done,\n\n### Step 1: Import Libraries and Load Dataset\n\nWe will import the required libraries such as [TensorFlow](https://www.geeksforgeeks.org/python/introduction-to-tensorflow/), [Keras](https://www.geeksforgeeks.org/deep-learning/what-is-keras/), [numpy](https://www.geeksforgeeks.org/numpy/python-numpy/), [matplotlib.pyplot](https://www.geeksforgeeks.org/python/pyplot-in-matplotlib/). Also we will load the MNIST dataset for our model.\n\n- Loads raw MNIST digit images without labels for the SSL pre-training task.\n- Normalizes pixel values to be between 0 and 1.\n- Adds a channel dimension to images to fit CNN input shape.\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport numpy as np\n\n(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.expand_dims(x_train, -1)\nx_test = np.expand_dims(x_test, -1)\n\nx_train_small = x_train[:1000]\nx_test_small = x_test[:200]\n```\n\n### Step 2: Prepare Rotation Task Dataset\n\nWe will,\n\n- Defines four rotation angles (0°, 90°, 180°, 270°) as prediction targets.\n- Rotates each image by these angles and records the rotation label.\n- Creates a new dataset where the task is to predict the rotation angle, forming a self-supervised task\n\n```python\nangles = [0, 90, 180, 270]\n\ndef rotate_images(images, angles):\n    rotated_images = []\n    labels = []\n    for img in images:\n        for i, angle in enumerate(angles):\n            rotated = tf.image.rot90(img, k=angle // 90)\n            rotated_images.append(rotated.numpy())\n            labels.append(i)\n    return np.array(rotated_images), np.array(labels)\n\nx_train_rot, y_train_rot = rotate_images(x_train_small, angles)\nx_test_rot, y_test_rot = rotate_images(x_test_small, angles)\n```\n\n### Step 3: Define and Compile CNN Model for Rotation Classification\n\nWe will,\n\n- Defines a simple CNN with convolutional and pooling layers to learn image features.\n- The last layer outputs probabilities over 4 classes (rotation angles).\n- Compiles the model with [Adam optimizer](https://www.geeksforgeeks.org/deep-learning/adam-optimizer/) and [sparse categorical crossentropy loss](https://www.geeksforgeeks.org/machine-learning/what-is-sparse-categorical-crossentropy/) for classification.\n\n```python\nmodel = models.Sequential([\n    layers.Input(shape=(28, 28, 1)),\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(len(angles), activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n```\n\n### Step 4: Train the Model on Rotated Images\n\n- Trains the model on the self-supervised rotation prediction task.\n- Uses the generated rotation labels as targets.\n- Validates on a similar rotated test set to monitor performance.\n\n```python\nmodel.fit(x_train_rot, y_train_rot, epochs=5, batch_size=64,\n          validation_data=(x_test_rot, y_test_rot))\n```\n\n**Output:**\n\n![Training](https://media.geeksforgeeks.org/wp-content/uploads/20250902144837821810/Screenshot-2025-09-02-144801.webp)\n\n### Step 5: Visualized Rotation Predicted Results\n\n- Uses the trained model to predict rotation angles on test images.\n- Randomly selects 5 rotated images to display.\n- Shows original image with true and predicted rotation angle to check model accuracy visually.\n\n```python\nimport matplotlib.pyplot as plt\n\npredictions = model.predict(x_test_rot)\n\nnum_examples = 5\nindices = np.random.choice(len(x_test_rot), num_examples, replace=False)\n\nfor i, idx in enumerate(indices):\n    img = x_test_rot[idx].squeeze()\n    true_label = y_test_rot[idx]\n    pred_label = np.argmax(predictions[idx])\n\n    plt.subplot(1, num_examples, i + 1)\n    plt.imshow(img, cmap='gray')\n    plt.title(f\"True: {angles[true_label]}°\\nPred: {angles[pred_label]}°\")\n    plt.axis('off')\n\nplt.show()\n```\n\n**Output:**\n\n![Result](https://media.geeksforgeeks.org/wp-content/uploads/20250902144946947855/SSL.webp)\n\n### Step 6: Load Labeled MNIST Data for Fine-Tuning\n\nNow we will,\n\n- Loads fully labeled MNIST dataset for downstream digit classification task.\n- Preprocesses images and selects smaller subsets for quick fine-tuning.\n\n```python\n(x_train_labeled, y_train_labeled), (x_test_labeled,\n                                     y_test_labeled) = tf.keras.datasets.mnist.load_data()\n\nx_train_labeled = x_train_labeled.astype('float32') / 255.\nx_test_labeled = x_test_labeled.astype('float32') / 255.\nx_train_labeled = np.expand_dims(x_train_labeled, -1)\nx_test_labeled = np.expand_dims(x_test_labeled, -1)\n\nx_train_fine = x_train_labeled[:1000]\ny_train_fine = y_train_labeled[:1000]\nx_test_fine = x_test_labeled[:200]\ny_test_fine = y_test_labeled[:200]\n```\n\n### Step 7: Modify and Fine-Tune Model on Labeled Digital Data\n\nHere,\n\n- Freezes convolutional layers to keep learned features unchanged.\n- Replaces output layer to predict 10 digit classes instead of rotations.\n- Compiles and trains the model on labeled data to adapt it for digit recognition.\n\n```python\nfor layer in model.layers[:-2]:\n    layer.trainable = False\n\nmodel.pop()\nmodel.add(layers.Dense(10, activation='softmax'))\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train_fine, y_train_fine, epochs=5, batch_size=64,\n          validation_data=(x_test_fine, y_test_fine))\n```\n\n**Output:**\n\n![Training](https://media.geeksforgeeks.org/wp-content/uploads/20250902144739637718/Screenshot-2025-09-02-144708.webp)\n\n### Step 8: Visualize Fine-Tuned Predictions\n\nModel will,\n\n- Predicts digit classes on labeled test images after fine-tuning.\n- Randomly selects 5 test images to display.\n- Shows images with ground truth and predicted digit labels for visual performance check.\n\n```python\npredictions = model.predict(x_test_fine)\n\nindices = np.random.choice(len(x_test_fine), 5, replace=False)\n\nfor i, idx in enumerate(indices):\n    img = x_test_fine[idx].squeeze()\n    true_label = y_test_fine[idx]\n    pred_label = np.argmax(predictions[idx])\n\n    plt.subplot(1, 5, i + 1)\n    plt.imshow(img, cmap='gray')\n    plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n    plt.axis('off')\n\nplt.show()\n```\n\n**Output:**\n\n![Fine-Tuned Result](https://media.geeksforgeeks.org/wp-content/uploads/20250902145011711542/fine-tuned.webp)\n\n## Applications of SSL\n\n- **Computer Vision**: Improves tasks like image and video recognition, object detection and medical image analysis by learning from unlabeled images to create strong visual representations.\n- **Natural Language Processing (NLP)**: Enhances language models (e.g., BERT, GPT) by learning context and semantics from large unlabeled text, boosting tasks like translation, sentiment analysis and text classification.\n- **Speech Recognition**: Helps transcribe and understand spoken language by learning from large volumes of unlabeled audio data.\n- **Healthcare**: Assists in medical image analysis and diagnosis where labeled medical data is scarce due to expert annotation costs.\n- **Autonomous Systems and Robotics**: Enables robots and self-driving cars to learn from raw sensor and video data for navigation, perception and decision-making under varied conditions.\n\n## Advantages of Self-Supervised Learning\n\n- **Less Dependence on Labeled Data**: Learns useful features from large amounts of unlabeled data, reducing the cost and time of manual labeling.\n- **Better Generalization**: Models learn from the data's inherent structure, helping them perform well on new, unseen data.\n- **Supports Transfer Learning**: Pre-trained SSL models can be adapted easily to related tasks, speeding up training and improving accuracy.\n- **Scalable**: Can handle very large datasets without the need for expensive annotations, making it ideal for big data scenarios.\n\n## Limitations of Self-Supervised Learning\n\n- **Quality of Supervision Signal**: The automatically generated labels (pseudo-labels) can be noisy or incomplete, leading to lower accuracy compared to supervised learning.\n- **Task Restrictions**: Less effective for highly complex or unstructured data where meaningful pretext tasks are difficult to design.\n- **Training Complexity**: SSL methods like contrastive learning require careful design, tuning and more computational resources.\n- **High Computational Cost**: Training SSL models often demands significant computation power and time, especially on large datasets."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/dimensionality-reduction/", "content": "# Introduction to Dimensionality Reduction\n\nWhen working with machine learning models, datasets with too many features can cause issues like slow computation and overfitting. Dimensionality reduction helps to reduce the number of features while retaining key information. It converts high-dimensional data into a lower-dimensional space while preserving important details.\n\nFor example, when you are building a model to predict house prices with features like bedrooms, square footage and location. If you add too many features such as room condition or flooring type, the dataset becomes large and complex.\n\n## How Dimensionality Reduction Works?\n\nLets understand how dimensionality Reduction is used with the help of example. Imagine a dataset where each data point exists in a 3D space defined by axes X, Y and Z. If most of the data variance occurs along X and Y then the Z-dimension may contribute very little to understanding the structure of the data.\n\n![Dimensionality Reduction](https://media.geeksforgeeks.org/wp-content/uploads/20250912173457828130/dimension.webp)\n\n- **Before Reduction** we can see that data exist in 3D (X,Y,Z). It has high redundancy and Z contributes little meaningful information\n- On the right after reducing the dimensionality the data is represented in lower-dimensional spaces. The top plot (X-Y) maintains the meaningful structure while the bottom plot (Z-Y) shows that the Z-dimension contributed little useful information.\n\nThis process makes data analysis more efficient hence improving computation speed and visualization while minimizing redundancy\n\n## Dimensionality Reduction Techniques\n\nDimensionality reduction techniques can be broadly divided into two categories:\n\n### 1. Feature Selection\n\n[Feature selection](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/)chooses the most relevant features from the dataset without altering them. It helps remove redundant or irrelevant features, improving model efficiency. Some common methods are:\n\n- [Filter methods](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/) rank the features based on their relevance to the target variable.\n- [Wrapper methods](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/) use the model performance as the criteria for selecting features.\n- [Embedded methods](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/) combine feature selection with the model training process.\n\n### 2. Feature Extraction\n\n[Feature extraction](https://www.geeksforgeeks.org/machine-learning/what-is-feature-extraction/) involves creating new features by combining or transforming the original features. These new features retain most of the dataset's important information in fewer dimensions. Common feature extraction methods are:\n\n1. **[Principal Component Analysis (PCA):](https://www.geeksforgeeks.org/data-analysis/principal-component-analysis-pca/)** Converts correlated variables into uncorrelated principal components hence reducing dimensionality while maintaining as much variance as possible enabling more efficient analysis.\n2. **[Missing Value Ratio:](https://www.geeksforgeeks.org/machine-learning/ml-handling-missing-values/)** Variables with missing data beyond a set threshold are removed, improving dataset reliability.\n3. **[Backward Feature Elimination:](https://www.geeksforgeeks.org/machine-learning/ml-multiple-linear-regression-backward-elimination-technique/)** Starts with all features and removes the least significant ones in each iteration. The process continues until only the most impactful features remain, optimizing model performance.\n4. **[Forward Feature Selection:](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/)** It begins with one feature, adds others incrementally and keeps those improving model performance.\n5. **[Random Forest](https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/):** Random forest uses [decision trees](https://www.geeksforgeeks.org/machine-learning/decision-tree/) to evaluate feature importance, automatically selecting the most relevant features without the need for manual coding, enhancing model accuracy.\n6. **[Factor Analysis:](https://www.geeksforgeeks.org/machine-learning/introduction-to-factor-analytics/)** Groups variables by correlation and keeps the most relevant ones for further analysis.\n7. **[Independent Component Analysis (ICA):](https://www.geeksforgeeks.org/machine-learning/ml-independent-component-analysis/)** Identifies statistically independent components, ideal for applications like 'blind source separation' where traditional correlation-based methods fall short.\n\n## Real World Use Case\n\nDimensionality reduction plays a important role in many real-world applications such as text categorization, image retrieval, gene expression analysis and more. Here are a few examples:\n\n1. **Text Categorization:** With vast amounts of online data dimensionality reduction helps classify text documents into predefined categories by reducing the feature space like word or phrase features while maintaining accuracy.\n2. **Image Retrieval**: As image data grows indexing based on visual content like color, texture, shape rather than just text descriptions has become essential. This allows for better retrieval of images from large databases.\n3. **Gene Expression Analysis**: Dimensionality reduction accelerates gene expression analysis help to classify samples like leukemia by identifying key features, improve both speed and accuracy.\n4. **Intrusion Detection**: In cybersecurity dimensionality reduction helps analyze user activity patterns to detect suspicious behaviors and intrusions by identifying optimal features for network monitoring.\n\n## Advantages\n\nAs seen earlier high dimensionality makes models inefficient. Let's now summarize the key advantages of reducing dimensionality.\n\n- **Faster Computation**: With fewer features machine learning algorithms can process data more quickly. This results in faster model training and testing which is particularly useful when working with large datasets.\n- **Better Visualization**: As we saw in the earlier figure reducing dimensions makes it easier to visualize data and reveal hidden patterns.\n- **Prevent Overfitting**: With few features models are less likely to memorize the training data and overfit. This helps the model generalize better to new, unseen data improve its ability to make accurate predictions.\n\n## Disadvantages\n\n- **Data Loss & Reduced Accuracy:** Some important information may be lost during dimensionality reduction and affect model performance.\n- **Choosing the Right Components:** Deciding how many dimensions to keep is difficult as keeping too few may lose valuable information while keeping too many can led to overfitting."}
{"reference": "https://www.geeksforgeeks.org/computer-vision/computer-vision-projects/", "content": "# 40+ Top Computer Vision Projects [2025 Updated]\n\n**Computer Vision** is a branch of **Artificial Intelligence (AI)** that helps computers understand and interpret context of images and videos. It is used in domains like **security cameras, photo editing, self-driving cars and robots** to recognize objects and navigate real world using machine learning.\n\n![Top Computer Vision Projects](https://media.geeksforgeeks.org/wp-content/uploads/20230602175548/Top-Computer-Vision-Projects-(1).webp)\n\nThis article will explore some of the **best Computer Vision projects,** ranging from beginner-level to expert-level for individuals at different skill levels and experience.\n\n## Top Computer Vision Projects\n\n1. [Detect the RGB color from a webcam using Python – OpenCV](https://www.geeksforgeeks.org/python/detect-the-rgb-color-from-a-webcam-using-python-opencv/)\n2. [Face Detection using Python and OpenCV with a webcam](https://www.geeksforgeeks.org/python/face-detection-using-python-and-opencv-with-webcam/)\n3. [Face and Hand Landmarks Detection using Python – Mediapipe, OpenCV](https://www.geeksforgeeks.org/python/face-detection-using-python-and-opencv-with-webcam/)\n4. [Real-Time Edge Detection using OpenCV](https://www.geeksforgeeks.org/machine-learning/face-and-hand-landmarks-detection-using-python-mediapipe-opencv/)\n5. [Implement Canny Edge Detector in Python using OpenCV](https://www.geeksforgeeks.org/machine-learning/implement-canny-edge-detector-in-python-using-opencv/)\n6. [Gun Detection using Python-OpenCV](https://www.geeksforgeeks.org/machine-learning/gun-detection-using-python-opencv/)\n7. [Real-time object color detection using OpenCV](https://www.geeksforgeeks.org/machine-learning/gun-detection-using-python-opencv/)\n8. [Right and Left Hand Detection Using Python](https://www.geeksforgeeks.org/python/right-and-left-hand-detection-using-python/)\n9. [Age Detection Using Deep Learning in OpenCV](https://www.geeksforgeeks.org/computer-vision/age-detection-using-deep-learning-in-opencv/)\n10. [OpenCV – Drowsiness Detection](https://www.geeksforgeeks.org/python/python-opencv-drowsiness-detection/)\n11. [Build GUI Application Pencil Sketch from Photo in Python](https://www.geeksforgeeks.org/python/build-gui-application-pencil-sketch-from-photo-in-python/)\n12. [Measure Size of an Object Using Python OpenCV](https://www.geeksforgeeks.org/python/measure-size-of-an-object-using-python-opencv/)\n13. [Brightness Control With Hand Detection using OpenCV in Python](https://www.geeksforgeeks.org/python/brightness-control-with-hand-detection-using-opencv-in-python/)\n14. [Car driving using hand detection in Python](https://www.geeksforgeeks.org/python/car-driving-using-hand-detection-in-python/)\n15. [Contour Detection with Custom Seeds using Python – OpenCV](https://www.geeksforgeeks.org/python/contour-detection-with-custom-seeds-using-python-opencv/)\n16. [Find Co-ordinates of Contours using OpenCV | Python](https://www.geeksforgeeks.org/python/find-co-ordinates-of-contours-using-opencv-python/)\n17. [Live Webcam Drawing using OpenCV](https://www.geeksforgeeks.org/python/live-webcam-drawing-using-opencv/)\n18. [Black and white image colorization with OpenCV and Deep Learning](https://www.geeksforgeeks.org/computer-vision/black-and-white-image-colorization-with-opencv-and-deep-learning/)\n19. [Detect and Recognize Car License Plate from a video in real-time](https://www.geeksforgeeks.org/python/detect-and-recognize-car-license-plate-from-a-video-in-real-time/)\n20. [License Plate Recognition with OpenCV and Tesseract OCR](https://www.geeksforgeeks.org/machine-learning/license-plate-recognition-with-opencv-and-tesseract-ocr/)\n21. [Handwritten Digit Recognition using Neural Network](https://www.geeksforgeeks.org/python/detect-and-recognize-car-license-plate-from-a-video-in-real-time/)\n22. [Image Classification with Convolutional Neural Networks (CNNs) Using PyTorch](https://www.geeksforgeeks.org/deep-learning/building-a-convolutional-neural-network-using-pytorch/)\n23. [Human Pose Estimation with OpenCV](https://www.geeksforgeeks.org/machine-learning/python-opencv-pose-estimation/)\n24. [Age and Gender Detection Using OpenCV in Python](https://www.geeksforgeeks.org/machine-learning/age-and-gender-detection-using-opencv-in-python/)\n25. [Face detection using Cascade Classifier using OpenCV-Python](https://www.geeksforgeeks.org/python/face-detection-using-cascade-classifier-using-opencv-python/)\n26. [Face recognition using Artificial Intelligence](https://www.geeksforgeeks.org/machine-learning/face-recognition-using-artificial-intelligence/)\n27. [Face recognition using GUI](https://www.geeksforgeeks.org/machine-learning/python-face-recognition-using-gui/)\n28. [FaceMask Detection using TensorFlow in Python](https://www.geeksforgeeks.org/deep-learning/facemask-detection-using-tensorflow-in-python/)\n29. [Python OpenCV – Super-resolution with deep learning](https://www.geeksforgeeks.org/computer-vision/python-opencv-super-resolution-with-deep-learning/)\n30. [Real-Time Road Lane Detection](https://www.geeksforgeeks.org/machine-learning/opencv-real-time-road-lane-detection/)\n31. [CIFAR-10 Image Classification in TensorFlow](https://www.geeksforgeeks.org/deep-learning/cifar-10-image-classification-in-tensorflow/)\n32. [Dog Breed Classification Using Transfer Learning](https://www.geeksforgeeks.org/deep-learning/dog-breed-classification-using-transfer-learning/)\n33. [Flower Recognition Using Convolutional Neural Network](https://www.geeksforgeeks.org/deep-learning/flower-recognition-using-convolutional-neural-network/)\n34. [Emojify using Face Recognition with Machine Learning](https://www.geeksforgeeks.org/machine-learning/emojify-using-face-recognition-with-machine-learning/)\n35. [Cat & Dog Classification using Convolutional Neural Network in Python](https://www.geeksforgeeks.org/deep-learning/cat-dog-classification-using-convolutional-neural-network-in-python/)\n36. [Video Analysis with Convolutional LSTM Networks](https://www.geeksforgeeks.org/deep-learning/video-classification-with-a-3d-convolutional-neural-network/)\n37. [Deep Learning for Artistic Style Transfer](https://www.geeksforgeeks.org/deep-learning/neural-style-transfer-with-tensorflow/)\n38. [Lung Cancer Detection using Convolutional Neural Network (CNN) Tensorflow](https://www.geeksforgeeks.org/deep-learning/lung-cancer-detection-using-convolutional-neural-network-cnn/)\n39. [Lung Cancer Detection Using Transfer Learning](https://www.geeksforgeeks.org/deep-learning/lung-cancer-detection-using-transfer-learning/)\n40. [Pneumonia Detection Using Deep Learning](https://www.geeksforgeeks.org/deep-learning/pneumonia-detection-using-deep-learning/)\n41. [Detecting Covid-19 with Chest X-ray](https://www.geeksforgeeks.org/machine-learning/detecting-covid-19-with-chest-x-ray/)\n42. [Skin Cancer Detection Using TensorFlow](https://www.geeksforgeeks.org/deep-learning/skin-cancer-detection-using-tensorflow/)\n43. [Traffic Signs Recognition using CNN and Keras in Python](https://www.geeksforgeeks.org/deep-learning/traffic-signs-recognition-using-cnn-and-keras-in-python/)\n44. [Vehicle license plate recognition](https://www.geeksforgeeks.org/python/detect-and-recognize-car-license-plate-from-a-video-in-real-time//)\n45. [Image Segmentation with U-Net using Tensorflow](https://www.geeksforgeeks.org/deep-learning/image-segmentation-using-tensorflow/)\n46. [Facial expression detection using the Deepface module in Python](https://www.geeksforgeeks.org/python/facial-expression-detection-using-deepface-module-in-python/)\n47. [Image Classifier using Tensorflow Object Detection API](https://www.geeksforgeeks.org/machine-learning/ml-training-image-classifier-using-tensorflow-object-detection-api/)\n\n> **Must Read:**\n> - [100+ Machine Learning Projects with Source Code](https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/)\n> - [30+ Best Artificial Intelligence Project Ideas With Source code](https://www.geeksforgeeks.org/artificial-intelligence/best-artificial-intelligence-project-ideas/)\n> - [Top Generative AI Projects](https://www.geeksforgeeks.org/artificial-intelligence/generative-ai-projects/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/supervised-machine-learning/", "content": "# Supervised Machine Learning\n\nSupervised learning is a type of machine learning where a model learns from labelled data—meaning every input has a corresponding correct output. The model makes predictions and compares them with the true outputs, adjusting itself to reduce errors and improve accuracy over time. The goal is to make accurate predictions on new, unseen data. For example, a model trained on images of handwritten digits can recognise new digits it has never seen before.\n\n![Supervised Machine Learning](https://media.geeksforgeeks.org/wp-content/uploads/20241022160725494723/supervised-machine-learning.webp)\n\n## Types of Supervised Learning in Machine Learning\n\nSupervised learning can be applied to two main types of problems:\n\n- **[Classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/)**: Where the output is a categorical variable (e.g., spam vs. non-spam emails, yes vs. no).\n- **[Regression](https://www.geeksforgeeks.org/machine-learning/regression-in-machine-learning/)**: Where the output is a continuous variable (e.g., predicting house prices, stock prices).\n\n![Types of Supervised Learning](https://media.geeksforgeeks.org/wp-content/uploads/20250902175259468148/difff.webp)\n\nWhile training the model, data is usually split in the ratio of 80:20 i.e. 80% as training data and the rest as testing data. In training data, we feed input as well as output for 80% of data. The model learns from training data only. We use different supervised learning algorithms (which we will discuss in detail in the next section) to build our model.\n\n![Sample](https://media.geeksforgeeks.org/wp-content/uploads/20250902165132990858/supervised-data.webp)\n\nBoth the above figures have labelled data set as follows:\n\n**Figure A**: It is a dataset of a shopping store that is useful in predicting whether a customer will purchase a particular product under consideration or not based on his/her gender, age and salary.\n\n- **Input**: Gender, Age, Salary\n- **Output**: Purchased i.e. 0 or 1; 1 means yes the customer will purchase and 0 means that the customer won't purchase it.\n\n**Figure B**: It is a Meteorological dataset that serves the purpose of predicting wind speed based on different parameters.\n\n- **Input**: Dew Point, Temperature, Pressure, Relative Humidity, Wind Direction\n- **Output**: Wind Speed\n\n## Working of Supervised Machine Learning\n\nThe working of supervised machine learning follows these key steps:\n\n### 1. Collect Labeled Data\n\n- Gather a dataset where each input has a known correct output (label).\n- **Example**: Images of handwritten digits with their actual numbers as labels.\n\n### 2. Split the Dataset\n\n- Divide the data into training data (about 80%) and testing data (about 20%).\n- The model will learn from the training data and be evaluated on the testing data.\n\n### 3. Train the Model\n\n- Feed the training data (inputs and their labels) to a suitable supervised learning algorithm (like Decision Trees, SVM or Linear Regression).\n- The model tries to find patterns that map inputs to correct outputs.\n\n### 4. Validate and Test the Model\n\n- Evaluate the model using testing data it has never seen before.\n- The model predicts outputs and these predictions are compared with the actual labels to calculate accuracy or error.\n\n### 5. Deploy and Predict on New Data\n\n- Once the model performs well, it can be used to predict outputs for completely new, unseen data.\n\n## Supervised Machine Learning Algorithms\n\nSupervised learning can be further divided into several different types, each with its own unique characteristics and applications. Here are some of the most common types of supervised learning algorithms:\n\n- **[Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/)**: Linear regression is a type of supervised learning regression algorithm that is used to predict a continuous output value. It is one of the simplest and most widely used algorithms in supervised learning.\n- **[Logistic Regression](https://www.geeksforgeeks.org/machine-learning/understanding-logistic-regression/)**: Logistic regression is a type of supervised learning classification algorithm that is used to predict a binary output variable.\n- **[Decision Trees](https://www.geeksforgeeks.org/machine-learning/decision-tree/)**: Decision tree is a tree-like structure that is used to model decisions and their possible consequences. Each internal node in the tree represents a decision, while each leaf node represents a possible outcome.\n- **[Random Forests](https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/)**: Random forests again are made up of multiple decision trees that work together to make predictions. Each tree in the forest is trained on a different subset of the input features and data. The final prediction is made by aggregating the predictions of all the trees in the forest.\n- **[Support Vector Machine(SVM)](https://www.geeksforgeeks.org/machine-learning/support-vector-machine-algorithm/)**: The SVM algorithm creates a hyperplane to segregate n-dimensional space into classes and identify the correct category of new data points. The extreme cases that help create the hyperplane are called support vectors, hence the name Support Vector Machine.\n- **[K-Nearest Neighbors](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/)**: KNN works by finding k training examples closest to a given input and then predicts the class or value based on the majority class or average value of these neighbors. The performance of KNN can be influenced by the choice of k and the distance metric used to measure proximity.\n- **[Gradient Boosting](https://www.geeksforgeeks.org/machine-learning/ml-gradient-boosting/)**: Gradient Boosting combines weak learners, like decision trees, to create a strong model. It iteratively builds new models that correct errors made by previous ones.\n- **[Naive Bayes Algorithm](https://www.geeksforgeeks.org/machine-learning/naive-bayes-classifiers/)**: The Naive Bayes algorithm is a supervised machine learning algorithm based on applying Bayes' Theorem with the “naive” assumption that features are independent of each other given the class label.\n\nLet's summarize the supervised machine learning algorithms in table:\n\n| Algorithm          | Regression, Classification | Purpose                                      | Method                                                                 | Use Cases                                                                 |\n|--------------------|----------------------------|----------------------------------------------|------------------------------------------------------------------------|---------------------------------------------------------------------------|\n| Linear Regression  | Regression                 | Predict continuous output values             | Linear equation minimizing sum of squares of residuals                 | Predicting continuous values                                               |\n| Logistic Regression| Classification             | Predict binary output variable               | Logistic function transforming linear relationship                     | Binary classification tasks                                                |\n| Decision Trees     | Both                       | Model decisions and outcomes                 | Tree-like structure with decisions and outcomes                        | Classification and Regression tasks                                        |\n| Random Forests     | Both                       | Improve classification and regression accuracy| Combining multiple decision trees                                      | Reducing overfitting, improving prediction accuracy                        |\n| SVM                | Both                       | Create hyperplane for classification or predict continuous values | Maximizing margin between classes or predicting continuous values      | Classification and Regression tasks                                        |\n| KNN                | Both                       | Predict class or value based on k closest neighbors | Finding k closest neighbors and predicting based on majority or average | Classification and Regression tasks, sensitive to noisy data              |\n| Gradient Boosting  | Both                       | Combine weak learners to create strong model | Iteratively correcting errors with new models                          | Classification and Regression tasks to improve prediction accuracy        |\n| Naive Bayes        | Classification             | Predict class based on feature independence assumption | Bayes' theorem with feature independence assumption                    | Text classification, spam filtering, sentiment analysis, medical          |\n\nThese types of supervised learning in machine learning vary based on the problem we're trying to solve and the dataset we're working with. In classification problems, the task is to assign inputs to predefined classes, while regression problems involve predicting numerical outcomes.\n\n## Practical Examples of Supervised learning\n\nFew practical examples of supervised machine learning across various industries:\n\n- **Fraud Detection in Banking**: Utilizes supervised learning algorithms on historical transaction data, training models with labeled datasets of legitimate and fraudulent transactions to accurately predict fraud patterns.\n- **Parkinson Disease Prediction**: Parkinson’s disease is a progressive disorder that affects the nervous system and the parts of the body controlled by the nerves.\n- **Customer Churn Prediction**: Uses supervised learning techniques to analyze historical customer data, identifying features associated with churn rates to predict customer retention effectively.\n- **Cancer cell classification**: Implements supervised learning for cancer cells based on their features and identifying them if they are ‘malignant’ or ‘benign.\n- **Stock Price Prediction**: Applies supervised learning to predict a signal that indicates whether buying a particular stock will be helpful or not.\n\n## Advantages\n\nHere are some advantages of supervised learning listed below:\n\n- **Simplicity & clarity**: Easy to understand and implement since it learns from labeled examples.\n- **High accuracy**: When sufficient labeled data is available, models achieve strong predictive performance.\n- **Versatility**: Works for both classification like spam detection, disease prediction and regression like price forecasting.\n- **Generalization**: With enough diverse data and proper training, models can generalize well to unseen inputs.\n- **Wide application**: Used in speech recognition, medical diagnosis, sentiment analysis, fraud detection and more.\n\n## Disadvantages\n\n- **Requires labeled data**: Large amounts of labeled datasets are expensive and time-consuming to prepare.\n- **Bias from data**: If training data is biased or unbalanced, the model may learn and amplify those biases.\n- **Overfitting risk**: Model may memorize training data instead of learning general patterns, especially with small datasets.\n- **Limited adaptability**: Performance drops significantly when applied to data distributions very different from training data.\n- **Not scalable for some problems**: In tasks with millions of possible labels like natural language, supervised labeling becomes impractical."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/machine-learning-projects/", "content": "# 100+ Machine Learning Projects with Source Code [2025]\n\nThis article provides over 100 Machine Learning projects and ideas to provide hands-on experience for both beginners and professionals. Whether you're a student enhancing your resume or a professional advancing your career these projects offer practical insights into the world of [Machine Learning](https://www.geeksforgeeks.org/machine-learning/machine-learning/) and [Data Science](https://www.geeksforgeeks.org/data-science/data-science/).\n\n## Machine Learning Project for Beginners\n\nOnce you've learned the [basics of machine learning](https://www.geeksforgeeks.org/machine-learning/machine-learning/), it's important to try out some practical projects to strengthen your skills. This section includes fun and simple machine learning projects for beginners that you can quickly pick up to build a strong foundation.\n\n### 1. Text and Image Processing\n\nMachine Learning can understand text and images. From detecting spam emails to recognizing handwritten digits or even coloring old black-and-white photos, these projects show how ML works with everyday data.\n\n1. [Detecting Spam Emails](https://www.geeksforgeeks.org/nlp/detecting-spam-emails-using-tensorflow-in-python/)\n2. [SMS Spam Detection](https://www.geeksforgeeks.org/deep-learning/sms-spam-detection-using-tensorflow-in-python/)\n3. [Classification of Text Documents](https://www.geeksforgeeks.org/machine-learning/classification-of-text-documents-using-the-approach-of-naive-bayes/)\n4. [Classify Handwritten Digits](https://www.geeksforgeeks.org/python/python-classifying-handwritten-digits-with-tensorflow/)\n5. [OCR of Handwritten digits](https://www.geeksforgeeks.org/machine-learning/ocr-of-handwritten-digits-opencv/)\n6. [Recognizing HandWritten Digits](https://www.geeksforgeeks.org/machine-learning/recognizing-handwritten-digits-in-scikit-learn/)\n7. [Identifying handwritten digits using Logistic Regression](https://www.geeksforgeeks.org/machine-learning/identifying-handwritten-digits-using-logistic-regression-pytorch/)\n8. [Cartooning an Image](https://www.geeksforgeeks.org/blogs/cartooning-an-image-using-opencv-python/)\n9. [Count number of Object](https://www.geeksforgeeks.org/computer-vision/count-number-of-object-using-python-opencv/)\n10. [Count number of Faces](https://www.geeksforgeeks.org/python/count-number-of-faces-using-python-opencv/)\n11. [Text Detection and Extraction](https://www.geeksforgeeks.org/python/text-detection-and-extraction-using-opencv-and-ocr/)\n12. [CIFAR-10 Image Classification](https://www.geeksforgeeks.org/deep-learning/cifar-10-image-classification-in-tensorflow/)\n13. [Black and white image colorization](https://www.geeksforgeeks.org/computer-vision/black-and-white-image-colorization-with-opencv-and-deep-learning/)\n14. [Handwritten Digit Recognition using Neural Network](https://www.geeksforgeeks.org/machine-learning/handwritten-digit-recognition-using-neural-network/)\n\n### 2. Social Media and Sentiment Analysis\n\nPeople express their opinions on social media every day. Machine Learning can study these posts to understand whether people feel positive, negative or neutral about a topic.\n\n1. [Twitter Sentiment Analysis](https://www.geeksforgeeks.org/python/twitter-sentiment-analysis-using-python/)\n2. [Facebook Sentiment Analysis](https://www.geeksforgeeks.org/nlp/facebook-sentiment-analysis-using-python/)\n\n### 3. Finance and Economics\n\nThe financial world deals with huge amounts of data every day. Machine Learning can be used to detect fraud, predict stock and cryptocurrency prices and even estimate housing values. These projects show how ML can help make smarter financial decisions.\n\n1. [Credit Card Fraud Detection](https://www.geeksforgeeks.org/machine-learning/ml-credit-card-fraud-detection/)\n2. [Dogecoin Price Prediction](https://www.geeksforgeeks.org/machine-learning/dogecoin-price-prediction-with-machine-learning/)\n3. [Zillow Home Value (Zestimate) Prediction](https://www.geeksforgeeks.org/machine-learning/zillow-home-value-zestimate-prediction-in-ml/)\n4. [Bitcoin Price Prediction](https://www.geeksforgeeks.org/machine-learning/bitcoin-price-prediction-using-machine-learning-in-python/)\n5. [Online Payment Fraud Detection](https://www.geeksforgeeks.org/machine-learning/online-payment-fraud-detection-using-machine-learning-in-python/)\n6. [Stock Price Prediction](https://www.geeksforgeeks.org/machine-learning/stock-price-prediction-using-machine-learning-in-python/)\n7. [Stock Price Prediction Project using TensorFlow](https://www.geeksforgeeks.org/nlp/stock-price-prediction-project-using-tensorflow/)\n8. [Microsoft Stock Price Prediction](https://www.geeksforgeeks.org/machine-learning/microsoft-stock-price-prediction-with-machine-learning/)\n9. [Predicting Stock Price Direction using Support Vector Machines](https://www.geeksforgeeks.org/machine-learning/predicting-stock-price-direction-using-support-vector-machines/)\n10. [Share Price Forecasting Using Facebook Prophet](https://www.geeksforgeeks.org/machine-learning/share-price-forecasting-using-facebook-prophet/)\n\n### 4. Retail and Commerce\n\nShops and businesses want to know what customers like, how much they will spend and how to improve sales. Machine Learning can help by forecasting sales, analyzing product prices, grouping customers and even studying online reviews.\n\n1. [Sales Forecast Prediction](https://www.geeksforgeeks.org/python/sales-forecast-prediction-python/)\n2. [Customer Churn Analysis Prediction](https://www.geeksforgeeks.org/machine-learning/python-customer-churn-analysis-prediction/)\n3. [Inventory Demand Forecasting](https://www.geeksforgeeks.org/machine-learning/inventory-demand-forecasting-using-machine-learning-python/)\n4. [Customer Segmentation](https://www.geeksforgeeks.org/machine-learning/customer-segmentation-using-unsupervised-machine-learning-in-python/)\n5. [Analyzing selling price of used cars](https://www.geeksforgeeks.org/python/analyzing-selling-price-of-used-cars-using-python/)\n6. [Box Office Revenue Prediction](https://www.geeksforgeeks.org/machine-learning/box-office-revenue-prediction-using-linear-regression-in-ml/)\n7. [Flipkart Reviews Sentiment Analysis](https://www.geeksforgeeks.org/nlp/flipkart-reviews-sentiment-analysis-using-python/)\n8. [Click-Through Rate Prediction](https://www.geeksforgeeks.org/machine-learning/click-through-rate-prediction/)\n9. [Loan Approval Prediction using Multiple Machine Learning Models](https://www.geeksforgeeks.org/machine-learning/loan-approval-prediction-using-machine-learning/)\n10. [Loan Eligibility prediction using SVM](https://www.geeksforgeeks.org/machine-learning/loan-eligibility-prediction-using-machine-learning-models-in-python/)\n11. [House Price Prediction](https://www.geeksforgeeks.org/machine-learning/house-price-prediction-using-machine-learning-in-python/)\n12. [Boston Housing Prediction](https://www.geeksforgeeks.org/machine-learning/ml-boston-housing-kaggle-challenge-with-linear-regression/)\n13. [Employee Management System](https://www.geeksforgeeks.org/python/employee-management-system-using-python/)\n\n### 5. Healthcare\n\nMachine Learning is helping doctors and researchers predict diseases earlier and more accurately. These projects focus on health problems like heart disease, cancer, Parkinson's and autism, showing how data can be used to save lives.\n\n1. [Disease Prediction](https://www.geeksforgeeks.org/machine-learning/disease-prediction-using-machine-learning/)\n2. [Heart Disease Prediction Using Logistic Regression](https://www.geeksforgeeks.org/machine-learning/ml-heart-disease-prediction-using-logistic-regression/)\n3. [Prediction of Wine type](https://www.geeksforgeeks.org/deep-learning/prediction-of-wine-type-using-deep-learning/)\n4. [Parkinson's Disease Prediction](https://www.geeksforgeeks.org/machine-learning/parkinson-disease-prediction-using-machine-learning-python/)\n5. [Breast Cancer Wisconsin Diagnosis using Logistic Regression](https://www.geeksforgeeks.org/machine-learning/ml-kaggle-breast-cancer-wisconsin-diagnosis-using-logistic-regression/)\n6. [Cancer cell classification](https://www.geeksforgeeks.org/machine-learning/ml-cancer-cell-classification-using-scikit-learn/)\n7. [Breast Cancer Wisconsin Diagnosis using KNN and Cross-Validation](https://www.geeksforgeeks.org/machine-learning/ml-kaggle-breast-cancer-wisconsin-diagnosis-using-knn/)\n8. [Autism Prediction](https://www.geeksforgeeks.org/machine-learning/autism-prediction-using-machine-learning/)\n9. [Medical Insurance Price Prediction](https://www.geeksforgeeks.org/machine-learning/medical-insurance-price-prediction-using-machine-learning-python/)\n10. [Skin Cancer Detection](https://www.geeksforgeeks.org/deep-learning/skin-cancer-detection-using-tensorflow/)\n11. [Heart Disease Prediction using ANN](https://www.geeksforgeeks.org/deep-learning/heart-disease-prediction-using-ann/)\n12. [Predicting Air Quality Index](https://www.geeksforgeeks.org/python/predicting-air-quality-index-using-python/)\n13. [Predicting Air Quality with Neural Networks](https://www.geeksforgeeks.org/deep-learning/predicting-air-quality-with-neural-networks/)\n14. [Titanic Survival Prediction](https://www.geeksforgeeks.org/machine-learning/titanic-survival-prediction-using-ml/)\n\n### 6. Food and Sports\n\nMachine Learning is being used in many everyday areas like food quality testing and sports analysis. It can predict wine quality, estimate calories burned, forecast insurance costs and even predict cricket match scores, helping people make better decisions in daily life.\n\n1. [Wine Quality Prediction](https://www.geeksforgeeks.org/machine-learning/wine-quality-prediction-machine-learning/)\n2. [IPL Score Prediction Using Deep Learning](https://www.geeksforgeeks.org/deep-learning/ipl-score-prediction-using-deep-learning/)\n3. [Calories Burnt Prediction using Machine Learning](https://www.geeksforgeeks.org/machine-learning/calories-burnt-prediction-using-machine-learning/)\n\n### 7. Transportation, Traffic and Environment\n\nTransport systems and the environment generate large amounts of data. Machine Learning can study this data to improve traffic planning, forecast ride demands and even predict rainfall to help in agriculture and disaster management.\n\n1. [Vehicle Count Prediction From Sensor Data](https://www.geeksforgeeks.org/dsa/vehicle-count-prediction-from-sensor-data/)\n2. [Ola Bike Ride Request Forecast](https://www.geeksforgeeks.org/machine-learning/ola-bike-ride-request-forecast-using-ml/)\n3. [Rainfall Prediction](https://www.geeksforgeeks.org/machine-learning/rainfall-prediction-using-machine-learning-python/)\n\n### 8. Other Important Machine Learning Projects\n\nMachine Learning can also be used in many other areas like detecting fake news, predicting tips at restaurants or forecasting product demand. These projects explore unique and practical uses of ML.\n\n1. [Human Scream Detection and Analysis for Controlling Crime Rate](https://www.geeksforgeeks.org/machine-learning/human-scream-detection-and-analysis-for-controlling-crime-rate-project-idea/)\n2. [Spaceship Titanic Project](https://www.geeksforgeeks.org/machine-learning/spaceship-titanic-project-using-machine-learning-python/)\n3. [Inventory Demand Forecasting](https://www.geeksforgeeks.org/machine-learning/inventory-demand-forecasting-using-machine-learning-python/)\n4. [Waiter's Tip Prediction](https://www.geeksforgeeks.org/machine-learning/waiters-tip-prediction-using-machine-learning/)\n5. [Fake News Detection](https://www.geeksforgeeks.org/machine-learning/fake-news-detection-using-machine-learning/)\n6. [Fake News Detection Model](https://www.geeksforgeeks.org/nlp/fake-news-detection-model-using-tensorflow-in-python/)\n7. [Predict Fuel Efficiency](https://www.geeksforgeeks.org/deep-learning/predict-fuel-efficiency-using-tensorflow-in-python/)\n\n## Advanced Machine Learning Projects With Source Code\n\nHere we have discussed a variety of complex machine-learning projects that will challenge both your practical engineering skills and your theoretical knowledge of machine learning.\n\n### 1. Image and Video Processing\n\nMachine Learning is very powerful in working with pictures and videos. These projects include things like detecting faces, identifying diseases from X-rays, classifying animals and recognizing traffic signs.\n\n1. [Multiclass image classification](https://www.geeksforgeeks.org/deep-learning/multiclass-image-classification-using-transfer-learning/)\n2. [Image Caption Generator](https://www.geeksforgeeks.org/deep-learning/image-caption-generator-using-deep-learning-on-flickr8k-dataset/)\n3. [FaceMask Detection](https://www.geeksforgeeks.org/deep-learning/facemask-detection-using-tensorflow-in-python/)\n4. [Dog Breed Classification](https://www.geeksforgeeks.org/deep-learning/dog-breed-classification-using-transfer-learning/)\n5. [Flower Recognition](https://www.geeksforgeeks.org/deep-learning/flower-recognition-using-convolutional-neural-network/)\n6. [Cat & Dog Classification using CNN](https://www.geeksforgeeks.org/deep-learning/cat-dog-classification-using-convolutional-neural-network-in-python/)\n7. [Traffic Signs Recognition](https://www.geeksforgeeks.org/deep-learning/traffic-signs-recognition-using-cnn-and-keras-in-python/)\n8. [Residual Networks (ResNet)](https://www.geeksforgeeks.org/deep-learning/residual-networks-resnet-deep-learning/)\n9. [Lung Cancer Detection using CNN](https://www.geeksforgeeks.org/deep-learning/lung-cancer-detection-using-convolutional-neural-network-cnn/)\n10. [Lung Cancer Detection Using Transfer Learning](https://www.geeksforgeeks.org/deep-learning/lung-cancer-detection-using-transfer-learning/)\n11. [Black and white image colorization](https://www.geeksforgeeks.org/computer-vision/black-and-white-image-colorization-with-opencv-and-deep-learning/)\n12. [Pneumonia Detection using Deep Learning](https://www.geeksforgeeks.org/deep-learning/pneumonia-detection-using-deep-learning/)\n13. [Detecting Covid-19 with Chest X-ray](https://www.geeksforgeeks.org/machine-learning/detecting-covid-19-with-chest-x-ray/)\n14. [Detecting COVID-19 From Chest X-Ray Images using CNN](https://www.geeksforgeeks.org/deep-learning/detecting-covid-19-from-chest-x-ray-images-using-cnn/)\n15. [Image Segmentation](https://www.geeksforgeeks.org/deep-learning/image-segmentation-using-tensorflow/)\n\n### 2. Recommendation Systems\n\nRecommendation systems suggest what you might like to watch, listen to or buy. These projects show how ML can recommend movies, music or talks based on your preferences.\n\n1. [Ted Talks Recommendation System](https://www.geeksforgeeks.org/machine-learning/ted-talks-recommendation-system-with-machine-learning/)\n2. [Movie Recommender System](https://www.geeksforgeeks.org/machine-learning/python-implementation-of-movie-recommender-system/)\n3. [Movie recommendation based on emotion](https://www.geeksforgeeks.org/python/movie-recommendation-based-emotion-python/)\n4. [Music Recommendation System](https://www.geeksforgeeks.org/machine-learning/music-recommendation-system-using-machine-learning/)\n\n### 3. Speech and Language Processing\n\nWith Machine Learning, computers can understand and process human language. Projects like speech recognition, chatbots and sentiment analysis show how ML makes communication with machines easier.\n\n1. [Speech Recognition](https://www.geeksforgeeks.org/python/speech-recognition-in-python-using-google-speech-api/)\n2. [Voice Assistant](https://www.geeksforgeeks.org/python/voice-assistant-using-python/)\n3. [Next Sentence Prediction](https://www.geeksforgeeks.org/machine-learning/next-sentence-prediction-using-bert/)\n4. [Hate Speech Detection](https://www.geeksforgeeks.org/deep-learning/hate-speech-detection-using-deep-learning/)\n5. [Fine-tuning BERT model for Sentiment Analysis](https://www.geeksforgeeks.org/nlp/fine-tuning-bert-model-for-sentiment-analysis/)\n6. [Sentiment Classification Using BERT](https://www.geeksforgeeks.org/nlp/sentiment-classification-using-bert/)\n7. [Sentiment Analysis with RNN](https://www.geeksforgeeks.org/python/sentiment-analysis-with-an-recurrent-neural-networks-rnn/)\n8. [Autocorrect Feature](https://www.geeksforgeeks.org/nlp/autocorrector-feature-using-nlp-in-python/)\n9. [Analysis of Restaurant reviews](https://www.geeksforgeeks.org/nlp/python-nlp-analysis-of-restaurant-reviews/)\n10. [Restaurant Review Analysis Using NLP and SQLite](https://www.geeksforgeeks.org/nlp/restaurant-review-analysis-using-nlp-and-sqlite/)\n\n### 4. Security and Surveillance\n\nMachine Learning is also used in safety and security. Projects like intrusion detection and license plate recognition help in crime prevention and monitoring.\n\n1. [Intrusion Detection System](https://www.geeksforgeeks.org/machine-learning/intrusion-detection-system-using-machine-learning-algorithms/)\n2. [License Plate Recognition](https://www.geeksforgeeks.org/machine-learning/license-plate-recognition-with-opencv-and-tesseract-ocr/)\n3. [Detect and Recognize Car License Plate](https://www.geeksforgeeks.org/python/detect-and-recognize-car-license-plate-from-a-video-in-real-time/)\n\n### 5. Other Advanced Machine Learning Projects\n\nSome projects focus on exciting new areas like predicting a person's age, tracking body movements or recognizing daily activities. These show the wide range of ML applications.\n\n1. [Age Detection](https://www.geeksforgeeks.org/computer-vision/age-detection-using-deep-learning-in-opencv/)\n2. [Face and Hand Landmarks Detection](https://www.geeksforgeeks.org/machine-learning/face-and-hand-landmarks-detection-using-python-mediapipe-opencv/)\n3. [Human Activity Recognition](https://www.geeksforgeeks.org/deep-learning/human-activity-recognition-using-deep-learning-model/)\n4. [Sequential Model](https://www.geeksforgeeks.org/deep-learning/how-can-tensorflow-be-used-with-abalone-dataset-to-build-a-sequential-model/) with Abalone Dataset\n\n> For more real world project you can refer to our [21 Projects, 21 Days: ML, Deep Learning & GenAI Program](https://www.geeksforgeeks.org/courses/twenty-projects-in-twenty-days) where you willl build 21 projects in 21 days and if you are able to make 21 projects in 21 days 90% of course fees is refunded."}
{"reference": "https://www.geeksforgeeks.org/system-design/system-design-tutorial/", "content": "# System Design Tutorial\n\nSystem Design is the process of designing the architecture, components, and interfaces for a system so that it meets the end-user requirements. This specifically designed System Design tutorial will help you to learn and master System Design concepts in the most efficient way, from the basics to the advanced level.\n\n## Why Learn System Design?\n\nSystem design is important for anyone who wants to build a robust, scalable, and efficient software application. Whether you are building a small-scale application or a large one, understanding system design allows you to architect solutions that can handle real-world complexities.\n\n- **Scalability and Reliability:** System design ensures systems can grow and handle increased demand without failure.\n- **Efficient Resource Management:** It helps in optimizing resource allocation, ensuring fast and responsive applications.\n- **Adaptability**: System design enables the creation of systems that can evolve with changing business needs, reducing long-term costs.\n- **Architectural Understanding:** Learning different system architectures (e.g., microservices, monolithic) helps in building applications suited to various needs.\n- **Interview Preparation:** Mastering system design is key to excelling in system design interviews, commonly asked in tech company hiring processes.\n\n## Basics\n\n- [System Design Introduction - HLD & LLD](https://www.geeksforgeeks.org/system-design/getting-started-with-system-design/)\n- [Functional and Non Functional Requirements](https://www.geeksforgeeks.org/software-engineering/functional-vs-non-functional-requirements/)\n\n## High Level Design\n\n- [What is High Level Design?](https://www.geeksforgeeks.org/system-design/what-is-high-level-design-learn-system-design/)\n\n### System Architectural Styles\n\n- [Monolithic Architecture](https://www.geeksforgeeks.org/system-design/monolithic-architecture-system-design/)\n- [Microservices](https://www.geeksforgeeks.org/system-design/microservices/)\n- [Monolithic vs Microservices Architecture](https://www.geeksforgeeks.org/software-engineering/monolithic-vs-microservices-architecture/)\n- [Event-Driven Architecture](https://www.geeksforgeeks.org/system-design/event-driven-architecture-system-design/)\n- [Serverless Architecture](https://www.geeksforgeeks.org/system-design/serverless-architectures/)\n- [Stateful vs. Stateless Architecture](https://www.geeksforgeeks.org/system-design/stateful-vs-stateless-architecture/)\n- [Pub/Sub Architecture](https://www.geeksforgeeks.org/system-design/what-is-pub-sub/)\n\n### Scalability\n\n- [Horizontal and Vertical Scaling](https://www.geeksforgeeks.org/system-design/system-design-horizontal-and-vertical-scaling/)\n- [Which Scalability approach is right for our Application?](https://www.geeksforgeeks.org/system-design/which-scalability-approach-is-right-for-our-application-system-design/)\n- [Primary Bottlenecks that Hurt the Scalability of an Application](https://www.geeksforgeeks.org/system-design/primary-bottlenecks-that-hurt-the-scalability-of-an-application-system-design/)\n\n### Databases in Designing Systems\n\n- [Choosing a Database - SQL or NoSQL](https://www.geeksforgeeks.org/system-design/which-database-to-choose-while-designing-a-system-sql-or-nosql/)\n- [File and Database Storage Systems](https://www.geeksforgeeks.org/system-design/file-and-database-storage-systems-in-system-design/)\n- [Database Replication in System Design](https://www.geeksforgeeks.org/system-design/database-replication-and-their-types-in-system-design/)\n- [Database Sharding](https://www.geeksforgeeks.org/system-design/database-sharding-a-system-design-concept/)\n- [Block, Object, and File Storage](https://www.geeksforgeeks.org/system-design/block-object-and-file-storage-in-cloud-with-difference/)\n- [Normalization Process in DBMS](https://www.geeksforgeeks.org/dbms/introduction-of-database-normalization/)\n- [SQL Query Optimization](https://www.geeksforgeeks.org/sql/best-practices-for-sql-query-optimizations/)\n- [Denormalization in Databases](https://www.geeksforgeeks.org/dbms/denormalization-in-databases/)\n- [Intro to Redis](https://www.geeksforgeeks.org/system-design/introduction-to-redis-server/)\n\n### Consistency, Availability, Reliability & Maintainability\n\n- [Availability in System Design](https://www.geeksforgeeks.org/system-design/availability-in-system-design/)\n- [How to achieve High Availability?](https://www.geeksforgeeks.org/system-design/what-is-high-availability-in-system-design/)\n- [Consistency in System Design](https://www.geeksforgeeks.org/system-design/consistency-in-system-design/)\n- [Consistency pattern](https://www.geeksforgeeks.org/system-design/consistency-patterns/)\n- [CAP Theorem](https://www.geeksforgeeks.org/system-design/cap-theorem-in-system-design/)\n- [Reliability in System Design](https://www.geeksforgeeks.org/system-design/reliability-in-system-design/)\n- [Fault Tolerance in System Design](https://www.geeksforgeeks.org/system-design/fault-tolerance-in-system-design/)\n- [Maintainability](https://www.geeksforgeeks.org/system-design/maintainability-in-system-design/)\n\n### Load Balancing\n\n- [Concurrency and Parallelism](https://www.geeksforgeeks.org/operating-systems/difference-between-concurrency-and-parallelism/)\n- [Load Balancer](https://www.geeksforgeeks.org/system-design/what-is-load-balancer-system-design/)\n- [Load Balancing Algorithms](https://www.geeksforgeeks.org/system-design/load-balancing-algorithms/)\n- [Consistent Hashing](https://www.geeksforgeeks.org/system-design/consistent-hashing/)\n\n### Latency, Throughput and Caching\n\n- [Latency and Throughput](https://www.geeksforgeeks.org/system-design/latency-in-system-design/)\n- [Caching in System Design](https://www.geeksforgeeks.org/system-design/caching-system-design-concept-for-beginners/)\n\n### API Gateway, Message Queues & Rate Limiting\n\n- [What is API Gateway](https://www.geeksforgeeks.org/system-design/what-is-api-gateway-system-design/)\n- [Message Queues](https://www.geeksforgeeks.org/system-design/message-queues-system-design/)\n- [Rate Limiting](https://www.geeksforgeeks.org/system-design/rate-limiting-in-system-design/)\n- [Rate Limiting Algorithm](https://www.geeksforgeeks.org/system-design/rate-limiting-algorithms-system-design/)\n\n### Protocols, CDN, Proxies & WebSockets\n\n- [Communication Protocols](https://www.geeksforgeeks.org/system-design/communication-protocols-in-system-design/)\n- [Domain Name System](https://www.geeksforgeeks.org/computer-networks/domain-name-system-dns-in-application-layer/)\n- [DNS Caching](https://www.geeksforgeeks.org/computer-networks/what-is-dns-caching/)\n- [Time to Live(TTL)](https://www.geeksforgeeks.org/computer-networks/what-is-time-to-live-ttl/)\n- [Content Delivery Network(CDN)](https://www.geeksforgeeks.org/system-design/what-is-content-delivery-networkcdn-in-system-design/)\n- [Proxies in System Design](https://www.geeksforgeeks.org/system-design/network-protocols-and-proxies-in-system-design/)\n- [Forward Proxy vs Reverse Proxy](https://www.geeksforgeeks.org/system-design/difference-between-forward-proxy-and-reverse-proxy/)\n- [Websockets](https://www.geeksforgeeks.org/web-tech/what-is-web-socket-and-how-it-is-different-from-the-http/)\n\n### Testing\n\n- [Unit Testing](https://www.geeksforgeeks.org/software-testing/unit-testing-software-testing/)\n- [Integration Testing](https://www.geeksforgeeks.org/software-testing/software-engineering-integration-testing/)\n- [CI/CD Pipeline](https://www.geeksforgeeks.org/system-design/cicd-pipeline-system-design/)\n\n### Security Measures\n\n- [Security Measures in System Design](https://www.geeksforgeeks.org/system-design/essential-security-measures-in-system-design/)\n- [Authentication and Authorization](https://www.geeksforgeeks.org/computer-networks/difference-between-authentication-and-authorization/)\n- [Secure Socket Layer (SSL) and Transport Layer Security (TLS)](https://www.geeksforgeeks.org/computer-networks/difference-between-secure-socket-layer-ssl-and-transport-layer-security-tls/)\n- [Secure Software Developement Life Cycle (SSDLC)](https://www.geeksforgeeks.org/ethical-hacking/what-is-secure-software-development-life-cycle-ssdlc/)\n- [Data Backup and Disaster Recovery](https://www.geeksforgeeks.org/cloud-computing/what-is-data-backup-and-disaster-recovery/)\n\n### Distributed System Design\n\n- [Consensus Algorithms in Distributed System](https://www.geeksforgeeks.org/operating-systems/consensus-algorithms-in-distributed-system/)\n- [Distributed Tracing](https://www.geeksforgeeks.org/system-design/distributed-tracing-system-design/)\n- [Secure Communication in Distributed System](https://www.geeksforgeeks.org/operating-systems/secure-communication-in-distributed-system/)\n\n### Cost & Performance Optimizations\n\n- [Software Cost Estimation](https://www.geeksforgeeks.org/software-engineering/software-cost-estimation/)\n- [Performance Optimization Techniques](https://www.geeksforgeeks.org/system-design/optimization-techniques-for-system-design/)\n\n## Low Level Design(LLD)\n\n### Core Concepts\n\n- [Object-Oriented Programing(OOP) Concepts](https://www.geeksforgeeks.org/system-design/object-oriented-programingoop-concepts-for-designing-sytems/)\n- [Modularity and Interfaces](https://www.geeksforgeeks.org/system-design/inroduction-to-modularity-and-interfaces-in-system-design/)\n- [What is Low Level Design or LLD](https://www.geeksforgeeks.org/system-design/what-is-low-level-design-or-lld-learn-system-design/)\n\n### Design Principles\n\n- [SOLID Principles](https://www.geeksforgeeks.org/system-design/solid-principle-in-programming-understand-with-real-life-examples/)\n- [DRY Principle](https://www.geeksforgeeks.org/software-engineering/dont-repeat-yourselfdry-in-software-development/)\n- [KISS Principle](https://www.geeksforgeeks.org/software-engineering/kiss-principle-in-software-development/)\n- [YAGNI Principle](https://www.geeksforgeeks.org/software-engineering/what-is-yagni-principle-you-arent-gonna-need-it/)\n\n### UML\n\n- [Unified Modeling Language (UML)](https://www.geeksforgeeks.org/system-design/unified-modeling-language-uml-introduction/)\n\n### Design Patterns\n\n- [Design Patterns](https://www.geeksforgeeks.org/system-design/software-design-patterns/)\n- [Singleton Pattern](https://www.geeksforgeeks.org/system-design/singleton-design-pattern/)\n- [Factory Method](https://www.geeksforgeeks.org/system-design/factory-method-for-designing-pattern/)\n- [Abstract Factory](https://www.geeksforgeeks.org/system-design/abstract-factory-pattern/)\n- [Builder Pattern](https://www.geeksforgeeks.org/system-design/builder-design-pattern/)\n- [Prototype Pattern](https://www.geeksforgeeks.org/system-design/prototype-design-pattern/)\n- [Adapter Pattern](https://www.geeksforgeeks.org/system-design/adapter-pattern/)\n- [Decorator Pattern](https://www.geeksforgeeks.org/system-design/decorator-pattern/)\n- [Composite Pattern](https://www.geeksforgeeks.org/java/composite-design-pattern-in-java/)\n- [Proxy Pattern](https://www.geeksforgeeks.org/system-design/proxy-design-pattern/)\n- [Facade Pattern](https://www.geeksforgeeks.org/system-design/facade-design-pattern-introduction/)\n- [Observer Pattern](https://www.geeksforgeeks.org/system-design/observer-pattern-set-1-introduction/)\n- [Strategy Pattern](https://www.geeksforgeeks.org/system-design/strategy-pattern-set-1/)\n- [Command Pattern](https://www.geeksforgeeks.org/system-design/state-design-pattern/)\n- [State Pattern](https://www.geeksforgeeks.org/system-design/state-design-pattern/)\n- [Template Method Pattern](https://www.geeksforgeeks.org/system-design/template-method-design-pattern/)\n\n## Interview Questions & Answers of System Design\n\n- [URL Shortening Service](https://www.geeksforgeeks.org/system-design/system-design-url-shortening-service/)\n- [Design Dropbox](https://www.geeksforgeeks.org/system-design/design-dropbox-a-system-design-interview-question/)\n- [Design Twitter](https://www.geeksforgeeks.org/interview-experiences/design-twitter-a-system-design-interview-question/)\n- [System Design Netflix – Complete Architecture](https://www.geeksforgeeks.org/system-design/system-design-netflix-a-complete-architecture/)\n- [System Design of Uber App – Uber System Architecture](https://www.geeksforgeeks.org/system-design/system-design-of-uber-app-uber-system-architecture/)\n- [Design BookMyShow](https://www.geeksforgeeks.org/system-design/design-bookmyshow-a-system-design-interview-question/)\n- [Designing Facebook Messenger](https://www.geeksforgeeks.org/system-design/desiging-facebook-messenger-system-design-interview/)\n- [Designing Whatsapp Messenger](https://www.geeksforgeeks.org/system-design/designing-whatsapp-messenger-system-design/)\n- [Designing Instagram](https://www.geeksforgeeks.org/system-design/design-instagram-a-system-design-interview-question/)\n- [Designing Airbnb](https://www.geeksforgeeks.org/system-design/system-design-of-airline-management-system/)\n- [System Designing of Airline Management System](https://www.geeksforgeeks.org/system-design/system-design-of-airline-management-system/)\n- [Common Design Interview Questions](https://www.geeksforgeeks.org/system-design/most-commonly-asked-system-design-interview-problems-questions/)\n\n## Tips for System Design interview\n\n- [How to Crack System Design Round in Interviews?](https://www.geeksforgeeks.org/interview-experiences/how-to-crack-system-design-round-in-interviews/)\n- [5 Tips to Crack Low-Level System Design Interviews](https://www.geeksforgeeks.org/system-design/5-tips-to-crack-low-level-system-design-interviews/)\n- [5 Common System Design Concepts for Interview Preparation](https://www.geeksforgeeks.org/system-design/5-common-system-design-concepts-for-interview-preparation/)\n- [6 Steps To Approach Object-Oriented Design Questions in Interview](https://www.geeksforgeeks.org/interview-experiences/steps-to-approach-object-oriented-design-questions-in-interview/)\n\n## System Design Life Cycle\n\nSystem Design Life Cycle\n------------------------\n\nIntroduction of SOLID Design\n----------------------------\n\nIntroduction to the Design Patterns\n-----------------------------------\n\nCreational Design Patterns\n--------------------------\n\nSystem Design Tutorial | A complete Overview\n---------------------------------------------"}
{"reference": "https://www.geeksforgeeks.org/videos/category/sde-sheet/", "content": "# SDE Sheet Videos\n\n## Video List\n\n### Print Left View of Binary Tree\n- **Duration**: 09:34  \n- **Views**: 13.4K  \n- **Date**: 09/01/2025  \n- **Tags**: Tree, SDE Sheet, GFG SDE Sheet, binary-tree  \n- [Watch Video](/videos/print-left-view-of-binary-tree-1/)\n\n### Print a Binary Tree in Vertical Order\n- **Duration**: 16:09  \n- **Views**: 11.4K  \n- **Date**: 09/01/2025  \n- **Tags**: Tree, SDE Sheet, GFG SDE Sheet, binary-tree  \n- [Watch Video](/videos/print-a-binary-tree-in-vertical-order-1/)\n\n### Print Bottom View of Binary Tree\n- **Duration**: 09:32  \n- **Views**: 22.4K  \n- **Date**: 09/01/2025  \n- **Tags**: SDE Sheet, GFG SDE Sheet, binary-tree  \n- [Watch Video](/videos/print-bottom-view-of-binary-tree/)\n\n### SDE Sheet - Rearrange characters\n- **Duration**: 15:13  \n- **Views**: 6.8K  \n- **Date**: 11/11/2024  \n- **Tags**: SDE Sheet, GFG SDE Sheet, heap  \n- [Watch Video](/videos/sde-sheet-rearrange-characters/)\n\n### SDE Sheet - Maximum Path Sum\n- **Duration**: 12:42  \n- **Views**: 3.5K  \n- **Date**: 11/11/2024  \n- **Tags**: SDE Sheet, GFG SDE Sheet, binary-tree  \n- [Watch Video](/videos/sde-sheet-maximum-path-sum/)\n\n### SDE Sheet - Heap Sort\n- **Duration**: 15:53  \n- **Views**: 460  \n- **Date**: 07/11/2024  \n- **Tags**: Sorting, SDE Sheet, GFG SDE Sheet, heap  \n- [Watch Video](/videos/sde-sheet-heap-sort/)\n\n### SDE Sheet - Serialize and Deserialize a Binary Tree\n- **Duration**: 13:19  \n- **Views**: 3.2K  \n- **Date**: 07/11/2024  \n- **Tags**: SDE Sheet, GFG SDE Sheet, binary-tree  \n- [Watch Video](/videos/sde-sheet-serialize-and-deserialize-a-binary-tree/)\n\n### SDE Sheet - Flattening a Linked List\n- **Duration**: 16:39  \n- **Views**: 310  \n- **Date**: 29/10/2024  \n- **Tags**: SDE Sheet, GFG SDE Sheet, linked-list  \n- [Watch Video](/videos/sde-sheet-flattening-a-linked-list-1/)\n\n### SDE Sheet - Find median in a stream\n- **Duration**: 12:41  \n- **Views**: 2.8K  \n- **Date**: 14/10/2024  \n- **Tags**: SDE Sheet, GFG SDE Sheet, heap  \n- [Watch Video](/videos/sde-sheet-find-median-in-a-stream/)\n\n### SDE Sheet - Floyd Warshall\n- **Duration**: 22:39  \n- **Views**: 41.9K  \n- **Date**: 11/10/2024  \n- **Tags**: SDE Sheet, GFG SDE Sheet, graph  \n- [Watch Video](/videos/sde-sheet-floyd-warshall-1/)\n\n### SDE Sheet - Coin Piles\n- **Duration**: 19:49  \n- **Views**: 11.7K  \n- **Date**: 30/09/2024  \n- **Tags**: Array, SDE Sheet, GFG SDE Sheet, binary-search, greedy  \n- [Watch Video](/videos/sde-sheet-coin-piles/)\n\n### SDE Sheet - Huffman Decoding\n- **Duration**: 08:24  \n- **Views**: 4.8K  \n- **Date**: 30/09/2024  \n- **Tags**: SDE Sheet, GFG SDE Sheet, greedy, heap  \n- [Watch Video](/videos/sde-sheet-huffman-decoding/)\n\n*Showing 1-12 of 13 videos*"}
{"reference": "https://www.geeksforgeeks.org/category/blogs/", "content": "# GBlog\n\n2.9K+ posts\n\n## Recent Articles\n\n### [Careers and Jobs in C++](https://www.geeksforgeeks.org/blogs/careers-and-jobs-in-c/)\n\n**Last Updated:** 12 August 2025\n\nC++ is one of the most widely used programming languages, especially in industries requiring high performance, low-level memory control, and system-level programming. From... [read more](https://www.geeksforgeeks.org/blogs/careers-and-jobs-in-c/)\n\n### [GeeksforGeeks Patna Classroom - Learn, Build & Grow with Us](https://www.geeksforgeeks.org/blogs/gfg-patna/)\n\n**Last Updated:** 21 August 2025\n\nYour tech learning journey just got closer to home – welcome to GeeksforGeeks Patna! After opening offline centers in Bengaluru, Hyderabad, Pune, and Noida, we’re excited t... [read more](https://www.geeksforgeeks.org/blogs/gfg-patna/)\n\n### [ChatGPT 5 Explained Everything: What's New and How to Use](https://www.geeksforgeeks.org/blogs/chatgpt-5/)\n\n**Last Updated:** 11 August 2025\n\nOpenAI introduced a new model, ChatGPT-5, which is a major step forward in intelligence compared to earlier models, excelling in areas like coding, math, writing, health, ... [read more](https://www.geeksforgeeks.org/blogs/chatgpt-5/)\n\n**Tags:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [ChatGPT](https://www.geeksforgeeks.org/tag/chatgpt/)\n\n### [How to Run LLMs Model Locally](https://www.geeksforgeeks.org/blogs/how-to-run-llms-model-locally/)\n\n**Last Updated:** 22 August 2025\n\nWell, we assume that at this stage you were aware of AI and LLM and how it works but do you know that you can download and run the LLMs locally on your desktop? So that yo... [read more](https://www.geeksforgeeks.org/blogs/how-to-run-llms-model-locally/)\n\n**Tags:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [how-to-install](https://www.geeksforgeeks.org/tag/how-to-install/), [AI Tools](https://www.geeksforgeeks.org/tag/ai-tools/)\n\n### [20 Backend Project Ideas: Beginner to Pro](https://www.geeksforgeeks.org/blogs/backend-project-ideas/)\n\n**Last Updated:** 23 July 2025\n\nBackend development is in high demand, so companies are constantly searching for skilled developers: engineers who can build systems and maintain those systems that power ... [read more](https://www.geeksforgeeks.org/blogs/backend-project-ideas/)\n\n**Tags:** [Project-Ideas](https://www.geeksforgeeks.org/tag/project-ideas/), [Backend-Development](https://www.geeksforgeeks.org/tag/backend-development/)\n\n### [GATE ECE Subject-wise Preparation Guide for 2026](https://www.geeksforgeeks.org/blogs/gate-ece-subject-wise-preparation-guide-for-2026/)\n\n**Last Updated:** 23 July 2025\n\nThe Graduate Aptitude Test in Engineering (GATE) for Electronics and Communication Engineering (ECE) is a highly competitive exam that paves the way for postgraduate studi... [read more](https://www.geeksforgeeks.org/blogs/gate-ece-subject-wise-preparation-guide-for-2026/)\n\n### [Test Series for GATE 2026 - CS/IT and DA](https://www.geeksforgeeks.org/blogs/test-series-for-gate-2026-cs-it-and-da/)\n\n**Last Updated:** 23 May 2025\n\nThe GATE (Graduate Aptitude Test in Engineering) exam is a major gateway for students aspiring for higher studies or jobs in top companies. If you're preparing for GATE 20... [read more](https://www.geeksforgeeks.org/blogs/test-series-for-gate-2026-cs-it-and-da/)\n\n**Tags:** [GBlog 2025](https://www.geeksforgeeks.org/tag/gblog-2025/)\n\n### [History And Evolution of Web Development](https://www.geeksforgeeks.org/blogs/history-and-evolution-of-web-development/)\n\n**Last Updated:** 05 August 2025\n\nWeb development has grown rapidly since it began in the late 20th century. It started with basic, static pages used to share information and has evolved into dynamic, inte... [read more](https://www.geeksforgeeks.org/blogs/history-and-evolution-of-web-development/)\n\n### [Ronald Anthony - Geek On The Top | Engineer the Path You Want](https://www.geeksforgeeks.org/blogs/ronald-anthony-geek-on-the-top/)\n\n**Last Updated:** 05 May 2025\n\nAt Geek on the Top, we are constantly connecting and sharing success stories of Geeks from all over the world who have reached their life’s most significant milestones. If... [read more](https://www.geeksforgeeks.org/blogs/ronald-anthony-geek-on-the-top/)\n\n### [Flutter Roadmap: A Complete Guide](https://www.geeksforgeeks.org/blogs/flutter-roadmap/)\n\n**Last Updated:** 23 July 2025\n\nFlutter has quickly become one of the most popular cross-platform frameworks, allowing developers to build beautiful, high-performance apps for Android, iOS, web, and desk... [read more](https://www.geeksforgeeks.org/blogs/flutter-roadmap/)\n\n**Tags:** [Flutter](https://www.geeksforgeeks.org/tag/flutter/), [Roadmap](https://www.geeksforgeeks.org/tag/roadmap/), [GBlog 2025](https://www.geeksforgeeks.org/tag/gblog-2025/)\n\n### [Hack the Future: A Gen AI Hackathon](https://www.geeksforgeeks.org/blogs/hack-the-future-a-gen-ai-hackathon/)\n\n**Last Updated:** 28 March 2025\n\nHack the Future: A Gen AI Sprint Powered by Data is an exciting hackathon that brings together the brightest minds from across India to tackle some of the most pressing ch... [read more](https://www.geeksforgeeks.org/blogs/hack-the-future-a-gen-ai-hackathon/)\n\n**Tags:** [Hackathon](https://www.geeksforgeeks.org/tag/hackathon/), [GBlog 2025](https://www.geeksforgeeks.org/tag/gblog-2025/)\n\n### [What is Decentralized AI Model](https://www.geeksforgeeks.org/blogs/what-is-decentralized-ai-model/)\n\n**Last Updated:** 23 July 2025\n\nDecentralized artificial intelligence is that form of AI in which one central authority does not control all operations but rather distributes computing power to many devi... [read more](https://www.geeksforgeeks.org/blogs/what-is-decentralized-ai-model/)\n\n**Tags:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/), [GBlog 2025](https://www.geeksforgeeks.org/tag/gblog-2025/)\n\n### [Cursor AI](https://www.geeksforgeeks.org/blogs/how-to-use-cursor-ai-with-examples/)\n\n**Last Updated:** 24 July 2025\n\nCursor AI is an AI-powered code editor built on Visual Studio Code platform which is designed to significantly enhance developer productivity. By integrating advanced arti... [read more](https://www.geeksforgeeks.org/blogs/how-to-use-cursor-ai-with-examples/)\n\n**Tags:** [Cursor AI](https://www.geeksforgeeks.org/tag/cursor-ai/), [AI Code Editor](https://www.geeksforgeeks.org/tag/ai-code-editor/)\n\n### [What is ShadCN and Why it is Used](https://www.geeksforgeeks.org/blogs/what-is-shadcn-and-why-it-is-used/)\n\n**Last Updated:** 23 July 2025\n\nCreating a user interface that’s both functional and visually appealing is essential for any web application, but it can often be time-consuming and challenging. ShadCN is... [read more](https://www.geeksforgeeks.org/blogs/what-is-shadcn-and-why-it-is-used/)\n\n**Tags:** [GBlog 2025](https://www.geeksforgeeks.org/tag/gblog-2025/)\n\n### [Building your first GraphQL server with Apollo Server](https://www.geeksforgeeks.org/blogs/building-graphql-server-with-apollo-server/)\n\n**Last Updated:** 23 July 2025\n\nAPIs are central in web development these days; there is REST, which has been the traditional way. Unfortunately, it causes problems of over-fetching and under-fetching vi... [read more](https://www.geeksforgeeks.org/blogs/building-graphql-server-with-apollo-server/)\n\n**Tags:** [GraphQL](https://www.geeksforgeeks.org/tag/graphql/), [GBlog 2025](https://www.geeksforgeeks.org/tag/gblog-2025/)\n\n[1](https://www.geeksforgeeks.org/category/blogs/page/1/?type=recent) [2](https://www.geeksforgeeks.org/category/blogs/page/2/?type=recent) [3](https://www.geeksforgeeks.org/category/blogs/page/3/?type=recent) [4](https://www.geeksforgeeks.org/category/blogs/page/4/?type=recent) ... [192](https://www.geeksforgeeks.org/category/blogs/page/192/?type=recent)"}
{"reference": "https://www.geeksforgeeks.org/blogs/machine-learning-pipeline/", "content": "# What is Machine Learning Pipeline?\n\nIn artificial intelligence, developing a successful machine learning model involves more than selecting the best algorithm; it requires effective data management, training, and deployment in an organized manner. A **machine learning pipeline** becomes crucial in this situation.\n\n![What is Machine Learning pipeline](https://media.geeksforgeeks.org/wp-content/uploads/20250212144007512095/What-is--Machine--Learning--pipeline.webp)\n\nA machine learning pipeline is an organized approach that automates the entire process, from collecting raw data to deploying a trained model for practical use. This article will examine the **main phases of creating a machine-learning pipeline.**\n\n## Table of Contents\n\n- [Introduction to Machine learning pipeline](#introduction-to-machine-learning-pipeline)\n- [Benefits of Machine Learning pipeline](#benefits-of-machine-learning-pipeline)\n- [Steps to build Machine Learning Pipeline](#steps-to-build-machine-learning-pipeline)\n- [Implementation for model Training](#implementation-for-model-training)\n- [Implementation code](#implementation-code)\n\n## Introduction to Machine learning pipeline\n\nA [**Machine Learning**](https://www.geeksforgeeks.org/machine-learning/ml-machine-learning/) **Pipeline** is a systematic workflow designed to automate the process of **building, training, and deploying of** [**ML models**](https://www.geeksforgeeks.org/machine-learning/machine-learning-models/). It includes several steps, such as **data collection, preprocessing, feature engineering, model training, evaluation and deployment.**\n\nRather than managing each step individually, pipelines help simplify and standardize the workflow, making machine learning development **faster, more efficient and scalable**. They also enhance data management by enabling the extraction, transformation, and loading of data from various sources.\n\n## Benefits of Machine Learning pipeline\n\nA **Machine Learning Pipeline** offers several advantages by automating and streamlining the process of developing, training and deploying machine learning models. Here are the key benefits:\n\n1. **Automation and Efficiency:** It automates the repetitive tasks such as [**data cleaning**](https://www.geeksforgeeks.org/data-analysis/what-is-data-cleaning/), **model training and testing**. It saves time and speeds up the development process and allows data scientists to focus on more strategic task.\n\n2. **Faster Model Deployment:** It helps in quickly moving a trained model into real-world use. It is useful for AI applications like **stock trading, fraud detection and healthcare.**\n\n3. **Improve Accuracy & Consistency:** It ensures that data is processed the same way every time reducing human error and making predictions more reliable.\n\n4. **Handles Large Data easily:** **ML pipeline** works efficiently with big datasets and can run on powerful cloud platforms for better performance.\n\n5. **Cost-Effective:** **Machine Learning Pipeline** saves time and money by automating tasks that would normally require manual work. This means fewer mistakes and less work for extra workers, making the process more efficient and cost-effective.\n\n## Steps to build Machine Learning Pipeline\n\nA **machine learning pipeline** is a step-by-step process that automates data preparation, model training and deployment. Here, we will discuss the key steps:\n\n### Step 1: Data Collection and Preprocessing\n\n- Gather data from sources like[**databases**](https://www.geeksforgeeks.org/dbms/what-is-database/), [**APIs**](https://www.geeksforgeeks.org/software-testing/what-is-an-api/) or CSV files.\n- Clean the data by handling missing values, duplicates and errors.\n- Normalize and standardize numerical values.\n- Convert categorical variables into a machine readable format.\n\n### Step 2: Feature Engineering\n\n- Select the most important features for better model performance.\n- Create new features for feature extraction or transformation.\n\n### Step 3: Data splitting\n\n- Divide the dataset into training, validation and testing sets.\n- When dealing with imbalanced datasets, use random sampling.\n\n### Step 4: Model Selection & Training\n\n- Choose the best algorithm based on the problem includes [**classification**](https://www.geeksforgeeks.org/machine-learning/basic-concept-classification-data-mining/), [**regression**](https://www.geeksforgeeks.org/machine-learning/regression-in-machine-learning/), [**Clustering**](https://www.geeksforgeeks.org/machine-learning/clustering-in-machine-learning/) etc.\n- Train the model using the training dataset.\n\n### Step 5: Model evaluation & Optimization\n\n- Test the model's performance using accuracy, precision, recall and other [metrics](https://www.geeksforgeeks.org/machine-learning/metrics-for-machine-learning-model/).\n- [**Tune hyperparameters**](https://www.geeksforgeeks.org/machine-learning/hyperparameter-tuning/) using **Grid Search or Random Search** and [avoiding overfitting](https://www.geeksforgeeks.org/machine-learning/how-to-avoid-overfitting-in-machine-learning/) using techniques like [**cross- validation**](https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/).\n\n### Step 6: Model Deployment\n\n- Deploy the trained model using [**Flask**](https://www.geeksforgeeks.org/python/flask-tutorial/), FastAPI, [**TensorFlow**](https://www.geeksforgeeks.org/python/introduction-to-tensorflow/) and cloud services.\n- Save the trained model for real-world applications.\n\n### Step 7: Continuous learning & Monitoring\n\n- Automates the pipeline using[**MLOps**](https://www.geeksforgeeks.org/machine-learning/what-is-mlops/) tools like **MLflow or Kubeflow.**\n- Update the model with new data to maintain accuracy.\n\n## Implementation for model Training\n\n### 1. Import Libraries\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n```\n\n### 2. Load and Prepare the data\n\n```python\n# Load dataset\ndf = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n\n# Select relevant features\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\ndf = df[features + ['Survived']].dropna()  # Drop rows with missing values\n\n# Display the first few rows\nprint(df.head())\n```\n\n**Output:**\n\n![output1](https://media.geeksforgeeks.org/wp-content/uploads/20250226111219618620/output1.png)\n\n### 3. Define Preprocessing Steps\n\n```python\n# Define numerical and categorical features\nnum_features = ['Age', 'SibSp', 'Parch', 'Fare']\ncat_features = ['Pclass', 'Sex', 'Embarked']\n\n# Define transformers\nnum_transformer = StandardScaler()  # Standardization for numerical features\ncat_transformer = OneHotEncoder(handle_unknown='ignore')  # One-hot encoding for categorical features\n\n# Combine transformers into a preprocessor\npreprocessor = ColumnTransformer([\n    ('num', num_transformer, num_features),\n    ('cat', cat_transformer, cat_features)\n])\n```\n\n### 4. Split the data for training and Testing\n\n```python\n# Define target and features\nX = df[features]\ny = df['Survived']\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Display the shape of the data\nprint(f\"Training set shape: {X_train.shape}\")\nprint(f\"Testing set shape: {X_test.shape}\")\n```\n\n**Output:**\n\n```\nTraining set shape: (567, 7)\nTesting set shape: (143, 7)\n```\n\n### 5. Build and Train model\n\n```python\n# Define the pipeline\npipeline = Pipeline([\n    ('preprocessor', preprocessor),  # Data transformation\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # ML model\n])\n\n# Train the model\npipeline.fit(X_train, y_train)\nprint(\"Model training complete!\")\n```\n\n**Output:**\n\n```\nModel training complete!\n```\n\n### 6. Evaluate the Model\n\n```python\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Compute accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\n```\n\n**Output:**\n\n```\nModel Accuracy: 0.76\n```\n\n### 7. Save and Load the Model\n\n```python\nimport joblib\n\n# Save the trained pipeline\njoblib.dump(pipeline, 'ml_pipeline.pkl')\n\n# Load the model\nloaded_pipeline = joblib.load('ml_pipeline.pkl')\n\n# Predict using the loaded model\nsample_data = pd.DataFrame([{'Pclass': 3, 'Sex': 'male', 'Age': 25, 'SibSp': 0, 'Parch': 0, 'Fare': 7.5, 'Embarked': 'S'}])\nprediction = loaded_pipeline.predict(sample_data)\nprint(f\"Prediction: {'Survived' if prediction[0] == 1 else 'Did not Survive'}\")\n```\n\n**Output:**\n\n```\nPrediction: Did not Survive\n```\n\n## Implementation code\n\n```python\n# Step 1: Import Required Libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport joblib  # For saving and loading models\n\n# Step 2: Load and Prepare the Data\n# Load dataset (Titanic dataset as an example)\ndf = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n\n# Select relevant features\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\ndf = df[features + ['Survived']].dropna()  # Drop rows with missing values\n\n# Display the first few rows of the dataset\nprint(\"Data Sample:\\n\", df.head())\n\n# Step 3: Define Preprocessing Steps\n# Define numerical and categorical features\nnum_features = ['Age', 'SibSp', 'Parch', 'Fare']\ncat_features = ['Pclass', 'Sex', 'Embarked']\n\n# Define transformers for preprocessing\nnum_transformer = StandardScaler()  # Standardize numerical features\ncat_transformer = OneHotEncoder(handle_unknown='ignore')  # One-hot encode categorical features\n\n# Combine transformers into a single preprocessor\npreprocessor = ColumnTransformer([\n    ('num', num_transformer, num_features),\n    ('cat', cat_transformer, cat_features)\n])\n\n# Step 4: Split Data into Training and Testing Sets\n# Define target and features\nX = df[features]\ny = df['Survived']\n\n# Split into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Training set shape: {X_train.shape}\")\nprint(f\"Testing set shape: {X_test.shape}\")\n\n# Step 5: Build the Machine Learning Pipeline\n# Define the pipeline (includes preprocessing + RandomForest classifier)\npipeline = Pipeline([\n    ('preprocessor', preprocessor),  # Apply preprocessing steps\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # ML model (RandomForest)\n])\n\n# Step 6: Train the Model\n# Train the model using the pipeline\npipeline.fit(X_train, y_train)\nprint(\"Model training complete!\")\n\n# Step 7: Evaluate the Model\n# Make predictions on the test data\ny_pred = pipeline.predict(X_test)\n\n# Compute accuracy of the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\n\n# Step 8: Save and Load the Model\n# Save the trained pipeline (preprocessing + model)\njoblib.dump(pipeline, 'ml_pipeline.pkl')\n\n# Load the model back\nloaded_pipeline = joblib.load('ml_pipeline.pkl')\n\n# Predict using the loaded model\nsample_data = pd.DataFrame([{'Pclass': 3, 'Sex': 'male', 'Age': 25, 'SibSp': 0, 'Parch': 0, 'Fare': 7.5, 'Embarked': 'S'}])\nprediction = loaded_pipeline.predict(sample_data)\n\n# Output prediction for a sample input\nprint(f\"Prediction for Sample Data: {'Survived' if prediction[0] == 1 else 'Did not Survive'}\")\n```\n\n**Output:**\n\n![output2](https://media.geeksforgeeks.org/wp-content/uploads/20250226111314585621/output2.png)\n\n## Conclusion\n\nTo sum it up, a **machine pipeline** simplifies and automates the complex process of developing AI models, ensuring **efficiency, accuracy and scalability**. By integrating structured steps like data preprocessing, model training, evaluation and deployment, it streamlines machine learning workflows. With the growing demand for AI-driven insights, ML pipelines will continue to be a key enabler of innovation and making machine learning faster and more applicable to real world challenges."}
{"reference": "https://www.geeksforgeeks.org/courses/interview-qna-skill-up", "content": "# Interview Q&A Series\n\nThe **Interview Q&A Course** is a preparation guide for technical interviews across domains. Whether you're preparing for software development, data science, cloud computing, or cybersecurity roles, this structured resource gives you direct access to the most commonly asked questions, topic-wise and role-specific, collected from real interviews.\n\n## Course Overview\n\nThe Interview Q&A Mastery Course is designed to help you crack technical interviews with confidence. Whether you're aiming for top product-based companies like Google, Amazon, and Microsoft or service-based companies like TCS, Infosys, and Wipro, this course gives you a clear, structured roadmap to prepare.\n\nIt's not just another list of questions. This course brings together 2000+ real-world interview questions, handpicked and organized across domains, topics, and technologies, all in one place. With a mix of theory, coding problems, aptitude, puzzles, and personal interview questions, it offers a complete prep solution for both freshers and working professionals.\n\nFrom core CS subjects to latest tech like Blockchain, DevOps, Data Science, and Android, you'll find role-specific Q&A banks with additional resources from trusted platforms like GeeksforGeeks.\n\nBy the end of this course, you'll know what questions to expect, how to answer them, and how to confidently handle technical rounds.\n\n### Course Highlights\n\n* Covers 2000+ Most Asked Interview Questions\n* Organized Topic-wise & Tech Stack-wise\n* Curated from Real SDE, Analyst, and System Design Interviews\n* Includes Coding Questions, Theory, Aptitude & Puzzles\n* Suitable for Beginners to Advanced Candidates\n* Helpful for Product-based & Service-based Company Interviews\n* Includes System Design, DBMS, DSA, and Emerging Tech Topics\n\n## Course Content\n\n### 01 Programming Languages Interview Questions\n\n* C Programming\n* C++ Programming\n* Python Programming\n* Java Programming\n* Java Microservices\n* Java Multithreading\n\n### 02 Core CS Subjects Interview Questions\n\n* DBMS\n* SQL\n* Operating Systems\n* Computer Networks\n* IP Addressing\n* OS-CN-DBMS\n* Distributed Systems\n* System Design\n* HLD | LLD\n* Software Engineering\n* OOPs\n* Recursion\n\n### 03 Personal & Aptitude Interview Questions\n\n* Common Interview Questions\n* Puzzles\n* Personal Questions\n* General Aptitude\n\n### 04 Data Structures Interview Questions\n\n* Arrays | Top 50 Array Problems\n* Linked List\n* Stacks | Top 50 Stack Problems\n* Queues | Top 50 Queue Problems\n* Trees | Top 50 Tree Problems\n* Hashing | Top 20 Hashing Questions\n* Graphs | Top 50 Graph Problems"}
{"reference": "https://www.geeksforgeeks.org/articles-on-computer-science-subjects-gq/", "content": "# Computer Science Core Subjects\n\nThis guide is designed to help you learn core computer science subjects. It covers topics like Operating Systems, DBMS, Computer Networks, Programming, Data Structures, and more, offering detailed tutorials.\n\n## 1. Computer Science Core Foundations\n\n- [Computer Fundamentals](https://www.geeksforgeeks.org/computer-science-fundamentals/computer-fundamentals-tutorial/)\n- [Engineering Mathematics](https://www.geeksforgeeks.org/engineering-mathematics/engineering-mathematics-tutorials/)\n- [Maths for Computer Science](https://www.geeksforgeeks.org/computer-science-fundamentals/mathematics-for-computer-science/)\n\n## 2. Systems & Networking\n\n- [Operating Systems](https://www.geeksforgeeks.org/operating-systems/operating-systems/)\n- [Computer Organization and Architecture](https://www.geeksforgeeks.org/computer-organization-architecture/computer-organization-and-architecture-tutorials/)\n- [Computer Networks](https://www.geeksforgeeks.org/computer-networks/computer-network-tutorials/)\n- [Theory of Computation](https://www.geeksforgeeks.org/theory-of-computation/theory-of-computation-automata-tutorials/)\n- [Compiler Design](https://www.geeksforgeeks.org/compiler-design/compiler-design-tutorials/)\n- [Distributed Systems](https://www.geeksforgeeks.org/distributed-systems/distributed-systems-tutorial/)\n- [Linux Tutorial](https://www.geeksforgeeks.org/linux-unix/linux-tutorial/)\n- [Cybersecurity Tutorial](https://www.geeksforgeeks.org/ethical-hacking/cyber-security-tutorial/)\n\n## 3. Data and Database Technologies\n\n- [Database Management System (DBMS)](https://www.geeksforgeeks.org/dbms/dbms/)\n- [Data Warehousing](https://www.geeksforgeeks.org/dbms/data-warehousing-tutorial/)\n\n## 4. Data Science\n\n- [Machine Learning Tutorial](https://www.geeksforgeeks.org/machine-learning/machine-learning/)\n- [Artificial Intelligence Tutorial](https://www.geeksforgeeks.org/artificial-intelligence/artificial-intelligence/)\n- [Data Analysis Tutorial](https://www.geeksforgeeks.org/data-analysis/data-analysis-tutorial/)\n- [Data Science Tutorial](https://www.geeksforgeeks.org/data-science/data-science-with-python-tutorial/)\n\n## 5. Programming & Software Development\n\n- [Software Engineering](https://www.geeksforgeeks.org/software-engineering/software-engineering/)\n- [Web Technology](https://www.geeksforgeeks.org/web-tech/web-technology/)"}
{"reference": "https://www.geeksforgeeks.org/campus-training-program/", "content": "# Placement Training Program\n\nA B2B program that focuses on technical campus training to enable students to become interview ready and employable.\n\nAssisting Campus Students\n-------------------------\n\nThe focus of this program is to equip students with industry-standard methodologies and knowledge to help them become job-ready.\n\n**Interview Centric**\n\n**Skill Centric**\n\n**Basic Programming**\n\n## Features of this Program\n\nOur exclusive Placement Training Program is designed to provide the students of your college with the competitive edge they need in today's job market.\n\n**Live classes by industry experts**  \nStudents get to interact with industry professionals for expert guidance and advice\n\n**Dedicated doubt assistance**  \n24X7 Assistance by dedicated TAs ensure that students get personalized attention, feedback, and insights\n\n**LMS with practice questions & quiz**  \nEnhance learning through interactive practice and assessment with our learning management system\n\n**Project centric learning**  \nGet a better understanding of how factual concepts are implemented in real-life scenarios\n\n**Real-time interview centric contests**  \nFoster healthy competition among students through coding contests, encouraging them to enhance their problem-solving abilities and coding speed.\n\n## An advantage to Campus\n\nEnrolling your campus for this program will help you strengthen your colleges’ reputation, demonstrate better results, build industry connections and help your students become future-technology ready.\n\n**Performance Tracker**  \nGain insights into your students' progress like never before. Stay informed about their quiz scores, project completion rates, and coding challenges to ensure personalized guidance and tailored support.\n\n**Skill enhancement**  \nThrough interactive learning, coding exercises, and hands-on projects, your campus will witness a significant boost in students' proficiency and their readiness to tackle real-world challenges.\n\n**Hiring assistance**  \nFrom resume building workshops to interview preparation and connecting them with top-tier companies, our program ensures that your campus becomes a launchpad for professional success.\n\n**Key account manager**  \nOur dedicated account manager serves as your direct point of contact, ensuring that your campus's unique needs are understood and catered to.\n\n## Placement Oriented Training Program\n\nThrough this program, your campus ensures that students are not just academically strong, but also industry-ready. Our Placement Oriented Training Program is the bridge between classroom learning and professional success\n\n**B2B Business**  \nThis collaborative approach paves the way for a mutually beneficial relationship, enhancing your students' education while contributing to your campus's growth.\n\n**Upscale your Campus with GfG**  \nElevate your campus's educational offerings by integrating GeeksforGeeks into your curriculum. Our comprehensive resources, expert guidance, and industry-aligned programs can add immense value to your campus's reputation\n\n**Placement Centric**  \nWe understand the significance of a strong foundation in technical and soft skills for securing job placements.With our Placement Centric offerings, your campus will become a launchpad for success!\n\n**Affordable Prices**  \nWe understand the budget constraints that institutions may face, which is why we have tailored our pricing to ensure that even the most cost-conscious campuses can benefit from our offerings.\n\n## Our Partner Institutions\n\nWe are already revolutionizing education and paving the way for brighter futures in these campuses’. Your college can be the next!\n\n## Certificate\n\nGet job-ready with affordable, career-aligned training programs taught by expert instructors from top companies and universities. Start pursuing your career dreams today with our program and get GeeksforGeeks certified\n\n## Testimonials\n\nHear what our students say  \nFind GeeksforGeeks alumni profiles and hear what they say about GeekforGeeks courses!\n\n**Nikhil Isaac**  \nGeeks for Geeks' DSA course has been an absolute game-changer for my career. As an electronics engineering student aspiring to land an internship at a FAANG company, I knew I needed to strengthen my data structures and programming algorithms skills. This course provided the comprehensive and structured learning I was seeking\n\n**Sarvesh Chavan**  \nThe GFG DSA course exceeded my expectations. The content is well-structured, with clear explanations and relevant examples. Thank you GeeksforGeeks for amazing content. The interactive approach truly enhances learning. Overall, it's a great course for mastering Data Structures and Algorithms.\n\n**Pranav Masekar**  \nThe DSA course was comprehensive and well-structured, covering essential data structures and algorithms. The instructors provided clear explanations and practical examples, making it easy to understand and apply the concepts. The course greatly improved my problem-solving skills and prepared me for coding interviews. Highly recommended!\n\n**Apoorva Chauhan**  \nI usually read from this app when I cannot use my laptop. Useful App to Learn DS & Algo, Programming while travelling. It has access to all content I can read from my laptop and is....\n\n**Ajit Pawar**  \nI recently completed the online DSA (Data Structures and Algorithms) course, and I must say it was an exceptional learning experience. The course was well-structured, comprehensive, and delivered with utmost professionalism. I would like to express my sincere appreciation for the incredible effort put in by the instructors and the entire course team.\n\n**Susmit Garudkar**  \nThe course is very organised and i am able to learn and revised all the things that are needed for placements is efficient manne\n\n**Pratiksha Kadam**  \nGeeksforGeeks have very helpful course for all the students who want to know about DSA in details\n\n## Hiring assistance with GfG\n\nWe collaborate closely with campuses to understand their unique needs, curricula, and student profiles. Leveraging our extensive industry network, we connect students with leading companies actively seeking fresh talent.\n\n**GFG Recruitment Platform**  \nEmpowering tech talent to connect with top companies and unlock their career potential\n\n**Monthly Job-A-Thon**  \nMonthly hiring challenges providing access to multiple job openings via a single contest\n\n**Job Fair**  \nFree job fair where hundreds of companies are invited with multiple job openings for students\n\n**Placement Assistance**  \nDedicated placement cell aimed at assisting students with their job applications process\n\n## Learning Journey\n\nWith us, the journey is just as rewarding as the destination! Have a look at what the students will experience-\n\n**Training Program**  \n**Access to Contests**  \n**Access to Hiring Partners**\n\n### Start Here\n\n**01 Programming Languages**  \n**02 Data Structures & Algorithms**  \n**03 Live Sessions**  \n**04 Practice Questions**  \n**05 Assessment Tests**  \n**06 Placement Assistance**  \n**07 Get a SDE Role**\n\n**Crack Interview**\n\n## Frequently Asked Questions\n\n**Questions you might have about our products and services**\n\n**How would this training program be helpful in placements?**  \nThis training program is designed in such a way that every candidate would be prepared on industry relevant requirements. Expert mentors would help each and every candidate and will ensure their learning curve is growing extensively.\n\n**Who are eligible for this training program?**  \nStudents who wants to get into product based companies (from 3rd Semester till 7th Semester) and targeting software developer roles can be part of this training program.\n\n**How is this training program is different?**  \nGeeksforGeeks offers lots of perks to the universities and institutions with this training program like: 24*7 Doubt Support, LIVE Classes from Industry Experts, LMS access to stakeholders for performance tracking, Placement Assistance etc.\n\n**How the curriculum is designed for the training program?**  \nWe design the curriculum according to the university or an individual institution requirement. Also, we provide our curriculum which is curated by industry experts and mentors.\n\n**Do you provide certification to the students over the completion of this training program?**  \nYes, GeeksforGeeks provides certification after the completion of the training program."}
{"reference": "https://www.geeksforgeeks.org/web-technology/", "content": "# Web Development Technologies\n\nWeb development refers to building, creating, and maintaining websites. It includes aspects such as web design, web publishing, web programming, and database management. It is the creation of an application that works over the internet, i.e., websites.\n\n## Basics of Web Development\n\nTo better understand the foundation of web development, it is recommended to take a look at the concepts used in web development.\n\nThere are two major areas: **Frontend** and **Backend** which forms the backbone of web development each plays a crucial role in creating seamless, functional web experiences.\n\n### Frontend Development\n\nIn this module, we explore the core technologies that run in the user’s browser—the client side—including how web pages are structured, styled, and made interactive, building everything users see and interact with.\n\n- **[HTML (HyperText Markup Language):](https://www.geeksforgeeks.org/html/html-tutorial/)** HTML is the language used to create the basic structure and content of web pages. It uses elements, tags, and attributes to organize text, images, and links.\n- **[CSS (Cascading Style Sheets):](https://www.geeksforgeeks.org/css/css-tutorial/)** CSS is used to style the HTML content. It controls colors, fonts, layouts, and how the page looks on different devices. More importantly, CSS enables you to do this independent of the HTML that makes up each web page.\n- **[JS (JavaScript):](https://www.geeksforgeeks.org/javascript/javascript-tutorial/)** JavaScript adds life to web pages by making them interactive. It handles things like buttons, animations, and form checks.\n\n### Backend Development\n\nIn this module, we will explore the technologies that work behind the scenes on the server to handle data, run the website, and store information.\n\n#### Server-Side Programming Languages\n\nIn Backend Development, Server-side programming languages are used to write code that runs on the server, not in the user’s browser. This [server-side scripting](https://www.geeksforgeeks.org/html/difference-between-server-side-scripting-and-client-side-scripting/) handles tasks like processing data, managing databases, and controlling how the website works behind the scenes.\n\nBelow are some popular languages used to build the back end of web applications:\n\n- **[JavaScript/Node.js:](https://www.geeksforgeeks.org/node-js/nodejs/)** JavaScript is a popular programming language mainly used to add interactivity on the client side (in browsers). With Node.js, JavaScript can also run on the server side. Node.js is an open-source environment that allows JavaScript to build fast, scalable back-end services like APIs. Many big companies like PayPal, Uber, and Netflix use Node.js for their server-side code.\n- **[PHP:](https://www.geeksforgeeks.org/php/php-tutorial/)** PHP is a server-side scripting language designed specifically for web development. Since PHP code executed on the server-side, so it is called a server-side scripting language.\n- **[Python:](https://www.geeksforgeeks.org/python/python-programming-language-tutorial/)** Python is a programming language that lets you work quickly and integrate systems more efficiently.\n- **[Ruby:](https://www.geeksforgeeks.org/ruby/ruby-programming-language/)** An object-oriented programming language designed to be simple and natural to use. Ruby helps developers write clean and readable code.\n- **[Java:](https://www.geeksforgeeks.org/java/java/)** Java is one of the most popular and widely used programming languages and platforms. It is highly scalable. Java components are easily available.\n- **[Golang(Go):](https://www.geeksforgeeks.org/go-language/go/)** Golang is a procedural and statically typed programming language having the syntax similar to C programming language. Sometimes it is termed as Go Programming Language.\n- **[C#:](https://www.geeksforgeeks.org/c-sharp/introduction-to-c-sharp/)** A modern, object-oriented language often used to build web applications on Microsoft platforms.\n\n#### Databases\n\nA database is where a website’s data like user's data, product's data are stored and organized. It is part of the backend (server side) that manages and keeps this information safe. Websites use databases to save and access information like user details, content, and transactions. Some databases organize data in tables (called relational databases, like MySQL), while others store data in flexible formats (called NoSQL databases, like MongoDB).\n\nThere are basically two types of databases:\n\n**1. SQL/Relational Database**\n\nA relational database stores data in tables, similar to a spreadsheet, where each table has rows and columns. The rows hold individual records, and the columns define the data attributes. Tables can be linked to each other through special keys, allowing related data to be connected.\n\n- **[MySQL](https://www.geeksforgeeks.org/sql/sql-tutorial/):** MySQL is an open-source relational database management system that uses SQL for managing structured data. It’s known for its reliability, ease of use, and performance, widely used in web applications.\n- **[Postgre SQL](https://www.geeksforgeeks.org/postgresql/postgresql-tutorial/):** PostgreSQL is a powerful, open-source relational database that supports advanced SQL features and complex queries. It handles structured data, ensures ACID compliance, and is known for its reliability and extensibility.\n\n**2. NoSQL Databases**\n\nA NoSQL database stores data in a flexible, non-tabular format, unlike traditional relational databases. Instead of using tables with rows and columns, NoSQL databases might use documents, key-value pairs, wide-columns, or graphs to store data. This allows them to handle large amounts of unstructured or semi-structured data efficiently. They are designed to scale easily and manage big data applications.\n\n- **[Mongodb](https://www.geeksforgeeks.org/mongodb/mongodb-tutorial/):** MongoDB is a NoSQL database storing data in JSON-like documents. It handles unstructured data, supports powerful queries, and scales easily across servers, making it popular for flexible, scalable applications.\n- **[Cassandra](https://www.geeksforgeeks.org/dbms/apache-cassandra-nosql-database/):** Apache Cassandra is an open-source NoSQL database that is used for handling big data. It has the capability to handle structure, semi-structured, and unstructured data.\n- **[Redis](https://www.geeksforgeeks.org/system-design/introduction-to-redis-server/):** Redis is an in-memory NoSQL database known for its speed. It supports various data structures like strings, hashes, and lists, making it ideal for caching, real-time analytics, and messaging.\n\n**Note:** We use [Database management systems](https://www.geeksforgeeks.org/dbms/introduction-of-dbms-database-management-system-set-1/) help keep the data safe, organized, and easy to use.\n\n## APIs and Data Exchange Formats\n\nDuring Website development, different software components and web applications constantly need to communicate and share information. For instance, the frontend of your web application (running in the user's browser) needs to get data from the backend (running on a server), or your application might need to fetch information from a third-party service like a weather provider or a payment gateway. This communication is made possible through Application Programming Interfaces (APIs) and standardized Data Formats.\n\n**Data Exchange formate for API Communication:** When applications communicate via APIs, they need a common, structured way to represent the data being exchanged. This is where data formats come in.\n\nBelow are two common data formats used extensively in web development for API communication:\n\n- **[JSON:](https://www.geeksforgeeks.org/javascript/javascript-json/)** JSON or JavaScript Object Notation is a format for structuring data.\n- **[XML:](https://www.geeksforgeeks.org/html/xml-basics/)** Extensible Markup Language (XML) is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable.\n\n## Version Control and Deployment\n\nDeveloping a web application involves more than just writing code. Two critical processes that ensure a smooth, organized, and reliable development workflow are[****Version Control****](https://www.geeksforgeeks.org/git/version-control-systems/)and[****Deployment****](https://www.geeksforgeeks.org/websites-apps/deployment-in-web-development/).\n\n****Version control**** helps manage the evolution of your codebase, especially when working in teams, while ****deployment**** is the process of making your web application accessible to the world. Modern development practices tightly integrate these two concepts, often through automation.\n\n## Graphics\n\nGraphical elements are one of the key feature of any webpage. They can be used to convey important points better than text does and beautify the webpage.\n\n- **[Canvas:](https://www.geeksforgeeks.org/html/html-canvas-basics/)** The HTML “canvas” element is used to draw graphics via JavaScript.\n- **[SVG:](https://www.geeksforgeeks.org/html/html-svg-basics/)** SVG stands for Scalable Vector Graphics. It basically defines vector-based graphics in XML format.\n\n## Some Important Links on Web Technology\n\n- [How can I start to learn Web Development?](https://www.geeksforgeeks.org/blogs/can-start-learn-web-development/)\n- [10 Best Web Development Project Ideas For Beginners [2025]](https://www.geeksforgeeks.org/blogs/web-development-project-ideas-for-beginners/)\n- [History And Evolution of Web Development](https://www.geeksforgeeks.org/blogs/history-and-evolution-of-web-development/)\n- [Web 1.0, Web 2.0 and Web 3.0 with their difference](https://www.geeksforgeeks.org/blogs/web-1-0-web-2-0-and-web-3-0-with-their-difference/)\n- [Top Trends in Web Development](https://www.geeksforgeeks.org/blogs/top-web-development-trends/)\n- [Top 9 Technologies Transforming the Future of Web Development](https://www.geeksforgeeks.org/blogs/top-9-technologies-transforming-the-future-of-web-development-comprehensive-guide/)"}
{"reference": "https://www.geeksforgeeks.org/deep-learning/multi-layer-perceptron-learning-in-tensorflow/", "content": "# Multi-Layer Perceptron Learning in Tensorflow\n\nMulti-Layer Perceptron (MLP) consists of fully connected dense layers that transform input data from one dimension to another. It is called multi-layer because it contains an input layer, one or more hidden layers and an output layer. The purpose of an MLP is to model complex relationships between inputs and outputs.\n\n## Components of Multi-Layer Perceptron (MLP)\n\n![backpropagation_in_neural_network_8](https://media.geeksforgeeks.org/wp-content/uploads/20250929154234052438/backpropagation_in_neural_network_8.webp)\n\n### Layers\n\n- **Input Layer**: Each neuron or node in this layer corresponds to an input feature. For instance, if you have three input features the input layer will have three neurons.\n- **Hidden Layers**: MLP can have any number of hidden layers with each layer containing any number of nodes. These layers process the information received from the input layer.\n- **Output Layer**: The output layer generates the final prediction or result. If there are multiple outputs, the output layer will have a corresponding number of neurons.\n\nEvery connection in the diagram is a representation of the fully connected nature of an MLP. This means that every node in one layer connects to every node in the next layer. As the data moves through the network each layer transforms it until the final output is generated in the output layer.\n\n## Working of Multi-Layer Perceptron\n\nLet's see working of the multi-layer perceptron. The key mechanisms such as forward propagation, loss function, backpropagation and optimization.\n\n### 1. Forward Propagation\n\nIn forward propagation the data flows from the input layer to the output layer, passing through any hidden layers. Each neuron in the hidden layers processes the input as follows:\n\n**1. Weighted Sum**: The neuron computes the weighted sum of the inputs:\n\n> $$ z = \\sum_{i} w_i x_i + b $$\n\n**Where**:\n\n- $x_i$ is the input feature.\n- $w_i$ is the corresponding weight.\n- $b$ is the bias term.\n\n**2. Activation Function**: The weighted sum $z$ is passed through an activation function to introduce non-linearity. Common activation functions include:\n\n- **Sigmoid**: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n- **ReLU (Rectified Linear Unit)**: $f(z) = \\max(0, z)$\n- **Tanh (Hyperbolic Tangent)**: $\\tanh(z) = \\frac{2}{1 + e^{-2z}} - 1$\n\n### 2. Loss Function\n\nOnce the network generates an output the next step is to calculate the loss using a [loss function](https://www.geeksforgeeks.org/deep-learning/loss-functions-in-deep-learning/). In supervised learning this compares the predicted output to the actual label.\n\nFor a classification problem the commonly used [binary cross-entropy](https://www.geeksforgeeks.org/deep-learning/binary-cross-entropy-log-loss-for-binary-classification/) loss function is:\n\n> $$ L = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right] $$\n\n**Where**:\n\n- $y_i$ is the actual label.\n- $\\hat{y}_i$ is the predicted label.\n- $N$ is the number of samples.\n\nFor regression problems the [mean squared error (MSE)](https://www.geeksforgeeks.org/python/python-mean-squared-error/) is often used:\n\n> $$ MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 $$\n\n### 3. Backpropagation\n\nThe goal of training an MLP is to minimize the loss function by adjusting the network's weights and biases. This is achieved through [backpropagation](https://www.geeksforgeeks.org/machine-learning/backpropagation-in-neural-network/):\n\n1. **Gradient Calculation**: The gradients of the loss function with respect to each weight and bias are calculated using the chain rule of calculus.\n2. **Error Propagation**: The error is propagated back through the network, layer by layer.\n3. **Gradient Descent**: The network updates the weights and biases by moving in the opposite direction of the gradient to reduce the loss: $w = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}$\n\n**Where**:\n\n- $w$ is the weight.\n- $\\eta$ is the learning rate.\n- $\\frac{\\partial L}{\\partial w}$ is the gradient of the loss function with respect to the weight.\n\n### 4. Optimization\n\nMLPs rely on optimization algorithms to iteratively refine the weights and biases during training. Popular optimization methods include:\n\n- **[Stochastic Gradient Descent (SGD)](https://www.geeksforgeeks.org/machine-learning/ml-stochastic-gradient-descent-sgd/)**: Updates the weights based on a single sample or a small batch of data: $w = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}$\n- **[Adam Optimizer](https://www.geeksforgeeks.org/deep-learning/adam-optimizer/)**: An extension of SGD that incorporates momentum and adaptive learning rates for more efficient training:\n\n> $$ m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\cdot g_t $$\n> $$ v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\cdot g_t^2 $$\n\nHere $g_t$ represents the gradient at time $t$ and $\\beta_1, \\beta_2$ are decay rates.\n\nNow that we are done with the theory part of multi-layer perception, let's go ahead and implement code in python using the TensorFlow library.\n\n## Implementing Multi Layer Perceptron\n\nIn this section, we will guide through building a neural network using TensorFlow.\n\n### 1. Importing Modules and Loading Dataset\n\nFirst we import necessary libraries such as [TensorFlow](https://www.geeksforgeeks.org/python/introduction-to-tensorflow/), [NumPy](https://www.geeksforgeeks.org/python/introduction-to-numpy/) and [Matplotlib](https://www.geeksforgeeks.org/python/python-introduction-matplotlib/) for visualizing the data. We also load the [MNIST dataset](https://www.geeksforgeeks.org/machine-learning/mnist-dataset/).\n\n```python\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n```\n\n### 2. Loading and Normalizing Image Data\n\nNext we normalize the image data by dividing by 255 (since pixel values range from 0 to 255) which helps in faster convergence during training.\n\n```python\ngray_scale = 255\n\nx_train = x_train.astype('float32') / gray_scale\nx_test = x_test.astype('float32') / gray_scale\n\nprint(\"Feature matrix (x_train):\", x_train.shape)\nprint(\"Target matrix (y_train):\", y_train.shape)\nprint(\"Feature matrix (x_test):\", x_test.shape)\nprint(\"Target matrix (y_test):\", y_test.shape)\n```\n\n**Output:**\n\n![data](https://media.geeksforgeeks.org/wp-content/uploads/20250522205803738807/data.png)\n\n### 3. Visualizing Data\n\nTo understand the data better we plot the first 100 training samples each representing a digit.\n\n```python\nfig, ax = plt.subplots(10, 10)\nk = 0\nfor i in range(10):\n    for j in range(10):\n        ax[i][j].imshow(x_train[k].reshape(28, 28), aspect='auto')\n        k += 1\nplt.show()\n```\n\n**Output:**\n\n![Sample-Images](https://media.geeksforgeeks.org/wp-content/uploads/20250205023853302691/Sample-Images.png)\n\n### 4. Building the Neural Network Model\n\nHere we build a Sequential neural network model. The model consists of:\n\n- **Flatten Layer**: Reshapes 2D input (28x28 pixels) into a 1D array of 784 elements.\n- **Dense Layers**: Fully connected layers with 256 and 128 neurons, both using the relu-activation function.\n- **Output Layer**: The final layer with 10 neurons representing the 10 classes of digits (0-9) with [sigmoid](https://www.geeksforgeeks.org/machine-learning/derivative-of-the-sigmoid-function/) activation.\n\n```python\nmodel = Sequential([\n    Flatten(input_shape=(28, 28)),\n    Dense(256, activation='sigmoid'),  \n    Dense(128, activation='sigmoid'), \n    Dense(10, activation='softmax'),  \n])\n```\n\n### 5. Compiling the Model\n\nOnce the model is defined we compile it by specifying:\n\n- **Optimizer**: Adam for efficient weight updates.\n- **Loss Function**: Sparse categorical cross entropy, which is suitable for multi-class classification.\n- **Metrics**: Accuracy to evaluate model performance.\n\n```python\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n```\n\n### 6. Training the Model\n\nWe train the model on the training data using 10 epochs and a batch size of 2000. We also use 20% of the training data for validation to monitor the model's performance on unseen data during training.\n\n```python\nmod = model.fit(x_train, y_train, epochs=10, \n          batch_size=2000, \n          validation_split=0.2)\n\nprint(mod)\n```\n\n**Output:**\n\n![train](https://media.geeksforgeeks.org/wp-content/uploads/20250522205631017093/train.png)\n\n### 7. Evaluating the Model\n\nAfter training we evaluate the model on the test dataset to determine its performance.\n\n```python\nresults = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss, Test accuracy:', results)\n```\n\n**Output:**\n\n> Test loss, Test accuracy: [0.2682029604911804, 0.9257000088691711]\n\nWe got the accuracy of our model 92% by using model.evaluate() on the test samples.\n\n### 8. Visualizing Training and Validation Loss VS Accuracy\n\n```python\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(mod.history['accuracy'], label='Training Accuracy', color='blue')\nplt.plot(mod.history['val_accuracy'],\n         label='Validation Accuracy', color='orange')\nplt.title('Training and Validation Accuracy', fontsize=14)\nplt.xlabel('Epochs', fontsize=12)\nplt.ylabel('Accuracy', fontsize=12)\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.plot(mod.history['loss'], label='Training Loss', color='blue')\nplt.plot(mod.history['val_loss'], label='Validation Loss', color='orange')\nplt.title('Training and Validation Loss', fontsize=14)\nplt.xlabel('Epochs', fontsize=12)\nplt.ylabel('Loss', fontsize=12)\nplt.legend()\nplt.grid(True)\n\nplt.suptitle(\"Model Training Performance\", fontsize=16)\nplt.tight_layout()\nplt.show()\n```\n\n**Output:**\n\n![accvsloss](https://media.geeksforgeeks.org/wp-content/uploads/20250522205526583547/accvsloss.webp)\n\nThe model is learning effectively on the training set, but the validation accuracy and loss levels off which might indicate that the model is starting to overfit.\n\n## Advantages\n\n- **Versatility**: MLPs can be applied to a variety of problems, both classification and regression.\n- **Non-linearity**: Using activation functions MLPs can model complex, non-linear relationships in data.\n- **Parallel Computation**: With the help of GPUs, MLPs can be trained quickly by taking advantage of parallel computing.\n\n## Disadvantages\n\n- **Computationally Expensive**: MLPs can be slow to train especially on large datasets with many layers.\n- **Prone to Overfitting**: Without proper regularization techniques they can overfit the training data leading to poor generalization.\n- **Sensitivity to Data Scaling**: They require properly normalized or scaled data for optimal performance."}
{"reference": "https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/", "content": "# ML | Underfitting and Overfitting\n\nMachine learning models aim to perform well on both training data and new, unseen data and is considered \"good\" if:\n\n1. It learns patterns effectively from the training data.\n2. It generalizes well to new, unseen data.\n3. It avoids memorizing the training data (overfitting) or failing to capture relevant patterns (underfitting).\n\nTo evaluate how well a model learns and generalizes, we monitor its performance on both the training data and a separate validation or test dataset which is often measured by its **accuracy** or **prediction errors**. However, achieving this balance **can be challenging**. Two common issues that affect a model's performance and generalization ability are **overfitting** and **underfitting**. These problems are major contributors to poor performance in machine learning models. Let's us understand what they are and how they contribute to ML models.\n\n## Bias and Variance in Machine Learning\n\n[**Bias** and **variance**](https://www.geeksforgeeks.org/machine-learning/bias-vs-variance-in-machine-learning/) are two key sources of error in machine learning models that directly impact their performance and generalization ability.\n\n**Bias**: is the error that happens when a machine learning model is too simple and doesn't learn enough details from the data. It's like assuming all birds can only be small and fly, so the model fails to recognize big birds like ostriches or penguins that can't fly and get biased with predictions.\n\n- These assumptions make the model easier to train but may prevent it from capturing the underlying complexities of the data.\n- High bias typically leads to **underfitting**, where the model performs poorly on both training and testing data because it fails to learn enough from the data.\n- **Example**: A linear regression model applied to a dataset with a non-linear relationship.\n\n**Variance**: Error that happens when a machine learning model learns too much from the data, including random noise.\n\n- A high-variance model learns not only the patterns but also the noise in the training data, which leads to poor generalization on unseen data.\n- High variance typically leads to **overfitting**, where the model performs well on training data but poorly on testing data.\n\n## Overfitting and Underfitting: The Core Issues\n\n### 1. Overfitting in Machine Learning\n\nOverfitting happens when a model learns too much from the training data, including details that don’t matter (like noise or outliers).\n\n- For example, imagine fitting a very complicated curve to a set of points. The curve will go through every point, but it won’t represent the actual pattern.\n- As a result, the model works great on training data but fails when tested on new data.\n\nOverfitting models are like students who memorize answers instead of understanding the topic. They do well in practice tests (training) but struggle in real exams (testing).\n\n**Reasons for Overfitting:**\n\n1. High variance and low bias.\n2. The model is too complex.\n3. The size of the training data.\n\n### 2. Underfitting in Machine Learning\n\nUnderfitting is the opposite of overfitting. It happens when a model is too simple to capture what’s going on in the data.\n\n- For example, imagine drawing a straight line to fit points that actually follow a curve. The line misses most of the pattern.\n- In this case, the model doesn’t work well on either the training or testing data.\n\nUnderfitting models are like students who don’t study enough. They don’t do well in practice tests or real exams. **Note: The underfitting model has High bias and low variance.**\n\n**Reasons for Underfitting:**\n\n1. The model is too simple, So it may be not capable to represent the complexities in the data.\n2. The input features which is used to train the model is not the adequate representations of underlying factors influencing the target variable.\n3. The size of the training dataset used is not enough.\n4. Excessive regularization are used to prevent the overfitting, which constraint the model to capture the data well.\n5. Features are not scaled.\n\nLet's visually understand the concept of **underfitting, proper fitting, and overfitting**.\n\n![Bias and Variance-Geeksforgeeks](https://media.geeksforgeeks.org/wp-content/uploads/20230829151403/Bias-and-Variance-in-Machine-Learning.webp)\n\n*Bias and Variance*\n\n- **Underfitting**: Straight line trying to fit a curved dataset but cannot capture the data's patterns, leading to poor performance on both training and test sets.\n- **Overfitting**: A squiggly curve passing through all training points, failing to generalize performing well on training data but poorly on test data.\n- **Appropriate Fitting**: Curve that follows the data trend without overcomplicating to capture the true patterns in the data.\n\n## Balance Between Bias and Variance\n\nThe relationship between bias and variance is often referred to as the **bias-variance tradeoff**, which highlights the need for balance:\n\n- Increasing model complexity reduces bias but increases variance (risk of overfitting).\n- Simplifying the model reduces variance but increases bias (risk of underfitting).\n\nThe goal is to find an optimal balance where both bias and variance are minimized, resulting in good generalization performance.\n\nImagine you're trying to predict the price of houses based on their size, and you decide to draw a line or curve that best fits the data points on a graph. How well this line captures the trend in the data depends on the complexity of the model you use.\n\n![Underfitting and Overfitting in Machine Learning-Geeksforgeeks](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)\n\n*Underfitting and Overfitting*\n\n- When a model is too simple, like fitting a straight line to curved data, it has **high bias** and fails to capture the true relationship, leading to **underfitting**. For example, a linear model cannot represent a non-linear increase in house prices with size.\n- However, if the model becomes too complex, like a fourth-degree polynomial that adjusts to every point, it develops **high variance**, overfits the training data, and struggles to generalize to new data. This is **overfitting**, where the model performs well on training but poorly on testing.\n- An ideal model strikes a balance with **low bias and low variance**, capturing the overall pattern without overreacting to noise. For instance, a smooth second-degree polynomial fits the data well without being overly complex.\n\n## How to Address Overfitting and Underfitting?\n\n### Techniques to Reduce Underfitting\n\n1. Increase model complexity.\n2. Increase the number of features, performing [feature engineering](https://www.geeksforgeeks.org/machine-learning/what-is-feature-engineering/).\n3. Remove noise from the data.\n4. Increase the number of [epochs](https://www.geeksforgeeks.org/machine-learning/epoch-in-machine-learning/) or increase the duration of training to get better results.\n\n### Techniques to Reduce Overfitting\n\n1. Improving the quality of training data reduces overfitting by focusing on meaningful patterns, mitigate the risk of fitting the noise or irrelevant features.\n2. Increase the training data can improve the model's ability to generalize to unseen data and reduce the likelihood of overfitting.\n3. Reduce model complexity.\n4. [Early stopping](https://www.geeksforgeeks.org/machine-learning/regularization-by-early-stopping/) during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n5. [Ridge Regularization](https://www.geeksforgeeks.org/machine-learning/lasso-vs-ridge-vs-elastic-net-ml/) and [Lasso Regularization](https://www.geeksforgeeks.org/machine-learning/implementation-of-lasso-regression-from-scratch-using-python/).\n6. Use [dropout](https://www.geeksforgeeks.org/machine-learning/dropout-in-neural-networks/) for [neural networks](https://www.geeksforgeeks.org/machine-learning/neural-networks-a-beginners-guide/) to tackle overfitting."}
{"reference": "https://www.geeksforgeeks.org/legal/", "content": "# Legal\n\n## COMMUNITY\n\n- [Community Guidelines](https://www.geeksforgeeks.org/legal/community-guidelines/)\n- [Copyright Rules for Community](https://www.geeksforgeeks.org/legal/intellectual-property-rights-legal/)\n\n## COURSES\n\n- [User Guidelines](https://www.geeksforgeeks.org/legal/user-guidelines/)\n- [Payments and Refunds](https://practice.geeksforgeeks.org/terms-of-service)\n\n## WEBSITE TERMS OF USE\n\n- [Terms of Use](https://www.geeksforgeeks.org/legal/terms-of-use/)\n\n## WEBSITE PRIVACY POLICY\n\n- [General Privacy Policy](https://www.geeksforgeeks.org/legal/privacy-policy/#:~:text=Projects-,Privacy%20Policy,-Privacy%20Policy)\n- [GDPR](https://www.geeksforgeeks.org/legal/privacy-policy/#:~:text=be%20posted%20here.-,GDPR,-DO%20EU/UK)\n- [Data Processing Agreement](https://www.geeksforgeeks.org/legal/data-processing-agreement/)\n- [CCPA](https://www.geeksforgeeks.org/legal/privacy-policy/#:~:text=Legal%40geeksforgeeks.org-,CCPA,-DO%20CALIFORNIA%20RESIDENTS)\n- [Copyright and DMCA](https://www.geeksforgeeks.org/legal/privacy-policy/#:~:text=this%20privacy%20notice.-,Copyright%20Infringement%20and%20DMCA,-This%20site%20is)\n- [Cookie Policy](https://www.geeksforgeeks.org/legal/privacy-policy/#cookie-policy-heading)\n- [Help Center](https://www.geeksforgeeks.org/about/contact-us/?ref=footer)\n\n## THIRD-PARTY COPYRIGHT NOTICES\n\n- [Third-Party Copyright Notices](https://www.geeksforgeeks.org/legal/third-party-copyright-notices/)\n\n## JOBS\n\n- [Recruiter EULA](https://www.geeksforgeeks.org/legal/end-user-license-agreement-eula-for-recruiters/)\n- [Candidate T&C](https://www.geeksforgeeks.org/legal/job-portal-terms-of-service/)\n\n## MISCELLANEOUS POLICIES\n\n- [Anti-Money Laundering (AML)](https://www.geeksforgeeks.org/legal/anti-money-laundering/)\n- [Anti-Terrorism Financing and Proceeds of Unlawful Activities](https://www.geeksforgeeks.org/legal/anti-terrorism-financing-proceeds-of-unlawful-activities-policy/)\n- [Anti-Trust](https://www.geeksforgeeks.org/legal/anti-trust-policy/)\n- [Modern Slavery](https://www.geeksforgeeks.org/legal/modern-slavery-policy/)\n\n## CONNECT PLATFORM POLICIES\n\n- [User Policy](https://www.geeksforgeeks.org/users-policy/)\n- [Mentor Policy](https://www.geeksforgeeks.org/mentor-policy/)\n\nCorporate & Communications Address:  \nA-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)\n\nRegistered Address:  \nK 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305"}
{"reference": "https://www.geeksforgeeks.org/tag/deep-learning/", "content": "# Deep Learning\n\n95 posts\n\n## Recent Articles\n\n### Inverse Reinforcement Learning\n**Last Updated:** 26 June 2025\n\nIn traditional reinforcement learning (RL), an agent learns a policy (behavior strategy) by maximizing a known reward function. Inverse Reinforcement Learning reverses this... [read more](https://www.geeksforgeeks.org/deep-learning/inverse-reinforcement-learning/)\n\n**Tags:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)\n\n### Behavioral Cloning in Reinforcement Learning\n**Last Updated:** 23 July 2025\n\nBehavioral Cloning (BC) is a core imitation learning technique in which an agent learns to perform a task by directly imitating expert behavior. Instead of learning through... [read more](https://www.geeksforgeeks.org/deep-learning/behavioral-cloning/)\n\n**Tags:** [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)\n\n### PixelRNN\n**Last Updated:** 23 July 2025\n\nPixelRNN is a deep generative model designed for image generation, particularly pixel-by-pixel modeling of images. The model uses Recurrent Neural Networks, a Deep Learning... [read more](https://www.geeksforgeeks.org/deep-learning/pixelrnn/)\n\n**Tags:** [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/) [GenAI](https://www.geeksforgeeks.org/tag/genai/)\n\n### Fine-Tuning using LoRA and QLoRA\n**Last Updated:** 20 June 2025\n\nFine tuning updates all the parameters of a pre-trained model to adapt it for a specific task, offering high accuracy but requiring significant computational resources and... [read more](https://www.geeksforgeeks.org/deep-learning/fine-tuning-using-lora-and-qlora/)\n\n**Tags:** [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### TensorFlow Playground: A walkthrough\n**Last Updated:** 23 July 2025\n\nTensorFlow Playground is an interactive web tool that lets users explore neural networks visually. It offers a hands-on interface to adjust neurons, layers, activation functions... [read more](https://www.geeksforgeeks.org/deep-learning/tensorflow-playground-a-walkthrough/)\n\n**Tags:** [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Deep Learning for Finance: A comprehensive guide\n**Last Updated:** 23 July 2025\n\nDeep learning is transforming the financial industry by enabling institutions to analyze massive, complex datasets, predict market trends, and manage risk with remarkable... [read more](https://www.geeksforgeeks.org/deep-learning/deep-learning-for-finance-a-comprehensive-guide/)\n\n**Tags:** [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Fine-Grained Image Classification\n**Last Updated:** 23 July 2025\n\nTraditional image classification divides images into generic classes (e.g., cats vs. dogs). On the other hand, fine-grained image classification (FGIC) tries to identify... [read more](https://www.geeksforgeeks.org/deep-learning/fine-grained-image-classification/)\n\n**Tags:** [Picked](https://www.geeksforgeeks.org/tag/picked/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### How to implement cost-sensitive learning in decision trees?\n**Last Updated:** 23 July 2025\n\nDecision trees are tools for classification, but they can struggle with imbalanced datasets where one class significantly outnumbers the other. Cost-sensitive learning is... [read more](https://www.geeksforgeeks.org/python/how-to-implement-cost-sensitive-learning-in-decision-trees/)\n\n**Tags:** [Python](https://www.geeksforgeeks.org/category/programming-language/python/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Machine Learning](https://www.geeksforgeeks.org/tag/machine-learning/)\n\n### NVIDIA Training and Certifications\n**Last Updated:** 23 July 2025\n\nWhen it comes to pushing the boundaries of AI and Deep Learning, NVIDIA stands at the forefront. Their comprehensive training and learning paths cater to both beginners and... [read more](https://www.geeksforgeeks.org/blogs/nvidia-courses-and-certifications/)\n\n**Tags:** [GBlog](https://www.geeksforgeeks.org/category/blogs/) [Nvidia](https://www.geeksforgeeks.org/tag/nvidia/) [Artificial Intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence/) [Artificial-intelligence](https://www.geeksforgeeks.org/tag/artificial-intelligence-2/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Spotlight](https://www.geeksforgeeks.org/tag/spotlight/) [GBlog 2024](https://www.geeksforgeeks.org/tag/gblog-2024/)\n\n### Integrating Deep Learning model With Django\n**Last Updated:** 23 July 2025\n\nIn this project, we will be integrating a deep learning model with the Django framework. This deep learning model converts greyscale images to colorful images. We will store... [read more](https://www.geeksforgeeks.org/deep-learning/integrating-deep-learning-model-with-django/)\n\n**Tags:** [Python Django](https://www.geeksforgeeks.org/tag/python-django/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/)\n\n### Best Deep Learning Courses Online with Certificates\n**Last Updated:** 23 July 2025\n\nAs the world becomes more technologically advanced, deep learning is playing a huge role in shaping the future. If you're interested in this exciting field, finding the best... [read more](https://www.geeksforgeeks.org/gfg-academy/best-deep-learning-courses-online-with-certificates/)\n\n**Tags:** [Picked](https://www.geeksforgeeks.org/tag/picked/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Best Courses](https://www.geeksforgeeks.org/tag/best-courses/) [GFG Academy](https://www.geeksforgeeks.org/category/gfg-academy/)\n\n### Feedforward Neural Network\n**Last Updated:** 26 July 2025\n\nFeedforward Neural Network (FNN) is a type of artificial neural network in which information flows in a single direction i.e from the input layer through hidden layers to the... [read more](https://www.geeksforgeeks.org/nlp/feedforward-neural-network/)\n\n**Tags:** [Picked](https://www.geeksforgeeks.org/tag/picked/) [Blogathon](https://www.geeksforgeeks.org/category/blogathon/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [NLP](https://www.geeksforgeeks.org/category/ai-ml-ds/nlp/) [AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/) [Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### Generative Models in AI: A Comprehensive Comparison of GANs and VAEs\n**Last Updated:** 23 July 2025\n\nThe world of artificial intelligence has witnessed a significant surge in the development of generative models, which have revolutionized the way we approach tasks like image... [read more](https://www.geeksforgeeks.org/deep-learning/generative-models-in-ai-a-comprehensive-comparison-of-gans-and-vaes/)\n\n**Tags:** [Picked](https://www.geeksforgeeks.org/tag/picked/) [Blogathon](https://www.geeksforgeeks.org/category/blogathon/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [Deep Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/deep-learning/) [AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/) [Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### What are Convolution Layers?\n**Last Updated:** 31 July 2025\n\nConvolution layers are key building blocks of convolutional neural networks (CNNs) which are used in computer vision and image processing. They apply convolution operations... [read more](https://www.geeksforgeeks.org/machine-learning/what-are-convolution-layers/)\n\n**Tags:** [Picked](https://www.geeksforgeeks.org/tag/picked/) [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [Blogathon](https://www.geeksforgeeks.org/category/blogathon/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [AI-ML-DS](https://www.geeksforgeeks.org/category/ai-ml-ds/) [Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n### Cora Dataset\n**Last Updated:** 23 July 2025\n\nThe Cora dataset stands as a fundamental resource in the field of graph machine learning, widely utilized for the development and benchmarking of various algorithms. Comprised... [read more](https://www.geeksforgeeks.org/machine-learning/cora-dataset/)\n\n**Tags:** [Picked](https://www.geeksforgeeks.org/tag/picked/) [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [Deep-Learning](https://www.geeksforgeeks.org/tag/deep-learning/) [DataSets](https://www.geeksforgeeks.org/tag/datasets/) [Data Science Blogathon 2024](https://www.geeksforgeeks.org/tag/data-science-blogathon-2024/)\n\n[1](https://www.geeksforgeeks.org/tag/deep-learning/page/1/?type=recent) [2](https://www.geeksforgeeks.org/tag/deep-learning/page/2/?type=recent) [3](https://www.geeksforgeeks.org/tag/deep-learning/page/3/?type=recent) [4](https://www.geeksforgeeks.org/tag/deep-learning/page/4/?type=recent) [5](https://www.geeksforgeeks.org/tag/deep-learning/page/5/?type=recent) [6](https://www.geeksforgeeks.org/tag/deep-learning/page/6/?type=recent) [7](https://www.geeksforgeeks.org/tag/deep-learning/page/7/?type=recent)"}
{"reference": "https://www.geeksforgeeks.org/python/numpy-tutorial/", "content": "# NumPy Tutorial - Python Library\n\n**Last Updated**: 12 Aug, 2025\n\nNumPy is a core Python library for numerical computing, built for handling large arrays and matrices efficiently.\n\n- **ndarray object** – Stores homogeneous data in n-dimensional arrays for fast processing.\n- **Vectorized operations** – Perform element-wise calculations without explicit loops.\n- **Broadcasting** – Apply operations across arrays of different shapes.\n- **Linear algebra functions** – Matrix multiplication, inversion, eigenvalues, etc.\n- **Statistical tools** – Mean, median, standard deviation, and more.\n- **Fourier transforms** – Fast computation for signal and image processing.\n- **Integration with other libraries** – Works seamlessly with Pandas, SciPy, and scikit-learn.\n\n> **Important Facts to Know**:\n> \n> - NumPy arrays are homogeneous, meaning all elements must be the same type, allowing efficient computation.\n> - Vectorized operations in NumPy can be 10 to 100 times faster than equivalent Python loops.\n\n## What is NumPy Used for?\n\nWith NumPy, you can perform a wide range of numerical operations, including:\n\n- Creating and manipulating arrays.\n- Performing element-wise and matrix operations.\n- Generating random numbers and statistical calculations.\n- Conducting linear algebra operations.\n- Working with Fourier transformations.\n- Handling missing values efficiently in datasets.\n\n## Why Learn NumPy?\n\n- NumPy speeds up math operations like addition and multiplication on large groups of numbers compared to regular Python.\n- It's good for handling large lists of numbers (arrays), so you don't have to write complicated loops.\n- It gives ready-to-use functions for statistics, algebra and random numbers.\n- Libraries like Pandas, SciPy, TensorFlow and many others are built on top of NumPy.\n- NumPy uses less memory and stores data more efficiently, which matters when working with lots of data.\n\n## NumPy Basics\n\nThis section covers the fundamentals of NumPy, including installation, importing the library and understanding its core functionalities. You will learn about the advantages of NumPy over Python lists and how to set up your environment for efficient numerical computing.\n\n- [Introduction to NumPy](https://www.geeksforgeeks.org/python/introduction-to-numpy/)\n- [Installing NumPy](https://www.geeksforgeeks.org/installation-guide/how-to-install-numpy-on-windows/)\n- [Understanding NumPy Arrays](https://www.geeksforgeeks.org/python/basics-of-numpy-arrays/)\n\n## NumPy Arrays\n\nNumPy arrays (ndarrays) are the backbone of the library. This section covers how to create and manipulate arrays effectively for data storage and processing.\n\n- [Creating NumPy Arrays](https://www.geeksforgeeks.org/numpy/different-ways-to-create-numpy-arrays-in-python/)\n- [Numpy Array Indexing](https://www.geeksforgeeks.org/python/numpy-indexing/) and [Slicing](https://www.geeksforgeeks.org/python/how-to-access-different-rows-of-a-multidimensional-numpy-array/)\n- [Reshaping](https://www.geeksforgeeks.org/python/reshape-numpy-array/) and [Resizing Arrays](https://www.geeksforgeeks.org/python/python-numpy-numpy-resize/)\n- [Stacking](https://www.geeksforgeeks.org/python/numpy-stack-in-python/) and [Splitting Arrays](https://www.geeksforgeeks.org/python/splitting-arrays-in-numpy/)\n- [Broadcasting in NumPy](https://www.geeksforgeeks.org/numpy/numpy-array-broadcasting/)\n\n## Mathematical Operations in NumPy\n\nThis section covers essential mathematical functions for array computations, including basic arithmetic, aggregation and mathematical transformations.\n\n- [Basic Arithmetic Operations](https://www.geeksforgeeks.org/numpy/numpy-arithmetic-operations/)\n- Aggregation Functions ([sum](https://www.geeksforgeeks.org/python/numpy-sum-in-python/), [mean](https://www.geeksforgeeks.org/python/numpy-mean-in-python/), [max](https://www.geeksforgeeks.org/python/numpy-maximum-in-python/), [min](https://www.geeksforgeeks.org/python/numpy-minimum-in-python/))\n- [Universal Functions in Numpy](https://www.geeksforgeeks.org/python/numpy-ufunc/)\n- [Mathematical Functions in Numpy](https://www.geeksforgeeks.org/python/numpy-mathematical-function/)\n\n## Linear Algebra with NumPy\n\nNumPy provides built-in functions for linear algebra operations essential for scientific computing and machine learning applications.\n\n- [Matrix Multiplication](https://www.geeksforgeeks.org/python/matrix-manipulation-python/) and [Manipulation](https://www.geeksforgeeks.org/python/matrix-manipulation-python/)\n- [Matrix & vector products in Numpy](https://www.geeksforgeeks.org/python/calculate-inner-outer-and-cross-products-of-matrices-and-vectors-using-numpy/)\n- [Determinants](https://www.geeksforgeeks.org/python/how-to-calculate-the-determinant-of-a-matrix-using-numpy/) and [Inverse of a Matrix](https://www.geeksforgeeks.org/numpy/how-to-inverse-a-matrix-using-numpy/)\n- [Inner](https://www.geeksforgeeks.org/numpy/compute-the-inner-product-of-vectors-for-1-d-arrays-using-numpy-in-python/) and [Outer Functions](https://www.geeksforgeeks.org/python/compute-the-outer-product-of-two-given-vectors-using-numpy-in-python/)\n- [Dot](https://www.geeksforgeeks.org/python/numpy-dot-python/) and [Vdot Functions](https://www.geeksforgeeks.org/python/numpy-vdot-python/)\n- [Eigenvalues and Eigenvectors](https://www.geeksforgeeks.org/engineering-mathematics/eigen-values/)\n\n## Random Number Generation and Statistics\n\nNumPy's random module provides a list of functions for generating random numbers, which are essential for simulations, cryptography and machine learning applications. It supports various probability distributions, such as normal, uniform and Poisson and enable statistical analysis.\n\n- [Generating Random Numbers](https://www.geeksforgeeks.org/python/random-sampling-in-numpy-randint-function/)\n- [Normal Distribution](https://www.geeksforgeeks.org/numpy/normal-distribution-in-numpy/)\n- [Binomial Distribution](https://www.geeksforgeeks.org/numpy/binomial-distribution-in-numpy/)\n- [Poisson Distribution](https://www.geeksforgeeks.org/python/numpy-random-poisson-in-python/)\n- [Uniform Distribution](https://www.geeksforgeeks.org/python/numpy-random-uniform-in-python/)\n- [Exponential Distribution](https://www.geeksforgeeks.org/python/numpy-random-exponential-in-python/)\n- [Chi-square Distribution](https://www.geeksforgeeks.org/python/numpy-random-chisquare-in-python/)\n- [Statistical Functions (mean, median, variance, standard deviation)](https://www.geeksforgeeks.org/tag/python-numpy-statistics-functions/)\n\n## Advanced NumPy Operations\n\nThis section covers advanced NumPy techniques to enhance performance and handle complex computations. It includes vectorized operations for speed optimization, memory management strategies and integration with Pandas for efficient data analysis.\n\n- [Vectorized Operations for Performance Optimization](https://www.geeksforgeeks.org/numpy/vectorized-operations-in-numpy/)\n- [Broadcasting in Numpy](https://www.geeksforgeeks.org/numpy/numpy-array-broadcasting/)\n- [Sparse Matrices in Numpy](https://www.geeksforgeeks.org/python/how-to-create-a-sparse-matrix-in-python/)\n- [Working with Images in Numpy](https://www.geeksforgeeks.org/python/image-processing-with-scipy-and-numpy-in-python/)\n\n## NumPy Quiz\n\nTest your knowledge of NumPy with this quiz, covering key topics such as array operations, mathematical functions and broadcasting.\n\n- [NumPy Quiz](https://www.geeksforgeeks.org/quizzes/python-numpy-quiz/)\n\nRefer to [Practice Exercises, Questions and Solutions](https://www.geeksforgeeks.org/python/python-numpy-practice-exercises-questions-and-solutions/) for hands-on numpy problems."}
{"reference": "https://www.geeksforgeeks.org/courses/maths-for-computer-science-skill-up", "content": "# Maths for Computer Science - Skill Up\n\n**Self-Paced Course**\n\n**Course Description**\n\nMaths for Computer Science builds a strong mathematical foundation for students and professionals. Covering Number Theory, Probability, Linear Algebra, and more, the course links theory to practical applications in cryptography, machine learning, and data analysis. Through clear lessons and real-world examples, learners gain the skills needed to solve complex computing problems.\n\n**Duration:** 7 Weeks\n\n**Interested:** 10k+ Geeks\n\n## Course Overview\n\nThis course is designed to provide computer science students with a robust mathematical foundation, encompassing critical areas such as Number Theory, Probability, Linear Algebra, Statistics, and more. It aims to equip learners with essential tools and concepts to address mathematical challenges in computer science effectively.\n\nThe course has each week dedicated to a specific mathematical domain. Daily topics are paired with daily practice quizzes.\n\n### Course Highlights\n\n- Understand number systems, primes, and modular arithmetic for cryptography and algorithm design.\n- Master random variables, distributions, and theorems like Bayes for machine learning applications.\n- Learn vectors, matrices, and transformations for graphics, AI, and optimization problems.\n- Gain skills in data analysis, hypothesis testing, and decision-making with real-world relevance.\n- Access curated GeeksforGeeks articles and problem sets for hands-on practice.\n- Build confidence for interviews and exams with a focus on mathematical problem-solving.\n\n## Course Content\n\n### 01 Number Theory\n\n- Introduction to number systems.\n- Types of number systems and conversions (decimal, binary, octal, hexadecimal).\n- Basic concepts including HCF, LCM, and Euclids division algorithm.\n- Primes, their significance in cryptography, and prime factorization.\n- Miscellaneous concepts like Catalan numbers, Fibonacci sequence, and the pigeonhole principle.\n- Modular arithmetic and its applications.\n- Foundational theorems such as the Chinese Remainder Theorem, Fermats Little Theorem, and Eulers Theorem.\n\n### 02 Probability\n\n- Introduction to probability, sample spaces, and event types.\n- Conditional probability and Bayes theorem.\n- Random variables, probability distributions, expected value, and variance.\n- Discrete probability distributions (uniform, binomial, Poisson).\n- Continuous probability distributions.\n- Law of large numbers.\n- Moment generating functions.\n\n### 03 Statistics\n\n- Introduction to statistics and its types.\n- Descriptive statistics for data summarization.\n- Inferential statistics for predictions and decision-making.\n- Central limit theorem and its importance. Hypothesis testing fundamentals.\n- Parametric methods (Z-test, T-test, ANOVA, Pearson correlation).\n- Non-parametric methods (Chi-square test, Mann-Whitney U test, Wilcoxon signed-rank test).\n\n### 04 Linear Algebra\n\n- Scalars, vectors, and matrices basics.\n- Vector operations (addition, dot product, cross product).\n- Types of matrices, matrix operations, and transformation matrices.\n- Linear transformations, eigenvalues, and eigenvectors.\n- Gaussian elimination and solving systems of linear equations.\n- Singular Value Decomposition (SVD) and LU decomposition.\n- Vector norms and vector spaces.\n\n## Frequently Asked Questions\n\n### 01 What prior knowledge is needed?\n\n### 02 Will this help with specific computer science topics?\n\n### 03 Who should take this course?"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/", "content": "# Machine Learning Interview Questions and Answers\n\nMachine Learning concepts form the foundation of how models are built, trained and evaluated. From understanding supervised and unsupervised learning, to working with algorithms like regression, decision trees and neural networks, every concept plays a role in solving real-world problems. In interviews, questions are often asked around these core ideas, testing both theoretical knowledge and practical application.\n\n## 1. What do you understand by Machine Learning (ML) and how does it differ from artificial intelligence (AI) and Data Science?\n\nMachine Learning (ML) is a branch of Artificial Intelligence that deals with building algorithms capable of learning from data. Instead of being explicitly programmed with fixed rules, these algorithms identify patterns in data and use them to make predictions or decisions that improve with experience.\n\n| Aspect | Artificial Intelligence (AI) | Machine Learning (ML) | Data Science |\n| --- | --- | --- | --- |\n| **Definition** | Broad field aiming to build systems that mimic human intelligence | Subset of AI that learns patterns from data for prediction or decision-making | Field focused on extracting insights and knowledge from data |\n| **Scope** | Reasoning, problem-solving, planning, natural language, robotics | Algorithms for classification, regression, clustering, etc. | Data collection, cleaning, analysis, visualization, ML and reporting |\n| **Techniques Used** | Expert systems, NLP, robotics, ML, deep learning | Regression, decision trees, neural networks, clustering | Statistics, ML, data visualization, domain knowledge |\n| **Example** | Chatbots, self-driving cars, expert systems | Spam detection, recommendation systems, fraud detection | Analyzing sales trends, customer segmentation, forecasting |\n\n## 2. What is overfitting in machine learning and how can it be avoided?\n\n**1. Overfitting:** It occurs when a model not only learns the true patterns in the training data but also memorizes the noise or random fluctuations. This results in high accuracy on training data but poor performance on unseen/test data.\n\n**Ways to Avoid Overfitting:**\n\n- **Early Stopping:** Stop training when validation accuracy stops improving, even if training accuracy is still increasing.\n- **Regularization:** Apply techniques like L1 (Lasso) or L2 (Ridge) regularization which add penalties to large weights to reduce model complexity.\n- **Cross-Validation:** Use k-fold cross-validation to ensure the model generalizes well.\n- **Dropout (for Neural Networks):** Randomly drop neurons during training to prevent over-reliance on specific nodes.\n- **Simpler Models:** Avoid overly complex models when simpler ones can explain the data well.\n\n**2. Underfitting**: It occurs when a model is too simple to capture the underlying patterns in the data. This leads to poor accuracy on both training and test data.\n\n**Ways to Avoid Underfitting:**\n\n- **Use a More Complex Model:** Choose models with higher complexity to learn pattern like decision trees, neural networks, etc.\n- **Add Relevant Features:** Include meaningful features that better represent the data.\n- **Reduce Regularization:** Too much regularization can restrict the model's ability to learn.\n- **Train Longer:** Allow the model more epochs or iterations to properly learn patterns.\n\n## 3. What is Regularization?\n\nRegularization is a technique used to reduce model complexity and prevent overfitting. It works by adding a penalty term to the loss function to discourage the model from assigning too much importance (large weights) to specific features. This helps the model generalize better on unseen data.\n\n**Ways to Apply Regularization:**\n\n- **L1 Regularization (Lasso):** Adds the absolute value of weights as a penalty which can shrink some weights to zero and perform feature selection.\n- **L2 Regularization (Ridge):** Adds the squared value of weights as a penalty which reduces large weights but doesn't eliminate them.\n- **Elastic Net:** Combines both L1 and L2 penalties to balance feature selection and weight reduction.\n- **Dropout (for Neural Networks):** Randomly drops neurons during training to avoid over-reliance on specific nodes.\n\n## 4. Explain Lasso and Ridge Regularization. How do they help in Elastic Net Regularization?\n\n**1. Lasso Regularization (L1):** Lasso adds a penalty equal to the absolute value of the model's weights to the loss function. It can shrink some weights to exactly zero, performing feature selection.\n\n**Formula:**\n\n> Lasso Loss = MSE + λ ∑_{i=1}^{n} ||w_i||\n\nWhere:\n\n- MSE = Mean Squared Error\n- w_i = model weights\n- λ = regularization strength\n\n**2. Ridge Regularization (L2):** It adds a penalty equal to the square of the model's weights to the loss function. It reduces large weights but does not set them to zero, helping generalization.\n\n**Formula:**\n\n> Ridge Loss = MSE + λ ∑_{i=1}^{n} w_i²\n\nWhere:\n\n- MSE = Mean Squared Error\n- w_i = model weights\n- λ = regularization strength\n\n**Key Differences:**\n\n- **Lasso (L1):** Can set weights to zero → feature selection. Use it when we have many irrelevant features.\n- **Ridge (L2):** Reduces weights but keeps all features → no feature elimination. Use when all features are useful but want to avoid overfitting.\n\n**3. Elastic Net Regularization:** Elastic Net combines both L1 (Lasso) and L2 (Ridge) penalties, balancing feature selection and weight reduction. It is especially useful when features are correlated, as it avoids Lasso's limitation of picking only one feature from a group.\n\n## 5. What are different Model Evaluation Techniques in Machine Learning?\n\nModel evaluation techniques are used to assess how well a machine learning model performs on unseen data. Choosing the right technique depends on the type of problem like classification, regression, etc and type of dataset we have.\n\n- **Train-Test Split:** Divide data into training and testing sets like 70:30 or 80:20 to evaluate model performance on unseen data. Here 70% data will be used for training and 30% will be used to test accuracy of model.\n- **Cross-Validation:** Split data into k folds, train on k-1 folds, validate on the remaining fold and average the results to reduce bias.\n- **Confusion Matrix (for Classification):** Counts True Positives, True Negatives, False Positives and False Negatives.\n- **Accuracy:** Proportion of correct predictions over total predictions.\n- **Precision:** Here correct positive predictions are divided by Total predicted positives.\n- **Recall (Sensitivity):** Here correct positive predictions are divided by Total actual positives.\n- **F1-Score:** Harmonic mean of precision and recall. It balances precision and recall.\n- **ROC Curve & AUC:** Measures model's ability to distinguish between classes. Here AUC is area under the ROC curve.\n- **Loss Functions (for Regression/Classification):** Quantifies prediction error to optimize model. It can include: Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), etc.\n\n## 6. Explain Confusion Matrix.\n\nA confusion matrix is a table used to evaluate the performance of a classification model. It compares the predicted labels with the actual labels, telling how well the model is performing and what types of errors it makes.\n\n*Confusion Matrix*\n\nHere:\n\n- **True Positives (TP):** Correctly predicted positive cases.\n- **True Negatives (TN):** Correctly predicted negative cases.\n- **False Positives (FP):** Negative cases incorrectly predicted as positive.\n- **False Negatives (FN):** Positive cases incorrectly predicted as negative.\n\nIt is used in metrics like Accuracy, Precision, Recall and F1-Score.\n\n## 7. What is the difference between precision and recall? How F1 combines both?\n\n**1. Precision:** It is the ratio between the true positives(TP) and all the positive examples (TP+FP) predicted by the model. In other words, precision measures how many of the predicted positive examples are actually true positives. It is a measure of the model's ability to avoid false positives and make accurate positive predictions.\n\n> Precision = TP / (TP + FP)\n\nExample: In spam detection, high precision means most emails marked as spam are truly spam.\n\n**2. Recall:** It calculate the ratio of true positives (TP) and the total number of examples (TP+FN) that actually fall in the positive class. Recall measures how many of the actual positive examples are correctly identified by the model. It is a measure of the model's ability to avoid false negatives and identify all positive examples correctly.\n\n> Recall = TP / (TP + FN)\n\nExample: In disease detection, high recall means most sick patients are correctly identified.\n\n**Key Difference:**\n\n- Precision is about being exact (avoiding false positives).\n- Recall is about being comprehensive (avoiding false negatives).\n\n**3. F1-Score (Balance of Both):** Used when both precision and recall matter.\n\n> F1 = 2 × (Precision × Recall) / (Precision + Recall)\n\n## 8. Different Loss Functions in Machine Learning\n\nLoss functions measure the error between the model's predicted output and the actual target value. They guide the optimization process during training. Some of them are:\n\n**1. Mean Squared Error (MSE):** Used in regression problem. It penalizes larger errors more heavily by squaring them.\n\n> MSE = (1/n) ∑_{i=1}^{n} (y_i - ŷ_i)²\n\n**2. Mean Absolute Error (MAE):** Used in regression as it takes absolute differences between predicted and actual values. It is less sensitive to outliers than MSE.\n\n> MAE = (1/n) ∑_{i=1}^{n} | y_i - ŷ_i |\n\n**3. Huber Loss:** It combines MSE and MAE making it less sensitive to outliers than MSE.\n\n**4. Cross-Entropy Loss (Log Loss):** Used in classification problem. It measures the difference between predicted probability distribution and actual labels.\n\n> CE = -(1/n) ∑_{i=1}^{n} [y_i log(ŷ_i) + (1-y_i) log(1-ŷ_i)]\n\n**5. Hinge Loss:** Used for classification with SVMs. It encourages maximum margin between classes.\n\n**6. KL Divergence:** Measures how one probability distribution differs from another hence used in probabilistic models.\n\n**7. Exponential Loss:** Used in boosting methods like AdaBoost; penalizes misclassified points more strongly.\n\n**8. R-squared (R²):** Used in regression and measures how well the model explains variance in the target variable.\n\n> R² = 1 - [∑_{i=1}^{n} (y_i - ŷ_i)² / ∑_{i=1}^{n} (y_i - ȳ)²]\n\n## 9. What is AUC–ROC Curve?\n\n**ROC Curve (Receiver Operating Characteristic):** The ROC curve is a graphical plot that shows the trade-off between True Positive Rate (TPR / Recall) and False Positive Rate (FPR) at different threshold values.\n\n- **TPR (Recall):** TPR = TP / (TP + FN)\n- **FPR:** FPR = FP / (FP + TN)\n\n**AUC (Area Under the Curve):** AUC is the area under the ROC curve. It represents the probability that a randomly chosen positive instance is ranked higher than a randomly chosen negative instance.\n\n- AUC = 1 → Perfect classifier\n- AUC = 0.5 → Random guessing\n- AUC < 0.5 → Worse than random\n\nROC shows performance across thresholds. AUC summarizes overall model performance into a single number.\n\n**Example:** If a medical test has an AUC of 0.90, it means there's a 90% chance that the model will rank a randomly chosen diseased patient higher than a healthy one.\n\n## 10. Is accuracy always a good metric for classification performance?\n\nNo, accuracy can be misleading, especially with imbalanced datasets. In such cases:\n\n- Precision and Recall provide better insight into model performance.\n- F1-score combines precision and recall as their harmonic mean, giving a balanced measure of model effectiveness, especially when the classes are imbalanced.\n\n## 11. What is Cross-Validation?\n\nCross-validation is a model evaluation technique used to test how well a machine learning model generalizes to unseen data. Instead of training and testing on a single split, the dataset is divided into multiple subsets (called folds) and the model is trained and tested multiple times on different folds.\n\n**How It Works:**\n\n1. Split the dataset into k folds like 5 or 10.\n2. Train the model on (k-1) folds and test it on the remaining fold.\n3. Repeat this process k times so that every fold is used for testing once.\n4. Take the average of all results as the final performance score.\n\n**Types of Cross-Validation:**\n\n- **k-Fold Cross-Validation:** Dataset is divided into k equal fold and training/testing is repeated k times.\n- **Stratified k-Fold:** Similar to k-Fold but keeps class distribution balanced (useful in classification).\n- **Leave-One-Out (LOO):** Special case where k = number of samples and every single point acts as a test set once.\n- **Hold-Out Method:** Simple train/test split and is considered a basic form of validation.\n\n## 12. Explain k-Fold Cross-Validation, Leave-One-Out (LOO) and Hold-Out Method.\n\n**1. k-Fold Cross-Validation:** The dataset is divided into k equal folds. The model is trained on (k-1) folds and tested on the remaining fold. This process is repeated k times, with each fold used once as the test set. The final score is the average of all k test results.\n\n> CV_error = (1/k) ∑_{i=1}^{k} error_i\n\n**2. Leave-One-Out Cross-Validation (LOO):** A special case of k-Fold where k = number of samples. Each observation is used once as the test set while the remaining data is used for training. It gives very accurate estimates but is computationally expensive for large datasets.\n\n**3. Hold-Out Method:** The simplest technique where the dataset is split into two parts: a training set and a testing set (e.g., 70% train, 30% test). The model is trained on the training set and evaluated on the test set. It is fast but may lead to biased results depending on the split.\n\n## 13. Difference Between Regularization, Standardization and Normalization\n\n**1. Regularization:** A technique used to reduce overfitting by adding a penalty term to the model's loss function, discouraging overly complex models. Examples are: L1 (Lasso), L2 (Ridge), Elastic Net.\n\nWorks on model parameters (weights).\n\n**2. Standardization:** A preprocessing step that rescales features so they have mean = 0 and standard deviation = 1\n\n> x' = (x - μ) / σ\n\nUseful for algorithms sensitive to feature scales like SVM, KNN, Logistic Regression, etc.\n\n**3. Normalization:** A preprocessing step that rescales feature values into a fixed range, usually [0, 1].\n\n> x' = (x - x_min) / (x_max - x_min)\n\nUseful when features have very different scales or units.\n\n| Aspect | Regularization | Standardization | Normalization |\n| --- | --- | --- | --- |\n| Purpose | Prevent overfitting | Rescale features (mean = 0, std = 1) | Rescale features to a range (e.g., [0,1]) |\n| Works On | Model weights | Input features | Input features |\n| Main Idea | Add penalty to loss function | Center and scale features | Shrink features into fixed range |\n| Example Techniques | L1, L2, Elastic Net | Z-score scaling | Min-Max scaling |\n| When to Use | High variance/overfitting | Algorithms needing Gaussian-like distribution | Features with different ranges/units |\n\n## 14. What is Feature Engineering in Machine Learning?\n\nFeature engineering is the process of creating, transforming or selecting relevant features from raw data to improve the performance of a machine learning model. Better features often lead to better model accuracy and generalization. It also reduces overfitting and make the model easier to interpret.\n\n**Key Steps in Feature Engineering:**\n\n- **Feature Creation:** Generate new features from existing data like extracting \"year\" or \"month\" from a date column.\n- **Feature Transformation:** Apply scaling, normalization or mathematical transformations (log, square root) to features.\n- **Feature Encoding:** Convert categorical variables into numerical form like one-hot encoding, label encoding.\n- **Feature Selection:** Identify and keep only the most relevant features using techniques like correlation analysis, mutual information or model-based importance scores.\n\nExample:\n\n- Raw data: Date of Birth → Feature engineered: Age\n- Raw data: Text review → Feature engineered: Sentiment score\n\n## 15. Difference between Feature Engineering and Feature Selection?\n\n| Aspect | Feature Engineering | Feature Selection |\n| --- | --- | --- |\n| **Definition** | Process of creating, transforming or deriving new features from raw data to improve model performance. | Process of selecting the most relevant features from the existing dataset to reduce noise and improve model performance. |\n| **Purpose** | To enhance or create meaningful features that the model can learn from. | To remove irrelevant or redundant features and simplify the model. |\n| **Process** | Involves feature creation, transformation, encoding, scaling, etc. | Involves statistical tests, correlation analysis, mutual information or model-based importance scores. |\n| **Output** | New or transformed features added to the dataset. | Subset of the original features retained for modeling. |\n| **Example** | Extracting `Age` from `Date of Birth or` generating sentiment scores from text. | Selecting top 10 features with highest importance from 50 features using Random Forest. |\n\n## 16. Feature Selection Techniques in Machine Learning\n\nFeature selection is the process of choosing the most relevant features from your dataset to improve model performance, reduce overfitting and simplify the model.\n\n**1. Filter Methods:** Filter methods evaluate each feature independently with target variable. Feature with high correlation with target variable are selected as it means this feature has some relation and can help us in making predictions. Here features are selected based on statistical measures without involving any machine learning model.\n\nExamples:\n\n- **Correlation Coefficient:** Remove features highly correlated with others.\n- **Chi-Square Test:** For categorical features.\n- **ANOVA F-Test:** For numerical features.\n\n**2. Wrapper Methods:** It uses different combination of features and compute relation between these subset features and target variable and based on conclusion addition and removal of features are done. Stopping criteria for selecting the best subset are usually pre-defined by the person training the model such as when the performance of the model decreases or a specific number of features are achieved.\n\nExamples:\n\n- **Forward Selection:** Start with no features and add one at a time.\n- **Backward Elimination:** Start with all features and remove one at a time.\n- **Recursive Feature Elimination (RFE):** Iteratively removes least important features using model weights.\n\n**3. Embedded Methods:** Embedded methods perform feature selection during the model training process allowing the model to select the most relevant features based on the training process dynamically.\n\nExamples:\n\n- **Lasso Regression (L1 regularization):** Can shrink some feature coefficients to zero.\n- **Decision Tree / Random Forest Feature Importance:** Select features based on importance scores learned during training.\n\n## 17. What is Dimensionality Reduction in Machine Learning?\n\nDimensionality reduction is the process of reducing the number of features (variables) in a dataset while retaining most of the important information. It helps in simplifying models, improving performance, reducing overfitting and speeding up computation. Feature selection and Engineering comes under this.\n\n- Reduces computational cost for high-dimensional datasets.\n- Helps visualize data in 2D or 3D space.\n- Reduces overfitting by removing irrelevant or noisy features.\n\n**Example:** A dataset has 100 features. Using PCA, it can be reduced to 10 principal components that capture 95% of the variance.\n\n## 18. What is Categorical Data and how to handle it?\n\nCategorical data refers to features that represent discrete values or categories, rather than continuous numerical values. Examples include gender (Male, Female), color (Red, Blue, Green) or product type (Electronics, Clothing).\n\nTypes of Categorical Data:\n\n- **Nominal**: Categories with no inherent order. Example: Red, Blue, Green.\n- **Ordinal**: Categories with a meaningful order. Example: Low, Medium, High.\n\nMachine learning models require numerical inputs, so categorical data needs to be handelled using encoding. Common techniques include:\n\n**1. Label Encoding:**\n\n- Converts each category into a unique integer.\n- Example: `Red=0, Blue=1, Green=2`.\n- Suitable for ordinal data.\n\n**2. One-Hot Encoding:**\n\n- Converts categories into binary vectors, creating a new column for each category.\n- Example: `Color` with `Red, Blue, Green` becomes three columns: `[1,0,0], [0,1,0], [0,0,1]`.\n- Suitable for nominal data.\n\n**3. Binary Encoding:**\n\n- Converts categories into binary code, reducing dimensionality compared to one-hot encoding.\n\n**4. Target / Mean Encoding:**\n\n- Replaces categories with mean of target variable for regression or probability of positive class in classification.\n\n## 19. Difference between label encoding and one hot encoding?\n\n| Aspect | Label Encoding | One-Hot Encoding |\n| --- | --- | --- |\n| **Definition** | Converts each category into a unique integer. | Converts categories into binary vectors with separate columns for each category. |\n| **Use Case** | Suitable for ordinal data (ordered categories). | Suitable for nominal data (unordered categories). |\n| **Example** | Color: Red=0, Blue=1, Green=2 | Color: Red → [1,0,0], Blue → [0,1,0], Green → [0,0,1] |\n| **Model Interpretation** | May introduce false ordinal relationship for nominal features. | Preserves categorical nature without implying order. |\n| **Output Dimension** | 1 column, integer values | N columns (N = number of categories) |\n| **Pros** | Simple, compact representation | Avoids false relationships between categories |\n| **Cons** | Can mislead models if data is nominal | Increases dimensionality for high-cardinality features |\n\n## 20. What is Upsampling and Downsampling?\n\nUpsampling and downsampling are techniques used to handle imbalanced datasets where the number of samples in different classes is unequal.\n\n**1. Upsampling (Oversampling):** Increases the number of samples in the minority class to balance the dataset.Techniques include:\n\n- **Random Oversampling:** Duplicate random samples from the minority class.\n- **SMOTE (Synthetic Minority Over-sampling Technique):** Generate synthetic samples by interpolating between existing minority samples.\n\n**2. Downsampling (Undersampling):** Reduces the number of samples in the majority class to balance the dataset. Techniques include:\n\n- **Random Undersampling:** Randomly remove samples from the majority class.\n- **Cluster-Based Undersampling:** Remove samples based on clustering to retain diversity.\n\n**Example:** We have a dataset of 1000 positive samples, 100 negative samples.\n\n- Upsampling create 900 additional negative samples.\n- Downsampling reduce positive samples to 100.\n\n## 21. Explain SMOTE method used to handle data imbalance\n\nSMOTE (Synthetic Minority Over-sampling Technique) creates synthetic data points for minority classes using linear interpolation between existing samples.\n\n- The model is trained on more diverse examples rather than duplicating existing points.\n- It may introduce noise into the dataset, potentially affecting model performance if overused.\n\n## 22. How to handle missing and duplicate values?\n\nMissing values are common in real-world datasets and can affect model performance. Techniques to Handle Missing Values are:\n\n**1. Remove Rows or Columns:**\n\n- Drop rows with missing values using `dropna()` in pandas.\n- Drop columns if most values are missing.\n\n**2. Imputation:**\n\n- **Mean/Median/Mode Imputation:** Replace missing values with mean/median (for numerical) or mode (for categorical).\n- **Forward/Backward Fill:** Fill missing values using previous or next valid value in time series data.\n- **Prediction-Based Imputation:** Predict missing values using a model trained on other features.\n\n**3. Flag Missing Values:**\n\n- Create a new binary column to indicate whether a value was missing.\n\nDuplicate rows can lead to biased or misleading results. Techniques to Handle Duplicates:\n\n1. **Identify Duplicates:** Use duplicated() in pandas to check for repeated rows.\n2. **Remove Duplicates:** Use drop_duplicates() in pandas to remove repeated rows.\n3. **Keep the Most Relevant Row:** Sometimes you may want to keep the latest or first occurrence based on a timestamp or priority column.\n\n## 23. What are outliers and how to handle them?\n\nOutliers are data points that differ significantly from other observations in the dataset. They can arise due to errors, variability in data or rare events.\n\n- Can skew statistics like mean and standard deviation.\n- Can mislead machine learning models, especially regression and distance-based algorithms.\n\n**Detection Methods:**\n\n- **Box Plot / IQR Method:** Identify points outside `Q1 - 1.5*IQR` or `Q3 + 1.5*IQR`.\n- **Z-Score Method:** Points with |z| > 3 are considered outliers.\n- **Visualization:** Scatter plots, histograms or violin plots.\n\n**Handling Methods:**\n\n- **Remove Outliers:** Delete extreme values if they are errors or irrelevant.\n- **Transform Data:** Apply log, square root or other transformations to reduce skewness.\n- **Cap/Floor Values:** Replace extreme values with upper/lower bounds (Winsorization).\n- **Use Robust Models:** Models like Decision Trees or Random Forests are less sensitive to outliers.\n\n## 24. Different Hypothesis in Machine Learning?\n\nIn machine learning, a hypothesis is a function or model that maps input features to output predictions. Different hypotheses represent different types of models or assumptions about the data.\n\n**1. Null Hypothesis (H₀):**\n\n- Assumes no effect or no relationship exists between features and target.\n- Often used in statistical testing to validate model assumptions.\n- Example: \"Feature X has no impact on predicting Y.\"\n\n**2. Alternative Hypothesis (H₁ or Ha):**\n\n- Assumes there is a relationship or effect.\n- Example: \"Feature X significantly affects predicting Y.\"\n\n**3. Parametric Hypotheses:**\n\n- Assume the data follows a known distribution and have fixed parameters.\n- Example: Linear regression assumes a linear relationship with parameters (weights).\n\n**4. Non-Parametric Hypotheses:**\n\n- Make no assumptions about the underlying data distribution.\n- Examples: Decision Trees, K-Nearest Neighbors.\n\n**5. Machine Learning Hypothesis Function (hθ):**\n\n- Represents the model used to make predictions.\n- Example: h_θ(x) = θ_0 + θ_1 x_1 + θ_2 x_2 + … + θ_n x_n\n- In supervised learning, the goal is to find the hypothesis that minimizes error on the training data.\n\n## 25. What is Bias-Variance tradeoff?\n\nThe bias-variance tradeoff is a fundamental concept in machine learning that describes the tradeoff between two sources of error that affect model performance.\n\n*Bias-Variance tradeoff*\n\n**1. Bias:**\n\n- Error due to wrong assumptions in the learning algorithm.\n- High bias means underfitting and model is too simple to capture patterns.\n- Example: Linear model trying to fit highly non-linear data.\n\n**2. Variance:**\n\n- Error due to model being too sensitive to small fluctuations in training data.\n- High variance means overfitting and model performs well on training data but poorly on unseen data.\n- Example: Deep decision tree memorizing training data.\n\n**3. Tradeoff:**\n\n- Decreasing bias usually increases variance and vice versa.\n- Our goal is to find a balance that minimizes total error.\n\n> Total Error = Bias² + Variance + Irreducible Error\n\n## 26. What is Hyperparameter Tuning in Machine Learning?\n\nHyperparameter tuning is the process of finding the best set of hyperparameters for a machine learning model to maximize performance. Hyperparameters are parameters set before training like learning rate, number of trees in Random Forest, regularization strength, etc that cannot be learned directly from the data.\n\nCommon Hyperparameter Tuning Methods are:\n\n- **Grid Search:** It tries all possible combinations of hyperparameters from a predefined set. It is simple and exhaustive, but computationally expensive for large search spaces.\n- **Random Search:** Randomly samples combinations of hyperparameters are taken from a given range. Often faster than grid search and can find good results in **fewer iterations**.\n- **Bayesian Optimization:** Builds a probabilistic model of the objective function and selects hyperparameters to maximize performance. Efficient for expensive models; balances exploration and exploitation.\n\n## 27. What is Linear Regression? What are its Assumption?\n\nLinear Regression is a supervised learning algorithm used to predict a continuous target variable based on one or more input features by fitting a linear relationship.\n\n> y = mx + c\n\nWhere:\n\n- y = predicted output\n- x = input feature\n- m = slope (coefficient)\n- c = intercept\n\n**Assumptions of Linear Regression**\n\n1. **Linearity:** Relationship between x and y is linear.\n2. **Independence:** Data points are independent.\n3. **Homoscedasticity:** Error terms have constant variance.\n4. **Normality of Errors:** Residuals follow a normal distribution.\n5. **No Multicollinearity:** Features should not be highly correlated.\n\n## 28. Explain how sigmoid function work in Logistic Regression and why it is not a Regrresion Model even though it name has it?\n\nIn logistic regression, we want to predict probabilities for binary outcomes (e.g., 0 or 1). The sigmoid function converts any real number into a value between 0 and 1, making it suitable for probabilities.\n\nSigmoid Equation:\n\n> σ(z) = 1 / (1 + e^{-z})\n\n- Despite the name, logistic regression is used for classification, not regression. As it does not predict continuous values like linear regression, but instead predicts probabilities.\n- A threshold (e.g., 0.5) is applied to classify outcomes as 0 or 1.\n\n## 29. How to choose an optimal number of clusters?\n\n- **[Elbow Method](https://www.geeksforgeeks.org/machine-learning/elbow-method-for-optimal-value-of-k-in-kmeans/):** Plot the explained variance or within-cluster sum of squares (WCSS) against the number of clusters. The \"elbow\" point where the curve starts to flatten, indicates the optimal number of clusters.\n- **[Silhouette Score](https://www.geeksforgeeks.org/machine-learning/silhouette-algorithm-to-determine-the-optimal-value-of-k/):** Measures how similar each point is to its own cluster compared to other clusters. A higher silhouette score indicates better-defined clusters. The optimal number of clusters is the one with the highest average silhouette score.\n- **Gap Statistic:** Compares the clustering result with a random clustering of the same data. A larger gap between the real and random clustering suggests a more appropriate number of clusters.\n\n## 30. What is Multicollinearity and Why is it a Problem?\n\nMulticollinearity occurs when two or more independent features are highly correlated with each other in a dataset. This means one feature can be linearly predicted from another with high accuracy. It can cause problems like:\n\n1. **Unstable Coefficients:** Makes regression coefficients unreliable and highly sensitive to small changes in data.\n2. **Interpretation Difficulty:** Hard to determine the individual effect of each feature on the target variable.\n3. **Reduced Model Performance:** May not affect prediction accuracy much, but impacts the explainability of the model.\n4. **Inflated Variance:** Leads to high standard errors in coefficient estimates.\n\n**Detection Methods:**\n\n- **Correlation Matrix:** Check for high correlation between features.\n- **Variance Inflation Factor (VIF):** A VIF > 5 (or 10) usually indicates strong multicollinearity.\n\n**Solution:**\n\n- Remove or combine correlated features.\n- Use Principal Component Analysis (PCA) or other dimensionality reduction techniques.\n- Apply regularization methods like Ridge regression.\n\n## 31. What is Variance Inflation Factor?\n\nThe Variance Inflation Factor (VIF) is a statistical measure used to detect multicollinearity in regression models. It shows how much the variance of a regression coefficient is inflated because of correlation with other independent variables.\n\n> VIF_i = 1 / (1 - R_i²)\n\nHere R_i² is coefficient of determination when the i^{th} feature is regressed on all other features.\n\n**Interpretation:**\n\n- **VIF = 1:** No correlation with other features.\n- **1 < VIF < 5:** Moderate correlation, usually acceptable.\n- **VIF > 5 (or 10):** High multicollinearity i.e it is problematic and need to be resolved.\n\n## 32. What is Information Gain and Entropy in Decision Tree?\n\n**1. Entropy**\n\n- Entropy is a measure of impurity or randomness in a dataset.\n- If all samples belong to the same class → entropy = 0 (pure).\n- If classes are equally mixed → entropy is high.\n\n> Entropy(S) = - ∑_{i=1}^{c} p_i log₂(p_i)\n\nWhere:\n\n- p_i = proportion of samples belonging to class i\n- c = number of classes\n\n**2. Information Gain**\n\n- Information Gain measures the reduction in entropy when a dataset is split based on a feature.\n- Higher information gain means the feature is better at splitting the data.\n\n> IG(S, A) = Entropy(S) - ∑_{v ∈ Values(A)} (|S_v| / |S|) Entropy(S_v)\n\nWhere:\n\n- S = dataset\n- A = feature used for split\n- S_v = subset of S where feature A = v\n\n**Relationship between Entropy and Information Gain:**\n\n- Entropy should be minimized i.e less impurity after splitting.\n- Information Gain should be maximized i.e best feature chosen for splitting.\n- Decision Trees always pick the feature with the highest Information Gain to reduce entropy the most.\n\n## 33. How to Prevent Overfitting in Decision Trees?\n\nDecision trees are prone to overfitting because they can grow very deep and capture noise along with patterns. To prevent overfitting we can use following techniques:\n\n1. **Limit Tree Depth:** Restrict max_depth so the tree doesn't grow too complex.\n2. **Minimum Samples for Split/Leaf:** Set min_samples_split or min_samples_leaf to ensure splits happen only when enough data is present.\n3. **Pruning:** Remove branches that add little value (pre-pruning or post-pruning).\n4. **Feature Selection:** Use only relevant features to avoid unnecessary splits.\n5. **Use Ensemble Methods:** Techniques like Random Forest and Gradient Boosting average multiple trees to reduce variance.\n6. **Cross-Validation:** Helps monitor performance on unseen data and avoid overly complex trees.\n\n## 34. What is Pruning in Decision Trees?\n\nPruning is the process of removing unnecessary branches from a decision tree that do not provide significant predictive knowledge. It helps make the tree simpler, smaller and less overfitted. It improves generalization on unseen data and makes the model more interpretable and efficient. We have 2 types of pruning:\n\n**1. Pre-Pruning (Early Stopping):**\n\n- Stop growing the tree early by setting constraints like max_depth, min_samples_split or min_samples_leaf.\n- Prevents the tree from becoming too complex.\n\n**2. Post-Pruning:**\n\n- Grow the full tree first, then remove branches that have little impact on accuracy.\n- Example: Cost Complexity Pruning (CCP) balances tree accuracy and size using a penalty term.\n\n## 35. Explain ID3 and CART\n\n**1. ID3 (Iterative Dichotomiser 3):** ID3 is a decision tree algorithm used only for classification. It uses Entropy and Information Gain to decide which feature should split the dataset. It works like:\n\n- Calculate entropy of the dataset.\n- For each feature, calculate information gain.\n- Choose the feature with the highest information gain for the split.\n- Repeat this process until all records are classified or stopping conditions are met.\n\n**2. CART (Classification and Regression Trees):** CART can be used for both classification and regression problems. It uses Gini Index for classification and Mean Squared Error (MSE) for regression. It works like:\n\n- For each feature, calculate Gini Index (for classification) or MSE (for regression).\n- Select the feature with the lowest impurity.\n- Split the dataset into two branches (CART always creates binary trees).\n- Repeat the process until stopping conditions are met.\n\n| Feature | **ID3** | **CART** |\n| --- | --- | --- |\n| **Used for** | Classification only | Classification & Regression |\n| **Split Criterion** | Information Gain (Entropy) | Gini Index (classification), MSE (regression) |\n| **Output** | Multi-way split possible | Always binary split (2 branches) |\n| **Handling Data** | Categorical mainly | Both numerical and categorical |\n\n## 36. Explain Naive Bayes and Bayes' Theorem.\n\nBayes' Theorem calculates the probability of an event based on prior knowledge of related events.\n\n> P(A|B) = (P(B|A) · P(A)) / P(B)\n\nWhere:\n\n- P(A∣B): Posterior probability (probability of A given B).\n- P(B∣A): Likelihood (probability of B given A).\n- P(A): Prior probability of A.\n- P(B): Evidence or probability of B.\n\nNaive Bayes is a classification algorithm based on Bayes' theorem. It assumes that all features are independent (naive assumption). It is widely used in weather forecast and classifying emails as spam or not spam. Its working is:\n\n1. Calculate prior probability of each class.\n2. Compute likelihood of features for each class.\n3. Apply Bayes' theorem to get posterior probability.\n4. Assign the class with the highest posterior probability.\n\n## 37. What are the assumptions of Naive Bayes?\n\nNaive Bayes is based on a few key assumptions that simplify calculations:\n\n1. **Feature Independence:** All features are assumed to be independent of each other given the class label.\n2. **All Features Contribute Equally:** Each feature contributes equally and independently to the outcome.\n3. **Categorical or Conditional Probability:** Features can be categorical or continuous, but for continuous data, it's assumed to follow a probability distribution (like Gaussian).\n4. **Correctly Labeled Data:** The training dataset is assumed to be accurately labeled, because incorrect labels affect probability estimates.\n\n## 38. What are the types of Naive Bayes algorithm?\n\nThe main types of Naive Bayes algorithms are:\n\n- **Gaussian Naive Bayes:** Assumes continuous features follow a normal (Gaussian) distribution. Often used for features like height, weight or temperature.\n- **Multinomial Naive Bayes:** Works with discrete count data such as word counts in text classification (e.g., spam detection).\n- **Bernoulli Naive Bayes:** Suitable for binary features (0 or 1) like whether a word occurs in a document or not.\n- **Categorical Naive Bayes:** Used when features are categorical (like color: red, green, blue) rather than numeric.\n\n## 39. Explain K-Nearest Neighbors (KNN) working.\n\nK-Nearest Neighbors (KNN) is a supervised learning algorithm used for classification and regression. It predicts the output of a data point based on the majority class or average value of its K nearest neighbors. KNN is non-parametric algorithm and performance depends on K value and distance metric.\n\n**How KNN works:**\n\n1. Choose the number of neighbors K.\n2. Calculate the distance (e.g., Euclidean) between the new data point and all points in the training set.\n3. Select the K nearest neighbors based on distance.\n4. For classification, assign the most frequent class among neighbors. For regression, take the average value of neighbors.\n\n## 40. Why is KNN a lazy algorithm?\n\nK-Nearest Neighbors (KNN) is called a lazy learning algorithm because it does not learn an explicit model during training. Instead, it stores all training data and waits until a query (test data) is given to make predictions.\n\n- No training phase and all computation happens at prediction time.\n- Memory-intensive because it stores the entire training dataset.\n- Simplicity makes it easy to implement but can be slow for large datasets.\n\n## 41. How does the K value affect KNN?\n\nA small K value makes KNN sensitive to noise and can lead to overfitting. A large K value smooths decision boundaries but can cause underfitting by ignoring local patterns. Choosing the right K balances overfitting and underfitting, often determined using cross-validation.\n\n## 42. What are the different distance metrics in Machine Learning?\n\n- **Euclidean Distance:** Straight-line distance between two points in space.\n- **Manhattan Distance:** Sum of absolute differences of coordinates.\n- **Minkowski Distance:** Generalized form of Euclidean and Manhattan distances.\n- **Cosine Similarity:** Measures the cosine of the angle between two vectors (used for text or high-dimensional data).\n- **Hamming Distance:** Number of positions at which corresponding elements differ (used for categorical or binary data).\n- **Mahalanobis Distance:** Accounts for correlations between variables and useful for multivariate data.\n\n## 43. How to find the optimal value of K in KNN?\n\nDifferent techniques to find the optimal K include:\n\n- **Cross-Validation:** Test multiple K values using k-fold cross-validation and pick the one with the best validation performance.\n- **Elbow Method:** Plot error rate versus K and choose the K at the \"elbow\" point where error stabilizes.\n- **Silhouette Score:** Evaluate clustering quality (for KNN in clustering contexts) to select K with the best score.\n- **Gap Statistic:** Compare intra-cluster variation with a reference null distribution to choose K.\n- **Grid Search:** Systematically test a range of K values and select the best based on performance metrics.\n- **Trial and Error:** Manually test different K values and evaluate model accuracy (useful for small datasets).\n\n## 44. What is KNN Imputer and how does it work?\n\nKNN Imputer fills missing values by referencing the k nearest neighbors of a data point based on a distance metric (e.g., Euclidean distance).\n\n- **Neighborhood-based Imputation:** Finds k closest points to the missing value.\n- **Imputation:** Uses the mean or median of neighbors to fill the missing value.\n- **Distance Parameter:** k defines how many neighbors are considered and the distance metric controls similarity.\n\n## 45. What are the different distance metrics in Machine Learning?\n\nDistance metrics measure how similar or dissimilar two data points are. They are widely used in clustering, K-NN and other ML algorithms. Different metrics work better depending on the type of data and problem. Common Distance Metrics:\n\n**1. Euclidean Distance:**\n\n- Straight-line distance between two points in space.\n- Most commonly used for continuous data.\n\n**2. Manhattan Distance (L1 Norm):**\n\n- Sum of absolute differences between coordinates.\n- Works well when you want to penalize differences equally across dimensions.\n\n**3. Minkowski Distance:**\n\n- Generalization of Euclidean and Manhattan distances.\n- Can be tuned with a parameter **p**: p=1 → Manhattan, p=2 → Euclidean.\n\n**4. Cosine Similarity / Cosine Distance:**\n\n- Measures the angle between two vectors, not magnitude.\n- Useful for text data, document similarity or high-dimensional sparse data.\n\n**5. Jaccard Distance:**\n\n- Measures dissimilarity between sets.\n- Often used for binary or categorical features.\n\n## 46. What is the decision boundary in SVM?\n\nIn Support Vector Machine (SVM), the decision boundary is the line (in 2D) or hyperplane (in higher dimensions) that separates data points of different classes. It is chosen so that the margin which is the distance between the hyperplane and the nearest data points, called support vectors is maximized. The decision boundary in SVM is the hyperplane that best separates the classes while maintaining the largest possible margin for better generalization.\n\n## 47. Does SVM only work with linear data points?\n\nNo, SVMs are not limited to linear data. While a linear SVM works well when data is linearly separable, for non-linear data SVM uses the kernel trick. Kernels like polynomial, RBF or sigmoid transforms the data into a higher-dimensional space where a linear separation becomes possible.\n\n## 48. What is the kernel trick?\n\nThe kernel trick in SVM is a technique that allows the algorithm to handle non-linear data by transforming it into a higher-dimensional space where it becomes linearly separable. Instead of explicitly computing the transformation, the kernel function computes the similarity between data points in the transformed space hence making the process efficient.\n\n**Popular kernel functions in SVM:**\n\n- **Linear Kernel:** Works well when the data is linearly separable or when the number of features is very large like text classification. It is fast and simple.\n- **Polynomial Kernel:** Useful when the relationship between features is non-linear but still polynomial in nature. Example: classifying data that follows circular or curved boundaries.\n- **RBF (Radial Basis Function) Kernel / Gaussian Kernel:** Best for highly complex and non-linear data where no clear linear boundary exists. It is the most commonly used kernel in practice.\n- **Sigmoid Kernel:** Behaves similarly to neural networks and can be used for certain datasets, but it is less common compared to RBF and polynomial kernels.\n\n## 49. What is Ensemble Learning\n\nEnsemble learning is a technique in Machine Learning where multiple models (often called weak learners) are combined to produce a stronger and more accurate model. Instead of relying on a single model, ensemble methods aggregate the predictions from several models to improve performance, reduce errors and handle overfitting.\n\n**Different Techniques of Ensemble Learning:**\n\n- **Bagging (Bootstrap Aggregating):** Builds several models on random subsets of data and averages their predictions. Example: Random Forest.\n- **Boosting:** Trains models sequentially where each new model focuses on correcting the errors of the previous ones. Example: AdaBoost, XGBoost.\n- **Stacking:** Trains multiple base models and combines predictions from multiple models using another model (meta-learner) to make the final prediction.\n- **Voting:** Combines results from different models and chooses the majority vote (for classification) or average (for regression).\n\n## 50. Explain Bagging and Boosting.\n\n1. **Bagging (Bootstrap Aggregating):**\n\n- Bagging trains multiple models in parallel using random subsets of the training data (with replacement).\n- Each model gives a prediction and results are combined by majority voting (classification) or averaging (regression).\n- It reduces variance and prevents overfitting.\n- Example: Random Forest.\n\n**2. Boosting:**\n\n- Boosting trains models sequentially where each new model focuses on correcting the mistakes of the previous ones.\n- Models are combined by assigning higher weights to more accurate models.\n- It reduces bias and improves accuracy but can overfit if not controlled.\n- Examples: AdaBoost, Gradient Boosting, XGBoost.\n\n## 51. What is Random Forest?\n\nRandom Forest is an ensemble learning method that builds multiple decision trees and combines their results to improve accuracy and stability. Instead of relying on a single decision tree, it takes the majority vote (for classification) or average (for regression) of many trees.\n\n- Handles large datasets with higher accuracy than a single decision tree.\n- Reduces overfitting by combining multiple trees.\n- Works well with both categorical and numerical data.\n- Provides feature importance, helping to understand which variables are most influential.\n\n**How Random Forest Works:**\n\n1. Creates multiple random subsets of the dataset using bootstrapping (sampling with replacement).\n2. Builds a decision tree for each subset, but at each node, it selects a random subset of features instead of using all features.\n3. Each tree makes a prediction independently.\n4. The final prediction is made by combining all tree outputs (majority voting for classification, average for regression).\n\n## 52. What is Bootstrapping?\n\nBootstrapping is a sampling technique used in statistics and machine learning where we create multiple datasets by randomly selecting data points with replacement from the original dataset.\n\n- \"With replacement\" means the same data point can appear multiple times in a new sample.\n- Each bootstrap sample is usually the same size as the original dataset.\n- It helps to estimate the variability and improve model stability by training on different random samples.\n- Used in ensemble methods like Bagging and Random Forest to reduce variance and prevent overfitting.\n\n**Example**: If the dataset is [1, 2, 3, 4] then one bootstrap sample could be [2, 4, 2, 1] and another could be [3, 1, 4, 4].\n\n## 53. What are some of the hyperparameters of the random forest regressor which help to avoid overfitting?\n\nThe important hyperparameters of a Random Forest Regressor that help to control overfitting are:\n\n- **max_depth**: Restricts how deep a tree can grow. Smaller depth reduces complexity and prevents overfitting.\n- **n_estimators**: Number of trees in the forest. More trees usually improve stability, but too many just increase computation without reducing overfitting.\n- **min_samples_split**: Minimum samples required to split a node. Higher values prevent trees from creating overly specific splits.\n- **min_samples_leaf**: Minimum samples required at a leaf node. Larger values create smoother predictions and avoid capturing noise.\n- **max_leaf_nodes**: Limits the number of leaf nodes, thereby controlling tree growth and depth.\n- **max_features**: Number of features considered for splitting at each node. Using fewer features introduces randomness and helps reduce overfitting.\n- **bootstrap**: Whether to sample data with replacement for each tree. Bootstrapping introduces diversity in trees, reducing overfitting.\n- **max_samples**: If bootstrap is True, this defines how many samples are drawn to train each tree. Controlling this adds more randomness.\n\n## 54. Whether decision tree or random forest is more robust to outliers\n\nDecision trees are somewhat sensitive to outliers, as extreme values can influence the splits. Random forests, being an ensemble of multiple decision trees, aggregate results from several trees which reduces the impact of outliers. Therefore, random forests are generally more robust to outliers compared to a single decision tree.\n\n## 55. How does Random Forest ensure diversity among trees?\n\n- **Bagging (Bootstrap Aggregating):** Each tree is trained on a random subset of the data.\n- **Feature Randomness:** Each split considers a random subset of features, preventing trees from being identical.\n\n## 56. Explain AdaBoost, XGBoost and CatBoost.\n\n### 1. AdaBoost (Adaptive Boosting)\n\n- Works by combining multiple weak learners (usually shallow decision trees).\n- Each new learner focuses more on the misclassified samples of the previous learners by assigning higher weights to them.\n- Final prediction is a weighted majority vote (classification) or weighted sum (regression).\n- **Best used when:** You have simple models and want to improve them by focusing on difficult cases.\n\n### 2. XGBoost (Extreme Gradient Boosting)\n\n- An optimized implementation of Gradient Boosting with high performance and regularization features.\n- Builds trees sequentially where each new tree corrects errors of the previous ones by minimizing a differentiable loss function.\n- Includes regularization terms (L1 and L2) to avoid overfitting.\n- Highly efficient, parallelizable and widely used in competitions.\n- **Best used when:** You need fast, accurate models for structured/tabular data.\n\n### 3. CatBoost (Categorical Boosting)\n\n- A gradient boosting algorithm designed to handle categorical features directly without needing extensive preprocessing like one-hot encoding.\n- Uses ordered boosting to reduce prediction shift (bias caused by using the same data for building and training).\n- Often requires less tuning and works well.\n- **Best used when:** Dataset has many categorical features and minimal preprocessing is preferred.\n\n## 57. What is the difference between Gradient Boosting and CatBoost?\n\n| Feature | Gradient Boosting | CatBoost |\n| --- | --- | --- |\n| **Handling Categorical Data** | Needs manual preprocessing like Label Encoding or One-Hot Encoding. | Handles categorical features natively, i.e no need for extra encoding. |\n| **Boosting Type** | Uses standard boosting where new models are trained sequentially on residuals. | Uses Ordered Boosting to prevent prediction shift (overfitting from using same data in training). |\n| **Training Speed** | Slower if dataset is large and categorical preprocessing is heavy. | Faster training for categorical-heavy datasets since encoding is avoided. |\n| **Overfitting Control** | May overfit if not tuned properly. | More robust against overfitting due to ordered boosting and symmetric trees. |\n| **Best Use Case** | General-purpose tabular datasets with numerical data. | Datasets with many categorical features (e.g., e-commerce, text-based or survey data). |\n\n## 58. Explain K-Means Clustering\n\nClustering is an unsupervised learning technique where data is grouped into clusters such that:\n\n- Points in the same cluster are more similar to each other.\n- Points in different clusters are more dissimilar from each other.\n\nK-Means is a popular clustering algorithm that divides the dataset into K clusters. Each cluster is represented by its centroid (average of all data points in that cluster). The goal is to minimize the distance of points from their cluster centroids. It is widely used in customer segmentation, image compression, anomaly detection and pattern recognition.\n\n- It works well when clusters are spherical and well-separated.\n- Sensitive to the initial placement of centroids.\n- Requires predefining K which can be chosen using methods like Elbow Method or Silhouette Score.\n- Can struggle with non-linear or overlapping clusters.\n\n**How K-Means Works:**\n\n1. Choose the number of clusters K.\n2. Randomly initialize K centroids.\n3. Assign each data point to the nearest centroid (cluster assignment).\n4. Recalculate centroids as the mean of all points in a cluster.\n5. Repeat steps 3–4 until centroids no longer change (convergence).\n\n**Example**: If K=3 and you feed customer purchase data, K-Means may group customers into 3 clusters like \"low spenders\" \"medium spenders\" and \"high spenders.\"\n\n## 59. What is the concept of convergence in K-means?\n\nConvergence occurs when centroids stabilize and data point assignments no longer change. Conditions for Convergence:\n\n- Proper initialization (e.g., k-means++)\n- Data naturally forms well-separated clusters\n- Correct choice of number of clusters (k)\n- Setting maximum iterations and tolerance for centroid changes\n\n## 60. What is the advanced version of K-Means?\n\nWhile K-Means is simple and widely used, it has limitations like sensitivity to outliers, need to predefine K and difficulty handling non-spherical clusters. Several advanced versions and alternatives improve upon it:\n\n**1. K-Medoids (PAM – Partitioning Around Medoids):**\n\n- Instead of using the mean as the cluster center, it uses an actual data point (medoid).\n- More robust to outliers compared to K-Means.\n\n**2. K-Means++:**\n\n- An improved version of K-Means initialization.\n- Chooses initial centroids more carefully which leads to better convergence and avoids poor clustering results.\n\n**3. Mini-Batch K-Means:**\n\n- Uses small random samples (mini-batches) of data instead of the entire dataset.\n- Much faster and scalable for large datasets.\n\n**4. Fuzzy C-Means (Soft K-Means):**\n\n- Instead of hard assignment, each point has a probability of belonging to multiple clusters.\n- Useful when clusters overlap.\n\n## 61. Explain K-Means++ and Fuzzy C-Means\n\n### 1. K-Means++\n\n- K-Means++ is an improved version of the standard K-Means algorithm.\n- The main improvement is in centroid initialization i.e instead of picking centroids randomly, it chooses them far apart from each other.\n- This reduces the chances of poor clustering and improves convergence speed.\n- Works the same as K-Means after initialization: assigns points to the nearest centroid and updates centroids iteratively.\n- **Best for:** General clustering problems where standard K-Means may converge to a local minimum.\n\n### 2. Fuzzy C-Means (FCM)\n\n- Fuzzy C-Means is a soft clustering algorithm, unlike K-Means which assigns points to one cluster only.\n- Each data point has a membership probability for each cluster, ranging between 0 and 1.\n- Centroids are computed based on weighted membership values of points.\n- Useful when clusters overlap or when strict cluster boundaries are unrealistic.\n- **Best for:** Image segmentation, medical data or any scenario where a point can belong partially to multiple clusters.\n\n## 62. What is Hierarchical Clustering?\n\nHierarchical clustering is an unsupervised clustering technique that builds a hierarchy of clusters, either by merging smaller clusters into bigger ones or splitting larger clusters into smaller ones. It produces a dendrogram which is a tree-like diagram showing the arrangement of clusters. Distance metrics (Euclidean, Manhattan) and linkage methods (single, complete, average) determine how clusters are merged or split.\n\nUnlike K-Means, it does not require predefining the number of clusters. Types of Hierarchical Clustering:\n\n### 1. Agglomerative Clustering (Bottom-Up)\n\n- It uses a bottom-up approach by merging small clusters into bigger ones.\n- At each step, it merges the two closest clusters based on a chosen distance metric (e.g., Euclidean, Manhattan).\n- The process continues until all points are merged into a single cluster or a stopping criterion is met.\n- Produces a dendrogram showing how clusters are combined.\n- **Pros:** Easy to understand, no need to predefine number of clusters.\n- **Cons:** Can be computationally expensive for large datasets.\n\n### 2. Divisive Clustering (Top-Down)\n\n- It is a top-down approach and it splits large clusters into smaller ones.\n- At each step, it splits the cluster into smaller clusters based on dissimilarity.\n- Continues splitting until each point forms its own cluster or a stopping criterion is met.\n- Produces a dendrogram that can be cut at different levels to choose the number of clusters.\n- **Pros:** Can reveal the overall hierarchical structure clearly.\n- **Cons:** Rarely used in practice because it is more computationally intensive than agglomerative clustering.\n\n## 63. Explain Linkage Methods in Hierarchical Clustering\n\nIn hierarchical clustering, linkage methods determine how the distance between clusters is calculated when merging or splitting them. The choice of linkage affects the shape and structure of the resulting clusters. Common Linkage Methods are:\n\n**1. Single Linkage (Nearest Neighbor):**\n\n- Distance between two clusters = shortest distance between any two points, one from each cluster.\n- Can result in \"chaining effect\" where clusters may become long and stretched.\n\n**2. Complete Linkage (Furthest Neighbor):**\n\n- Distance between two clusters = largest distance between any two points, one from each cluster.\n- Produces compact, tightly bound clusters, less sensitive to outliers.\n\n**3. Average Linkage:**\n\n- Distance between two clusters = average distance between all pairs of points from both clusters.\n- Balances the properties of single and complete linkage, producing moderately compact clusters.\n\n**4. Centroid Linkage:**\n\n- Distance between clusters = distance between the centroids (mean points) of the clusters.\n- Can handle larger datasets but may sometimes cause inversions in dendrograms.\n\n**5. Ward's Linkage:**\n\n- Merges clusters to minimize the total within-cluster variance.\n- Produces clusters that are roughly equal in size and very compact.\n\n## 64. Explain DBSCAN and OPTICS\n\n**1. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**\n\nDBSCAN is a density-based clustering algorithm that groups together points that are closely packed in space and labels points in low-density regions as noise or outliers. It is particularly useful for discovering clusters of arbitrary shapes without needing to predefine the number of clusters. The algorithm relies on two key parameters:\n\n- `eps` (maximum distance for neighborhood points)\n- `minPts` (minimum points required to form a dense region).\n\n**Working of DBSCAN:**\n\n- Start with an unvisited point.\n- If the point has at least `minPts` within distance `eps`, it becomes a core point and a new cluster starts.\n- Add all points density-reachable from the core point to the cluster.\n- Repeat the process for all unvisited points until all points are either clustered or marked as noise.\n\n**Advantages:**\n\n- Detects clusters of any shape.\n- Identifies outliers/noise automatically.\n- No need to predefine the number of clusters.\n\n**Disadvantages:**\n\n- Sensitive to the choice of `eps` and `minPts`.\n- Struggles with clusters of varying density.\n- Computationally expensive for very large datasets.\n\n### 2. OPTICS (Ordering Points To Identify the Clustering Structure)\n\nOPTICS is an extension of DBSCAN designed to handle clusters with varying densities. Instead of producing flat clusters, it creates an ordering of points based on reachability distances, allowing detection of clusters at different density levels. This produces a reachability plot which can be used to identify hierarchical cluster structures.\n\n**Working of OPTICS:**\n\n- Compute the core distance for each point (distance to its `minPts`-th neighbor).\n- Calculate the reachability distance from each point to its neighbors.\n- Order points based on reachability distance to form a reachability plot.\n- Identify clusters as valleys in the reachability plot representing dense regions.\n\n**Advantages:**\n\n- Handles clusters with varying densities effectively.\n- Can detect hierarchical structures of clusters.\n- Identifies outliers/noise.\n\n**Disadvantages:**\n\n- More computationally intensive than DBSCAN.\n- Reachability plot interpretation can be complex for large datasets.\n\n## 65. Explain GMM, DPMM and Affinity Propagation\n\n### 1. GMM (Gaussian Mixture Model)\n\nGMM is a probabilistic clustering algorithm that assumes data points are generated from a mixture of several Gaussian distributions with unknown parameters. Unlike K-Means which assigns each point to a single cluster, GMM assigns a probability of belonging to each cluster. It is more flexible and can model elliptical clusters rather than only spherical ones.\n\n**Working of GMM:**\n\n- Initialize parameters (means, covariances and mixing coefficients).\n- Use the Expectation-Maximization (EM) algorithm to iteratively update.\n- **E-step:** Compute probabilities of each point belonging to each cluster.\n- **M-step:** Update parameters to maximize the likelihood based on these probabilities.\n- Repeat until convergence.\n\n**Advantages:**\n\n- Handles clusters with different shapes, sizes and orientations.\n- Provides soft clustering, giving probabilities instead of hard assignments.\n\n**Disadvantages:**\n\n- Requires specifying the number of clusters in advance.\n- Sensitive to initialization and may converge to local optima.\n\n### 2. DPMM (Dirichlet Process Mixture Model)\n\nDPMM is a non-parametric Bayesian clustering algorithm which is an extension of GMM. It does not require predefining the number of clusters. Instead, it uses a Dirichlet Process to allow the number of clusters to grow with the data.\n\n**Working of DPMM:**\n\n- Start with a potentially infinite number of clusters.\n- Assign data points probabilistically to existing clusters or create a new cluster based on the Dirichlet Process.\n- Use Bayesian inference (e.g., Gibbs sampling) to update cluster assignments.\n\n**Advantages:**\n\n- Automatically determines the optimal number of clusters.\n- Handles complex and evolving datasets.\n\n**Disadvantages:**\n\n- Computationally intensive due to Bayesian inference.\n- More complex to implement and interpret compared to GMM.\n\n### 3. Affinity Propagation\n\nAffinity Propagation is a message-passing clustering algorithm that identifies exemplars which are representative points for each cluster. Unlike K-Means or GMM, it does not require specifying the number of clusters.\n\n**Working of Affinity Propagation:**\n\n- Initialize similarity scores between all pairs of points.\n- Exchange responsibility and availability messages iteratively:\n- **Responsibility:** How suitable a point is as an exemplar for another point.\n- **Availability:** How appropriate it would be for a point to choose another point as its exemplar.\n- After convergence, select exemplars and assign points to the nearest exemplar.\n\n**Advantages:**\n\n- Automatically finds the number of clusters.\n- Works well with non-spherical clusters.\n- No need for initialization like K-Means.\n\n**Disadvantages:**\n\n- High memory usage for large datasets due to similarity matrix.\n- Slower for very large datasets.\n\n## 66. Explain Association Rule Mining\n\nAssociation Rule Mining is a data mining technique used to discover relationships or patterns among items in large datasets, particularly transactional data. It identifies rules that show how the presence of certain items in a transaction implies the presence of other items. It helps finding hidden patterns in large datasets and is useful for recommendations, cross-selling and promotions. It uses:\n\n- **Support:** Fraction of transactions that contain the itemset.\n- **Confidence:** Likelihood that the consequent occurs when the antecedent occurs.\n- **Lift:** Measures how much more often the antecedent and consequent occur together than expected if independent.\n\n**Working Steps:**\n\n1. Find frequent itemsets that meet a minimum support threshold using Apriori or FP-Growth.\n2. Generate association rules from these frequent itemsets that satisfy a minimum confidence threshold.\n3. Optionally, calculate lift to measure rule strength.\n\n**Example:** Suppose a small grocery dataset has transactions:\n\n| Transaction ID | Items Bought |\n| --- | --- |\n| 1 | Milk, Bread |\n| 2 | Milk, Diaper, Beer |\n| 3 | Bread, Diaper, Milk |\n| 4 | Bread, Beer |\n\n- **Rule:** {Milk, Bread} → {Diaper}\n- **Support:** 1/4 = 25% (1 transaction contains all three items)\n- **Confidence:** 1/2 = 50% (2 transactions contain Milk and Bread, only 1 also contains Diaper)\n- **Lift:** Confidence / Support of Diaper = 0.5 / 0.5 = 1\n\n## 67. Explain Apriori Algorithm and FP-Growth Algorithm\n\n### 1. Apriori Algorithm\n\nApriori is a classic algorithm for association rule mining. It identifies frequent itemsets in transactional datasets and generates strong rules based on minimum support and confidence thresholds.\n\n**Working Steps:**\n\n1. Scan the dataset to find all frequent 1-itemsets that meet the minimum support.\n2. Generate candidate 2-itemsets from the frequent 1-itemsets and count their occurrences.\n3. Repeat the process to generate k-itemsets until no more frequent itemsets can be found.\n4. From frequent itemsets, generate association rules that satisfy minimum confidence.\n\n### 2. FP-Growth Algorithm (Frequent Pattern Growth)\n\nFP-Growth is an efficient alternative to Apriori. Instead of generating candidate itemsets, it uses a compressed data structure called FP-Tree to store transactions.It is faster than Apriori for large datasets and requires fewer scans of the dataset. It handles large transaction datasets efficiently.\n\n**Working Steps:**\n\n1. Build an FP-Tree by scanning the dataset once to store frequent items in a compact tree structure.\n2. Recursively extract frequent itemsets from the FP-Tree using a divide-and-conquer approach.\n3. Generate association rules from the frequent itemsets.\n\n## 68. Explain Content-Based and Collaborative Filtering Recommendation Systems\n\n**1. Content-Based Filtering**: It recommends items to a user based on the features of items they have liked in the past. It analyzes item attributes like genre, category, keywords or specifications and matches them with the user's preferences.\n\n- Can recommend items without knowing item features.\n- Can provide serendipitous recommendations that are different from what the user already knows.\n- Struggles with cold start problem (new users or new items).\n- Requires large user interaction data to be effective.\n\n**Working:**\n\n- Represent items using a feature vector.\n- Compare the feature vectors of new items with items the user liked using similarity metrics (e.g., cosine similarity).\n- Recommend items with the highest similarity scores.\n\nFor example, a user watches movies with action and sci-fi genres. The system recommends other action or sci-fi movies based on these features.\n\n**2. Collaborative Filtering**: It recommends items based on user behavior and interactions, rather than item features. It assumes that users with similar tastes in the past will like similar items in the future.\n\n- Can recommend items without knowing item features.\n- Can provide serendipitous recommendations that are different from what the user already knows.\n- Struggles with cold start problem (new users or new items).\n- Requires large user interaction data to be effective.\n\n**Working:**\n\n- **User-Based CF:** Finds users similar to the target user and recommends items they liked.\n- **Item-Based CF:** Finds items similar to those the user liked and recommends them.\n\nFor example, user A and user B both liked movies X and Y. User A liked movie Z, so movie Z is recommended to User B.\n\n## 69. Explain the EM Algorithm\n\nThe Expectation-Maximization (EM) algorithm is a statistical technique used to find maximum likelihood estimates of parameters in models with latent (hidden) variables. It is widely used in clustering like Gaussian Mixture Models, missing data imputation and probabilistic models.\n\n- Can handle missing or incomplete data.\n- Works well for probabilistic models and mixture models.\n- Can converge to local maxima instead of the global maximum which can cause a problem.\n- Sensitive to initial parameter values.\n\nThe EM algorithm works iteratively in two main steps:\n\n**1. Expectation Step (E-step):**\n\n- Estimate the probability that each data point belongs to each cluster (or hidden state) using the current parameters.\n- Essentially, calculate expected values of the latent variables given the observed data.\n\n**2. Maximization Step (M-step):**\n\n- Update the model parameters to maximize the likelihood using the probabilities calculated in the E-step.\n- This step refines estimates of parameters like means, variances and mixture coefficients in clustering.\n\n**3. Repeat** the E-step and M-step until the parameters converge or the likelihood improvement is below a threshold.\n\n## 70. Explain Markov Model and Hidden Markov Model (HMM)\n\n**1. Markov Model (MM)**: A Markov Model is a probabilistic model that represents a system which moves between states with certain probabilities. The key property is the Markov property which states that the next state depends only on the current state, not on the past history.\n\n- Simple and mathematically tractable.\n- Useful for modeling sequential data where future depends only on present.\n- Cannot model systems where the next state depends on more than just the current state.\n\n**Working:**\n\n- Define a set of states.\n- Define transition probabilities between states.\n- Predict the next state based on the current state using these probabilities.\n\nExample: Weather prediction: If today is **sunny**, the probability that tomorrow is sunny or rainy depends only on **today's weather**, not on previous\n\n**2. Hidden Markov Model (HMM)**: It is an extension of Markov Model where the states are hidden (not directly observable) and we only observe emissions or outputs that depend probabilistically on these hidden states.\n\n- Can model sequential data with hidden processes.\n- Widely used in speech recognition, bioinformatics and NLP.\n- Requires training to estimate transition and emission probabilities.\n- Computationally more complex than basic Markov Models.\n\n**Working:**\n\n- Define hidden states and observable outputs.\n- Define transition probabilities between hidden states and emission probabilities from states to observations.\n- Use algorithms like Forward-Backward or Viterbi to infer hidden states from observed data.\n\nExample: In speech recognition the actual phonemes (hidden states) are not observed, but the audio signal (observations) is observed. HMM predicts the sequence of phonemes from the signal.\n\n## 71. Explain PCA (Principal Component Analysis)\n\nPrincipal Component Analysis (PCA) is a dimensionality reduction technique used in machine learning and statistics. It transforms a high-dimensional dataset into a lower-dimensional space while preserving as much variance (information) as possible. PCA is widely used for visualization, noise reduction and feature extraction.\n\n- Reduces computational complexity by lowering dimensions.\n- Removes redundant or correlated features.\n- Helps in visualizing high-dimensional data.\n- Principal components may lack interpretability.\n- Assumes linear relationships between features.\n- Sensitive to scaling of features and standardization is necessary.\n\n**Working of PCA:**\n\n1. Standardize the data to have mean 0 and variance 1.\n2. Compute the covariance matrix of the features.\n3. Calculate the eigenvalues and eigenvectors of the covariance matrix.\n4. Eigenvectors define the directions (principal components).\n5. Eigenvalues indicate the amount of variance in each direction.\n6. Select top k principal components with the highest eigenvalues.\n7. Transform the original data onto the new k-dimensional space.\n\n**Example:**\n\n- Dataset with features like height, weight, age and income.\n- PCA can reduce it to 2 or 3 principal components that capture most of the variance for visualization or modeling.\n\n## 72. Why does PCA maximize variance in the data?\n\nPCA focuses on directions with highest variance, as variance represents information content. By projecting data onto these directions:\n\n- Information is preserved while reducing dimensionality.\n- Less important features with low variance are discarded, simplifying the data.\n\n## 73. Explain NMF, LDA and t-SNE\n\n**1. NMF (Non-Negative Matrix Factorization)**: NMF is a dimensionality reduction and feature extraction technique where a non-negative matrix is factorized into two lower-rank non-negative matrices. It is often used for topic modeling, image processing and recommendation systems.\n\n- Produces interpretable components since values are non-negative.\n- Useful in text mining and image decomposition.\n- Sensitive to initialization.\n- May converge to local minima.\n\n**Working:**\n\n- Input matrix V (e.g., document-term matrix) is approximated as V ≈ W · H where W and H are non-negative matrices.\n- W represents basis features and H represents coefficients for reconstructing the original data.\n- Iteratively update W and H to minimize reconstruction error.\n\n**2. LDA (Latent Dirichlet Allocation)**: LDA is a probabilistic topic modeling algorithm used to discover hidden topics in a collection of documents. Each document is represented as a mixture of topics and each topic is a distribution over words.\n\n- Discovers hidden thematic structures in large text corpora.\n- Can handle unlabeled data effectively.\n- Assumes bag-of-words, ignoring word order.\n- Choosing the number of topics is often subjective.\n\n**Working:**\n\n- Assign each word in a document to a topic randomly initially.\n- Iteratively update topic assignments using Dirichlet priors to maximize the likelihood of observed words.\n- After convergence, output: topic distribution per document or word distribution per topic.\n\n**3. t-SNE (t-Distributed Stochastic Neighbor Embedding):** It is a non-linear dimensionality reduction technique mainly used for visualizing high-dimensional data in 2D or 3D space. It preserves local structure (similar points stay close) while reducing dimensions.\n\n- Excellent for visualizing clusters in high-dimensional data.\n- Preserves local neighborhoods well.\n- Computationally expensive for large datasets.\n- Does not preserve global distances.\n- Results can vary depending on perplexity and initialization.\n\n**Working:**\n\n- Compute pairwise similarities between points in high-dimensional space.\n- Define similarities in lower-dimensional space.\n- Minimize Kullback-Leibler divergence between the two distributions using gradient descent.\n\n## 74. Explain Manifold Learning and Its Techniques\n\nManifold Learning is a non-linear dimensionality reduction technique used to uncover the low-dimensional structure (manifold) embedded in high-dimensional data. The idea is that high-dimensional data often lies on a lower-dimensional manifold and learning this structure helps in visualization, feature extraction and noise reduction. Key Techniques in Manifold Learning:\n\n**1. Isomap (Isometric Mapping):**\n\n- Preserves the geodesic (shortest path) distances between points on the manifold.\n- Good for unfolding non-linear structures in high-dimensional data.\n- Example: Mapping a Swiss roll dataset to a flat 2D plane.\n\n**2. Locally Linear Embedding (LLE):**\n\n- Preserves local relationships among neighboring points.\n- Each point is expressed as a linear combination of its neighbors, then projected to a lower-dimensional space while preserving these relationships.\n- Works well when data lies on a smooth manifold.\n\n**3. t-SNE (t-Distributed Stochastic Neighbor Embedding):**\n\n- Focuses on preserving local neighborhoods while reducing dimensions for visualization.\n- Maps similar points close together in 2D or 3D for cluster visualization.\n\n**4. UMAP (Uniform Manifold Approximation and Projection):**\n\n- Preserves both local and some global structures.\n- Faster than t-SNE for large datasets and useful for visualizing clusters.\n\n**5. Multidimensional Scaling (MDS):**\n\n- Preserves pairwise distances between points while reducing dimensions.\n- Can work for both linear and non-linear data depending on distance metric.\n\n## 75. Explain Time Series Analysis and Forecasting\n\nTime Series Analysis is the study of data points collected sequentially over time. It focuses on understanding patterns, trends, seasonality and other temporal structures in data. Common applications include stock prices, weather data, sales trends and sensor readings.\n\nForecasting is the process of predicting future values based on historical time series data. Time series forecasting helps in decision-making, resource planning and trend prediction.\n\n- Captures temporal patterns and dependencies in data.\n- Helps in planning, inventory management and forecasting future trends.\n- Requires large historical data for accurate predictions.\n- Sensitive to outliers and sudden changes in data.\n- Modeling seasonality and trends can be complex.\n\n**Key Components of Time Series:**\n\n1. **Trend:** Long-term increase or decrease in data (e.g., yearly sales growth).\n2. **Seasonality:** Repeating patterns at fixed intervals (e.g., monthly or yearly).\n3. **Cyclic Patterns:** Fluctuations without fixed periodicity (e.g., economic cycles).\n4. **Noise:** Random variations or irregular fluctuations.\n\n## 76. Explain ARIMA and SARIMA Models\n\n**1. ARIMA (AutoRegressive Integrated Moving Average)**: It is a popular statistical model for time series forecasting, especially when the data is non-stationary. It combines three components:\n\n1. **AR (AutoRegressive):** Uses past values of the series to predict the current value.\n2. **I (Integrated):** Uses differencing to make the series stationary (remove trends).\n3. **MA (Moving Average):** Uses past forecast errors to improve prediction.\n\n**Notation:** ARIMA(p, d, q)\n\n- **p:** Number of lag observations in AR component.\n- **d:** Degree of differencing to make series stationary.\n- **q:** Number of lagged forecast errors in MA component.\n\n**Advantages:**\n\n- Effective for non-stationary time series.\n- Captures trend and autocorrelation in data.\n\n**Disadvantages:**\n\n- Assumes linear relationships.\n- Does not handle seasonality directly.\n\n**Example:** ARIMA forecasting monthly sales of a product without strong seasonality.\n\n**2. SARIMA (Seasonal ARIMA)**: It extends ARIMA to handle seasonal effects in time series. It includes seasonal components along with non-seasonal ARIMA components.\n\n**Notation:** SARIMA(p, d, q)(P, D, Q, m)\n\n- **p, d, q:** Non-seasonal ARIMA parameters.\n- **P, D, Q:** Seasonal AR, differencing and MA parameters.\n- **m:** Number of periods in a season (e.g., 12 for monthly data with yearly seasonality).\n\n**Advantages:**\n\n- Handles both trend and seasonality.\n- Widely used for seasonal sales, weather and demand forecasting.\n\n**Disadvantages:**\n\n- More complex to tune than ARIMA.\n- Requires enough seasonal data for accurate modeling.\n\n**Example:** SARIMA forecasting electricity demand which shows yearly seasonal patterns.\n\n## 77. Explain Exponential Smoothing in Time Series\n\nExponential Smoothing is a time series forecasting method that gives more weight to recent observations while gradually decreasing the weight for older observations. It is widely used for short-term forecasting because it reacts quickly to changes in data.\n\n- Simple and computationally efficient.\n- Reacts quickly to recent changes in the data.\n- Works well for short-term forecasting.\n- Not ideal for complex patterns with irregular fluctuations.\n- Requires careful tuning of smoothing parameters.\n\nFor example, Predicting next month's sales based on recent monthly sales, giving higher weight to the last few months.\n\nTypes of Exponential Smoothing are:\n\n**1. Simple Exponential Smoothing (SES):**\n\n- Used for data without trend or seasonality.\n- Forecast is a weighted average of past observations, with weights decreasing exponentially for older data.\n- Formula: F_{t+1} = α · Y_t + (1 - α) · F_t\n- Here α (alpha) is Smoothing factor between 0 and 1.\n\n**2. Holt's Linear Exponential Smoothing:**\n\n- Used for data with trend but no seasonality.\n- Extends SES by adding a trend component.\n- Forecast formula: F_{t+h} = L_t + h · T_t\n- Here L_t is Level at time t and T_t Trend at time t.\n\n**3. Holt-Winters Exponential Smoothing:**\n\n- Used for data with trend and seasonality.\n- Can be additive (seasonal effect is constant) or multiplicative (seasonal effect changes proportionally).\n- Forecast formula (additive):\n- Here S is Seasonal component and m is Season length.\n\n## 78. What is the concept drift in ML?\n\nConcept drift refers to the change in the statistical properties of data (input or target variable) over time which causes a trained model to become less accurate because it was built on old data patterns.\n\n**Example**: A spam detection model trained on last year's emails may fail when spammers change their techniques this year.\n\n**Types of Concept Drift:**\n\n- **Sudden Drift:** The data distribution changes abruptly.\n- **Gradual Drift:** The change happens slowly over time.\n- **Recurring Drift:** Old patterns reappear after some time.\n\n**Handling Concept Drift:**\n\n- Regularly retraining the model with new data.\n- Using adaptive learning algorithms that update as new data arrives.\n\n## 79. What is Reinforcement Learning?\n\nReinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent takes actions, receives feedback in the form of rewards or penalties and adjusts its behavior to maximize long-term rewards.\n\n- **Agent:** The learner or decision-maker.\n- **Environment:** The system the agent interacts with.\n- **State:** Current situation of the agent in the environment.\n- **Action:** Choice made by the agent.\n- **Reward:** Feedback signal for the action taken.\n- **Policy:** Strategy that defines the agent's actions in given states.\n\n**Example:**\n\n- A robot learning to walk.\n- A self-driving car deciding when to stop or accelerate.\n- A game-playing AI improves its moves through trial and error.\n\nRL is about learning by trial and error with feedback, aiming to maximize cumulative rewards over time.\n\n## 80. What is a Markov Decision Process (MDP)?\n\nA Markov Decision Process (MDP) is a mathematical framework used in Reinforcement Learning to model decision-making situations where outcomes are partly random and partly under the control of an agent. It provides a structured way to describe environments in terms of states, actions, rewards and transitions, assuming the Markov property i.e the future state depends only on the current state and action, not on past states.\n\n**Components of MDP:**\n\n- **States (S):** All possible situations"}
{"reference": "https://www.geeksforgeeks.org/courses/aptitude-and-reasoning-skill-up", "content": "# Aptitude and Reasoning - Skill Up\n\n## Self-Paced Course\n\n**Course Description**\n\nThe Aptitude and Reasoning Course is a complete 9-week program designed to develop critical thinking, problem-solving, and analytical skills. This structured course helps learners with the techniques to crack competitive exams, aptitude tests, and real-world decision-making scenarios. Covering quantitative aptitude, logical reasoning, and verbal ability, this program provides a thorough foundation for mastering aptitude and reasoning skills.\n\n**Duration:** 9 Weeks\n\n**Interested:** 29k+ interested Geeks\n\n## Course Overview\n\nThis 9-week aptitude and reasoning program combines theoretical concepts, practical problem-solving exercises, and quizzes to develop experience in aptitude and reasoning. Participants will learn strategies to tackle complex problems, improve time management, and enhance logical and analytical thinking. By the end, learners will be well-prepared to succeed in aptitude tests and apply reasoning skills in professional and academic contexts.\n\n### Course Highlights\n\n* Master quantitative aptitude with techniques for efficient calculations\n* Develop logical reasoning skills for pattern recognition and critical analysis\n* Enhance verbal ability for comprehension, vocabulary, and sentence structuring\n* Practice data interpretation and problem-solving with real-world scenarios\n* Solve puzzles and logical problems to boost cognitive abilities\n* Gain confidence through mock tests and performance analysis\n* Apply reasoning skills to competitive exam formats and case studies\n* Learn time-bound strategies to optimize performance under pressure\n\n## Course Content\n\n### 01 Quantitative Aptitude (Part 1)\n\n* Number systems, divisibility rules, and properties\n* Calculating LCM and HCF, Applications in Problem-Solving\n* Percentage calculations, increase/decrease, and applications\n* Ratios, proportions, and variation problems\n* Cost price, selling price, and profit/loss calculations\n* Mean, weighted average, and related problems\n* Age-based problems and logical approaches\n* Practice: Problem sets and timed quizzes\n\n### 02 Quantitative Aptitude (Part 2)\n\n* Simple interest formulas and applications\n* Compound interest formulas and calculations\n* Mixture problems and alligation techniques\n* Work efficiency, wages distribution, and related problems\n* Problems on pipes filling and emptying tanks\n* Speed, distance, and relative motion problems\n* Upstream, downstream, and stream-based calculations\n* Practice: Problem sets and timed exercises\n\n### 03 Quantitative Aptitude (Part 3)\n\n* Race and relative speed problems\n* Linear equations, quadratic equations, and algebraic identities\n* Basic trigonometry and height/distance problems\n* Area and perimeter of 2D shapes (triangles, circles, etc.)\n* Volume and surface area of 3D shapes (cubes, cylinders, etc.)\n* Lines, angles, triangles, and polygons\n* Arrangements and selections\n* Practice: Problem sets and timed quizzes\n\n### 04 Quantitative Aptitude (Part 4)\n\n* Basic probability concepts and problems\n* Clock problems and angle calculations\n* Arithmetic and geometric progressions\n* Logarithm properties and problem-solving\n* Techniques for quick calculations of Simplifications and approximations\n* Tables, bar graphs, pie charts, and caselets\n* Practice: Data interpretation sets and mock test analysis\n* Comprehensive test covering all quantitative aptitude topics\n\n## Frequently Asked Questions\n\n### 01 What are the prerequisites for this course?\n\n### 02 Will this course help me with specific competitive exams?\n\n### 03 How much time should I dedicate to the course each week?\n\n### 04 Are there any resources provided for practice?"}
{"reference": "https://www.geeksforgeeks.org/deep-learning/deep-learning-tutorial/", "content": "# Deep Learning Tutorial\n\nDeep Learning is a subset of Artificial Intelligence (AI) that helps machines to learn from large datasets using multi-layered neural networks. It automatically finds patterns and makes predictions and eliminates the need for manual feature extraction. Deep Learning tutorial covers the basics to advanced topics making it perfect for beginners and those with experience.\n\n## Introduction to Neural Networks\n\nNeural Networks are fundamentals of deep learning inspired by human brain. It consists of layers of interconnected nodes or \"neurons\" each designed to perform specific calculations. These nodes receive input data, process it through various mathematical functions and pass the output to subsequent layers.\n\n### Basic Components of Neural Networks\n\nThe basic components of neural network are:\n\n- Layers in Neural Networks\n- Weights and Biases\n- Forward Propagation\n- Activation Functions\n- Loss Functions\n- Backpropagation\n- Learning Rate\n\n### Optimization Algorithm in Deep Learning\n\nOptimization algorithms in deep learning are used to minimize the loss function by adjusting the weights and biases of the model. The most common ones are:\n\n- Optimization algorithms in deep learning\n- Gradient Descent\n- Stochastic Gradient Descent (SGD)\n- Batch Normalization\n- Mini-batch Gradient Descent\n- Adam (Adaptive Moment Estimation)\n- Momentum-based Gradient Optimizer\n- Adagrad Optimizer\n- RMSProp Optimizer\n\nA deep learning framework provides tools and APIs for building and training models. Popular frameworks like TensorFlow, PyTorch and Keras simplify model creation and deployment.\n\n> For more details you can refer to: [What is a Deep Learning Framework?](https://www.geeksforgeeks.org/deep-learning/deep-learning-frameworks/)\n\n## Types of Deep Learning Models\n\nLets see various types of Deep Learning Models:\n\n### 1. Convolutional Neural Networks (CNNs)\n\nConvolutional Neural Networks (CNNs) are a class of deep neural networks that are designed for processing grid-like data such as images. They use convolutional layers to automatically detect patterns like edges, textures and shapes in the data.\n\n- Deep Learning Algorithms\n- Convolutional Neural Networks (CNNs)\n- Basics of Digital Image Processing\n- Importance for CNN\n- Padding\n- Convolutional Layers\n- Pooling Layers\n- Fully Connected Layers\n- Backpropagation in CNNs\n- CNN based Image Classification using PyTorch\n- CNN based Images Classification using TensorFlow\n\n**CNN Based Architectures:** There are various architectures in CNNs that have been developed for specific kinds of problems such as:\n\n- Convolutional Neural Network (CNN) Architectures\n- LeNet-5\n- AlexNet\n- VGGnet\n- VGG-16 Network\n- GoogLeNet/Inception\n- ResNet (Residual Network)\n- MobileNet\n\n### 2. Recurrent Neural Networks (RNNs)\n\nRecurrent Neural Networks (RNNs) are a class of neural networks that are used for modeling sequence data such as time series or natural language.\n\n- Recurrent Neural Networks (RNNs)\n- How RNN Differs from Feedforward Neural Networks\n- Backpropagation Through Time (BPTT)\n- Vanishing Gradient and Exploding Gradient Problem\n- Training of RNN in TensorFlow\n- Sentiment Analysis with RNN\n\n**Types of Recurrent Neural Networks:** There are various types of RNN which are as follows:\n\n- Types of Recurrent Neural Networks\n- Bidirectional RNNs\n- Long Short-Term Memory (LSTM)\n- Bidirectional Long Short-Term Memory (Bi-LSTM)\n- Gated Recurrent Units (GRU)\n\n### 3. Generative Models in Deep Learning\n\nGenerative models generate new data that resembles the training data. The key types of generative models include:\n\n- Generative Adversarial Networks (GANs)\n- Autoencoders\n- GAN vs. Transformer Models\n\n**Types of Generative Adversarial Networks (GANs):** GANs consist of two neural networks, the generator and the discriminator that compete with each other. Variants of GANs include:\n\n- Deep Convolutional GAN (DCGAN)\n- Conditional GAN (cGAN)\n- Cycle-Consistent GAN (CycleGAN)\n- Super-Resolution GAN (SRGAN)\n- StyleGAN\n\n**Types of Autoencoders:** Autoencoders are neural networks used for unsupervised learning that learns to compress and reconstruct data. Various types of Autoencoders include:\n\n- Types of Autoencoders\n- Sparse Autoencoder\n- Denoising Autoencoder\n- Convolutional Autoencoder\n- Variational Autoencoder\n\n### 4. Deep Reinforcement Learning (DRL)\n\nDeep Reinforcement Learning combines the representation learning power of deep learning with the decision-making ability of reinforcement learning. It helps agents to learn optimal behaviors in complex environments through trial and error using high-dimensional sensory inputs.\n\n- Deep Reinforcement Learning\n- Reinforcement Learning\n- Markov Decision Processes\n\n**Key Algorithms in Deep Reinforcement Learning**\n\n- Deep Q-Networks (DQN)\n- REINFORCE\n- Actor-Critic Methods\n- Proximal Policy Optimization (PPO)\n\n## Advantages and Disadvantages of Deep Learning\n\n### Advantages:\n\n1. High accuracy and automation in complex tasks.\n2. Automatic feature extraction from data.\n\n### Disadvantages:\n\n1. Needs large datasets and computational power.\n2. Complex architecture and training process.\n\n> For more details you can refer to: [Advantages and disadvantages of Deep Learning](https://www.geeksforgeeks.org/deep-learning/advantages-and-disadvantages-of-deep-learning/)\n\n## Challenges in Deep Learning\n\n1. **Data Requirements:** Requires large datasets for training.\n2. **Computational Resources:** Needs powerful hardware.\n3. **Interpretability:** Models are hard to interpret.\n4. **Overfitting:** Risk of poor generalization to new data.\n\n> For more details you can refer to: [Challenges in Deep Learning](https://www.geeksforgeeks.org/deep-learning/challenges-in-deep-learning/)\n\n## Practical Applications of Deep Learning\n\n1. **Self-Driving Cars:** Recognize objects and navigate roads.\n2. **Medical Diagnostics:** Analyze medical images for disease detection.\n3. **Speech Recognition:** Power virtual assistants like Siri and Alexa.\n4. **Facial Recognition:** Identify individuals in images/videos.\n5. **Recommendation Systems:** Suggest personalized content (Netflix, Amazon).\n\n> For more details you can refer to: [Practical Applications](https://www.geeksforgeeks.org/deep-learning/deep-learning-examples/)\n\nThis Deep Learning tutorial is for both beginners and experienced learners. Whether you're just starting out or want to expand your knowledge, this tutorial will help you understand the key concepts and techniques in Deep Learning."}
{"reference": "https://www.geeksforgeeks.org/nlp/nlp-project-ideas-for-beginners/)", "content": "# 10 NLP Project Ideas For Beginners\n\nMachine Learning is a rapidly growing field, and **Natural Language Processing (NLP)** is one of its most exciting and promising branches. NLP focuses on enabling computers to understand, interpret, and generate human language, and it plays an essential role in various applications like sentiment analysis, chatbots, language translation, and more.\n\nIf you are looking to dive into the world of NLP and enhance your machine learning skills, implementing practical projects is the way to go. In this article, we present 10 NLP project ideas to not only help you learn the intricacies of NLP but also improve your overall knowledge of machine learning.\n\n## 10 NLP Project Ideas For Beginners\n\n### 1. Text Summarization\n\nSummarization is a technique in [natural language processing](https://www.geeksforgeeks.org/nlp/natural-language-processing-nlp-tutorial/) that shortens text while preserving its essential facts. It works by training a machine learning model on a large dataset to recognize key details and generate a summary. This technique enhances information retrieval efficiency and offers a chance for beginners to hone their machine learning skills. In summary, summarization is a valuable tool for condensing lengthy texts and improving the overall efficiency of information retrieval. Here is a basic idea for [Text Summarizer](https://www.geeksforgeeks.org/python/python-text-summarizer/) in Python.\n\n### 2. Fake News Detector\n\nThe Fake News Detector project is a response to the growing issue of misinformation and fake news in the modern world. With the widespread use of social media and online platforms, it has become increasingly difficult to distinguish between reliable and fake information. This project aims to develop a system that can automatically detect and classify fake news articles, using Natural Language Processing (NLP) techniques. The project can help promote accurate information dissemination by providing users with a reliable source of news. Overall, the Fake News Detector project is a key step in the fight against misinformation and the promotion of accurate information dissemination. Here is a basic idea for [Fake News Detection Model](https://www.geeksforgeeks.org/nlp/fake-news-detection-model-using-tensorflow-in-python/) using TensorFlow in Python.\n\n### 3. Spam SMS Classification\n\nThe Spam SMS Classification project is a significant advancement in the field of Natural Language Processing (NLP). This project’s goal is to create a system that is capable of accurately classifying SMS messages as spam or ham. With the increasing number of unsolicited messages that people receive on their phones, this project aims to enhance SMS communication by filtering out unwanted and potentially harmful messages. By using NLP techniques, the project seeks to develop a model that can accurately differentiate between spam and legitimate messages. The importance of this project lies in its contribution to improving user security and privacy. Here is a basic idea for [SMS Spam Detection](https://www.geeksforgeeks.org/deep-learning/sms-spam-detection-using-tensorflow-in-python/) in Python.\n\n### 4. Toxic Comments Classification\n\nToxic Comments Classification is an innovative project that uses machine learning to identify and flag abusive comments online, thereby making online spaces safer for everyone. The project involves training a model on a large corpus of comments to detect patterns of abusive language or hate speech. This project offers a great opportunity for beginners to gain hands-on experience in natural language processing and machine learning. Overall, the Toxic Comments Classification project is a great initiative that can help make the Internet a safer and more inclusive place for all. Here you can refer to some [algorithms for classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/).\n\n### 5. Named Entity Recognition (NER)\n\nNamed Entity Recognition (NER) is a fascinating natural language processing project that involves identifying and categorizing named entities in the text. The project aims to extract useful information from unstructured text data and organize it in a structured format. By training a machine learning model on a large corpus of text data, NER can automate the process of extracting relevant information. This project offers a great opportunity for beginners to gain practical experience with natural language processing techniques and machine learning algorithms. Through this project, participants can develop their skills in data preprocessing, feature engineering, model selection, and evaluation. Additionally, NER has many real-world applications, including information retrieval, question answering, and text summarization. You can also refer to the following article for [Named Entity Recognition](https://www.geeksforgeeks.org/nlp/named-entity-recognition/).\n\n### 6. Generating Research Papers Titles\n\nGenerating research paper titles is an innovative NLP project that uses machine learning to generate unique and effective titles for academic papers. The project involves training a model on a large corpus of academic papers to identify the patterns and characteristics of successful titles. The project is a great opportunity for beginners to gain practical experience with NLP techniques and machine learning algorithms. Through this project, participants can develop their skills in data preprocessing, feature engineering, model selection, and evaluation. Overall, the Generating Research Paper Titles project is an excellent initiative that can help researchers streamline their writing process and produce more impactful academic papers.\n\n### 7. Spell and Grammar Checking\n\nSpell and Grammar Checking is a fascinating NLP project that uses machine learning to identify and correct spelling and grammar mistakes in the text. The project involves training a model on a large corpus of text data to detect common errors and suggest corrections. This project is highly useful for those who need to produce error-free documents, such as students, professionals, and writers. By using this model, users can save a significant amount of time and effort in proofreading their documents. The project is also a great opportunity for beginners to gain practical experience with NLP techniques and machine learning algorithms. Overall, the Spell and Grammar Checking project is a great initiative that can help users improve the quality of their written communication. Here is a basic idea you can get [Grammar Checker in Python](https://www.geeksforgeeks.org/python/grammar-checker-in-python-using-language-check/) using Language-check.\n\n### 8. Sentence Autocomplete\n\nSentence Autocomplete is an exciting NLP project that uses machine learning to predict the next word or phrase in a sentence. The project involves training a model on a large corpus of text data to pick out common patterns and predict the most likely next word or phrase based on the context. This project is widely useful for those who need to produce coherent and fluent sentences, including writers, bloggers, and content creators. Overall, the Sentence Autocomplete project is a great initiative that can help users improve the quality of their written communication. Here is a basic idea you can get [Autocomplete input suggestions](https://www.geeksforgeeks.org/python/autocomplete-input-suggestion-using-python-and-flask/) using Python and Flask.\n\n### 9. Chatbot Using NLP (Question Answering System)\n\nChatbot using NLP is a fascinating project that uses machine learning to create a conversational agent that can simulate human-like interactions. The project involves training a model on a large corpus of text data to identify patterns and respond to user queries in natural language. This project is highly useful for businesses that need to provide 24/7 customer service and engage with their customers in a personalized manner. Overall, the Chatbot using NLP project is an excellent initiative that can help businesses enhance their customer engagement and satisfaction. Here you can check the [benefits of using NLP based chatbot](https://www.geeksforgeeks.org/blogs/benefits-of-using-nlp-based-chatbot/).\n\n### 10. Sentiment Analysis with Python\n\nSentiment Analysis with Python is an exciting NLP project that leverages machine learning to identify and classify the emotional tone of a piece of text. The project involves training a model on a large corpus of text data to detect positive, negative, or neutral sentiment. This project is also useful for businesses that need to analyze customer feedback, monitor brand reputation, and make data-driven decisions. Overall, the Sentiment Analysis with Python project is a great initiative that can help businesses make informed decisions and enhance customer satisfaction. You can refer to this article to learn more about [sentiment analysis](https://www.geeksforgeeks.org/machine-learning/what-is-sentiment-analysis/).\n\n> **Must Read**\n> \n> - [Top 7 Applications of NLP](https://www.geeksforgeeks.org/nlp/top-7-applications-of-natural-language-processing/)\n> - [Phases of Natural Language Processing (NLP)](https://www.geeksforgeeks.org/machine-learning/phases-of-natural-language-processing-nlp/)\n> - [Top 50 NLP Interview Questions and Answers](https://www.geeksforgeeks.org/nlp/nlp-interview-questions/)\n\n## Conclusion\n\nUndertaking practical NLP projects is a great way to enhance your machine learning skills. By putting these 10 NLP project ideas into practice, you can gain hands-on experience in developing models for sentiment analysis, text categorization, language translation, chatbots, and more. These projects can improve your overall machine learning skills and deepen your understanding of natural language processing. To take your machine learning journey to the next level, dive in, gather real-world data, and start exploring these exciting NLP projects."}
{"reference": "https://www.geeksforgeeks.org/courses/category/cloud-devops", "content": "### We couldn't find what you're looking for"}
{"reference": "https://www.geeksforgeeks.org/courses", "content": "# GeeksforGeeks Courses\n\n## Popular Now\n\n### Generative AI Training Program - Live\n**Level:** Beginner to Advance  \n**Price:** $299.98 (was $399.98)  \n**Interested:** 14k+  \n[Explore](https://www.geeksforgeeks.org/courses/generative-ai-training-program)\n\n### Tech Interview 101: DSA to System Design for Working Professionals - Live\n**Level:** Beginner to Advance  \n**Price:** $359.98 (was $599.98)  \n**Rating:** 4.9  \n**Interested:** 367k+  \n[Explore](https://www.geeksforgeeks.org/courses/interviewe-101-data-structures-algorithm-system-design)\n\n### Java Backend Development - Live\n**Level:** Intermediate and Advance  \n**Price:** $299.98 (was $399.98)  \n**Rating:** 4.6  \n**Interested:** 361k+  \n[Explore](https://www.geeksforgeeks.org/courses/Java-backend-live)\n\n### Complete Machine Learning & Data Science - Live\n**Level:** Beginner to Advance  \n**Seats Left:** 4  \n**Price:** $119.98 (was $199.98)  \n**Rating:** 4.7  \n**Interested:** 529k+  \n[Explore](https://www.geeksforgeeks.org/courses/data-science-live)\n\n## Course Categories\n- [All](https://www.geeksforgeeks.org/courses/category/all)\n- [DSA / Placements](https://www.geeksforgeeks.org/courses/category/dsa-placements)\n- [Certification - ML & Data Science](https://www.geeksforgeeks.org/courses/category/machine-learning-data-science)\n- [GATE](https://www.geeksforgeeks.org/courses/category/gate)\n- [Development](https://www.geeksforgeeks.org/courses/category/development-testing)\n- [Cloud / DevOps](https://www.geeksforgeeks.org/courses/category/cloud-devops)\n- [Programming Languages](https://www.geeksforgeeks.org/courses/category/programming-languages)\n- [Exam Preparation](https://www.geeksforgeeks.org/courses/category/exam-preparation)\n\n## Live Courses\n\n### MERN Full Stack Development - Live\n**Level:** Beginner to Advance  \n**Price:** $239.98 (was $499.98)  \n**Rating:** 4.7  \n**Interested:** 394k+  \n[Explore](https://www.geeksforgeeks.org/courses/full-stack-node)\n\n### Tech Interview 101: DSA to System Design for Working Professionals - Live\n**Level:** Beginner to Advance  \n**Price:** $359.98 (was $599.98)  \n**Rating:** 4.9  \n**Interested:** 367k+  \n[Explore](https://www.geeksforgeeks.org/courses/interviewe-101-data-structures-algorithm-system-design)\n\n### DevOps Engineering: Planning to Production - Live\n**Level:** Beginner to Advance  \n**Price:** $239.98 (was $399.98)  \n**Rating:** 4.7  \n**Interested:** 131k+  \n[Explore](https://www.geeksforgeeks.org/courses/devops-live)\n\n### Complete Data Analytics - Live\n**Level:** Beginner to Advance  \n**Price:** $299.98 (was $439.98)  \n**Rating:** 4.3  \n**Interested:** 78k+  \n[Explore](https://www.geeksforgeeks.org/courses/data-analytics-training-program-excel-sql-python-powerbi)\n\n## Self-Paced Courses\n\n### Complete Interview Preparation\n**Level:** Beginner to Advance  \n**Price:** $139.98 (was $199.98)  \n**Rating:** 4.8  \n**Interested:** 982k+  \n[Explore](https://www.geeksforgeeks.org/courses/complete-interview-preparation)\n\n### System Design: Low-Level to High-Level - Self Paced\n**Level:** Beginner to Advance  \n**Price:** $139.98 (was $199.98)  \n**Rating:** 4.6  \n**Interested:** 80k+  \n[Explore](https://www.geeksforgeeks.org/courses/mastering-system-design-low-level-to-high-level-solutions)\n\n### Data Structures and Algorithms - Self Paced\n**Level:** Beginner to Advance  \n**Price:** $79.98 (was $119.98)  \n**Rating:** 4.7  \n**Interested:** 1479k+  \n[Explore](https://www.geeksforgeeks.org/courses/dsa-self-paced)\n\n### Django Web Development - Self Paced\n**Level:** Beginner and Intermediate  \n**Price:** $59.98 (was $99.98)  \n**Rating:** 4.7  \n**Interested:** 64k+  \n[Explore](https://www.geeksforgeeks.org/courses/mastering-django-framework-beginner-to-advance)\n\n## Build Your Foundations\n\n### C++ Programming - Self Paced\n**Level:** Beginner to Advance  \n**Price:** $39.98 (was $79.98)  \n**Rating:** 4.7  \n**Interested:** 297k+  \n[Explore](https://www.geeksforgeeks.org/courses/cpp-programming-basic-to-advanced)\n\n### Java Programming - Self Paced\n**Level:** Beginner to Advance  \n**Price:** $39.98 (was $79.98)  \n**Rating:** 4.6  \n**Interested:** 398k+  \n[Explore](https://www.geeksforgeeks.org/courses/java-online-course-complete-beginner-to-advanced)\n\n### Learn C with Data Structures - Self Paced\n**Level:** Beginner to Advance  \n**Price:** $39.98 (was $79.98)  \n**Rating:** 4.6  \n**Interested:** 212k+  \n[Explore](https://www.geeksforgeeks.org/courses/c-Programming-basic-to-advanced)\n\n### Python Programming - Self Paced\n**Level:** Beginner and Intermediate  \n**Price:** $39.98 (was $79.98)  \n**Rating:** 4.6  \n**Interested:** 409k+  \n[Explore](https://www.geeksforgeeks.org/courses/master-python-complete-beginner-to-advanced)\n\n## Newly Launched\n\n### 21 Projects, 21 Days: MERN Stack Program\n**Level:** Beginner to Advance  \n**Price:** $42 (was $69.98)  \n**Interested:** 804  \n[Explore](https://www.geeksforgeeks.org/courses/21-project-21-days-mern)\n\n### GATE Crash Course - CS/IT 2026\n**Price:** $89.98 (was $119.98)  \n**Interested:** 4k+  \n[Explore](https://www.geeksforgeeks.org/courses/gate-live-course-course-2026)\n\n### Placement Tayyari: DSA & Soft Skills for Students - Live\n**Level:** Beginner to Advance  \n**Price:** $199.98 (was $399.98)  \n**Interested:** 97k+  \n[Explore](https://www.geeksforgeeks.org/courses/placement-prep-programming-data-structures-algorithm)\n\n### NIMCET 2026 Preparation - Live\n**Level:** Beginner to Advance  \n**Price:** $139.98 (was $399.98)  \n**Interested:** 6k+  \n[Explore](https://www.geeksforgeeks.org/courses/nimcet-cracker-program)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/hierarchical-clustering/", "content": "# Hierarchical Clustering in Machine Learning\n\nHierarchical clustering is an unsupervised learning technique used to group similar data points into clusters by building a hierarchy (tree-like structure). Unlike flat clustering like [k-means](https://www.geeksforgeeks.org/machine-learning/k-means-clustering-introduction/) hierarchical clustering does not require specifying the number of clusters in advance.\n\nThe algorithm builds clusters step by step either by progressively merging smaller clusters or by splitting a large cluster into smaller ones. The process is often visualized using a dendrogram, which helps to understand data similarity.\n\nImagine we have four fruits with different weights: an apple (100g), a banana (120g), a cherry (50g) and a grape (30g). Hierarchical clustering starts by treating each fruit as its own group.\n\n- Start with each fruit as its own cluster.\n- Merge the closest items: grape (30g) and cherry (50g) are grouped first.\n- Next, apple (100g) and banana (120g) are grouped.\n- Finally, these two clusters merge into one.\n\nFinally all the fruits are merged into one large group, showing how hierarchical clustering progressively combines the most similar data points.\n\n## Dendrogram\n\nA dendrogram is like a family tree for clusters. It shows how individual data points or groups of data merge together. The bottom shows each data point as its own group and as we move up, similar groups are combined. The lower the merge point, the more similar the groups are. It helps us see how things are grouped step by step.\n\n![Dendrogram](https://media.geeksforgeeks.org/wp-content/uploads/20250905151703917591/dendrogram.webp)\n\n- At the bottom of the dendrogram the points P, Q, R, S and T are all separate.\n- As we move up, the closest points are merged into a single group.\n- The lines connecting the points show how they are progressively merged based on similarity.\n- The height at which they are connected shows how similar the points are to each other; the shorter the line the more similar they are\n\n## Types of Hierarchical Clustering\n\nNow we understand the basics of hierarchical clustering. There are two main types of hierarchical clustering.\n\n1. Agglomerative Clustering\n2. Divisive clustering\n\n### 1. Hierarchical Agglomerative Clustering\n\nIt is also known as the bottom-up approach or hierarchical [agglomerative clustering](https://www.geeksforgeeks.org/machine-learning/agglomerative-methods-in-machine-learning/) (HAC). Bottom-up algorithms treat each data as a singleton cluster at the outset and then successively agglomerate pairs of clusters until all clusters have been merged into a single cluster that contains all data.\n\n![Hierarchical Agglomerative Clustering](https://media.geeksforgeeks.org/wp-content/uploads/20200204181551/Untitled-Diagram71.png)\n\n### Workflow for Hierarchical Agglomerative clustering\n\n1. **Start with individual points:** Each data point is its own cluster. For example if we have 5 data points we start with 5 clusters each containing just one data point.\n2. **Calculate distances between clusters**: Calculate the distance between every pair of clusters. Initially since each cluster has one point this is the distance between the two data points.\n3. **Merge the closest clusters**: Identify the two clusters with the smallest distance and merge them into a single cluster.\n4. **Update distance matrix**: After merging we now have one less cluster. Recalculate the distances between the new cluster and the remaining clusters.\n5. **Repeat steps 3 and 4**: Keep merging the closest clusters and updating the distance matrix until we have only one cluster left.\n6. **Create a dendrogram**: As the process continues we can visualize the merging of clusters using a tree-like diagram called a dendrogram. It shows the hierarchy of how clusters are merged.\n\n### Implementation\n\nLet's see the implementation of Agglomerative Clustering,\n\n- Start with each data point as its own cluster.\n- Compute distances between all clusters.\n- Merge the two closest clusters based on a linkage method.\n- Update the distances to reflect the new cluster.\n- Repeat merging until the desired number of clusters or one cluster remains.\n- The dendrogram visualizes these merges as a tree, showing cluster relationships and distances.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import AgglomerativeClustering\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.datasets import make_blobs\n\nX, _ = make_blobs(n_samples=30, centers=3, cluster_std=10, random_state=42)\n\nclustering = AgglomerativeClustering(n_clusters=3)\nlabels = clustering.fit_predict(X)\n\nagg = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\nagg.fit(X)\n\ndef plot_dendrogram(model, **kwargs):\n    counts = np.zeros(model.children_.shape[0])\n    n_samples = len(model.labels_)\n\n    for i, merge in enumerate(model.children_):\n        current_count = 0\n        for child_idx in merge:\n            if child_idx < n_samples:\n                current_count += 1\n            else:\n                current_count += counts[child_idx - n_samples]\n        counts[i] = current_count\n\n    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n    dendrogram(linkage_matrix, **kwargs)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\nax1.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=70)\nax1.set_title(\"Agglomerative Clustering\")\nax1.set_xlabel(\"Feature 1\")\nax1.set_ylabel(\"Feature 2\")\n\nplt.sca(ax2)\nplot_dendrogram(agg, truncate_mode='level', p=5)\nplt.title(\"Hierarchical Clustering Dendrogram\")\nplt.xlabel(\"Sample index\")\nplt.ylabel(\"Distance\")\n\nplt.tight_layout()\nplt.show()\n```\n\n**Output :**\n\n![Agglomerative Clustering](https://media.geeksforgeeks.org/wp-content/uploads/20250911163404142502/download-.webp)\n\n### 2. Hierarchical Divisive clustering\n\n[Divisive clustering](https://www.geeksforgeeks.org/machine-learning/difference-between-agglomerative-clustering-and-divisive-clustering/) is also known as a top-down approach. Top-down clustering requires a method for splitting a cluster that contains the whole data and proceeds by splitting clusters recursively until individual data have been split into singleton clusters.\n\n### Workflow for Hierarchical Divisive clustering :\n\n1. **Start with all data points in one cluster:** Treat the entire dataset as a single large cluster.\n2. **Split the cluster**: Divide the cluster into two smaller clusters. The division is typically done by finding the two most dissimilar points in the cluster and using them to separate the data into two parts.\n3. **Repeat the process**: For each of the new clusters, repeat the splitting process: Choose the cluster with the most dissimilar points and split it again into two smaller clusters.\n4. **Stop when each data point is in its own cluster**: Continue this process until every data point is its own cluster or the stopping condition (such as a predefined number of clusters) is met.\n\n![Divisive Clustering](https://media.geeksforgeeks.org/wp-content/uploads/20250905120322801385/Untitled-Diagram-153-1.webp)\n\n### Implementation\n\nLet's see the implementation of Divisive Clustering,\n\n- Starts with all data points as one big cluster.\n- Finds the largest cluster and splits it into two using KMeans.\n- Repeats splitting the largest cluster until reaching the desired number of clusters.\n- Assigns cluster labels to each data point based on the splits.\n- Returns history of clusters at each step and final labels.\n- Visualizes data points colored by their final cluster.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nX, _ = make_blobs(n_samples=30, centers=5, cluster_std=10, random_state=42)\n\ndef divisive_clustering(data, max_clusters=3):\n    clusters = [data]\n    while len(clusters) < max_clusters:\n        cluster_to_split = max(clusters, key=lambda x: len(x))\n        clusters.remove(cluster_to_split)\n\n        kmeans = KMeans(n_clusters=2, random_state=42).fit(cluster_to_split)\n        cluster1 = cluster_to_split[kmeans.labels_ == 0]\n        cluster2 = cluster_to_split[kmeans.labels_ == 1]\n\n        clusters.extend([cluster1, cluster2])\n    return clusters\n\nclusters = divisive_clustering(X, max_clusters=3)\n\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\ncolors = ['r', 'g', 'b', 'c', 'm', 'y']\nfor i, cluster in enumerate(clusters):\n    plt.scatter(cluster[:, 0], cluster[:, 1], s=50,\n                c=colors[i], label=f'Cluster {i+1}')\nplt.title('Divisive Clustering Result')\nplt.legend()\n\nlinked = linkage(X, method='ward')\n\nplt.subplot(1, 2, 2)\ndendrogram(linked, orientation='top',\n           distance_sort='descending', show_leaf_counts=True)\nplt.title('Hierarchical Clustering Dendrogram')\n\nplt.tight_layout()\nplt.show()\n```\n\n**Output:**\n\n![Divisive Clustering](https://media.geeksforgeeks.org/wp-content/uploads/20250911163341572331/download.webp)\n\n## Computing Distance Matrix\n\nWhile merging two clusters we check the distance between two every pair of clusters and merge the pair with the least distance/most similarity. But the question is how is that distance determined. There are different ways of defining Inter Cluster distance/similarity. Some of them are:\n\n- **Min Distance**: Find the minimum distance between any two points of the cluster.\n- **Max Distance:** Find the maximum distance between any two points of the cluster.\n- **Group Average**: Find the average distance between every two points of the clusters.\n- **Ward's Method**: The similarity of two clusters is based on the increase in squared error when two clusters are merged.\n\n![Distance Matrix](https://media.geeksforgeeks.org/wp-content/uploads/20250912152548586277/group_average.webp)\n\nThe image compares cluster distance methods:\n\n- Min uses the shortest distance between clusters\n- Max uses the longest\n- Group Average computes the mean of all pairwise distances\n- Ward's method minimizes the increase in within-cluster variance during merging"}
{"reference": "https://www.geeksforgeeks.org/videos/category/web-development/", "content": "# Web Development Videos\n\n## Featured Videos\n\n### How to create a Multi Step Progress Bar in HTML CSS and JavaScript?\n- **Duration**: 30:39\n- **Views**: 8.2K\n- **Date**: 23/01/2025\n- **Tags**: Web Development, web-technology\n- [Watch Video](/videos/how-to-create-a-multi-step-progress-bar-in-html-css-and-javascript/)\n\n### How to create a simple counter Using ReactJS?\n- **Duration**: 07:01\n- **Views**: 13.3K\n- **Date**: 21/01/2025\n- **Tags**: Web Development, React JS, web-technology\n- [Watch Video](/videos/how-to-create-a-simple-counter-using-reactjs/)\n\n### How to show and hide Password in ReactJS?\n- **Duration**: 10:46\n- **Views**: 10.1K\n- **Date**: 20/01/2025\n- **Tags**: Web Development, React JS, web-technology\n- [Watch Video](/videos/how-to-show-and-hide-password-in-reactjs/)\n\n### How to create a dynamic report card using HTML, CSS and JavaScript?\n- **Duration**: 06:23\n- **Views**: 6.9K\n- **Date**: 20/01/2025\n- **Tags**: Web Development, css, JavaScript, HTML, web-technology\n- [Watch Video](/videos/how-to-create-a-dynamic-report-card-using-html-css-and-javascript/)\n\n### Currency converter app using ReactJS\n- **Duration**: 10:44\n- **Views**: 13.2K\n- **Date**: 20/01/2025\n- **Tags**: Web Development, React JS, react-js-project, web-technology\n- [Watch Video](/videos/currency-converter-app-using-reactjs/)\n\n### Random Quote Generator App using ReactJS\n- **Duration**: 08:39\n- **Views**: 2.7K\n- **Date**: 20/01/2025\n- **Tags**: Web Development, React JS, react-js-project, web-technology\n- [Watch Video](/videos/random-quote-generator-app-using-reactjs/)\n\n### How to download PDF file in ReactJS?\n- **Duration**: 07:01\n- **Views**: 6.5K\n- **Date**: 17/01/2025\n- **Tags**: Web Development, HTML, React JS, web-technology\n- [Watch Video](/videos/how-to-download-pdf-file-in-reactjs/)\n\n### Build a simple Song Lyrics Finder app using ReactJS\n- **Duration**: 13:12\n- **Views**: 11.7K\n- **Date**: 16/01/2025\n- **Tags**: Web Development, React JS, react-js-project, web-technology\n- [Watch Video](/videos/build-a-simple-song-lyrics-finder-app-using-reactjs/)\n\n### How to Design a Simple Calendar using JavaScript?\n- **Duration**: 18:02\n- **Views**: 12.4K\n- **Date**: 15/01/2025\n- **Tags**: Web Development, JavaScript\n- [Watch Video](/videos/how-to-design-a-simple-calendar-using-javascript/)\n\n### How to make a Toast Notification in HTML CSS and JavaScript?\n- **Duration**: 37:54\n- **Views**: 66.9K\n- **Date**: 08/01/2025\n- **Tags**: Web Development, web-technology\n- [Watch Video](/videos/how-to-make-a-toast-notification-in-html-css-and-javascript/)\n\n### What is Full Stack Development?\n- **Duration**: 14:09\n- **Views**: 17.2K\n- **Date**: 06/01/2025\n- **Tags**: Web Development, web-technology\n- [Watch Video](/videos/what-is-full-stack-development/)\n\n### How to Develop User Registration Form in React JS?\n- **Duration**: 33:28\n- **Views**: 20.6K\n- **Date**: 06/01/2025\n- **Tags**: Web Development, web-technology\n- [Watch Video](/videos/how-to-develop-user-registration-form-in-react-js-1/)\n\n*Showing 1-12 of 72 videos*"}
{"reference": "https://www.geeksforgeeks.org/courses/python-skill-up", "content": "# Python Skill Up\n\nSelf-Paced Course\n\n**Duration:** 4 Weeks  \n**Interested:** 55k+ Geeks\n\nThis course is designed to provide learners with a strong foundation in Python programming. It covers essential programming concepts including variables, loops, conditionals, functions, data structures, OOP, standard libraries, file handling, GUI programming, databases, and project development. This course is ideal for beginners, students, and professionals looking to start their programming journey with Python.\n\n## Course Overview\n\nThis 4-week intensive Python course walks learners through basic to advanced Python concepts. With a blend of theory, quizzes, and hands-on practice, learners build problem-solving skills, understand how Python works under the hood, and apply their learning in projects.\n\n### Course Highlights\n\n- Learn Python from scratch in a structured format\n- Master control flow, functions, recursion, and comprehensions\n- Dive into data structures, OOP, file handling, and exceptions\n- Work with databases like MySQL and MongoDB using Python\n- Use built-in modules like math, datetime, os, heapq, and functools\n- Understand APIs, JSON, CSV, and Excel file handling\n- Build desktop GUI apps with tkinter\n- Work on mini-projects and capstone tasks\n\n## Course Content\n\n### Week 1: Python Fundamentals\n\n- Introduction of Python & Setup\n- Input/Output, Variables, Keywords\n- Python Data Types and Operators\n- Conditional Statements and Control Flow\n- Loops (for, while, nested)\n- Functions (def, return, *args, **kwargs, lambda, recursion)\n- Strings, Lists, Tuples, Dictionaries, Sets\n- List Comprehensions\n\n### Week 2: Intermediate Python Concepts\n\n- Python Collections Module (Counter, OrderedDict, defaultdict, deque)\n- Exception Handling (try, except, built-in & user-defined exceptions)\n- File Handling: Reading, Writing, File Modes\n- OS and pathlib Module for Directory Management\n- OOP Concepts: Classes, Objects, Encapsulation, Inheritance, Polymorphism\n- Abstract Classes and Iterators\n- Python Projects (Tic Tac Toe, Number Guessing Game)\n\n### Week 3: Databases & Standard Libraries\n\n- Working with MySQL in Python\n- Introduction to MongoDB with Python\n- Built-in Python Libraries: math, random, datetime, os, sys, platform\n- Python DSA Libraries: heapq, bisect, array, collections, functools\n- GUI Programming with tkinter\n\n### Week 4: File Formats, APIs, and Advanced Python\n\n- Working with CSV (csv) and Excel files (openpyxl)\n- Reading and Writing JSON Data\n- Using APIs with Python (requests, API response handling)\n- Iterators and Generators, yield keyword\n- Advanced Comprehensions (List, Dict, Set) and Generator Expressions\n- Context Managers and with statement\n- Creating and Importing Python Modules\n- Packaging with pip and virtualenv\n- Mini Projects (e.g., Weather Notifier, Hangman Game)\n\n## Frequently Asked Questions\n\n### What is this Python course about?\n\n### What’s next after this course?\n\n### Do I need prior coding experience for this Python Course?\n\n### Who should take this Python course?"}
{"reference": "https://www.geeksforgeeks.org/data-visualization/python-data-visualization-tutorial/", "content": "# Python - Data Visualization Tutorial\n\nData visualization is the process of converting complex data into graphical formats such as charts, graphs, and maps. It allows users to understand patterns, trends, and outliers in large datasets quickly and clearly. By transforming data into visual elements, data visualization helps in making data more accessible and easier to interpret, allowing for more informed decisions and insights.\n\n## Features of Data Visualization\n\n- **Simplifies Complex Data:** Transforms complex datasets into easy-to-understand visuals.\n- **Identifies Patterns:** Helps spot trends and patterns that might not be obvious in raw data.\n- **Improves Decision-Making:** Provides visual clarity, helping decision-makers make informed choices faster.\n- **Highlights Key Insights:** Allows for the emphasis of important trends, outliers, and relationships.\n- **Interactive:** Many visualizations allow for user interaction, enabling deeper exploration of data.\n\n## Example: Plotting with Matplotlib\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndays = np.arange(1, 31)\nprices = 100 + np.cumsum(np.random.randn(30))\n\nplt.plot(days, prices, marker='o', linestyle='-', color='green')\nplt.title(\"Simulated Stock Price\")\nplt.xlabel(\"Day\")\nplt.ylabel(\"Price ($)\")\nplt.grid(True)\nplt.show()\n```\n\n**Output**\n\n![Stock Price Chart](https://media.geeksforgeeks.org/wp-content/uploads/20250811122249393818/Stock_Price.jpg)\n\n**Explanation:**\n\n- `np.arange(1, 31)` creates an array of days from 1 to 30.\n- `np.cumsum(np.random.randn(30))` generates random daily changes and sums them to simulate stock prices.\n- `plt.plot()` draws the stock price line with green circle markers.\n- `plt.title(), plt.xlabel(), plt.ylabel(),` and `plt.grid()` add labels, title and grid for clarity.\n\n## Table of Contents\n\n- [Data Visualization Basics](#data-visualization-basics)\n- [Data Visualization with Matplotlib](#data-visualization-with-matplotlib)\n- [Effective Data Visualization With Seaborn](#effective-data-visualization-with-seaborn)\n- [Data Visualization with Pandas](#data-visualization-with-pandas)\n- [Data Visualization with Plotly](#data-visualization-with-plotly)\n- [Data Visualization with Plotnine](#data-visualization-with-plotnine)\n- [Data Visualizations with Altair](#data-visualizations-with-altair)\n- [Interactive Data Visualization with Bokeh](#interactive-data-visualization-with-bokeh)\n- [Advanced Data Visualization with Pygal](#advanced-data-visualization-with-pygal)\n- [Choosing the Right Data Visualization Library](#choosing-the-right-data-visualization-library)\n\n## Data Visualization Basics\n\nAfter analyzing data, it is important to visualize the data to uncover patterns, trends, outliers, and insights that may not be apparent in raw data using visual elements like charts, graphs, and maps. **Choosing the right type of chart is crucial for effectively communicating your data. Different charts serve different purposes and can highlight various aspects of your data**. For a deeper dive into selecting the best chart for your data, check out this comprehensive guide on:\n\n- [What is Data Visualization and Why is It Important?](https://www.geeksforgeeks.org/data-visualization/data-visualization-and-its-importance/)\n- [Types of Data Visualization Charts](https://www.geeksforgeeks.org/data-visualization/types-of-data-visualization/)\n- [Choosing the Right Chart Type](https://www.geeksforgeeks.org/data-visualization/choosing-the-right-chart-type-a-technical-guide/)\n\nEqually important is selecting the right colors for your visualizations. Proper color choices highlight key information, improve readability, and make visuals more engaging. For expert advice on choosing the best colors for your charts, visit [How to select Colors for Data Visualizations?](https://www.geeksforgeeks.org/data-visualization/how-to-select-colors-for-data-visualizations/)\n\n## Data Visualization with Matplotlib\n\nMatplotlib is one of the most widely used libraries for data visualization in Python. It is highly flexible and allows users to create a wide range of static, animated, and interactive plots. It helps us create basic visualizations, and we can easily integrate it with other libraries like Seaborn for more advanced statistical graphics.\n\n- [Introduction to Matplotlib](https://www.geeksforgeeks.org/python/python-introduction-matplotlib/)\n- [Setting up Python Environment for installation](https://www.geeksforgeeks.org/installation-guide/install-matplotlib-python/)\n- [Pyplot in Matplotlib](https://www.geeksforgeeks.org/python/pyplot-in-matplotlib/)\n- [Matplotlib – Axes Class](https://www.geeksforgeeks.org/python/matplotlib-axes-class/)\n- [Data Visualization With Matplotlib](https://www.geeksforgeeks.org/data-visualization/data-visualization-using-matplotlib/)\n\n## Effective Data Visualization With Seaborn\n\nSeaborn is built on top of Matplotlib and provides a high-level interface for creating attractive and informative statistical plots. It integrates seamlessly with Pandas and makes it easier to create complex visualizations with minimal code.\n\n- [Data Visualization with Python Seaborn](https://www.geeksforgeeks.org/data-visualization/data-visualization-with-python-seaborn/)\n- [Data visualization with Seaborn Pairplot](https://www.geeksforgeeks.org/data-visualization/data-visualization-with-pairplot-seaborn-and-pandas/)\n- [Data Visualization with FacetGrid in Seaborn](https://www.geeksforgeeks.org/data-visualization/python-seaborn-facetgrid-method/)\n- [Time Series Visualization with Seaborn : Line Plot](https://www.geeksforgeeks.org/data-visualization/data-visualization-with-seaborn-line-plot/)\n\n## Data Visualization with Pandas\n\nPandas is a powerful library primarily used for data manipulation, but it also offers basic plotting capabilities. While it may not be as feature-rich as dedicated visualization libraries like Matplotlib or Seaborn, Pandas' built-in plotting is convenient for quick and simple visualizations.\n\n- [Data Visualization With Pandas](https://www.geeksforgeeks.org/data-visualization/pandas-built-in-data-visualization-ml/)\n- [Visualizing Time Series Data with pandas](https://www.geeksforgeeks.org/python/how-to-plot-timeseries-based-charts-using-pandas/)\n- [Plotting Geospatial Data using GeoPandas](https://www.geeksforgeeks.org/data-science/plotting-geospatial-data-using-geopandas/)\n\n> For more information, see [Pandas](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/) and check [Box Plots](https://www.geeksforgeeks.org/machine-learning/box-plot/) for details on specific charts.\n\n## Data Visualization with Plotly\n\nPlotly is an interactive visualization library that allows users to create a wide range of plots, including line plots, bar charts, and scatter plots. Plotly is known for its beautiful visuals and high interactivity, making it a popular choice for web-based dashboards.\n\n- [Introduction to Plotly](https://www.geeksforgeeks.org/python/getting-started-with-plotly-python/)\n- [Data Visualization with Plotly](https://www.geeksforgeeks.org/data-visualization/using-plotly-for-interactive-data-visualization-in-python/)\n\n## Data Visualization with Plotnine\n\nPlotnine is a Python library that implements the **Grammar of Graphics, inspired by R's ggplot2**. It provides a powerful and consistent way to create complex plots with minimal code.\n\n- [Introduction to Concept of Grammar of Graphics](https://www.geeksforgeeks.org/python/an-introduction-to-grammar-of-graphics-for-python/)\n- [Data Visualization using Plotnine](https://www.geeksforgeeks.org/data-visualization/data-visualization-using-plotnine-and-ggplot2-in-python/)\n\n## Data Visualizations with Altair\n\nAltair is a Python library for creating clear, interactive charts with minimal code. Based on Vega and Vega-Lite, it uses a declarative approach (meaning you specify what the chart should show, not how to draw it), making complex visualizations easy to build and understand.\n\n- [Data Visualization with Altair](https://www.geeksforgeeks.org/data-science/introduction-to-altair-in-python/)\n- [Aggregating Data for Large Datasets](https://www.geeksforgeeks.org/data-visualization/using-altair-on-data-aggregated-from-large-datasets/)\n- [Sharing and Publishing Visualizations with Altair](https://www.geeksforgeeks.org/data-analysis/sharing-and-publishing-visualizations-with-altair/)\n\n## Interactive Data Visualization with Bokeh\n\nBokeh is a powerful Python library for creating [interactive data visualization](https://www.geeksforgeeks.org/data-visualization/what-is-interactive-data-visualization/) and highly customizable visualizations. It is **designed for modern web browsers and allows for the creation of complex visualizations with ease**. Bokeh supports a wide range of plot types and interactivity features, making it a popular choice for interactive data visualization.\n\n- [Introduction to Bokeh in Python](https://www.geeksforgeeks.org/python/introduction-to-bokeh-in-python/)\n- [Interactive Data Visualization with Bokeh](https://www.geeksforgeeks.org/data-visualization/python-bokeh-tutorial-interactive-data-visualization-with-bokeh/)\n- [Practical Examples for Mastering Data Visualization with Bokeh](https://www.geeksforgeeks.org/data-visualization/interactive-data-visualization-with-python-and-bokeh/)\n\n## Advanced Data Visualization with Pygal\n\nPygal is known for its ease of use and ability to create beautiful, interactive charts that can be embedded in web applications. We can also create a wide range of charts including line charts, bar charts, pie charts and more, all with interactive capabilities.\n\n> To learn about it in detail, refer to [Data Visualization with Pygal](https://www.geeksforgeeks.org/data-visualization/data-visualization-with-pygal/#:~:text=Pygal%20is%20a%20powerful%20tool,visualizing%20data%20in%20various%20ways.)\n\n## Choosing the Right Data Visualization Library\n\n| Library   | Best For                  | Strengths                  | Limitations                  |\n|-----------|---------------------------|----------------------------|------------------------------|\n| Matplotlib| Static plots             | Highly customizable       | Steep learning curve        |\n| Seaborn   | Statistical visualizations| Easy to use, visually appealing | Limited interactivity     |\n| Plotly    | Interactive visualizations| Web integration, modern designs | Requires browser rendering |\n| Bokeh     | Web-based dashboards     | Real-time interactivity   | More complex setup          |\n| Altair    | Declarative statistical plots | Concise syntax         | Limited customization       |\n| Pygal     | Scalable SVG charts      | High-quality graphics     | Less suited for complex datasets |\n\nTo create impactful and engaging data visualizations. Start by selecting the appropriate chart type—bar charts for comparisons, line charts for trends, and pie charts for proportions.\n\n- Simplify your visualizations to focus on key insights.\n- Use annotations to guide the viewer’s attention.\n- Strategically use color to differentiate categories or highlight important data, but avoid overuse to prevent confusion.\n\n> For a more detailed exploration of these techniques consider below resources:\n>\n> - [Top 8 Python Libraries for Data Visualization](https://www.geeksforgeeks.org/python/top-python-libraries-for-data-visualization/)\n> - [Data Visualization in Infographics: Techniques and Examples](https://www.geeksforgeeks.org/data-visualization/data-visualization-in-infographics-techniques-and-examples/)\n> - [5 Best Practices for Effective and Good Data Visualizations](https://www.geeksforgeeks.org/data-visualization/5-best-practices-for-effective-and-good-data-visualizations/)\n> - [Bad Data Visualization Examples Explained](https://www.geeksforgeeks.org/data-visualization/bad-data-visualization-examples-explained/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/random-forest-algorithm-in-machine-learning/", "content": "# Random Forest Algorithm in Machine Learning\n\nRandom Forest is a machine learning algorithm that uses many decision trees to make better predictions. Each tree looks at different random parts of the data and their results are combined by voting for classification or averaging for regression which makes it as ensemble learning technique. This helps in improving accuracy and reducing errors.\n\n## Working of Random Forest Algorithm\n\n- **Create Many Decision Trees:** The algorithm makes many [decision trees](https://www.geeksforgeeks.org/machine-learning/decision-tree/) each using a random part of the data. So every tree is a bit different.\n- **Pick Random Features:** When building each tree it doesn't look at all the features (columns) at once. It picks a few at random to decide how to split the data. This helps the trees stay different from each other.\n- **Each Tree Makes a Prediction:** Every tree gives its own answer or prediction based on what it learned from its part of the data.\n- **Combine the Predictions:** For **classification** we choose a category as the final answer is the one that most trees agree on i.e majority voting and for **regression** we predict a number as the final answer is the average of all the trees predictions.\n- **Why It Works Well:** Using random data and features for each tree helps avoid overfitting and makes the overall prediction more accurate and trustworthy.\n\n## Key Features of Random Forest\n\n- **Handles Missing Data:** It can work even if some data is missing so you don't always need to fill in the gaps yourself.\n- **Shows Feature Importance:** It tells you which features (columns) are most useful for making predictions which helps you understand your data better.\n- **Works Well with Big and Complex Data:** It can handle large datasets with many features without slowing down or losing accuracy.\n- **Used for Different Tasks:** You can use it for both **classification** like predicting types or labels and **regression** like predicting numbers or amounts.\n\n## Assumptions of Random Forest\n\n- **Each tree makes its own decisions**: Every tree in the forest makes its own predictions without relying on others.\n- **Random parts of the data are used**: Each tree is built using random samples and features to reduce mistakes.\n- **Enough data is needed**: Sufficient data ensures the trees are different and learn unique patterns and variety.\n- **Different predictions improve accuracy**: Combining the predictions from different trees leads to a more accurate final result.\n\n## Implementing Random Forest for Classification Tasks\n\nHere we will predict survival rate of a person in titanic.\n\nYou can download dataset from [here](https://media.geeksforgeeks.org/wp-content/uploads/20250901164440637128/titanic.csv).\n\n- Import libraries like [pandas](https://www.geeksforgeeks.org/pandas/introduction-to-pandas-in-python/) and [scikit learn](https://www.geeksforgeeks.org/machine-learning/learning-model-building-scikit-learn-python-machine-learning-library/).\n- Load the Titanic dataset.\n- Remove rows with missing target values ('Survived').\n- Select features like class, sex, age, etc and convert 'Sex' to numbers.\n- Fill missing age values with the median.\n- Split the data into training and testing sets, then train a Random Forest model.\n- Predict on test data, check accuracy and print a sample prediction result.\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntitanic_data = pd.read_csv('titanic.csv')\n\ntitanic_data = titanic_data.dropna(subset=['Survived'])\n\nX = titanic_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\ny = titanic_data['Survived']\n\nX.loc[:, 'Sex'] = X['Sex'].map({'female': 0, 'male': 1})\n\nX.loc[:, 'Age'].fillna(X['Age'].median(), inplace=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\nrf_classifier.fit(X_train, y_train)\n\ny_pred = rf_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"\\nClassification Report:\\n\", classification_rep)\n\nsample = X_test.iloc[0:1]\nprediction = rf_classifier.predict(sample)\n\nsample_dict = sample.iloc[0].to_dict()\nprint(f\"\\nSample Passenger: {sample_dict}\")\nprint(f\"Predicted Survival: {'Survived' if prediction[0] == 1 else 'Did Not Survive'}\")\n```\n\n**Output:**\n\n![clf](https://media.geeksforgeeks.org/wp-content/uploads/20250530103109146105/clf.webp)\n\n*Random Forest for Classification Tasks*\n\nWe evaluated model's performance using a classification report to see how well it predicts the outcomes and used a random sample to check model prediction.\n\n## Implementing Random Forest for Regression Tasks\n\nWe will do house price prediction here.\n\n- Load the California housing dataset and create a DataFrame with features and target.\n- Separate the features and the target variable.\n- Split the data into training and testing sets (80% train, 20% test).\n- Initialize and train a Random Forest Regressor using the training data.\n- Predict house values on test data and evaluate using MSE and R² score.\n- Print a sample prediction and compare it with the actual value.\n\n```python\nimport pandas as pd\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ncalifornia_housing = fetch_california_housing()\ncalifornia_data = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\ncalifornia_data['MEDV'] = california_housing.target\n\nX = california_data.drop('MEDV', axis=1)\ny = california_data['MEDV']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n\nrf_regressor.fit(X_train, y_train)\n\ny_pred = rf_regressor.predict(X_test)\n\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nsingle_data = X_test.iloc[0].values.reshape(1, -1)\npredicted_value = rf_regressor.predict(single_data)\nprint(f\"Predicted Value: {predicted_value[0]:.2f}\")\nprint(f\"Actual Value: {y_test.iloc[0]:.2f}\")\n\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R-squared Score: {r2:.2f}\")\n```\n\n**Output:**\n\n![reg](https://media.geeksforgeeks.org/wp-content/uploads/20250530103449412261/reg.webp)\n\n*Random Forest for Regression Tasks*\n\nWe evaluated the model's performance using [Mean Squared Error](https://www.geeksforgeeks.org/maths/mean-squared-error/) and [R-squared Score](https://www.geeksforgeeks.org/machine-learning/ml-r-squared-in-regression-analysis/) which show how accurate the predictions are and used a random sample to check model prediction.\n\n## Advantages of Random Forest\n\n- Random Forest provides very accurate predictions even with large datasets.\n- Random Forest can handle missing data well without compromising with accuracy.\n- It doesn't require normalization or standardization on dataset.\n- When we combine multiple decision trees it reduces the risk of overfitting of the model.\n\n## Limitations of Random Forest\n\n- It can be computationally expensive especially with a large number of trees.\n- It's harder to interpret the model compared to simpler models like decision trees.\n\n### Related Article:\n\n- [Ensemble Learning](https://www.geeksforgeeks.org/machine-learning/a-comprehensive-guide-to-ensemble-learning/)"}
{"reference": "https://www.geeksforgeeks.org/java/java/", "content": "# Java Tutorial\n\nJava is a high-level, object-oriented programming language used to build web apps, mobile applications, and enterprise software systems.\n\n- Known for its Write Once, Run Anywhere capability, which means code written in Java can run on any device that supports the Java Virtual Machine (JVM).\n- Syntax and structure is similar to C-based languages like C++ and C#.\n\n> Try our ongoing free courses [Java Skillup](https://www.geeksforgeeks.org/courses/java-skill-up) and [Advance Java Skillup](https://www.geeksforgeeks.org/courses/advanced-java-skill-up) with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Why Learn Java?\n\n- Used to build Android apps, desktop and web apps, enterprise backend systems, and cloud-based software.\n- In high demand with many job opportunities in software development.\n- Has popular frameworks like Spring and Hibernate which makes it powerful for enterprise applications.\n- Supports object-oriented programming for clean and reusable code.\n- It runs on all platforms Windows, Mac, and Linux using the JVM.\n- Top companies like Amazon, Netflix, and LinkedIn use Java.\n\n## Hello World Program\n\nHere is a simple Java program that prints \"Hello World\".\n\n```java\npublic class Geeks { \n    public static void main(String args[]) \n    { \n        System.out.println(\"Hello World\"); \n    } \n}\n```\n\n**Output**\n\n```\nHello World\n```\n\n## Basics\n\nJava basics form the foundation of your programming journey, covering essential concepts like syntax, data types, variables, loops, and conditionals.\n\n- [Introduction](https://www.geeksforgeeks.org/java/introduction-to-java/)\n- [Download and Install Java](https://www.geeksforgeeks.org/linux-unix/download-install-java-windows-linux-macos/)\n- [JDK vs JRE vs JVM](https://www.geeksforgeeks.org/java/differences-jdk-jre-jvm/)\n- [Identifiers](https://www.geeksforgeeks.org/java/java-identifiers/)\n- [Keywords](https://www.geeksforgeeks.org/java/java-keywords/)\n- **Quiz**: [Java Basics and Identifiers](https://www.geeksforgeeks.org/quizzes/java-basics-and-identifiers/)\n- [Data Types](https://www.geeksforgeeks.org/java/java-data-types/)\n- [Variables](https://www.geeksforgeeks.org/java/variables-in-java/)\n- [Operators](https://www.geeksforgeeks.org/java/operators-in-java/)\n- **Quiz**: [Variables](https://www.geeksforgeeks.org/quizzes/java-variables/), [Operator](https://www.geeksforgeeks.org/quizzes/java-operator/)\n- [Decision Making (if, if-else, switch, break, continue, jump)](https://www.geeksforgeeks.org/java/decision-making-javaif-else-switch-break-continue-jump/)\n- [Loops](https://www.geeksforgeeks.org/java/loops-in-java/)\n- **Quiz**: [Control Statements and Loops](https://www.geeksforgeeks.org/quizzes/java-control-statements-and-loops/)\n- **Project:** [Number Guessing Game](https://www.geeksforgeeks.org/dsa/number-guessing-game-in-java/)\n\n## Methods\n\nJava methods are reusable blocks of code that perform specific tasks and help organize your program. They improve code readability, reduce repetition, and make debugging easier.\n\n- [Introduction to Methods](https://www.geeksforgeeks.org/java/methods-in-java/)\n- [Static Methods vs Instance Methods](https://www.geeksforgeeks.org/java/static-methods-vs-instance-methods-in-java/)\n- [Access Modifiers](https://www.geeksforgeeks.org/java/access-modifiers-java/)\n- [Command Line Arguments](https://www.geeksforgeeks.org/java/command-line-arguments-in-java/)\n- [Variable Arguments (Varargs)](https://www.geeksforgeeks.org/java/variable-arguments-varargs-in-java/)\n- **Quiz**: [Methods](https://www.geeksforgeeks.org/quizzes/java-methods/)\n\n## Arrays\n\nJava arrays are containers that store multiple values of the same data type in a single variable. They provide an efficient way to manage and access collections of data using index-based positions.\n\n- [Introduction](https://www.geeksforgeeks.org/java/arrays-in-java/)\n- [Declare and Initialize Arrays](https://www.geeksforgeeks.org/java/how-to-declare-and-initialize-an-array-in-java/)\n- [Multi-Dimensional Arrays](https://www.geeksforgeeks.org/java/multidimensional-arrays-in-java/)\n- **Quiz:** [Java Arrays](https://www.geeksforgeeks.org/quizzes/java-quiz/arrays-gq/)\n- [Jagged Arrays](https://www.geeksforgeeks.org/java/jagged-array-in-java/)\n- [Arrays Class](https://www.geeksforgeeks.org/java/array-class-in-java/)\n- [Final Arrays](https://www.geeksforgeeks.org/java/final-arrays-in-java/)\n- **Quiz:** [Array](https://www.geeksforgeeks.org/quizzes/java-array-programs/)\n- **Projects:** [Tic-Tac-Toe Game](https://www.geeksforgeeks.org/java/tic-tac-toe-game-in-java/)\n\n## Strings\n\nJava Strings represent sequences of characters and are widely used in text processing. They are immutable, meaning once created, their values cannot be changed.\n\n- [Introduction](https://www.geeksforgeeks.org/java/strings-in-java/)\n- [Why Strings are Immutable](https://www.geeksforgeeks.org/java/java-string-is-immutable-what-exactly-is-the-meaning/)\n- [String Concatenation](https://www.geeksforgeeks.org/java/java-string-concat-examples/)\n- [String Methods](https://www.geeksforgeeks.org/java/java-string-methods/)\n- **Quiz**: [String Basics](https://www.geeksforgeeks.org/quizzes/java-string-basics/)\n- [String Class](https://www.geeksforgeeks.org/java/string-class-in-java/)\n- [StringBuffer Class](https://www.geeksforgeeks.org/java/stringbuffer-class-in-java/)\n- [StringBuilder Class](https://www.geeksforgeeks.org/java/stringbuilder-class-in-java-with-examples/)\n- **Quiz:** [String Classes](https://www.geeksforgeeks.org/quizzes/java-string-classes/)\n- [Strings vs StringBuffer vs StringBuilder](https://www.geeksforgeeks.org/java/string-vs-stringbuilder-vs-stringbuffer-in-java/)\n\n## Regex\n\nJava Regex (Regular Expressions) allows pattern matching and text manipulation using the `java.util.regex` package. It is powerful for validating, searching, and replacing strings based on specific patterns.\n\n- [What is Java Regex?](https://www.geeksforgeeks.org/java/regular-expressions-in-java/)\n- [Pattern Class](https://www.geeksforgeeks.org/java/pattern-pattern-method-in-java-with-examples/)\n- [Matcher Class](https://www.geeksforgeeks.org/java/matcher-pattern-method-in-java-with-examples/)\n- [Character Class](https://www.geeksforgeeks.org/java/java-lang-character-class-methods-set-1/)\n- [Quantifiers](https://www.geeksforgeeks.org/java/quantifiers-in-java/)\n- **Quiz**: [Regex Basics and Pattern Matching](https://www.geeksforgeeks.org/quizzes/java-regex-basics-and-pattern-matching/)\n\n## OOP Concepts\n\nJava follows the Object-Oriented Programming (OOP) paradigm, which organizes code into classes and objects. Core OOP principles like inheritance, encapsulation, polymorphism, and abstraction make Java modular and scalable.\n\n- [What are OOP Concepts?](https://www.geeksforgeeks.org/java/object-oriented-programming-oops-concept-in-java/)\n- [Classes and Objects](https://www.geeksforgeeks.org/java/classes-objects-java/)\n- **Quiz:** [Classes and Objects](https://www.geeksforgeeks.org/quizzes/java-quiz/class-and-object-2-gq/)\n- [Constructors](https://www.geeksforgeeks.org/java/constructors-in-java/)\n- **Quiz**: [Constructors](https://www.geeksforgeeks.org/quizzes/java-quiz/constructors-2-gq/)\n- [Object Class](https://www.geeksforgeeks.org/java/object-class-in-java/)\n- [Abstraction](https://www.geeksforgeeks.org/java/abstraction-in-java-2/)\n- [Encapsulation](https://www.geeksforgeeks.org/java/encapsulation-in-java/)\n- [Inheritance](https://www.geeksforgeeks.org/java/inheritance-in-java/)\n- **Quiz**: [Inheritance and Abstraction](https://www.geeksforgeeks.org/quizzes/inheritance-2-gq/)\n- [Polymorphism](https://www.geeksforgeeks.org/java/polymorphism-in-java/)\n- [Packages](https://www.geeksforgeeks.org/java/packages-in-java/)\n- **Quiz**: [Polymorphism and Packages](https://www.geeksforgeeks.org/quizzes/java-polymorphism-and-packages/)\n- **Project:** [Simple Banking Application](https://www.geeksforgeeks.org/java/mini-banking-application-in-java/)\n\n## Interfaces\n\nJava interfaces define a contract that classes must follow, specifying method signatures without implementations. They enable abstraction and support multiple inheritance in Java through a clean, structured approach.\n\n- [Interfaces](https://www.geeksforgeeks.org/java/interfaces-in-java/)\n- [Class vs Interface](https://www.geeksforgeeks.org/java/differences-between-interface-and-class-in-java/)\n- **Quiz:** [Interfaces](https://www.geeksforgeeks.org/quizzes/java-interfaces/)\n- [Functional Interface](https://www.geeksforgeeks.org/java/java-functional-interfaces/)\n- [Nested Interface](https://www.geeksforgeeks.org/java/nested-interface-in-java/)\n- [Marker Interface](https://www.geeksforgeeks.org/java/marker-interface-in-java/)\n- **Quiz**: [Interface types and Comparator](https://www.geeksforgeeks.org/quizzes/java-interface-types-and-comparator/)\n- **Project:** [Employee Management System](https://www.geeksforgeeks.org/projects/program-for-employee-management-system/)\n\n## Exception Handling\n\nJava Exception Handling is a mechanism to handle runtime errors, ensuring the program runs smoothly without crashing. It uses keywords like try, catch, throw, throws, and finally to manage exceptions.\n\n- [Exceptions](https://www.geeksforgeeks.org/java/exceptions-in-java/)\n- [Try Catch Block](https://www.geeksforgeeks.org/java/java-try-catch-block/)\n- **Quiz:** [Java Exceptions](https://www.geeksforgeeks.org/quizzes/java-exceptions/?ref=quiz_lbp)\n- [Final, Finally and Finalize](https://www.geeksforgeeks.org/java/java-final-finally-and-finalize/)\n- [Throw and Throws](https://www.geeksforgeeks.org/java/throw-throws-java/)\n- [Customized Exception Handling](https://www.geeksforgeeks.org/java/user-defined-custom-exception-in-java/)\n- [Chained Exceptions](https://www.geeksforgeeks.org/java/chained-exceptions-in-java/)\n- [Null Pointer Exceptions](https://www.geeksforgeeks.org/java/null-pointer-exception-in-java/)\n- [Exception Handling with Method Overriding](https://www.geeksforgeeks.org/java/exception-handling-with-method-overriding-in-java/)\n- **Quiz**: [Exception Handling](https://www.geeksforgeeks.org/quizzes/exception-handling-2-gq/)\n\n## Memory Allocation\n\nJava Memory Allocation refers to how memory is assigned to variables, objects, and classes during program execution. It involves stack and heap memory, with the JVM managing allocation and garbage collection automatically.\n\n- [Java Memory Management](https://www.geeksforgeeks.org/java/java-memory-management/)\n- [How Java Objects Stored in Memory?](https://www.geeksforgeeks.org/java/how-are-java-objects-stored-in-memory/)\n- **Quiz**: [Java Memory Allocation](https://www.geeksforgeeks.org/quizzes/java-memory-allocation/)\n- [Types of Memory Areas Allocated by JVM](https://www.geeksforgeeks.org/java/how-many-types-of-memory-areas-are-allocated-by-jvm/)\n- [Stack vs Heap Memory Allocation](https://www.geeksforgeeks.org/java/java-stack-vs-heap-memory-allocation/)\n- **Quiz**: [Heap vs Stack](https://www.geeksforgeeks.org/quizzes/java-heap-vs-stack/)\n- [Garbage Collection](https://www.geeksforgeeks.org/java/garbage-collection-in-java/)\n- **Quiz:** [JVM Memory Management and Garbage Collection](https://www.geeksforgeeks.org/quizzes/jvm-memory-management-and-garbage-collection/)\n- [Types of JVM Garbage Collectors](https://www.geeksforgeeks.org/java/types-of-jvm-garbage-collectors-in-java-with-implementation-details/)\n- [Memory Leaks](https://www.geeksforgeeks.org/java/memory-leaks-in-java/)\n\n## Collections\n\nJava Collections provide a framework for storing and manipulating groups of objects efficiently. It includes interfaces like List, Set, and Map, along with classes like ArrayList, HashSet, and HashMap.\n\n- [Collections Class](https://www.geeksforgeeks.org/java/collections-class-in-java/)\n- [Collection Interface](https://www.geeksforgeeks.org/java/collection-interface-in-java-with-examples/)\n- **Quiz:** [Collection](https://www.geeksforgeeks.org/quizzes/java-collection-framework/?ref=quiz_lbp)\n- [List Interface](https://www.geeksforgeeks.org/java/list-interface-java-examples/)\n- [ArrayList](https://www.geeksforgeeks.org/java/arraylist-in-java/)\n- [LinkedList](https://www.geeksforgeeks.org/java/linked-list-in-java/)\n- **Quiz**: [List](https://www.geeksforgeeks.org/quizzes/java-list-interface/), [ArrayList](https://www.geeksforgeeks.org/quizzes/java-arraylist/?ref=quiz_lbp), [LinkedList](https://www.geeksforgeeks.org/quizzes/java-linkedlist/)\n- [Set Interface](https://www.geeksforgeeks.org/java/set-in-java/)\n- [HashSet](https://www.geeksforgeeks.org/java/hashset-in-java/)\n- [TreeSet](https://www.geeksforgeeks.org/java/treeset-in-java-with-examples/)\n- **Quiz**: [Set and HashSet](https://www.geeksforgeeks.org/quizzes/java-set-and-hashset-classes/?ref=quiz_lbp)\n- [Queue Interface](https://www.geeksforgeeks.org/java/queue-interface-java/)\n- [Priority Queue](https://www.geeksforgeeks.org/java/priority-queue-in-java/)\n- [Deque Interface](https://www.geeksforgeeks.org/java/deque-interface-java-example/)\n- [Map Interface](https://www.geeksforgeeks.org/java/map-interface-in-java/)\n- [HashMap](https://www.geeksforgeeks.org/java/java-util-hashmap-in-java-with-examples/)\n- **Quiz:** [Queue and Map Interface](https://www.geeksforgeeks.org/quizzes/java-queue-and-map-interface/?ref=quiz_lbp)\n- [Iterator](https://www.geeksforgeeks.org/java/iterators-in-java/)\n- [Comparator Interface](https://www.geeksforgeeks.org/java/java-comparator-interface/)\n- [Comparable Interface](https://www.geeksforgeeks.org/java/comparable-interface-in-java-with-examples/)\n- **Quiz**: [Iterators](https://www.geeksforgeeks.org/quizzes/java-iterators/?ref=quiz_lbp), [Comparator vs Comparable](https://www.geeksforgeeks.org/quizzes/java-comparator-vs-comparable/?ref=quiz_lbp)\n- **Project:** [Face Detection System](https://www.geeksforgeeks.org/java/image-processing-in-java-face-detection/)\n\n## Lambda Expressions and Streams\n\nJava Streams and Lambda Expressions simplify data processing by enabling functional-style operations on collections. Lambdas provide concise syntax for anonymous functions, while Streams allow efficient filtering, mapping, and reduction of data.\n\n- [Lambda Expressions](https://www.geeksforgeeks.org/java/lambda-expressions-java-8/)\n- [Method References](https://www.geeksforgeeks.org/java/java-method-references/)\n- [Java Streams](https://www.geeksforgeeks.org/java/java-8-stream-tutorial/)\n- **Quiz:** [Lambda Expressions and Streams](https://www.geeksforgeeks.org/quizzes/java-lambda-expressions-and-streams/?ref=quiz_lbp)\n- To know Java 8 in detail, refer to - [Java 8 Features](https://www.geeksforgeeks.org/java/java-8-features-tutorial/)\n\n## Multithreading and Synchronization\n\nJava Multithreading allows concurrent execution of two or more threads, enabling efficient CPU utilization and faster program performance. It is commonly used for tasks that required parallel processing and responsiveness from multiple ends.\n\n- [Introduction](https://www.geeksforgeeks.org/java/multithreading-in-java/)\n- [Threads](https://www.geeksforgeeks.org/java/java-threads/)\n- [Thread.start() vs Thread.run() Method](https://www.geeksforgeeks.org/java/difference-between-thread-start-and-thread-run-in-java/)\n- [Thread.sleep() Method](https://www.geeksforgeeks.org/java/thread-sleep-method-in-java-with-examples/)\n- [Runnable Interface](https://www.geeksforgeeks.org/java/runnable-interface-in-java/)\n- **Quiz:** [Thread Basics and Lifecycle](https://www.geeksforgeeks.org/quizzes/java-thread-basics-and-lifecycle/?ref=quiz_lbp)\n- [Main Thread](https://www.geeksforgeeks.org/java/main-thread-java/)\n- [Thread Priority in Multithreading](https://www.geeksforgeeks.org/java/java-thread-priority-multithreading/)\n- [Daemon Thread](https://www.geeksforgeeks.org/java/daemon-thread-java/)\n- **Quiz**: [Thread Methods and Daemon Threads](https://www.geeksforgeeks.org/quizzes/java-thread-methods-and-daemon-threads/)\n- [Java Synchronization](https://www.geeksforgeeks.org/java/synchronization-in-java/)\n- Quiz: [Synchronization Basics](https://www.geeksforgeeks.org/quizzes/java-synchronization-basics/)\n- [Thread Safety](https://www.geeksforgeeks.org/java/thread-safety-and-how-to-achieve-it-in-java/)\n- [Locks in Java](https://www.geeksforgeeks.org/java/how-to-use-locks-in-multi-threaded-java-program/)\n- [Lock vs Monitor in Concurrency](https://www.geeksforgeeks.org/java/difference-between-lock-and-monitor-in-java-concurrency/)\n- [Lock Framework vs Thread Synchronization](https://www.geeksforgeeks.org/java/lock-framework-vs-thread-synchronization-in-java/)\n- [Reentrant Lock](https://www.geeksforgeeks.org/java/reentrant-lock-in-java/)\n- [Deadlock in Multithreading](https://www.geeksforgeeks.org/java/deadlock-in-java-multithreading/)\n- [Thread Pools](https://www.geeksforgeeks.org/java/thread-pools-java/)\n- [Executor Framework](https://www.geeksforgeeks.org/java/what-is-java-executor-framework/)\n- **Quiz**: [Deadlocks and Synchronization](https://www.geeksforgeeks.org/quizzes/java-deadlocks-and-synchronization/)\n- **Project:** [Snake Game](https://www.geeksforgeeks.org/advance-java/design-snake-game/)\n\n## File Handling\n\nJava File Handling enables programs to create, read, write, and manipulate files stored on the system. It uses classes from the `java.io` and `java.nio` packages for efficient file operations.\n\n- [Introduction to Java IO](https://www.geeksforgeeks.org/java/java-io-input-output-in-java-with-examples/)\n- [Reader Class](https://www.geeksforgeeks.org/java/java-io-reader-class-java/)\n- [Writer Class](https://www.geeksforgeeks.org/java/java-io-writer-class-java/)\n- [File Handling](https://www.geeksforgeeks.org/java/file-handling-in-java/)\n- [File Class](https://www.geeksforgeeks.org/java/file-class-in-java/)\n- **Quiz:** [File Handling](https://www.geeksforgeeks.org/quizzes/java-file-handling/?ref=quiz_lbp)\n- [FileInputStream](https://www.geeksforgeeks.org/java/java-io-fileinputstream-class-java/)\n- [FileOutputStream](https://www.geeksforgeeks.org/java/fileoutputstream-in-java/)\n- [FileReader Class](https://www.geeksforgeeks.org/java/java-io-filereader-class/)\n- [FileWriter Class](https://www.geeksforgeeks.org/java/filewriter-class-in-java/)\n- [FileOutput Stream](https://www.geeksforgeeks.org/java/fileoutputstream-in-java/)\n- [BufferedReader Input Stream](https://www.geeksforgeeks.org/java/ways-to-read-input-from-console-in-java/)\n- [BufferedReader Output stream](https://www.geeksforgeeks.org/java/java-io-bufferedoutputstream-class-java/)\n- [Fast I/O](https://www.geeksforgeeks.org/competitive-programming/fast-io-in-java-in-competitive-programming/)\n- **Quiz:** [File Writing](https://www.geeksforgeeks.org/quizzes/java-file-writing/?ref=quiz_lbp)\n- [FilePermission Class](https://www.geeksforgeeks.org/java/java-io-filepermission-class-java/)\n- [FileDescriptor Class](https://www.geeksforgeeks.org/java/java-io-filedescriptor-java/)\n- **Project:** [Text Editor](https://www.geeksforgeeks.org/java/java-swing-create-a-simple-text-editor/)\n\n## Networking\n\nJava Networking enables communication between devices over a network using classes from the `java.net` package. It supports protocols like TCP and UDP for building client-server applications and data exchange.\n\n- [Introduction to Java Networking](https://www.geeksforgeeks.org/java/java-networking/)\n- [TCP Architecture](https://www.geeksforgeeks.org/computer-networks/tcp-ip-model/)\n- [UDP Architecture](https://www.geeksforgeeks.org/computer-networks/user-datagram-protocol-udp/)\n- [IPV4 vs IPV6](https://www.geeksforgeeks.org/computer-networks/differences-between-ipv4-and-ipv6/)\n- [Connection-Oriented vs Connectionless Protocols](https://www.geeksforgeeks.org/computer-networks/difference-between-connection-oriented-and-connection-less-services/)\n- **Quiz**: [Networking Basics and Protocols](https://www.geeksforgeeks.org/quizzes/java-networking-basics-and-protocols/)\n- [Socket Programming](https://www.geeksforgeeks.org/java/socket-programming-in-java/)\n- [Server Socket Class](https://www.geeksforgeeks.org/java/java-net-serversocket-class-in-java/)\n- **Quiz:** [Sockets and Server Communication](https://www.geeksforgeeks.org/quizzes/java-sockets-and-server-communication/)\n- [URL Class and Methods](https://www.geeksforgeeks.org/java/url-class-java-examples/)\n- **Project:** [Chat Application](https://www.geeksforgeeks.org/java/simple-chat-application-using-sockets-in-java/)\n\n## Java Database Connectivity (JDBC)\n\n- [Introduction to Java JDBC](https://www.geeksforgeeks.org/java/introduction-to-jdbc/)\n- [JDBC Driver](https://www.geeksforgeeks.org/java/jdbc-drivers/)\n- [JDBC Connection](https://www.geeksforgeeks.org/java/establishing-jdbc-connection-in-java/)\n- [Types of Statements in JDBC](https://www.geeksforgeeks.org/java/types-of-statements-in-jdbc/)\n- **Quiz**: [JDBC](https://www.geeksforgeeks.org/quizzes/java-jdbc/)\n\n## Interview Questions\n\nPrepare for Java interviews with these commonly asked questions, covering core concepts, OOP, collections, multithreading, exception handling, and frameworks like Spring and Hibernate.\n\n- [Core Java Interview Questions and Answers](https://www.geeksforgeeks.org/java/java-interview-questions/)\n\n## Important Links\n\n- [Comparison of various programming languages](https://www.geeksforgeeks.org/java/c-vs-java-vs-python/)\n- [Companies That Use Java](https://www.geeksforgeeks.org/java/companies-that-use-java/)\n- [Careers & Jobs in Java](https://www.geeksforgeeks.org/java/careers-jobs-in-java/)\n\n## Practice\n\n- [Java Exercises – Basic to Advanced Java Practice Programs](https://www.geeksforgeeks.org/java/java-exercises/)\n- [Java Coding Practice Problems](https://www.geeksforgeeks.org/java/java-coding-practice-problems-1/)\n- [Java Language MCQs with Answers](https://www.geeksforgeeks.org/quizzes/50-java-language-mcqs-with-answers-2/)\n\n## Explore\n\n### Java Basics\n\n- [Introduction to Java 3 min read](https://www.geeksforgeeks.org/java/introduction-to-java/)\n- [Java Programming Basics 9 min read](https://www.geeksforgeeks.org/java/java-programming-basics/)\n- [Java Methods 6 min read](https://www.geeksforgeeks.org/java/methods-in-java/)\n- [Access Modifiers in Java 5 min read](https://www.geeksforgeeks.org/java/access-modifiers-java/)\n- [Arrays in Java 7 min read](https://www.geeksforgeeks.org/java/arrays-in-java/)\n- [Java Strings 8 min read](https://www.geeksforgeeks.org/java/strings-in-java/)\n- [Regular Expressions in Java 3 min read](https://www.geeksforgeeks.org/java/regular-expressions-in-java/)\n\n### OOP & Interfaces\n\n- [Classes and Objects in Java 10 min read](https://www.geeksforgeeks.org/java/classes-objects-java/)\n- [Access Modifiers in Java 5 min read](https://www.geeksforgeeks.org/java/access-modifiers-java/)\n- [Java Constructors 10 min read](https://www.geeksforgeeks.org/java/constructors-in-java/)\n- [Java OOP(Object Oriented Programming) Concepts 10 min read](https://www.geeksforgeeks.org/java/object-oriented-programming-oops-concept-in-java/)\n- [Java Packages 7 min read](https://www.geeksforgeeks.org/java/packages-in-java/)\n- [Java Interface 11 min read](https://www.geeksforgeeks.org/java/interfaces-in-java/)\n\n### Collections\n\n- [Collections in Java 12 min read](https://www.geeksforgeeks.org/java/collections-in-java-2/)\n- [Collections Class in Java 13 min read](https://www.geeksforgeeks.org/java/collections-class-in-java/)\n- [Collection Interface in Java 4 min read](https://www.geeksforgeeks.org/java/collection-interface-in-java-with-examples/)\n- [Iterator in Java 5 min read](https://www.geeksforgeeks.org/java/iterators-in-java/)\n- [Java Comparator Interface 6 min read](https://www.geeksforgeeks.org/java/java-comparator-interface/)\n\n### Exception Handling\n\n- [Java Exception Handling 8 min read](https://www.geeksforgeeks.org/java/exceptions-in-java/)\n- [Java Try Catch Block 4 min read](https://www.geeksforgeeks.org/java/java-try-catch-block/)\n- [Java final, finally and finalize 4 min read](https://www.geeksforgeeks.org/java/java-final-finally-and-finalize/)\n- [Chained Exceptions in Java 3 min read](https://www.geeksforgeeks.org/java/chained-exceptions-in-java/)\n- [Null Pointer Exception in Java 5 min read](https://www.geeksforgeeks.org/java/null-pointer-exception-in-java/)\n- [Exception Handling with Method Overriding in Java 4 min read](https://www.geeksforgeeks.org/java/exception-handling-with-method-overriding-in-java/)\n\n### Java Advanced\n\n- [Java Multithreading Tutorial 3 min read](https://www.geeksforgeeks.org/java/java-multithreading-tutorial/)\n- [Synchronization in Java 10 min read](https://www.geeksforgeeks.org/java/synchronization-in-java/)\n- [File Handling in Java 4 min read](https://www.geeksforgeeks.org/java/file-handling-in-java/)\n- [Java Method References 9 min read](https://www.geeksforgeeks.org/java/java-method-references/)\n- [Java 8 Stream Tutorial 7 min read](https://www.geeksforgeeks.org/java/java-8-stream-tutorial/)\n- [Java Networking 6 min read](https://www.geeksforgeeks.org/java/java-networking/)\n- [JDBC Tutorial 5 min read](https://www.geeksforgeeks.org/java/jdbc-tutorial/)\n- [Java Memory Management 4 min read](https://www.geeksforgeeks.org/java/java-memory-management/)\n- [Garbage Collection in Java 6 min read](https://www.geeksforgeeks.org/java/garbage-collection-in-java/)\n- [Memory Leaks in Java 3 min read](https://www.geeksforgeeks.org/java/memory-leaks-in-java/)\n\n### Practice Java\n\n- [Java Interview Questions and Answers 15+ min read](https://www.geeksforgeeks.org/java/java-interview-questions/)\n- [Java Programs - Java Programming Examples 7 min read](https://www.geeksforgeeks.org/java/java-programming-examples/)\n- [Java Exercises - Basic to Advanced Java Practice Programs with Solutions 5 min read](https://www.geeksforgeeks.org/java/java-exercises/)\n- [Java Quiz | Level Up Your Java Skills 1 min read](https://www.geeksforgeeks.org/java/java-quiz/)\n- [Top 50 Java Project Ideas For Beginners and Advanced [Update 2025] 15+ min read](https://www.geeksforgeeks.org/blogs/java-projects/)"}
{"reference": "https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/", "content": "# Machine Learning\n\n**2.5K+ posts**\n\n## Recent Articles\n\n### Visualizing Classifier Decision Boundaries\n*Last Updated: 06 August 2025*\n\nVisualizing classifier decision boundaries is a way to gain intuitive insight into how machine learning models separate different classes in a feature space. These visuali...[read more](https://www.geeksforgeeks.org/machine-learning/visualizing-classifier-decision-boundaries/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Kuberflow vs. MLflow\n*Last Updated: 06 August 2025*\n\nKubeflow and MLflow are both tools for managing the machine learning lifecycle but they serve different purposes. Kubeflow is designed for building, deploying and managing...[read more](https://www.geeksforgeeks.org/machine-learning/kuberflow-vs-mlflow/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Huber Loss Function in Machine Learning\n*Last Updated: 01 August 2025*\n\nThe Huber Loss Function is a popular loss function used primarily in regression tasks. It is designed to be robust to outliers combining the best properties of two common ...[read more](https://www.geeksforgeeks.org/machine-learning/huber-loss-function-in-machine-learning/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### cuML : RAPIDS Machine Learning Library\n*Last Updated: 06 August 2025*\n\ncuML is a GPU accelerated machine learning library developed by NVIDIA as part of the RAPIDS AI ecosystem. It is designed to enable fast and scalable execution of traditio...[read more](https://www.geeksforgeeks.org/machine-learning/cuml-rapids-machine-learning-library/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Incremental Learning with Scikit-learn\n*Last Updated: 31 July 2025*\n\nIncremental Learning is a technique where a machine learning model learns from data in small chunks or batches rather than all at once. This is useful when working with ve...[read more](https://www.geeksforgeeks.org/machine-learning/incremental-learning-with-scikit-learn/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Reproducibility in Machine Learning\n*Last Updated: 02 August 2025*\n\nReproducibility in machine learning means being able to run the same experiment again and get the same results. For ML this means using the same code, data and settings an...[read more](https://www.geeksforgeeks.org/machine-learning/reproducibility-in-machine-learning/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Hierarchical Clustering for Categorical data\n*Last Updated: 29 July 2025*\n\nHierarchical clustering is a method of unsupervised learning that builds a hierarchy of clusters. For categorical data, distance or similarity measures like Hamming distan...[read more](https://www.geeksforgeeks.org/machine-learning/hierarchical-clustering-for-categorical-data/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Ml Model Deployment on Cloud\n*Last Updated: 29 July 2025*\n\nMachine learning(ML) model deploymenton the cloudis a foundationalcapability thatenables organizationsto operationalize AI at scaleby hosting, managing and servingML model...[read more](https://www.geeksforgeeks.org/machine-learning/ml-model-deployment-on-cloud/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### What is ModelOps?\n*Last Updated: 30 July 2025*\n\nModelOps, short forModel OperationsorModel Operationalization, is a discipline focused on the governance, lifecycle management, deployment, monitoring and continual improv...[read more](https://www.geeksforgeeks.org/machine-learning/what-is-modelops/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### What is ML Governance?\n*Last Updated: 25 July 2025*\n\nML governance is a structured framework for managing machine learning (ML) models and workflows throughout their lifecycle. It covers the rules, processes, and tools requi...[read more](https://www.geeksforgeeks.org/machine-learning/what-is-ml-governance/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### What is Sparse Categorical Crossentropy\n*Last Updated: 26 July 2025*\n\nSparse Categorical Crossentropyis a loss function commonly used in multi-class classification problems in machine learning and deep learning and is particularly used when ...[read more](https://www.geeksforgeeks.org/machine-learning/what-is-sparse-categorical-crossentropy/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/)\n\n### Fairlearn: assessing and improving fairness of AI systems\n*Last Updated: 25 July 2025*\n\nFairlearn is a Python library that helps data scientists and developers build machine learning models that are fair and responsible. Many AI systems unintentionally treat ...[read more](https://www.geeksforgeeks.org/machine-learning/fairlearn-assessing-and-improving-fairness-of-ai-systems/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Gini Coefficient\n*Last Updated: 28 July 2025*\n\nThe Gini Coefficient is a metric used to measure inequality or impurity in datasets. In machine learning, especially in decision trees, it quantifies how mixed the classes...[read more](https://www.geeksforgeeks.org/machine-learning/gini-coefficient/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### BentoML: Helping Deploy ML Models\n*Last Updated: 21 July 2025*\n\nBentoML model deployment is the process of converting a trained machine learning model into a fully functional API service. It allows you to package the model along with a...[read more](https://www.geeksforgeeks.org/machine-learning/bentoml-helping-deploy-ml-models/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)\n\n### Feature Engineering using Featuretools\n*Last Updated: 24 July 2025*\n\nFeature engineering is the process of creating new input features from raw data to improve machine learning models. Featuretools is a Python library that helps automate th...[read more](https://www.geeksforgeeks.org/machine-learning/feature-engineering-using-featuretools/)\n\n**Tags:** [Machine Learning](https://www.geeksforgeeks.org/category/ai-ml-ds/machine-learning/) [AI-ML-DS With Python](https://www.geeksforgeeks.org/tag/ai-ml-ds-python/)"}
{"reference": "https://www.geeksforgeeks.org/machine-learning/bias-vs-variance-in-machine-learning/", "content": "# Bias and Variance in Machine Learning\n\nThere are various ways to evaluate a machine-learning model. We can use MSE ([Mean Squared Error](https://www.geeksforgeeks.org/maths/mean-squared-error/)) for Regression; Precision, Recall, and ROC (Receiver operating characteristics) for a Classification Problem along with Absolute Error. In a similar way, Bias and Variance help us in parameter tuning and deciding better-fitted models among several built.\n\nBias is one type of error that occurs due to wrong assumptions about data such as assuming data is linear when in reality, data follows a complex function. On the other hand, variance gets introduced with high sensitivity to variations in training data. This also is one type of error since we want to make our model robust against noise. There are two types of error in machine learning. Reducible error and Irreducible error. Bias and Variance come under reducible error.\n\n## What is Bias?\n\nBias is simply defined as the inability of the model because of that there is some difference or error occurring between the model's predicted value and the actual value. These differences between actual or expected values and the predicted values are known as error or bias error or error due to bias. Bias is a systematic error that occurs due to wrong assumptions in the [machine learning](https://www.geeksforgeeks.org/machine-learning/machine-learning/) process.\n\nLet \\( Y \\) be the true value of a parameter, and let \\( \\hat{Y} \\) be an estimator of \\( Y \\) based on a sample of data. Then, the bias of the estimator \\( \\hat{Y} \\) is given by:\n\n\\[\n\\text{Bias}(\\hat{Y}) = E(\\hat{Y}) - Y\n\\]\n\nwhere \\( E(\\hat{Y}) \\) is the expected value of the estimator \\( \\hat{Y} \\). It is the measurement of the model that how well it fits the data.\n\n- **Low Bias:** Low bias value means fewer assumptions are taken to build the target function. In this case, the model will closely match the training dataset.\n- **High Bias:** High bias value means more assumptions are taken to build the target function. In this case, the model will not match the training dataset closely.\n\nThe high-bias model will not be able to capture the dataset trend. It is considered as the [underfitting](https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/) model which has a high error rate. It is due to a very simplified algorithm.\n\nFor example, a [linear regression](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/) model may have a high bias if the data has a non-linear relationship.\n\n### Ways to reduce high bias in Machine Learning:\n\n- **Use a more complex model:** One of the main reasons for high bias is the very simplified model. it will not be able to capture the complexity of the data. In such cases, we can make our mode more complex by increasing the number of hidden layers in the case of a [deep neural network.](https://www.geeksforgeeks.org/deep-learning/introduction-deep-learning/) Or we can use a more complex model like [Polynomial regression](https://www.geeksforgeeks.org/machine-learning/python-implementation-of-polynomial-regression/) for [non-linear datasets](https://www.geeksforgeeks.org/machine-learning/non-linear-regression-examples-ml/), [CNN](https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/) for [image processing](https://www.geeksforgeeks.org/computer-vision/image-processing/), and [RNN](https://www.geeksforgeeks.org/machine-learning/introduction-to-recurrent-neural-network/) for sequence learning.\n- **Increase the number of features:** By adding more features to train the dataset will increase the complexity of the model. And improve its ability to capture the underlying patterns in the data.\n- **Reduce** [****Regularization****](https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/) ****of the model:**** Regularization techniques such as [L1 or L2 regularization](https://www.geeksforgeeks.org/machine-learning/ml-implementing-l1-and-l2-regularization-using-sklearn/) can help to prevent [overfitting](https://www.geeksforgeeks.org/machine-learning/underfitting-and-overfitting-in-machine-learning/) and improve the generalization ability of the model. if the model has a high bias, reducing the strength of regularization or removing it altogether can help to improve its performance.\n- **Increase the size of the training data:** Increasing the size of the training data can help to reduce bias by providing the model with more examples to learn from the dataset.\n\n## What is Variance?\n\nVariance is the measure of spread in data from its [mean](https://www.geeksforgeeks.org/maths/mathematics-mean-variance-and-standard-deviation/) position. In machine learning variance is the amount by which the performance of a predictive model changes when it is trained on different subsets of the training data. More specifically, variance is the variability of the model that how much it is sensitive to another subset of the training dataset. i.e. how much it can adjust on the new subset of the training dataset.\n\nLet \\( Y \\) be the actual values of the target variable, and \\( \\hat{Y} \\) be the predicted values of the target variable. Then the [variance](https://www.geeksforgeeks.org/maths/mathematics-mean-variance-and-standard-deviation/) of a model can be measured as the expected value of the square of the difference between predicted values and the expected value of the predicted values.\n\n\\[\n\\text{Variance} = E[(\\hat{Y} - E[\\hat{Y}])^2]\n\\]\n\nwhere \\( E[\\bar{Y}] \\) is the expected value of the predicted values. Here expected value is averaged over all the training data.\n\nVariance errors are either low or high-variance errors.\n\n- **Low variance:** Low variance means that the model is less sensitive to changes in the training data and can produce consistent estimates of the target function with different subsets of data from the same distribution. **However, low variance can also indicate underfitting** if the model is too simple and fails to capture the underlying patterns in the data. This is when the model performs poorly on both the training data and testing data.\n- **High variance:** High variance means that the model is very sensitive to changes in the training data and can result in significant changes in the estimate of the target function when trained on different subsets of data from the same distribution. This is the case of overfitting when the model performs well on the training data but poorly on new, unseen test data. It fits the training data too closely that it fails on the new training dataset.\n\n### Ways to Reduce the reduce Variance in Machine Learning:\n\n- [****Cross-validation****](https://www.geeksforgeeks.org/machine-learning/cross-validation-machine-learning/)****:**** By splitting the data into training and testing sets multiple times, cross-validation can help identify if a model is overfitting or underfitting and can be used to tune hyperparameters to reduce variance.\n- [****Feature selection:****](https://www.geeksforgeeks.org/machine-learning/feature-selection-techniques-in-machine-learning/)By choosing the only relevant feature will decrease the model's complexity. and it can reduce the variance error.\n- [****Regularization****](https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/)****:**** We can use L1 or L2 regularization to reduce variance in machine learning models\n- [****Ensemble methods****](https://www.geeksforgeeks.org/machine-learning/ensemble-classifier-data-mining/)****:**** It will combine multiple models to improve generalization performance. [Bagging, boosting](https://www.geeksforgeeks.org/machine-learning/bagging-vs-boosting-in-machine-learning/), and stacking are common ensemble methods that can help reduce variance and improve generalization performance.\n- ****Simplifying the model:**** Reducing the complexity of the model, such as decreasing the number of parameters or layers in a neural network, can also help reduce variance and improve generalization performance.\n- [****Early stopping****](https://www.geeksforgeeks.org/deep-learning/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/)****:**** Early stopping is a technique used to prevent overfitting by stopping the training of the deep learning model when the performance on the validation set stops improving.\n\n## Mathematical Derivation for Total Error\n\n\\[\n\\begin{aligned}\n\\text{MSE} &= (Y - \\hat{Y})^2 \\\\\n&= (Y - E(\\hat{Y}) + E(\\hat{Y}) - \\hat{Y})^2 \\\\\n&= (Y - E(\\hat{Y}))^2 + (E(\\hat{Y}) - \\hat{Y})^2 + 2(Y - E(\\hat{Y}))(E(\\hat{Y}) - \\hat{Y})\n\\end{aligned}\n\\]\n\nApplying the Expectations on both sides.\n\n\\[\n\\begin{aligned}\nE[(Y - \\hat{Y})^2] &= E[(Y - E(\\hat{Y}))^2 + (E(\\hat{Y}) - \\hat{Y})^2 + 2(Y - E(\\hat{Y}))(E(\\hat{Y}) - \\hat{Y})] \\\\\n&= E[(Y - E(\\hat{Y}))^2] + E[(E(\\hat{Y}) - \\hat{Y})^2] + 2E[(Y - E(\\hat{Y}))(E(\\hat{Y}) - \\hat{Y})] \\\\\n&= [(Y - E(\\hat{Y}))^2] + E[(E(\\hat{Y}) - \\hat{Y})^2] + 2(Y - E(\\hat{Y}))E[(E(\\hat{Y}) - \\hat{Y})] \\\\\n&= [(Y - E(\\hat{Y}))^2] + E[(E(\\hat{Y}) - \\hat{Y})^2] + 2(Y - E(\\hat{Y}))[E[E(\\hat{Y})] - E[\\hat{Y}]] \\\\\n&= [(Y - E(\\hat{Y}))^2] + E[(E(\\hat{Y}) - \\hat{Y})^2] + 2(Y - E(\\hat{Y}))[E(\\hat{Y}) - E[\\hat{Y}]] \\\\\n&= [(Y - E(\\hat{Y}))^2] + E[(E(\\hat{Y}) - \\hat{Y})^2] + 2(Y - E(\\hat{Y}))[0] \\\\\n&= [(Y - E(\\hat{Y}))^2] + E[(E(\\hat{Y}) - \\hat{Y})^2] + 0 \\\\\n&= [\\text{Bias}^2] + \\text{Variance}\n\\end{aligned}\n\\]\n\n## Different Combinations of Bias-Variance\n\nThere can be four combinations between bias and variance.\n\n- **High Bias, Low Variance:** A model with high bias and low variance is said to be underfitting.\n- **High Variance, Low Bias:** A model with high variance and low bias is said to be overfitting.\n- **High-Bias, High-Variance:** A model has both high bias and high variance, which means that the model is not able to capture the underlying patterns in the data (high bias) and is also too sensitive to changes in the training data (high variance). As a result, the model will produce inconsistent and inaccurate predictions on average.\n- **Low Bias, Low Variance:** A model that has low bias and low variance means that the model is able to capture the underlying patterns in the data (low bias) and is not too sensitive to changes in the training data (low variance). This is the ideal scenario for a machine learning model, as it is able to generalize well to new, unseen data and produce consistent and accurate predictions. But in practice, it's not possible.\n\n![Bias-Variance Combinations](https://media.geeksforgeeks.org/wp-content/uploads/20230307114300/image_2023-03-07_114312041.png)\n\n*Bias-Variance Combinations*\n\nNow we know that the ideal case will be **Low Bias and Low variance**, but in practice, it is not possible. So, we trade off between Bias and variance to achieve a balanced bias and variance.\n\nA model with balanced bias and variance is said to have optimal generalization performance. This means that the model is able to capture the underlying patterns in the data without overfitting or underfitting. The model is likely to be just complex enough to capture the complexity of the data, but not too complex to overfit the training data. This can happen when the model has been carefully tuned to achieve a good balance between bias and variance, by adjusting the hyperparameters and selecting an appropriate model architecture.\n\n| **Machine Learning Algorithm** | **Bias** | **Variance** |\n| --- | --- | --- |\n| [Linear Regression](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/) | High Bias | Less Variance |\n| [Decision Tree](https://www.geeksforgeeks.org/machine-learning/decision-tree/) | Low Bias | High Variance |\n| [Random Forest](https://www.geeksforgeeks.org/machine-learning/random-forest-regression-in-python/) | Low Bias | High Variance |\n| [Bagging](https://www.geeksforgeeks.org/machine-learning/bagging-vs-boosting-in-machine-learning/) | Low Bias | High Variance |\n\n## Bias Variance Tradeoff\n\nIf the algorithm is too simple (hypothesis with linear equation) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex (hypothesis with high degree equation) then it may be on high variance and low bias. In the latter condition, the new entries will not perform well. Well, there is something between both of these conditions, known as a Trade-off or Bias Variance Trade-off. This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm can’t be more complex and less complex at the same time. For the graph, the perfect tradeoff will be like this.\n\n![Bias-Variance Tradeoff](https://media.geeksforgeeks.org/wp-content/uploads/20230315100857/ML--Bias-Vs-Variance-(1).png)\n\n*Bias-Variance Tradeoff*\n\nThe technique by which we analyze the performance of the machine learning model is known as Bias Variance Decomposition. Now we give 1-1 example of Bias Variance Decomposition for [classification](https://www.geeksforgeeks.org/machine-learning/getting-started-with-classification/) and [regression](https://www.geeksforgeeks.org/machine-learning/types-of-regression-techniques/).\n\n### Bias Variance Decomposition for Classification and Regression\n\nAs per the formula, we have derived total error as the sum of Bias squares and variance. We try to make sure that the bias and the variance are comparable and one does not exceed the other by too much difference.\n\n```python\n# Import the necessary libraries\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom mlxtend.evaluate import bias_variance_decomp\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Load the dataset\nX, y = load_iris(return_X_y=True)\n\n# Split train and test dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23, shuffle=True, stratify=y)\n\n# Build the classification model\ntree = DecisionTreeClassifier(random_state=123)\nclf = BaggingClassifier(base_estimator=tree, n_estimators=50, random_state=23)\n\n# Bias variance decompositions\navg_expected_loss, avg_bias, avg_var = bias_variance_decomp(clf, X_train, y_train, X_test, y_test, loss='0-1_loss', random_seed=23)\n# Print the value\nprint('Average expected loss: %.2f' % avg_expected_loss)\nprint('Average bias: %.2f' % avg_bias)\nprint('Average variance: %.2f' % avg_var)\n```\n\n**Output**:\n\n```\nAverage expected loss: 0.06  \nAverage bias: 0.05  \nAverage variance: 0.02\n```\n\nNow let's perform the same on the regression task. And check the values of the bias and variance.\n\n```python\n# Load the necessary libraries\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nfrom mlxtend.evaluate import bias_variance_decomp\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Laod the dataset\nX, y = fetch_california_housing(return_X_y=True)\n\n# Split train and test dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23, shuffle=True)\n\n# Build the regression model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n    tf.keras.layers.Dense(1)\n])\n\n# Set optimizer and loss\noptimizer = tf.keras.optimizers.Adam()\nmodel.compile(loss='mean_squared_error', optimizer=optimizer)\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=25, verbose=0)\n# Evaluations\naccuracy = model.evaluate(X_test, y_test)\nprint('Average: %.2f' % accuracy)\n\n# Bias variance decompositions\navg_expected_loss, avg_bias, avg_var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='mse', random_seed=23, epochs=5, verbose=0)\n\n# Print the result\nprint('Average expected loss: %.2f' % avg_expected_loss)\nprint('Average bias: %.2f' % avg_bias)\nprint('Average variance: %.2f' % avg_var)\n```\n\n**Output**:\n\n```\n162/162 [==============================] - 0s 802us/step - loss: 0.9195  \nAverage: 0.92  \nAverage expected loss: 2.30  \nAverage bias: 0.72  \nAverage variance: 1.58\n```"}
{"reference": "https://www.geeksforgeeks.org/aptitude/interview-corner/", "content": "# Interview Corner\n\nThis article serves as your **one-stop guide to interview preparation**, designed to help you succeed across different experience levels and company expectations. Here is what you should expect in a Tech Interview, please remember the following points:\n\n- Tech Interview Preparation does not have any fixed syllabus. Different companies, roles, and hiring managers have their own approaches. However, a few patterns have become standard over the years.\n- One thing is, most of the companies take an online round first where they check your problem-solving skills using coding problems. Once you qualify the online coding round, you go to the next face-to-face technical rounds, that includes live coding and domain specific discussions.\n- **For students**, the most important topics are Data Structures and Algorithms (DSA), Object Oriented Programming (OOP), DBMS, OS, SQL, Web Development basics, AI, ML, and Data Science basics. Some companies ask Aptitude, Puzzle, and Design (Low Level and High Level) as well for internship.\n- **For early working professionals**, the process and topics are almost same as freshers, with addition of questions related to previous work experience and technologies they've previously used.\n- For more **experienced working professionals**, the process varies a lot. Some top product-based companies like Google ask DSA for all levels. However, there is going to be a lot more focus on System Design and technologies used in the previous companies.\n\nLet us now explore different interview resources.\n\n## DSA\n\n- [GFG 160](https://www.geeksforgeeks.org/courses/gfg-160-series) - A complete list of top 160 questions + 90 bonus questions with editorials and video explanations.\n- [DSA 360](https://www.geeksforgeeks.org/courses/dsa-skill-up) - Try our ongoing free course with weekly topic coverage with mock contests, short notes, daily problems and quizzes.\n\n## LLD and HLD\n\n- [System Design Tutorial](https://www.geeksforgeeks.org/system-design/system-design-tutorial/)\n- [Design Patterns Interview Questions](https://www.geeksforgeeks.org/system-design/top-design-patterns-interview-questions/)\n- [System Design SkillUp](https://www.geeksforgeeks.org/courses/system-design-skill-up) - Try our ongoing free course with weekly topic coverage with mock contests, short notes, daily problems and quizzes.\n\n## DevOps\n\nHere are top resources to prepare for DevOps interviews, including cloud computing and AWS-specific roles\n\n- [DevOps Interview Questions](https://www.geeksforgeeks.org/devops/devops-interview-questions/)\n- [AWS Interview Questions](https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/)\n- [Google Cloud Platform (GCP) Interview Questions](https://www.geeksforgeeks.org/devops/google-cloud-platform-interview-questions/)\n- [DevOps SkillUp](https://www.geeksforgeeks.org/courses/devops-skill-up) - Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Interview Experiences\n\n- [Interview Experiences for all roles](https://www.geeksforgeeks.org/category/experiences/interview-experiences/)\n\n## Web Development\n\n- [Full Stack Interview Questions](https://www.geeksforgeeks.org/html/full-stack-developer-interview-questions-and-answers/)\n- [MERN Skillup](https://www.geeksforgeeks.org/courses/full-stack-web-dev-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Aptitude & Puzzles\n\n- [Aptitude Questions and Answers](https://www.geeksforgeeks.org/aptitude/aptitude-questions-and-answers/)\n- [Puzzles for Interviews](https://www.geeksforgeeks.org/aptitude/puzzles/)\n- [Aptitude & Reasoning Skillup](https://www.geeksforgeeks.org/courses/aptitude-and-reasoning-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n- [100 Days of Interview Puzzles SkillUp](https://www.geeksforgeeks.org/courses/100-days-of-interview-puzzles-skill-up) - Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Computer Subjects\n\n- [Commonly asked Computer Subject Interview Questions](https://www.geeksforgeeks.org/courses/cs-core-subjects-skill-up)\n- [CS Core SkillUp](https://www.geeksforgeeks.org/courses/cs-core-subjects-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Python\n\n- [Python Interview Questions](https://www.geeksforgeeks.org/python/python-interview-questions/)\n- [Python SkillUp](https://www.geeksforgeeks.org/courses/python-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Data Science and Machine Learning\n\n- [Data Science Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-interview-questions-and-answers/)\n- [Data Science Coding Interview Questions](https://www.geeksforgeeks.org/data-science/data-science-coding-interview-questions/)\n- [Machine Learning Interview Questions](https://www.geeksforgeeks.org/machine-learning/machine-learning-interview-questions/)\n- [Data Science SkillUp](https://www.geeksforgeeks.org/courses/ds-16): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Data Analytics\n\n- [Data Analyst Interview Questions](https://www.geeksforgeeks.org/data-science/data-analyst-interview-questions-and-answers/)\n- [Data Analytics SkillUp](https://www.geeksforgeeks.org/courses/data-analytics-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Software Testing\n\n- [Software Testing Interview Questions](https://www.geeksforgeeks.org/software-testing/software-testing-interview-questions/)\n- [Software Testing SkillUp](https://www.geeksforgeeks.org/courses/software-testing-skill-up): Try our ongoing free course with weekly topic coverage, notes, daily quizzes and coding problems.\n\n## Mobile App Development (Android Development)\n\n- [Application Developer Interview Questions](https://www.geeksforgeeks.org/interview-experiences/application-developer-interview-questions/)\n- [Android Interview Questions for SDE I to SDE III](https://www.geeksforgeeks.org/android/top-50-android-interview-questions-answers-sde-i-to-sde-iii/)"}
